{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from RobotModel import RobotDynamicsModel, TransformerDecoderModel2D, TransformerDecoderModelWithLoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "h = 20  # history length\n",
    "batch_size = 500 # Define batch size for DataLoader\n",
    "train_val_split_ratio = 0.8  # 80% train, 20% validation\n",
    "state_columns = ['x', 'y', 'yaw']\n",
    "# Prepare the data\n",
    "action_columns = ['accel', 'steer']\n",
    "\n",
    "input_size = h * (len(state_columns) + len(action_columns))  # h * (|x| + |a|)\n",
    "\n",
    "# Create sequences with history length h\n",
    "num_of_augmentation = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../RC/Data/Mujoco.csv is 9.090855244795481m\n",
      "Total duration is 9.090855244795481m\n",
      "torch.Size([8124, 100]) torch.Size([8124, 3])\n"
     ]
    }
   ],
   "source": [
    "finetuning_file_paths = [\"../RC/Data/Mujoco.csv\",\n",
    "                        ]\n",
    "\n",
    "finetuning_input_sequences = []\n",
    "finetuning_output_sequences = []\n",
    "finetuning_tot_duration = 0\n",
    "finetuning_num_of_augmentation = num_of_augmentation\n",
    "\n",
    "\n",
    "\n",
    "for file_path in finetuning_file_paths:\n",
    "    path_data = pd.read_csv(file_path)\n",
    "\n",
    "    # Display the first few rows\n",
    "    path_data.head()\n",
    "    times = np.array(path_data[\"timestamp\"])\n",
    "    dataset_duration = times[-1] - times[0]\n",
    "    finetuning_tot_duration += dataset_duration\n",
    "    print(f\"{file_path} is {dataset_duration/60}m\")\n",
    "    states = path_data[state_columns].values\n",
    "    actions = path_data[action_columns].values\n",
    "    # plot_path(states)\n",
    "    # cnt = 0\n",
    "    for _ in range(finetuning_num_of_augmentation):\n",
    "        # plot_path(augmented_states)\n",
    "        for i in range(len(states) - h - 20 * 30):\n",
    "            # Original sequence\n",
    "            # plot_path(states[i:i + h + 1])\n",
    "            if times[i+h] - times[i+h - 1] > 1/18:\n",
    "                # cnt+=1\n",
    "                continue\n",
    "\n",
    "            # transformed_state = apply_relative_transformation(states[i:i + h + 1])\n",
    "            transformed_state = states[i:i + h + 1]\n",
    "            # plot_path(np.array(transformed_state))\n",
    "            # break\n",
    "            # plot_path(np.array(transformed_state))\n",
    "            input_seq = np.concatenate((transformed_state[:h], actions[i:i + h]), axis=1).flatten()\n",
    "            output_seq = transformed_state[h]\n",
    "            finetuning_input_sequences.append(input_seq)\n",
    "            finetuning_output_sequences.append(output_seq)\n",
    "    # print(len(times) -  cnt)\n",
    "print(f\"Total duration is {finetuning_tot_duration/60}m\")\n",
    "\n",
    "\n",
    "# Convert to NumPy arrays and then to PyTorch tensors\n",
    "finetuning_input_sequences = np.array(finetuning_input_sequences)\n",
    "finetuning_output_sequences = np.array(finetuning_output_sequences)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "finetuning_inputs = torch.tensor(finetuning_input_sequences, dtype=torch.float32)\n",
    "finetuning_outputs = torch.tensor(finetuning_output_sequences, dtype=torch.float32)\n",
    "# Check shapes\n",
    "print(finetuning_inputs.shape, finetuning_outputs.shape)  # (samples, h * (|x| + |a|)), (samples, |x|)\n",
    "\n",
    "# Dataset and DataLoader Setup\n",
    "finetuning_dataset = TensorDataset(finetuning_inputs, finetuning_outputs)\n",
    "\n",
    "# Split dataset into train, validation, and test sets (80-10-10 split)\n",
    "finetuning_train_size = int(len(finetuning_dataset) * train_val_split_ratio)\n",
    "finetuning_val_size = (len(finetuning_dataset) - finetuning_train_size) // 2\n",
    "finetuning_test_size = len(finetuning_dataset) - finetuning_train_size - finetuning_val_size\n",
    "\n",
    "finetuning_train_set, finetuning_val_set, finetuning_test_set = random_split(finetuning_dataset, [finetuning_train_size, finetuning_val_size, finetuning_test_size])\n",
    "\n",
    "finetuning_train_loader = DataLoader(finetuning_train_set, batch_size=batch_size, shuffle=True)\n",
    "finetuning_val_loader = DataLoader(finetuning_val_set, batch_size=batch_size, shuffle=False)\n",
    "finetuning_test_loader = DataLoader(finetuning_test_set, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of LoRA parameters: 4\n"
     ]
    }
   ],
   "source": [
    "pretrained_model_path = 'Mujoco_model_v2.pth'\n",
    "pretrained_state_dict = torch.load(pretrained_model_path)\n",
    "\n",
    "\n",
    "finetuning_model = TransformerDecoderModelWithLoRA(input_size, len(state_columns), lora_r=4, lora_alpha=8)\n",
    "finetuning_model\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "finetuning_model.to(device)\n",
    "\n",
    "finetuning_model.load_state_dict(pretrained_state_dict, strict=False)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "# optimizer = torch.optim.Adam(finetuning_model.parameters(), lr=1e-4)\n",
    "\n",
    "# LoRA 파라미터만 업데이트하도록 설정\n",
    "lora_parameters = [p for n, p in finetuning_model.named_parameters() if 'lora' in n]\n",
    "if len(lora_parameters) == 0:\n",
    "    print(\"No LoRA parameters found!\")\n",
    "else:\n",
    "    print(f\"Number of LoRA parameters: {len(lora_parameters)}\")\n",
    "\n",
    "optimizer = torch.optim.Adam(lora_parameters, lr=1e-4)\n",
    "\n",
    "\n",
    "def finetuning_evaluate(loader):\n",
    "    finetuning_model.eval()  # Set model to evaluation mode\n",
    "    total_loss, total_samples = 0, 0\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient calculation for evaluation\n",
    "        for inputs, targets in loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            predictions = finetuning_model(inputs)\n",
    "            loss = criterion(predictions, targets)\n",
    "            total_loss += loss.item() * len(targets)\n",
    "            total_samples += len(targets)\n",
    "\n",
    "    return total_loss / total_samples  # Return average loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training w cuda\n",
      "Epoch [1/1000], Loss: 28.5462\n",
      "Saved Best Model at Epoch 2 with Validation Loss: 26.1574\n",
      "Epoch [2/1000], Loss: 29.2006\n",
      "Epoch [3/1000], Loss: 26.2309\n",
      "Epoch [4/1000], Loss: 28.5866\n",
      "Epoch [5/1000], Loss: 28.4548\n",
      "Epoch [6/1000], Loss: 24.8715\n",
      "Epoch [7/1000], Loss: 25.2564\n",
      "Epoch [8/1000], Loss: 28.4265\n",
      "Epoch [9/1000], Loss: 19.7819\n",
      "Epoch [10/1000], Loss: 25.8239\n",
      "Epoch [11/1000], Loss: 23.7147\n",
      "Epoch [12/1000], Loss: 23.5614\n",
      "Saved Best Model at Epoch 13 with Validation Loss: 21.3214\n",
      "Epoch [13/1000], Loss: 18.2896\n",
      "Epoch [14/1000], Loss: 27.2031\n",
      "Epoch [15/1000], Loss: 20.0655\n",
      "Epoch [16/1000], Loss: 19.6405\n",
      "Epoch [17/1000], Loss: 19.5194\n",
      "Epoch [18/1000], Loss: 18.5065\n",
      "Epoch [19/1000], Loss: 20.4270\n",
      "Epoch [20/1000], Loss: 15.8477\n",
      "Epoch [21/1000], Loss: 16.2431\n",
      "Epoch [22/1000], Loss: 16.0218\n",
      "Epoch [23/1000], Loss: 16.2304\n",
      "Saved Best Model at Epoch 24 with Validation Loss: 13.8087\n",
      "Epoch [24/1000], Loss: 13.6638\n",
      "Epoch [25/1000], Loss: 14.8123\n",
      "Epoch [26/1000], Loss: 11.7971\n",
      "Epoch [27/1000], Loss: 14.5381\n",
      "Epoch [28/1000], Loss: 12.1967\n",
      "Epoch [29/1000], Loss: 12.8932\n",
      "Epoch [30/1000], Loss: 12.5898\n",
      "Epoch [31/1000], Loss: 12.0217\n",
      "Epoch [32/1000], Loss: 12.5540\n",
      "Epoch [33/1000], Loss: 11.5925\n",
      "Epoch [34/1000], Loss: 9.4117\n",
      "Saved Best Model at Epoch 35 with Validation Loss: 9.7799\n",
      "Epoch [35/1000], Loss: 12.0246\n",
      "Epoch [36/1000], Loss: 8.3652\n",
      "Epoch [37/1000], Loss: 11.9927\n",
      "Epoch [38/1000], Loss: 10.1685\n",
      "Epoch [39/1000], Loss: 7.3900\n",
      "Epoch [40/1000], Loss: 8.7384\n",
      "Epoch [41/1000], Loss: 10.3542\n",
      "Epoch [42/1000], Loss: 8.7540\n",
      "Epoch [43/1000], Loss: 9.0214\n",
      "Epoch [44/1000], Loss: 11.1020\n",
      "Epoch [45/1000], Loss: 8.7929\n",
      "Saved Best Model at Epoch 46 with Validation Loss: 7.9034\n",
      "Epoch [46/1000], Loss: 8.1533\n",
      "Epoch [47/1000], Loss: 9.1416\n",
      "Epoch [48/1000], Loss: 7.4446\n",
      "Epoch [49/1000], Loss: 8.8499\n",
      "Epoch [50/1000], Loss: 7.8949\n",
      "Epoch [51/1000], Loss: 8.4341\n",
      "Epoch [52/1000], Loss: 6.9296\n",
      "Epoch [53/1000], Loss: 8.8277\n",
      "Epoch [54/1000], Loss: 7.4446\n",
      "Epoch [55/1000], Loss: 7.8535\n",
      "Epoch [56/1000], Loss: 8.1931\n",
      "Saved Best Model at Epoch 57 with Validation Loss: 6.8029\n",
      "Epoch [57/1000], Loss: 7.9294\n",
      "Epoch [58/1000], Loss: 6.8451\n",
      "Epoch [59/1000], Loss: 7.2732\n",
      "Epoch [60/1000], Loss: 6.1586\n",
      "Epoch [61/1000], Loss: 6.9718\n",
      "Epoch [62/1000], Loss: 5.9051\n",
      "Epoch [63/1000], Loss: 7.0849\n",
      "Epoch [64/1000], Loss: 7.1363\n",
      "Epoch [65/1000], Loss: 6.9072\n",
      "Epoch [66/1000], Loss: 9.1031\n",
      "Epoch [67/1000], Loss: 6.2809\n",
      "Saved Best Model at Epoch 68 with Validation Loss: 5.8853\n",
      "Epoch [68/1000], Loss: 6.6026\n",
      "Epoch [69/1000], Loss: 5.8448\n",
      "Epoch [70/1000], Loss: 4.9742\n",
      "Epoch [71/1000], Loss: 6.3028\n",
      "Epoch [72/1000], Loss: 6.7236\n",
      "Epoch [73/1000], Loss: 5.5676\n",
      "Epoch [74/1000], Loss: 6.8612\n",
      "Epoch [75/1000], Loss: 6.7988\n",
      "Epoch [76/1000], Loss: 4.9178\n",
      "Epoch [77/1000], Loss: 5.6655\n",
      "Epoch [78/1000], Loss: 5.0520\n",
      "Saved Best Model at Epoch 79 with Validation Loss: 5.0372\n",
      "Epoch [79/1000], Loss: 6.4376\n",
      "Epoch [80/1000], Loss: 4.7538\n",
      "Epoch [81/1000], Loss: 5.7999\n",
      "Epoch [82/1000], Loss: 5.0992\n",
      "Epoch [83/1000], Loss: 5.5248\n",
      "Epoch [84/1000], Loss: 4.3629\n",
      "Epoch [85/1000], Loss: 4.8365\n",
      "Epoch [86/1000], Loss: 5.2189\n",
      "Epoch [87/1000], Loss: 4.1904\n",
      "Epoch [88/1000], Loss: 4.4623\n",
      "Epoch [89/1000], Loss: 4.6076\n",
      "Saved Best Model at Epoch 90 with Validation Loss: 4.2951\n",
      "Epoch [90/1000], Loss: 4.6187\n",
      "Epoch [91/1000], Loss: 4.7290\n",
      "Epoch [92/1000], Loss: 4.7319\n",
      "Epoch [93/1000], Loss: 4.1069\n",
      "Epoch [94/1000], Loss: 4.4280\n",
      "Epoch [95/1000], Loss: 3.3226\n",
      "Epoch [96/1000], Loss: 4.3524\n",
      "Epoch [97/1000], Loss: 4.9331\n",
      "Epoch [98/1000], Loss: 4.6031\n",
      "Epoch [99/1000], Loss: 3.8567\n",
      "Epoch [100/1000], Loss: 4.1656\n",
      "Saved Best Model at Epoch 101 with Validation Loss: 3.7516\n",
      "Epoch [101/1000], Loss: 3.9080\n",
      "Epoch [102/1000], Loss: 3.8105\n",
      "Epoch [103/1000], Loss: 3.5503\n",
      "Epoch [104/1000], Loss: 3.8803\n",
      "Epoch [105/1000], Loss: 4.7713\n",
      "Epoch [106/1000], Loss: 4.3248\n",
      "Epoch [107/1000], Loss: 3.3478\n",
      "Epoch [108/1000], Loss: 3.4273\n",
      "Epoch [109/1000], Loss: 3.2638\n",
      "Epoch [110/1000], Loss: 3.8334\n",
      "Epoch [111/1000], Loss: 4.1037\n",
      "Saved Best Model at Epoch 112 with Validation Loss: 3.3174\n",
      "Epoch [112/1000], Loss: 4.0195\n",
      "Epoch [113/1000], Loss: 4.3413\n",
      "Epoch [114/1000], Loss: 3.5198\n",
      "Epoch [115/1000], Loss: 3.8579\n",
      "Epoch [116/1000], Loss: 3.5471\n",
      "Epoch [117/1000], Loss: 4.0204\n",
      "Epoch [118/1000], Loss: 3.3795\n",
      "Epoch [119/1000], Loss: 3.9409\n",
      "Epoch [120/1000], Loss: 3.5883\n",
      "Epoch [121/1000], Loss: 3.7535\n",
      "Epoch [122/1000], Loss: 2.9735\n",
      "Saved Best Model at Epoch 123 with Validation Loss: 3.0042\n",
      "Epoch [123/1000], Loss: 3.6328\n",
      "Epoch [124/1000], Loss: 3.4783\n",
      "Epoch [125/1000], Loss: 3.6991\n",
      "Epoch [126/1000], Loss: 3.6286\n",
      "Epoch [127/1000], Loss: 3.5334\n",
      "Epoch [128/1000], Loss: 3.2566\n",
      "Epoch [129/1000], Loss: 3.1581\n",
      "Epoch [130/1000], Loss: 3.3467\n",
      "Epoch [131/1000], Loss: 3.0084\n",
      "Epoch [132/1000], Loss: 3.4491\n",
      "Epoch [133/1000], Loss: 3.3532\n",
      "Saved Best Model at Epoch 134 with Validation Loss: 2.7446\n",
      "Epoch [134/1000], Loss: 2.9572\n",
      "Epoch [135/1000], Loss: 2.9930\n",
      "Epoch [136/1000], Loss: 2.8494\n",
      "Epoch [137/1000], Loss: 3.1053\n",
      "Epoch [138/1000], Loss: 3.0276\n",
      "Epoch [139/1000], Loss: 3.2489\n",
      "Epoch [140/1000], Loss: 2.9754\n",
      "Epoch [141/1000], Loss: 2.9681\n",
      "Epoch [142/1000], Loss: 2.7497\n",
      "Epoch [143/1000], Loss: 2.9240\n",
      "Epoch [144/1000], Loss: 3.0243\n",
      "Saved Best Model at Epoch 145 with Validation Loss: 2.5614\n",
      "Epoch [145/1000], Loss: 2.9413\n",
      "Epoch [146/1000], Loss: 3.0797\n",
      "Epoch [147/1000], Loss: 2.9945\n",
      "Epoch [148/1000], Loss: 3.2885\n",
      "Epoch [149/1000], Loss: 3.0522\n",
      "Epoch [150/1000], Loss: 2.3028\n",
      "Epoch [151/1000], Loss: 3.0785\n",
      "Epoch [152/1000], Loss: 3.1637\n",
      "Epoch [153/1000], Loss: 2.9876\n",
      "Epoch [154/1000], Loss: 2.6579\n",
      "Epoch [155/1000], Loss: 2.9221\n",
      "Saved Best Model at Epoch 156 with Validation Loss: 2.3958\n",
      "Epoch [156/1000], Loss: 2.6021\n",
      "Epoch [157/1000], Loss: 2.4197\n",
      "Epoch [158/1000], Loss: 3.0382\n",
      "Epoch [159/1000], Loss: 2.6045\n",
      "Epoch [160/1000], Loss: 2.6496\n",
      "Epoch [161/1000], Loss: 2.5705\n",
      "Epoch [162/1000], Loss: 2.6572\n",
      "Epoch [163/1000], Loss: 3.0621\n",
      "Epoch [164/1000], Loss: 2.7709\n",
      "Epoch [165/1000], Loss: 2.6234\n",
      "Epoch [166/1000], Loss: 2.5085\n",
      "Saved Best Model at Epoch 167 with Validation Loss: 2.2757\n",
      "Epoch [167/1000], Loss: 2.4646\n",
      "Epoch [168/1000], Loss: 2.4637\n",
      "Epoch [169/1000], Loss: 2.5645\n",
      "Epoch [170/1000], Loss: 2.8787\n",
      "Epoch [171/1000], Loss: 2.6019\n",
      "Epoch [172/1000], Loss: 2.9172\n",
      "Epoch [173/1000], Loss: 2.5800\n",
      "Epoch [174/1000], Loss: 2.3506\n",
      "Epoch [175/1000], Loss: 2.3559\n",
      "Epoch [176/1000], Loss: 2.6848\n",
      "Epoch [177/1000], Loss: 2.2897\n",
      "Saved Best Model at Epoch 178 with Validation Loss: 2.1636\n",
      "Epoch [178/1000], Loss: 2.6037\n",
      "Epoch [179/1000], Loss: 2.5510\n",
      "Epoch [180/1000], Loss: 2.4173\n",
      "Epoch [181/1000], Loss: 2.5714\n",
      "Epoch [182/1000], Loss: 2.4209\n",
      "Epoch [183/1000], Loss: 2.4532\n",
      "Epoch [184/1000], Loss: 2.4628\n",
      "Epoch [185/1000], Loss: 2.7026\n",
      "Epoch [186/1000], Loss: 2.2901\n",
      "Epoch [187/1000], Loss: 2.1898\n",
      "Epoch [188/1000], Loss: 2.4252\n",
      "Saved Best Model at Epoch 189 with Validation Loss: 2.0862\n",
      "Epoch [189/1000], Loss: 2.2519\n",
      "Epoch [190/1000], Loss: 2.3254\n",
      "Epoch [191/1000], Loss: 2.2821\n",
      "Epoch [192/1000], Loss: 2.2471\n",
      "Epoch [193/1000], Loss: 2.4082\n",
      "Epoch [194/1000], Loss: 2.1720\n",
      "Epoch [195/1000], Loss: 2.3202\n",
      "Epoch [196/1000], Loss: 2.2500\n",
      "Epoch [197/1000], Loss: 2.3159\n",
      "Epoch [198/1000], Loss: 2.4268\n",
      "Epoch [199/1000], Loss: 2.2432\n",
      "Saved Best Model at Epoch 200 with Validation Loss: 2.0242\n",
      "Epoch [200/1000], Loss: 2.2323\n",
      "Epoch [201/1000], Loss: 2.3236\n",
      "Epoch [202/1000], Loss: 2.4258\n",
      "Epoch [203/1000], Loss: 2.4652\n",
      "Epoch [204/1000], Loss: 2.6817\n",
      "Epoch [205/1000], Loss: 2.3728\n",
      "Epoch [206/1000], Loss: 2.3536\n",
      "Epoch [207/1000], Loss: 2.1028\n",
      "Epoch [208/1000], Loss: 2.2868\n",
      "Epoch [209/1000], Loss: 2.2548\n",
      "Epoch [210/1000], Loss: 1.8280\n",
      "Saved Best Model at Epoch 211 with Validation Loss: 1.9512\n",
      "Epoch [211/1000], Loss: 2.2681\n",
      "Epoch [212/1000], Loss: 2.4400\n",
      "Epoch [213/1000], Loss: 2.2351\n",
      "Epoch [214/1000], Loss: 2.2745\n",
      "Epoch [215/1000], Loss: 1.9413\n",
      "Epoch [216/1000], Loss: 2.4227\n",
      "Epoch [217/1000], Loss: 1.7479\n",
      "Epoch [218/1000], Loss: 2.3072\n",
      "Epoch [219/1000], Loss: 2.1006\n",
      "Epoch [220/1000], Loss: 2.0626\n",
      "Epoch [221/1000], Loss: 2.3335\n",
      "Saved Best Model at Epoch 222 with Validation Loss: 1.9031\n",
      "Epoch [222/1000], Loss: 2.3505\n",
      "Epoch [223/1000], Loss: 2.3491\n",
      "Epoch [224/1000], Loss: 2.1333\n",
      "Epoch [225/1000], Loss: 2.3559\n",
      "Epoch [226/1000], Loss: 2.0770\n",
      "Epoch [227/1000], Loss: 2.2629\n",
      "Epoch [228/1000], Loss: 2.1808\n",
      "Epoch [229/1000], Loss: 2.2245\n",
      "Epoch [230/1000], Loss: 1.9995\n",
      "Epoch [231/1000], Loss: 1.9988\n",
      "Epoch [232/1000], Loss: 2.1154\n",
      "Saved Best Model at Epoch 233 with Validation Loss: 1.8622\n",
      "Epoch [233/1000], Loss: 2.2455\n",
      "Epoch [234/1000], Loss: 2.3021\n",
      "Epoch [235/1000], Loss: 2.0331\n",
      "Epoch [236/1000], Loss: 1.9442\n",
      "Epoch [237/1000], Loss: 1.8547\n",
      "Epoch [238/1000], Loss: 2.2016\n",
      "Epoch [239/1000], Loss: 1.9950\n",
      "Epoch [240/1000], Loss: 2.3277\n",
      "Epoch [241/1000], Loss: 1.9976\n",
      "Epoch [242/1000], Loss: 2.0664\n",
      "Epoch [243/1000], Loss: 2.2187\n",
      "Saved Best Model at Epoch 244 with Validation Loss: 1.8251\n",
      "Epoch [244/1000], Loss: 2.0185\n",
      "Epoch [245/1000], Loss: 1.9876\n",
      "Epoch [246/1000], Loss: 2.0604\n",
      "Epoch [247/1000], Loss: 2.2710\n",
      "Epoch [248/1000], Loss: 1.8830\n",
      "Epoch [249/1000], Loss: 2.0097\n",
      "Epoch [250/1000], Loss: 2.0184\n",
      "Epoch [251/1000], Loss: 2.1179\n",
      "Epoch [252/1000], Loss: 1.9217\n",
      "Epoch [253/1000], Loss: 2.2040\n",
      "Epoch [254/1000], Loss: 2.1344\n",
      "Saved Best Model at Epoch 255 with Validation Loss: 1.7766\n",
      "Epoch [255/1000], Loss: 2.1654\n",
      "Epoch [256/1000], Loss: 1.9980\n",
      "Epoch [257/1000], Loss: 2.0155\n",
      "Epoch [258/1000], Loss: 1.9915\n",
      "Epoch [259/1000], Loss: 2.1645\n",
      "Epoch [260/1000], Loss: 2.1974\n",
      "Epoch [261/1000], Loss: 2.0636\n",
      "Epoch [262/1000], Loss: 2.0238\n",
      "Epoch [263/1000], Loss: 2.0636\n",
      "Epoch [264/1000], Loss: 2.0296\n",
      "Epoch [265/1000], Loss: 2.0255\n",
      "Saved Best Model at Epoch 266 with Validation Loss: 1.7379\n",
      "Epoch [266/1000], Loss: 2.2748\n",
      "Epoch [267/1000], Loss: 1.8420\n",
      "Epoch [268/1000], Loss: 2.3825\n",
      "Epoch [269/1000], Loss: 2.1144\n",
      "Epoch [270/1000], Loss: 1.8793\n",
      "Epoch [271/1000], Loss: 1.9475\n",
      "Epoch [272/1000], Loss: 1.8970\n",
      "Epoch [273/1000], Loss: 2.0010\n",
      "Epoch [274/1000], Loss: 1.8134\n",
      "Epoch [275/1000], Loss: 1.8721\n",
      "Epoch [276/1000], Loss: 1.9657\n",
      "Saved Best Model at Epoch 277 with Validation Loss: 1.7175\n",
      "Epoch [277/1000], Loss: 1.9080\n",
      "Epoch [278/1000], Loss: 1.9895\n",
      "Epoch [279/1000], Loss: 2.0359\n",
      "Epoch [280/1000], Loss: 2.1303\n",
      "Epoch [281/1000], Loss: 1.8619\n",
      "Epoch [282/1000], Loss: 2.1855\n",
      "Epoch [283/1000], Loss: 2.0282\n",
      "Epoch [284/1000], Loss: 2.0770\n",
      "Epoch [285/1000], Loss: 1.8918\n",
      "Epoch [286/1000], Loss: 2.0484\n",
      "Epoch [287/1000], Loss: 2.0456\n",
      "Saved Best Model at Epoch 288 with Validation Loss: 1.6772\n",
      "Epoch [288/1000], Loss: 1.9420\n",
      "Epoch [289/1000], Loss: 1.9310\n",
      "Epoch [290/1000], Loss: 1.9768\n",
      "Epoch [291/1000], Loss: 2.1028\n",
      "Epoch [292/1000], Loss: 2.0120\n",
      "Epoch [293/1000], Loss: 2.1428\n",
      "Epoch [294/1000], Loss: 2.0415\n",
      "Epoch [295/1000], Loss: 1.8472\n",
      "Epoch [296/1000], Loss: 1.8058\n",
      "Epoch [297/1000], Loss: 1.8615\n",
      "Epoch [298/1000], Loss: 1.8530\n",
      "Saved Best Model at Epoch 299 with Validation Loss: 1.6528\n",
      "Epoch [299/1000], Loss: 1.9655\n",
      "Epoch [300/1000], Loss: 1.9757\n",
      "Epoch [301/1000], Loss: 1.8360\n",
      "Epoch [302/1000], Loss: 2.0416\n",
      "Epoch [303/1000], Loss: 1.8882\n",
      "Epoch [304/1000], Loss: 1.8463\n",
      "Epoch [305/1000], Loss: 1.6233\n",
      "Epoch [306/1000], Loss: 1.7812\n",
      "Epoch [307/1000], Loss: 1.9530\n",
      "Epoch [308/1000], Loss: 1.7196\n",
      "Epoch [309/1000], Loss: 1.8361\n",
      "Saved Best Model at Epoch 310 with Validation Loss: 1.6363\n",
      "Epoch [310/1000], Loss: 1.5877\n",
      "Epoch [311/1000], Loss: 1.8695\n",
      "Epoch [312/1000], Loss: 1.8537\n",
      "Epoch [313/1000], Loss: 1.9321\n",
      "Epoch [314/1000], Loss: 1.8400\n",
      "Epoch [315/1000], Loss: 1.7364\n",
      "Epoch [316/1000], Loss: 1.8971\n",
      "Epoch [317/1000], Loss: 1.7978\n",
      "Epoch [318/1000], Loss: 1.8642\n",
      "Epoch [319/1000], Loss: 2.0127\n",
      "Epoch [320/1000], Loss: 2.1041\n",
      "Saved Best Model at Epoch 321 with Validation Loss: 1.5931\n",
      "Epoch [321/1000], Loss: 1.8554\n",
      "Epoch [322/1000], Loss: 1.8966\n",
      "Epoch [323/1000], Loss: 1.7070\n",
      "Epoch [324/1000], Loss: 1.6117\n",
      "Epoch [325/1000], Loss: 1.8409\n",
      "Epoch [326/1000], Loss: 1.7597\n",
      "Epoch [327/1000], Loss: 1.8120\n",
      "Epoch [328/1000], Loss: 1.8351\n",
      "Epoch [329/1000], Loss: 1.9882\n",
      "Epoch [330/1000], Loss: 1.7913\n",
      "Epoch [331/1000], Loss: 1.9539\n",
      "Saved Best Model at Epoch 332 with Validation Loss: 1.5550\n",
      "Epoch [332/1000], Loss: 1.7439\n",
      "Epoch [333/1000], Loss: 1.8023\n",
      "Epoch [334/1000], Loss: 1.9984\n",
      "Epoch [335/1000], Loss: 1.6756\n",
      "Epoch [336/1000], Loss: 1.7559\n",
      "Epoch [337/1000], Loss: 1.8315\n",
      "Epoch [338/1000], Loss: 1.8951\n",
      "Epoch [339/1000], Loss: 2.0226\n",
      "Epoch [340/1000], Loss: 1.8074\n",
      "Epoch [341/1000], Loss: 1.6428\n",
      "Epoch [342/1000], Loss: 1.9879\n",
      "Saved Best Model at Epoch 343 with Validation Loss: 1.5395\n",
      "Epoch [343/1000], Loss: 2.0360\n",
      "Epoch [344/1000], Loss: 1.9682\n",
      "Epoch [345/1000], Loss: 1.7007\n",
      "Epoch [346/1000], Loss: 1.7990\n",
      "Epoch [347/1000], Loss: 1.8367\n",
      "Epoch [348/1000], Loss: 1.8055\n",
      "Epoch [349/1000], Loss: 1.8201\n",
      "Epoch [350/1000], Loss: 1.7941\n",
      "Epoch [351/1000], Loss: 1.7244\n",
      "Epoch [352/1000], Loss: 1.6252\n",
      "Epoch [353/1000], Loss: 1.6618\n",
      "Saved Best Model at Epoch 354 with Validation Loss: 1.5048\n",
      "Epoch [354/1000], Loss: 1.7890\n",
      "Epoch [355/1000], Loss: 1.5654\n",
      "Epoch [356/1000], Loss: 1.9322\n",
      "Epoch [357/1000], Loss: 1.8220\n",
      "Epoch [358/1000], Loss: 1.8659\n",
      "Epoch [359/1000], Loss: 1.9594\n",
      "Epoch [360/1000], Loss: 1.8981\n",
      "Epoch [361/1000], Loss: 1.8937\n",
      "Epoch [362/1000], Loss: 1.8122\n",
      "Epoch [363/1000], Loss: 1.7643\n",
      "Epoch [364/1000], Loss: 1.8007\n",
      "Saved Best Model at Epoch 365 with Validation Loss: 1.4796\n",
      "Epoch [365/1000], Loss: 1.7339\n",
      "Epoch [366/1000], Loss: 1.6237\n",
      "Epoch [367/1000], Loss: 1.7474\n",
      "Epoch [368/1000], Loss: 1.8665\n",
      "Epoch [369/1000], Loss: 2.0154\n",
      "Epoch [370/1000], Loss: 1.7870\n",
      "Epoch [371/1000], Loss: 1.5856\n",
      "Epoch [372/1000], Loss: 1.5880\n",
      "Epoch [373/1000], Loss: 1.6939\n",
      "Epoch [374/1000], Loss: 1.7034\n",
      "Epoch [375/1000], Loss: 1.7331\n",
      "Saved Best Model at Epoch 376 with Validation Loss: 1.4478\n",
      "Epoch [376/1000], Loss: 1.8125\n",
      "Epoch [377/1000], Loss: 1.7735\n",
      "Epoch [378/1000], Loss: 1.8701\n",
      "Epoch [379/1000], Loss: 1.9104\n",
      "Epoch [380/1000], Loss: 1.5810\n",
      "Epoch [381/1000], Loss: 1.7205\n",
      "Epoch [382/1000], Loss: 1.5086\n",
      "Epoch [383/1000], Loss: 1.5332\n",
      "Epoch [384/1000], Loss: 1.8877\n",
      "Epoch [385/1000], Loss: 1.5904\n",
      "Epoch [386/1000], Loss: 1.7926\n",
      "Saved Best Model at Epoch 387 with Validation Loss: 1.4333\n",
      "Epoch [387/1000], Loss: 1.6248\n",
      "Epoch [388/1000], Loss: 1.9011\n",
      "Epoch [389/1000], Loss: 1.7105\n",
      "Epoch [390/1000], Loss: 1.9024\n",
      "Epoch [391/1000], Loss: 1.6114\n",
      "Epoch [392/1000], Loss: 1.6732\n",
      "Epoch [393/1000], Loss: 1.6743\n",
      "Epoch [394/1000], Loss: 1.5834\n",
      "Epoch [395/1000], Loss: 1.7665\n",
      "Epoch [396/1000], Loss: 1.5186\n",
      "Epoch [397/1000], Loss: 1.7460\n",
      "Saved Best Model at Epoch 398 with Validation Loss: 1.4186\n",
      "Epoch [398/1000], Loss: 1.6704\n",
      "Epoch [399/1000], Loss: 1.5884\n",
      "Epoch [400/1000], Loss: 1.5985\n",
      "Epoch [401/1000], Loss: 1.6773\n",
      "Epoch [402/1000], Loss: 1.7485\n",
      "Epoch [403/1000], Loss: 1.7219\n",
      "Epoch [404/1000], Loss: 1.5629\n",
      "Epoch [405/1000], Loss: 1.4487\n",
      "Epoch [406/1000], Loss: 1.6274\n",
      "Epoch [407/1000], Loss: 1.8846\n",
      "Epoch [408/1000], Loss: 1.7255\n",
      "Saved Best Model at Epoch 409 with Validation Loss: 1.3903\n",
      "Epoch [409/1000], Loss: 1.5909\n",
      "Epoch [410/1000], Loss: 1.6933\n",
      "Epoch [411/1000], Loss: 1.7420\n",
      "Epoch [412/1000], Loss: 1.7174\n",
      "Epoch [413/1000], Loss: 1.7243\n",
      "Epoch [414/1000], Loss: 1.6211\n",
      "Epoch [415/1000], Loss: 1.4965\n",
      "Epoch [416/1000], Loss: 1.5619\n",
      "Epoch [417/1000], Loss: 1.4865\n",
      "Epoch [418/1000], Loss: 1.6853\n",
      "Epoch [419/1000], Loss: 1.6370\n",
      "Saved Best Model at Epoch 420 with Validation Loss: 1.3737\n",
      "Epoch [420/1000], Loss: 1.5747\n",
      "Epoch [421/1000], Loss: 1.8479\n",
      "Epoch [422/1000], Loss: 1.7249\n",
      "Epoch [423/1000], Loss: 1.7728\n",
      "Epoch [424/1000], Loss: 1.5725\n",
      "Epoch [425/1000], Loss: 1.6640\n",
      "Epoch [426/1000], Loss: 1.4684\n",
      "Epoch [427/1000], Loss: 1.6203\n",
      "Epoch [428/1000], Loss: 1.5807\n",
      "Epoch [429/1000], Loss: 1.6719\n",
      "Epoch [430/1000], Loss: 1.5412\n",
      "Saved Best Model at Epoch 431 with Validation Loss: 1.3564\n",
      "Epoch [431/1000], Loss: 1.6541\n",
      "Epoch [432/1000], Loss: 1.6351\n",
      "Epoch [433/1000], Loss: 1.5159\n",
      "Epoch [434/1000], Loss: 1.7097\n",
      "Epoch [435/1000], Loss: 1.4690\n",
      "Epoch [436/1000], Loss: 1.6263\n",
      "Epoch [437/1000], Loss: 1.6753\n",
      "Epoch [438/1000], Loss: 1.8358\n",
      "Epoch [439/1000], Loss: 1.7321\n",
      "Epoch [440/1000], Loss: 1.7162\n",
      "Epoch [441/1000], Loss: 1.6160\n",
      "Epoch [442/1000], Loss: 1.7120\n",
      "Saved Best Model at Epoch 443 with Validation Loss: 1.3431\n",
      "Epoch [443/1000], Loss: 1.6442\n",
      "Epoch [444/1000], Loss: 1.8442\n",
      "Epoch [445/1000], Loss: 1.6306\n",
      "Epoch [446/1000], Loss: 1.4556\n",
      "Epoch [447/1000], Loss: 1.5097\n",
      "Epoch [448/1000], Loss: 1.6838\n",
      "Epoch [449/1000], Loss: 1.7413\n",
      "Epoch [450/1000], Loss: 1.4608\n",
      "Epoch [451/1000], Loss: 1.6043\n",
      "Epoch [452/1000], Loss: 1.6738\n",
      "Epoch [453/1000], Loss: 1.3879\n",
      "Epoch [454/1000], Loss: 1.4186\n",
      "Saved Best Model at Epoch 455 with Validation Loss: 1.3189\n",
      "Epoch [455/1000], Loss: 1.6970\n",
      "Epoch [456/1000], Loss: 1.7730\n",
      "Epoch [457/1000], Loss: 1.4772\n",
      "Epoch [458/1000], Loss: 1.6154\n",
      "Epoch [459/1000], Loss: 1.4281\n",
      "Epoch [460/1000], Loss: 1.5966\n",
      "Epoch [461/1000], Loss: 1.7140\n",
      "Epoch [462/1000], Loss: 1.7254\n",
      "Epoch [463/1000], Loss: 1.5789\n",
      "Epoch [464/1000], Loss: 1.5832\n",
      "Epoch [465/1000], Loss: 1.5053\n",
      "Saved Best Model at Epoch 466 with Validation Loss: 1.3048\n",
      "Epoch [466/1000], Loss: 1.6245\n",
      "Epoch [467/1000], Loss: 1.5475\n",
      "Epoch [468/1000], Loss: 1.4626\n",
      "Epoch [469/1000], Loss: 1.3437\n",
      "Epoch [470/1000], Loss: 1.5684\n",
      "Epoch [471/1000], Loss: 1.6458\n",
      "Epoch [472/1000], Loss: 1.6231\n",
      "Epoch [473/1000], Loss: 1.6350\n",
      "Epoch [474/1000], Loss: 1.6179\n",
      "Epoch [475/1000], Loss: 1.4591\n",
      "Epoch [476/1000], Loss: 1.6530\n",
      "Saved Best Model at Epoch 477 with Validation Loss: 1.2989\n",
      "Epoch [477/1000], Loss: 1.6268\n",
      "Epoch [478/1000], Loss: 1.6541\n",
      "Epoch [479/1000], Loss: 1.5181\n",
      "Epoch [480/1000], Loss: 1.7627\n",
      "Epoch [481/1000], Loss: 1.5856\n",
      "Epoch [482/1000], Loss: 1.5675\n",
      "Epoch [483/1000], Loss: 1.5265\n",
      "Epoch [484/1000], Loss: 1.4561\n",
      "Epoch [485/1000], Loss: 1.5940\n",
      "Epoch [486/1000], Loss: 1.6574\n",
      "Epoch [487/1000], Loss: 1.5469\n",
      "Saved Best Model at Epoch 488 with Validation Loss: 1.2867\n",
      "Epoch [488/1000], Loss: 1.5720\n",
      "Epoch [489/1000], Loss: 1.4167\n",
      "Epoch [490/1000], Loss: 1.9064\n",
      "Epoch [491/1000], Loss: 1.5509\n",
      "Epoch [492/1000], Loss: 1.5948\n",
      "Epoch [493/1000], Loss: 1.5278\n",
      "Epoch [494/1000], Loss: 1.5230\n",
      "Epoch [495/1000], Loss: 1.6448\n",
      "Epoch [496/1000], Loss: 1.5031\n",
      "Epoch [497/1000], Loss: 1.4841\n",
      "Epoch [498/1000], Loss: 1.4885\n",
      "Saved Best Model at Epoch 499 with Validation Loss: 1.2795\n",
      "Epoch [499/1000], Loss: 1.5034\n",
      "Epoch [500/1000], Loss: 1.6398\n",
      "Epoch [501/1000], Loss: 1.4776\n",
      "Epoch [502/1000], Loss: 1.4130\n",
      "Epoch [503/1000], Loss: 1.6308\n",
      "Epoch [504/1000], Loss: 1.7410\n",
      "Epoch [505/1000], Loss: 1.7512\n",
      "Epoch [506/1000], Loss: 1.5065\n",
      "Epoch [507/1000], Loss: 1.5662\n",
      "Epoch [508/1000], Loss: 1.6001\n",
      "Epoch [509/1000], Loss: 1.5645\n",
      "Epoch [510/1000], Loss: 1.5793\n",
      "Saved Best Model at Epoch 511 with Validation Loss: 1.2566\n",
      "Epoch [511/1000], Loss: 1.4103\n",
      "Epoch [512/1000], Loss: 1.4268\n",
      "Epoch [513/1000], Loss: 1.3791\n",
      "Epoch [514/1000], Loss: 1.5708\n",
      "Epoch [515/1000], Loss: 1.5143\n",
      "Epoch [516/1000], Loss: 1.7105\n",
      "Epoch [517/1000], Loss: 1.5208\n",
      "Epoch [518/1000], Loss: 1.3915\n",
      "Epoch [519/1000], Loss: 1.5301\n",
      "Epoch [520/1000], Loss: 1.4865\n",
      "Epoch [521/1000], Loss: 1.5868\n",
      "Epoch [522/1000], Loss: 1.6541\n",
      "Saved Best Model at Epoch 523 with Validation Loss: 1.2544\n",
      "Epoch [523/1000], Loss: 1.5138\n",
      "Epoch [524/1000], Loss: 1.2877\n",
      "Epoch [525/1000], Loss: 1.5147\n",
      "Epoch [526/1000], Loss: 1.5704\n",
      "Epoch [527/1000], Loss: 1.5117\n",
      "Epoch [528/1000], Loss: 1.6119\n",
      "Epoch [529/1000], Loss: 1.5172\n",
      "Epoch [530/1000], Loss: 1.5775\n",
      "Epoch [531/1000], Loss: 1.5482\n",
      "Epoch [532/1000], Loss: 1.5989\n",
      "Epoch [533/1000], Loss: 1.5232\n",
      "Saved Best Model at Epoch 534 with Validation Loss: 1.2393\n",
      "Epoch [534/1000], Loss: 1.4289\n",
      "Epoch [535/1000], Loss: 1.6604\n",
      "Epoch [536/1000], Loss: 1.4422\n",
      "Epoch [537/1000], Loss: 1.5119\n",
      "Epoch [538/1000], Loss: 1.5222\n",
      "Epoch [539/1000], Loss: 1.4935\n",
      "Epoch [540/1000], Loss: 1.4444\n",
      "Epoch [541/1000], Loss: 1.3362\n",
      "Epoch [542/1000], Loss: 1.5252\n",
      "Epoch [543/1000], Loss: 1.7491\n",
      "Epoch [544/1000], Loss: 1.4725\n",
      "Saved Best Model at Epoch 545 with Validation Loss: 1.2281\n",
      "Epoch [545/1000], Loss: 1.5789\n",
      "Epoch [546/1000], Loss: 1.5195\n",
      "Epoch [547/1000], Loss: 1.4846\n",
      "Epoch [548/1000], Loss: 1.4695\n",
      "Epoch [549/1000], Loss: 1.3186\n",
      "Epoch [550/1000], Loss: 1.3201\n",
      "Epoch [551/1000], Loss: 1.5230\n",
      "Epoch [552/1000], Loss: 1.5554\n",
      "Epoch [553/1000], Loss: 1.5629\n",
      "Epoch [554/1000], Loss: 1.5944\n",
      "Epoch [555/1000], Loss: 1.6519\n",
      "Saved Best Model at Epoch 556 with Validation Loss: 1.2251\n",
      "Epoch [556/1000], Loss: 1.3719\n",
      "Epoch [557/1000], Loss: 1.4212\n",
      "Epoch [558/1000], Loss: 1.6073\n",
      "Epoch [559/1000], Loss: 1.5511\n",
      "Epoch [560/1000], Loss: 1.5202\n",
      "Epoch [561/1000], Loss: 1.5971\n",
      "Epoch [562/1000], Loss: 1.5966\n",
      "Epoch [563/1000], Loss: 1.3530\n",
      "Epoch [564/1000], Loss: 1.3968\n",
      "Epoch [565/1000], Loss: 1.5780\n",
      "Epoch [566/1000], Loss: 1.4882\n",
      "Saved Best Model at Epoch 567 with Validation Loss: 1.2123\n",
      "Epoch [567/1000], Loss: 1.4227\n",
      "Epoch [568/1000], Loss: 1.4730\n",
      "Epoch [569/1000], Loss: 1.3770\n",
      "Epoch [570/1000], Loss: 1.3035\n",
      "Epoch [571/1000], Loss: 1.6616\n",
      "Epoch [572/1000], Loss: 1.5226\n",
      "Epoch [573/1000], Loss: 1.3775\n",
      "Epoch [574/1000], Loss: 1.4021\n",
      "Epoch [575/1000], Loss: 1.3995\n",
      "Epoch [576/1000], Loss: 1.6489\n",
      "Epoch [577/1000], Loss: 1.4113\n",
      "Epoch [578/1000], Loss: 1.4089\n",
      "Epoch [579/1000], Loss: 1.3533\n",
      "Saved Best Model at Epoch 580 with Validation Loss: 1.1802\n",
      "Epoch [580/1000], Loss: 1.2771\n",
      "Epoch [581/1000], Loss: 1.4383\n",
      "Epoch [582/1000], Loss: 1.6058\n",
      "Epoch [583/1000], Loss: 1.4780\n",
      "Epoch [584/1000], Loss: 1.4157\n",
      "Epoch [585/1000], Loss: 1.3689\n",
      "Epoch [586/1000], Loss: 1.4421\n",
      "Epoch [587/1000], Loss: 1.3272\n",
      "Epoch [588/1000], Loss: 1.7404\n",
      "Epoch [589/1000], Loss: 1.3920\n",
      "Epoch [590/1000], Loss: 1.2713\n",
      "Epoch [591/1000], Loss: 1.4476\n",
      "Epoch [592/1000], Loss: 1.3938\n",
      "Epoch [593/1000], Loss: 1.4695\n",
      "Epoch [594/1000], Loss: 1.5799\n",
      "Epoch [595/1000], Loss: 1.3185\n",
      "Epoch [596/1000], Loss: 1.5196\n",
      "Saved Best Model at Epoch 597 with Validation Loss: 1.1713\n",
      "Epoch [597/1000], Loss: 1.4660\n",
      "Epoch [598/1000], Loss: 1.5292\n",
      "Epoch [599/1000], Loss: 1.4737\n",
      "Epoch [600/1000], Loss: 1.5181\n",
      "Epoch [601/1000], Loss: 1.6197\n",
      "Epoch [602/1000], Loss: 1.4611\n",
      "Epoch [603/1000], Loss: 1.4648\n",
      "Epoch [604/1000], Loss: 1.5309\n",
      "Epoch [605/1000], Loss: 1.3108\n",
      "Epoch [606/1000], Loss: 1.6093\n",
      "Epoch [607/1000], Loss: 1.4697\n",
      "Epoch [608/1000], Loss: 1.5863\n",
      "Saved Best Model at Epoch 609 with Validation Loss: 1.1652\n",
      "Epoch [609/1000], Loss: 1.5430\n",
      "Epoch [610/1000], Loss: 1.3178\n",
      "Epoch [611/1000], Loss: 1.2112\n",
      "Epoch [612/1000], Loss: 1.4445\n",
      "Epoch [613/1000], Loss: 1.2893\n",
      "Epoch [614/1000], Loss: 1.4182\n",
      "Epoch [615/1000], Loss: 1.5182\n",
      "Epoch [616/1000], Loss: 1.5407\n",
      "Epoch [617/1000], Loss: 1.3908\n",
      "Epoch [618/1000], Loss: 1.2269\n",
      "Epoch [619/1000], Loss: 1.3505\n",
      "Saved Best Model at Epoch 620 with Validation Loss: 1.1495\n",
      "Epoch [620/1000], Loss: 1.4326\n",
      "Epoch [621/1000], Loss: 1.2771\n",
      "Epoch [622/1000], Loss: 1.4987\n",
      "Epoch [623/1000], Loss: 1.6107\n",
      "Epoch [624/1000], Loss: 1.3811\n",
      "Epoch [625/1000], Loss: 1.5780\n",
      "Epoch [626/1000], Loss: 1.3489\n",
      "Epoch [627/1000], Loss: 1.4519\n",
      "Epoch [628/1000], Loss: 1.5710\n",
      "Epoch [629/1000], Loss: 1.5273\n",
      "Epoch [630/1000], Loss: 1.3761\n",
      "Epoch [631/1000], Loss: 1.3379\n",
      "Epoch [632/1000], Loss: 1.4794\n",
      "Epoch [633/1000], Loss: 1.3458\n",
      "Epoch [634/1000], Loss: 1.4715\n",
      "Saved Best Model at Epoch 635 with Validation Loss: 1.1386\n",
      "Epoch [635/1000], Loss: 1.2886\n",
      "Epoch [636/1000], Loss: 1.4783\n",
      "Epoch [637/1000], Loss: 1.5949\n",
      "Epoch [638/1000], Loss: 1.6038\n",
      "Epoch [639/1000], Loss: 1.5852\n",
      "Epoch [640/1000], Loss: 1.5707\n",
      "Epoch [641/1000], Loss: 1.5212\n",
      "Epoch [642/1000], Loss: 1.4519\n",
      "Epoch [643/1000], Loss: 1.5028\n",
      "Epoch [644/1000], Loss: 1.3164\n",
      "Epoch [645/1000], Loss: 1.5778\n",
      "Saved Best Model at Epoch 646 with Validation Loss: 1.1322\n",
      "Epoch [646/1000], Loss: 1.3828\n",
      "Epoch [647/1000], Loss: 1.5137\n",
      "Epoch [648/1000], Loss: 1.6033\n",
      "Epoch [649/1000], Loss: 1.4546\n",
      "Epoch [650/1000], Loss: 1.4303\n",
      "Epoch [651/1000], Loss: 1.4409\n",
      "Epoch [652/1000], Loss: 1.4826\n",
      "Epoch [653/1000], Loss: 1.3045\n",
      "Epoch [654/1000], Loss: 1.4459\n",
      "Epoch [655/1000], Loss: 1.4381\n",
      "Epoch [656/1000], Loss: 1.4767\n",
      "Saved Best Model at Epoch 657 with Validation Loss: 1.1280\n",
      "Epoch [657/1000], Loss: 1.4200\n",
      "Epoch [658/1000], Loss: 1.7657\n",
      "Epoch [659/1000], Loss: 1.3049\n",
      "Epoch [660/1000], Loss: 1.3336\n",
      "Epoch [661/1000], Loss: 1.3616\n",
      "Epoch [662/1000], Loss: 1.4036\n",
      "Epoch [663/1000], Loss: 1.3388\n",
      "Epoch [664/1000], Loss: 1.2897\n",
      "Epoch [665/1000], Loss: 1.2200\n",
      "Epoch [666/1000], Loss: 1.4993\n",
      "Epoch [667/1000], Loss: 1.2707\n",
      "Epoch [668/1000], Loss: 1.3714\n",
      "Saved Best Model at Epoch 669 with Validation Loss: 1.1239\n",
      "Epoch [669/1000], Loss: 1.4169\n",
      "Epoch [670/1000], Loss: 1.3487\n",
      "Epoch [671/1000], Loss: 1.5438\n",
      "Epoch [672/1000], Loss: 1.4829\n",
      "Epoch [673/1000], Loss: 1.4339\n",
      "Epoch [674/1000], Loss: 1.4620\n",
      "Epoch [675/1000], Loss: 1.4012\n",
      "Epoch [676/1000], Loss: 1.3577\n",
      "Epoch [677/1000], Loss: 1.2341\n",
      "Epoch [678/1000], Loss: 1.4231\n",
      "Epoch [679/1000], Loss: 1.2279\n",
      "Saved Best Model at Epoch 680 with Validation Loss: 1.1116\n",
      "Epoch [680/1000], Loss: 1.2665\n",
      "Epoch [681/1000], Loss: 1.5635\n",
      "Epoch [682/1000], Loss: 1.3575\n",
      "Epoch [683/1000], Loss: 1.4524\n",
      "Epoch [684/1000], Loss: 1.4217\n",
      "Epoch [685/1000], Loss: 1.4510\n",
      "Epoch [686/1000], Loss: 1.4366\n",
      "Epoch [687/1000], Loss: 1.3807\n",
      "Epoch [688/1000], Loss: 1.3501\n",
      "Epoch [689/1000], Loss: 1.4427\n",
      "Epoch [690/1000], Loss: 1.3054\n",
      "Saved Best Model at Epoch 691 with Validation Loss: 1.1078\n",
      "Epoch [691/1000], Loss: 1.4611\n",
      "Epoch [692/1000], Loss: 1.3715\n",
      "Epoch [693/1000], Loss: 1.3212\n",
      "Epoch [694/1000], Loss: 1.3373\n",
      "Epoch [695/1000], Loss: 1.4090\n",
      "Epoch [696/1000], Loss: 1.3344\n",
      "Epoch [697/1000], Loss: 1.5306\n",
      "Epoch [698/1000], Loss: 1.4236\n",
      "Epoch [699/1000], Loss: 1.4136\n",
      "Epoch [700/1000], Loss: 1.5835\n",
      "Epoch [701/1000], Loss: 1.2587\n",
      "Epoch [702/1000], Loss: 1.5659\n",
      "Epoch [703/1000], Loss: 1.3008\n",
      "Saved Best Model at Epoch 704 with Validation Loss: 1.1006\n",
      "Epoch [704/1000], Loss: 1.3693\n",
      "Epoch [705/1000], Loss: 1.5029\n",
      "Epoch [706/1000], Loss: 1.3172\n",
      "Epoch [707/1000], Loss: 1.5412\n",
      "Epoch [708/1000], Loss: 1.3818\n",
      "Epoch [709/1000], Loss: 1.2568\n",
      "Epoch [710/1000], Loss: 1.2333\n",
      "Epoch [711/1000], Loss: 1.2427\n",
      "Epoch [712/1000], Loss: 1.4920\n",
      "Epoch [713/1000], Loss: 1.4648\n",
      "Epoch [714/1000], Loss: 1.2776\n",
      "Epoch [715/1000], Loss: 1.5264\n",
      "Saved Best Model at Epoch 716 with Validation Loss: 1.1005\n",
      "Epoch [716/1000], Loss: 1.3243\n",
      "Epoch [717/1000], Loss: 1.3612\n",
      "Epoch [718/1000], Loss: 1.1717\n",
      "Epoch [719/1000], Loss: 1.4073\n",
      "Epoch [720/1000], Loss: 1.2998\n",
      "Epoch [721/1000], Loss: 1.5665\n",
      "Epoch [722/1000], Loss: 1.4660\n",
      "Epoch [723/1000], Loss: 1.4153\n",
      "Epoch [724/1000], Loss: 1.3093\n",
      "Epoch [725/1000], Loss: 1.4805\n",
      "Epoch [726/1000], Loss: 1.5087\n",
      "Epoch [727/1000], Loss: 1.3219\n",
      "Epoch [728/1000], Loss: 1.3550\n",
      "Saved Best Model at Epoch 729 with Validation Loss: 1.0943\n",
      "Epoch [729/1000], Loss: 1.2587\n",
      "Epoch [730/1000], Loss: 1.5166\n",
      "Epoch [731/1000], Loss: 1.2569\n",
      "Epoch [732/1000], Loss: 1.3760\n",
      "Epoch [733/1000], Loss: 1.5844\n",
      "Epoch [734/1000], Loss: 1.4282\n",
      "Epoch [735/1000], Loss: 1.2861\n",
      "Epoch [736/1000], Loss: 1.3520\n",
      "Epoch [737/1000], Loss: 1.3209\n",
      "Epoch [738/1000], Loss: 1.3573\n",
      "Epoch [739/1000], Loss: 1.2627\n",
      "Saved Best Model at Epoch 740 with Validation Loss: 1.0892\n",
      "Epoch [740/1000], Loss: 1.3873\n",
      "Epoch [741/1000], Loss: 1.2669\n",
      "Epoch [742/1000], Loss: 1.3651\n",
      "Epoch [743/1000], Loss: 1.3151\n",
      "Epoch [744/1000], Loss: 1.2376\n",
      "Epoch [745/1000], Loss: 1.3153\n",
      "Epoch [746/1000], Loss: 1.2857\n",
      "Epoch [747/1000], Loss: 1.3801\n",
      "Epoch [748/1000], Loss: 1.3284\n",
      "Epoch [749/1000], Loss: 1.5354\n",
      "Epoch [750/1000], Loss: 1.3794\n",
      "Saved Best Model at Epoch 751 with Validation Loss: 1.0614\n",
      "Epoch [751/1000], Loss: 1.4605\n",
      "Epoch [752/1000], Loss: 1.4603\n",
      "Epoch [753/1000], Loss: 1.4116\n",
      "Epoch [754/1000], Loss: 1.2363\n",
      "Epoch [755/1000], Loss: 1.2914\n",
      "Epoch [756/1000], Loss: 1.1721\n",
      "Epoch [757/1000], Loss: 1.5628\n",
      "Epoch [758/1000], Loss: 1.2492\n",
      "Epoch [759/1000], Loss: 1.3178\n",
      "Epoch [760/1000], Loss: 1.1952\n",
      "Epoch [761/1000], Loss: 1.2259\n",
      "Epoch [762/1000], Loss: 1.4450\n",
      "Epoch [763/1000], Loss: 1.2999\n",
      "Epoch [764/1000], Loss: 1.0788\n",
      "Epoch [765/1000], Loss: 1.3096\n",
      "Epoch [766/1000], Loss: 1.4016\n",
      "Epoch [767/1000], Loss: 1.3454\n",
      "Saved Best Model at Epoch 768 with Validation Loss: 1.0533\n",
      "Epoch [768/1000], Loss: 1.2860\n",
      "Epoch [769/1000], Loss: 1.1272\n",
      "Epoch [770/1000], Loss: 1.2377\n",
      "Epoch [771/1000], Loss: 1.2233\n",
      "Epoch [772/1000], Loss: 1.3527\n",
      "Epoch [773/1000], Loss: 1.1383\n",
      "Epoch [774/1000], Loss: 1.2182\n",
      "Epoch [775/1000], Loss: 1.2467\n",
      "Epoch [776/1000], Loss: 1.4245\n",
      "Epoch [777/1000], Loss: 1.2567\n",
      "Epoch [778/1000], Loss: 1.3880\n",
      "Saved Best Model at Epoch 779 with Validation Loss: 1.0495\n",
      "Epoch [779/1000], Loss: 1.4169\n",
      "Epoch [780/1000], Loss: 1.2905\n",
      "Epoch [781/1000], Loss: 1.2084\n",
      "Epoch [782/1000], Loss: 1.2258\n",
      "Epoch [783/1000], Loss: 1.2257\n",
      "Epoch [784/1000], Loss: 1.4726\n",
      "Epoch [785/1000], Loss: 1.3515\n",
      "Epoch [786/1000], Loss: 1.2218\n",
      "Epoch [787/1000], Loss: 1.3258\n",
      "Epoch [788/1000], Loss: 1.2781\n",
      "Epoch [789/1000], Loss: 1.3083\n",
      "Epoch [790/1000], Loss: 1.1644\n",
      "Epoch [791/1000], Loss: 1.3323\n",
      "Saved Best Model at Epoch 792 with Validation Loss: 1.0379\n",
      "Epoch [792/1000], Loss: 1.4792\n",
      "Epoch [793/1000], Loss: 1.3763\n",
      "Epoch [794/1000], Loss: 1.5987\n",
      "Epoch [795/1000], Loss: 1.2170\n",
      "Epoch [796/1000], Loss: 1.1327\n",
      "Epoch [797/1000], Loss: 1.2133\n",
      "Epoch [798/1000], Loss: 1.3184\n",
      "Epoch [799/1000], Loss: 1.2139\n",
      "Epoch [800/1000], Loss: 1.3990\n",
      "Epoch [801/1000], Loss: 1.2722\n",
      "Epoch [802/1000], Loss: 1.3925\n",
      "Saved Best Model at Epoch 803 with Validation Loss: 1.0369\n",
      "Epoch [803/1000], Loss: 1.2435\n",
      "Epoch [804/1000], Loss: 1.3202\n",
      "Epoch [805/1000], Loss: 1.3762\n",
      "Epoch [806/1000], Loss: 1.4372\n",
      "Epoch [807/1000], Loss: 1.3797\n",
      "Epoch [808/1000], Loss: 1.1437\n",
      "Epoch [809/1000], Loss: 1.1719\n",
      "Epoch [810/1000], Loss: 1.5019\n",
      "Epoch [811/1000], Loss: 1.3680\n",
      "Epoch [812/1000], Loss: 1.2548\n",
      "Epoch [813/1000], Loss: 1.3682\n",
      "Epoch [814/1000], Loss: 1.4354\n",
      "Epoch [815/1000], Loss: 1.1913\n",
      "Epoch [816/1000], Loss: 1.3308\n",
      "Saved Best Model at Epoch 817 with Validation Loss: 1.0319\n",
      "Epoch [817/1000], Loss: 1.3565\n",
      "Epoch [818/1000], Loss: 1.4551\n",
      "Epoch [819/1000], Loss: 1.3315\n",
      "Epoch [820/1000], Loss: 1.3594\n",
      "Epoch [821/1000], Loss: 1.1323\n",
      "Epoch [822/1000], Loss: 1.2985\n",
      "Epoch [823/1000], Loss: 1.2480\n",
      "Epoch [824/1000], Loss: 1.3549\n",
      "Epoch [825/1000], Loss: 1.3694\n",
      "Epoch [826/1000], Loss: 1.3119\n",
      "Epoch [827/1000], Loss: 1.4430\n",
      "Epoch [828/1000], Loss: 1.2274\n",
      "Epoch [829/1000], Loss: 1.2661\n",
      "Epoch [830/1000], Loss: 1.3530\n",
      "Saved Best Model at Epoch 831 with Validation Loss: 1.0170\n",
      "Epoch [831/1000], Loss: 1.2239\n",
      "Epoch [832/1000], Loss: 1.2331\n",
      "Epoch [833/1000], Loss: 1.3551\n",
      "Epoch [834/1000], Loss: 1.5236\n",
      "Epoch [835/1000], Loss: 1.4277\n",
      "Epoch [836/1000], Loss: 1.1346\n",
      "Epoch [837/1000], Loss: 1.1839\n",
      "Epoch [838/1000], Loss: 1.2655\n",
      "Epoch [839/1000], Loss: 1.3227\n",
      "Epoch [840/1000], Loss: 1.3020\n",
      "Epoch [841/1000], Loss: 1.3416\n",
      "Epoch [842/1000], Loss: 1.2820\n",
      "Saved Best Model at Epoch 843 with Validation Loss: 1.0158\n",
      "Epoch [843/1000], Loss: 1.2841\n",
      "Epoch [844/1000], Loss: 1.4853\n",
      "Epoch [845/1000], Loss: 1.1450\n",
      "Epoch [846/1000], Loss: 1.1413\n",
      "Epoch [847/1000], Loss: 1.3489\n",
      "Epoch [848/1000], Loss: 1.1225\n",
      "Epoch [849/1000], Loss: 1.4175\n",
      "Epoch [850/1000], Loss: 1.2577\n",
      "Epoch [851/1000], Loss: 1.3074\n",
      "Epoch [852/1000], Loss: 1.3879\n",
      "Epoch [853/1000], Loss: 1.2600\n",
      "Epoch [854/1000], Loss: 1.3457\n",
      "Epoch [855/1000], Loss: 1.2672\n",
      "Saved Best Model at Epoch 856 with Validation Loss: 1.0137\n",
      "Epoch [856/1000], Loss: 1.1226\n",
      "Epoch [857/1000], Loss: 1.3521\n",
      "Epoch [858/1000], Loss: 1.4021\n",
      "Epoch [859/1000], Loss: 1.1716\n",
      "Epoch [860/1000], Loss: 1.3459\n",
      "Epoch [861/1000], Loss: 1.0003\n",
      "Epoch [862/1000], Loss: 1.2583\n",
      "Epoch [863/1000], Loss: 1.1971\n",
      "Epoch [864/1000], Loss: 1.2616\n",
      "Epoch [865/1000], Loss: 1.1980\n",
      "Epoch [866/1000], Loss: 1.3334\n",
      "Epoch [867/1000], Loss: 1.2797\n",
      "Epoch [868/1000], Loss: 1.1750\n",
      "Epoch [869/1000], Loss: 1.2186\n",
      "Saved Best Model at Epoch 870 with Validation Loss: 1.0071\n",
      "Epoch [870/1000], Loss: 1.2478\n",
      "Epoch [871/1000], Loss: 1.4720\n",
      "Epoch [872/1000], Loss: 1.3444\n",
      "Epoch [873/1000], Loss: 1.3330\n",
      "Epoch [874/1000], Loss: 1.3522\n",
      "Epoch [875/1000], Loss: 1.2046\n",
      "Epoch [876/1000], Loss: 1.3604\n",
      "Epoch [877/1000], Loss: 1.2043\n",
      "Epoch [878/1000], Loss: 1.2009\n",
      "Epoch [879/1000], Loss: 1.2825\n",
      "Epoch [880/1000], Loss: 1.3204\n",
      "Saved Best Model at Epoch 881 with Validation Loss: 1.0032\n",
      "Epoch [881/1000], Loss: 1.3851\n",
      "Epoch [882/1000], Loss: 1.2794\n",
      "Epoch [883/1000], Loss: 1.3179\n",
      "Epoch [884/1000], Loss: 1.1733\n",
      "Epoch [885/1000], Loss: 1.3346\n",
      "Epoch [886/1000], Loss: 1.3012\n",
      "Epoch [887/1000], Loss: 1.1488\n",
      "Epoch [888/1000], Loss: 1.1888\n",
      "Epoch [889/1000], Loss: 1.3759\n",
      "Epoch [890/1000], Loss: 1.4734\n",
      "Epoch [891/1000], Loss: 1.2400\n",
      "Epoch [892/1000], Loss: 1.2184\n",
      "Saved Best Model at Epoch 893 with Validation Loss: 0.9973\n",
      "Epoch [893/1000], Loss: 1.2461\n",
      "Epoch [894/1000], Loss: 1.5190\n",
      "Epoch [895/1000], Loss: 1.2968\n",
      "Epoch [896/1000], Loss: 1.1872\n",
      "Epoch [897/1000], Loss: 1.3077\n",
      "Epoch [898/1000], Loss: 1.3717\n",
      "Epoch [899/1000], Loss: 1.2308\n",
      "Epoch [900/1000], Loss: 1.2222\n",
      "Epoch [901/1000], Loss: 1.2093\n",
      "Epoch [902/1000], Loss: 1.0564\n",
      "Epoch [903/1000], Loss: 1.2252\n",
      "Epoch [904/1000], Loss: 1.3609\n",
      "Epoch [905/1000], Loss: 1.3695\n",
      "Epoch [906/1000], Loss: 1.3275\n",
      "Epoch [907/1000], Loss: 1.3241\n",
      "Epoch [908/1000], Loss: 1.2407\n",
      "Saved Best Model at Epoch 909 with Validation Loss: 0.9916\n",
      "Epoch [909/1000], Loss: 1.3016\n",
      "Epoch [910/1000], Loss: 1.4963\n",
      "Epoch [911/1000], Loss: 1.2193\n",
      "Epoch [912/1000], Loss: 1.3412\n",
      "Epoch [913/1000], Loss: 1.3606\n",
      "Epoch [914/1000], Loss: 1.0773\n",
      "Epoch [915/1000], Loss: 1.3270\n",
      "Epoch [916/1000], Loss: 1.2555\n",
      "Epoch [917/1000], Loss: 1.1964\n",
      "Epoch [918/1000], Loss: 1.3547\n",
      "Epoch [919/1000], Loss: 1.3541\n",
      "Epoch [920/1000], Loss: 1.3168\n",
      "Epoch [921/1000], Loss: 1.3097\n",
      "Epoch [922/1000], Loss: 1.3338\n",
      "Saved Best Model at Epoch 923 with Validation Loss: 0.9845\n",
      "Epoch [923/1000], Loss: 1.3827\n",
      "Epoch [924/1000], Loss: 1.2183\n",
      "Epoch [925/1000], Loss: 1.2396\n",
      "Epoch [926/1000], Loss: 1.3877\n",
      "Epoch [927/1000], Loss: 1.4407\n",
      "Epoch [928/1000], Loss: 1.5011\n",
      "Epoch [929/1000], Loss: 1.2299\n",
      "Epoch [930/1000], Loss: 1.1536\n",
      "Epoch [931/1000], Loss: 1.1054\n",
      "Epoch [932/1000], Loss: 1.3441\n",
      "Epoch [933/1000], Loss: 1.3744\n",
      "Epoch [934/1000], Loss: 1.1411\n",
      "Saved Best Model at Epoch 935 with Validation Loss: 0.9733\n",
      "Epoch [935/1000], Loss: 1.2471\n",
      "Epoch [936/1000], Loss: 1.2432\n",
      "Epoch [937/1000], Loss: 1.4066\n",
      "Epoch [938/1000], Loss: 1.4912\n",
      "Epoch [939/1000], Loss: 1.3645\n",
      "Epoch [940/1000], Loss: 1.1638\n",
      "Epoch [941/1000], Loss: 1.2818\n",
      "Epoch [942/1000], Loss: 1.2360\n",
      "Epoch [943/1000], Loss: 1.3790\n",
      "Epoch [944/1000], Loss: 1.2186\n",
      "Epoch [945/1000], Loss: 1.2695\n",
      "Epoch [946/1000], Loss: 1.2982\n",
      "Epoch [947/1000], Loss: 1.5174\n",
      "Epoch [948/1000], Loss: 1.3558\n",
      "Epoch [949/1000], Loss: 1.3049\n",
      "Epoch [950/1000], Loss: 1.4523\n",
      "Epoch [951/1000], Loss: 1.2644\n",
      "Epoch [952/1000], Loss: 1.2369\n",
      "Epoch [953/1000], Loss: 1.3998\n",
      "Saved Best Model at Epoch 954 with Validation Loss: 0.9716\n",
      "Epoch [954/1000], Loss: 1.3941\n",
      "Epoch [955/1000], Loss: 1.2380\n",
      "Epoch [956/1000], Loss: 1.2614\n",
      "Epoch [957/1000], Loss: 1.2964\n",
      "Epoch [958/1000], Loss: 1.3330\n",
      "Epoch [959/1000], Loss: 1.1974\n",
      "Epoch [960/1000], Loss: 1.3385\n",
      "Epoch [961/1000], Loss: 1.1941\n",
      "Epoch [962/1000], Loss: 1.2942\n",
      "Epoch [963/1000], Loss: 1.0695\n",
      "Epoch [964/1000], Loss: 1.0982\n",
      "Saved Best Model at Epoch 965 with Validation Loss: 0.9635\n",
      "Epoch [965/1000], Loss: 1.3229\n",
      "Epoch [966/1000], Loss: 1.2172\n",
      "Epoch [967/1000], Loss: 1.1443\n",
      "Epoch [968/1000], Loss: 1.1427\n",
      "Epoch [969/1000], Loss: 1.2257\n",
      "Epoch [970/1000], Loss: 1.1885\n",
      "Epoch [971/1000], Loss: 1.2590\n",
      "Epoch [972/1000], Loss: 1.1955\n",
      "Epoch [973/1000], Loss: 1.3183\n",
      "Epoch [974/1000], Loss: 1.3866\n",
      "Epoch [975/1000], Loss: 1.1281\n",
      "Epoch [976/1000], Loss: 1.3114\n",
      "Epoch [977/1000], Loss: 1.3074\n",
      "Epoch [978/1000], Loss: 1.1154\n",
      "Epoch [979/1000], Loss: 1.3265\n",
      "Epoch [980/1000], Loss: 1.2301\n",
      "Saved Best Model at Epoch 981 with Validation Loss: 0.9598\n",
      "Epoch [981/1000], Loss: 1.2119\n",
      "Epoch [982/1000], Loss: 1.4015\n",
      "Epoch [983/1000], Loss: 1.2663\n",
      "Epoch [984/1000], Loss: 1.1683\n",
      "Epoch [985/1000], Loss: 1.2681\n",
      "Epoch [986/1000], Loss: 1.1671\n",
      "Epoch [987/1000], Loss: 1.4283\n",
      "Epoch [988/1000], Loss: 1.1359\n",
      "Epoch [989/1000], Loss: 1.1288\n",
      "Epoch [990/1000], Loss: 1.2738\n",
      "Epoch [991/1000], Loss: 1.3526\n",
      "Epoch [992/1000], Loss: 1.2250\n",
      "Epoch [993/1000], Loss: 1.3064\n",
      "Epoch [994/1000], Loss: 1.4011\n",
      "Epoch [995/1000], Loss: 1.2941\n",
      "Saved Best Model at Epoch 996 with Validation Loss: 0.9561\n",
      "Epoch [996/1000], Loss: 1.2589\n",
      "Epoch [997/1000], Loss: 1.4186\n",
      "Epoch [998/1000], Loss: 1.3323\n",
      "Epoch [999/1000], Loss: 1.2801\n",
      "Epoch [1000/1000], Loss: 1.2040\n",
      "Test Loss: 0.9676\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training w {device}\")\n",
    "# Training loop with validation\n",
    "finetuning_best_val_loss = float('inf')  # Initialize best validation loss to infinity\n",
    "finetuning_train_losses, finetuning_val_losses = [], []\n",
    "last_saved_epoch = - 10\n",
    "\n",
    "cur_time = pd.Timestamp.now()\n",
    "tag = f\"{cur_time.year}_{cur_time.month}_{cur_time.day}_{cur_time.hour}_{cur_time.minute}\"\n",
    "\n",
    "num_epochs = 1000\n",
    "for epoch in range(num_epochs):\n",
    "    finetuning_model.train()\n",
    "    \n",
    "    finetuning_train_loss = 0\n",
    "    for inputs, targets in finetuning_train_loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        optimizer.zero_grad()\n",
    "        outputs = finetuning_model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        finetuning_train_loss += loss.item() * len(targets)\n",
    "    \n",
    "    finetuning_train_loss /= len(finetuning_train_set)\n",
    "    \n",
    "    finetuning_val_loss = finetuning_evaluate(finetuning_val_loader)\n",
    "    \n",
    "    finetuning_train_losses.append(finetuning_train_loss)\n",
    "    finetuning_val_losses.append(finetuning_val_loss)\n",
    "    \n",
    "    if finetuning_val_loss < finetuning_best_val_loss and epoch - last_saved_epoch > 10:\n",
    "        last_saved_epoch = epoch\n",
    "        finetuning_best_val_loss = finetuning_val_loss\n",
    "        torch.save(finetuning_model.state_dict(), f'Mujoco_finetuned_model_{tag}_LoRA.pth')\n",
    "        print(f\"Saved Best Model at Epoch {epoch + 1} with Validation Loss: {finetuning_val_loss:.4f}\")\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "finetuning_test_loss = finetuning_evaluate(finetuning_test_loader)\n",
    "print(f'Test Loss: {finetuning_test_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0kAAAHWCAYAAACi1sL/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAB1UklEQVR4nO3dd5hU5d3/8feZujs7O9sbsPReRUHEioIiGiuWGGLEaHyMqDHGaIwlaqImmhifxJLnl0SNiT2xxYIiIjZQQboU6QtsY9tsnXp+f5xh3JUi4O7O7PJ5XddcO3vmzJnv7B50Pvu97/sYpmmaiIiIiIiICAC2RBcgIiIiIiKSTBSSREREREREWlFIEhERERERaUUhSUREREREpBWFJBERERERkVYUkkRERERERFpRSBIREREREWlFIUlERERERKQVhSQREREREZFWFJJERERERERaUUgSEZGD8sQTT2AYBosWLUp0Kftl6dKlfP/736e4uBi32012djZTpkzh8ccfJxKJJLo8ERFJIo5EFyAiItLR/va3v3HllVdSUFDAxRdfzKBBg6ivr2fu3LlcdtlllJaW8stf/jLRZYqISJJQSBIRkW5t4cKFXHnllUycOJE33niD9PT0+GPXXXcdixYtYuXKle3yWo2NjaSlpbXLsUREJHE03E5ERDrUkiVLmDZtGj6fD6/Xy+TJk1m4cGGbfUKhEHfeeSeDBg0iJSWFnJwcjj32WObMmRPfp6ysjEsvvZRevXrhdrspKirirLPOYvPmzft8/TvvvBPDMHjqqafaBKRdxo0bx8yZMwF47733MAyD9957r80+mzdvxjAMnnjiifi2mTNn4vV62bBhA6eddhrp6enMmDGDq6++Gq/XS1NT026vddFFF1FYWNhmeN+bb77JcccdR1paGunp6Zx++umsWrVqn+9JREQ6lkKSiIh0mFWrVnHcccexbNkybrzxRm677TY2bdrEpEmT+OSTT+L73XHHHdx5552ceOKJPPTQQ9xyyy307t2bzz//PL7P9OnTeemll7j00kt55JFHuPbaa6mvr2fr1q17ff2mpibmzp3L8ccfT+/evdv9/YXDYaZOnUp+fj6///3vmT59OhdeeCGNjY28/vrru9Xy3//+l/POOw+73Q7AP//5T04//XS8Xi+/+93vuO222/jiiy849thjvzH8iYhIx9FwOxER6TC33noroVCIDz/8kP79+wPwgx/8gCFDhnDjjTcyf/58AF5//XVOO+00/t//+397PE5tbS0ff/wx999/PzfccEN8+80337zP11+/fj2hUIhRo0a10ztqKxAIcP7553PvvffGt5mmSc+ePXnuuec4//zz49tff/11GhsbufDCCwFoaGjg2muv5fLLL2/zvi+55BKGDBnCPffcs9efh4iIdCx1kkREpENEIhHefvttzj777HhAAigqKuJ73/seH374IX6/H4DMzExWrVrFl19+ucdjpaam4nK5eO+996ipqdnvGnYdf0/D7NrLj3/84zbfG4bB+eefzxtvvEFDQ0N8+3PPPUfPnj059thjAZgzZw61tbVcdNFF7Ny5M36z2+1MmDCBefPmdVjNIiKybwpJIiLSISorK2lqamLIkCG7PTZs2DCi0SglJSUA3HXXXdTW1jJ48GBGjRrFz3/+c5YvXx7f3+1287vf/Y4333yTgoICjj/+eO677z7Kysr2WYPP5wOgvr6+Hd/ZVxwOB7169dpt+4UXXkhzczOvvvoqYHWN3njjDc4//3wMwwCIB8KTTjqJvLy8Nre3336bioqKDqlZRES+mUKSiIgk3PHHH8+GDRt47LHHGDlyJH/72984/PDD+dvf/hbf57rrrmPdunXce++9pKSkcNtttzFs2DCWLFmy1+MOHDgQh8PBihUr9quOXQHm6/Z2HSW3243Ntvv/So866ij69u3L888/D8B///tfmpub40PtAKLRKGDNS5ozZ85ut1deeWW/ahYRkfankCQiIh0iLy8Pj8fD2rVrd3tszZo12Gw2iouL49uys7O59NJLeeaZZygpKWH06NHccccdbZ43YMAAfvazn/H222+zcuVKgsEgf/jDH/Zag8fj4aSTTuL999+Pd632JSsrC7DmQLW2ZcuWb3zu111wwQXMnj0bv9/Pc889R9++fTnqqKPavBeA/Px8pkyZsttt0qRJB/yaIiLSPhSSRESkQ9jtdk455RReeeWVNiu1lZeX8/TTT3PsscfGh8NVVVW1ea7X62XgwIEEAgHAWhmupaWlzT4DBgwgPT09vs/e/OpXv8I0TS6++OI2c4R2Wbx4Mf/4xz8A6NOnD3a7nffff7/NPo888sj+velWLrzwQgKBAP/4xz+YPXs2F1xwQZvHp06dis/n45577iEUCu32/MrKygN+TRERaR9a3U5ERL6Vxx57jNmzZ++2/Sc/+Qm/+c1vmDNnDsceeyxXXXUVDoeD//u//yMQCHDffffF9x0+fDiTJk3iiCOOIDs7m0WLFvHvf/+bq6++GoB169YxefJkLrjgAoYPH47D4eCll16ivLyc7373u/us7+ijj+bhhx/mqquuYujQoVx88cUMGjSI+vp63nvvPV599VV+85vfAJCRkcH555/Pn//8ZwzDYMCAAbz22msHNT/o8MMPZ+DAgdxyyy0EAoE2Q+3Ami/16KOPcvHFF3P44Yfz3e9+l7y8PLZu3crrr7/OMcccw0MPPXTArysiIu3AFBEROQiPP/64Cez1VlJSYpqmaX7++efm1KlTTa/Xa3o8HvPEE080P/744zbH+s1vfmMeeeSRZmZmppmammoOHTrUvPvuu81gMGiapmnu3LnTnDVrljl06FAzLS3NzMjIMCdMmGA+//zz+13v4sWLze9973tmjx49TKfTaWZlZZmTJ082//GPf5iRSCS+X2VlpTl9+nTT4/GYWVlZ5v/8z/+YK1euNAHz8ccfj+93ySWXmGlpaft8zVtuucUEzIEDB+51n3nz5plTp041MzIyzJSUFHPAgAHmzJkzzUWLFu33exMRkfZlmKZpJiyhiYiIiIiIJBnNSRIREREREWlFIUlERERERKQVhSQREREREZFWFJJERERERERaUUgSERERERFpRSFJRERERESklW5/MdloNMqOHTtIT0/HMIxElyMiIiIiIglimib19fX06NEDm23v/aJuH5J27NhBcXFxossQEREREZEkUVJSQq9evfb6eLcPSenp6YD1g/D5fAmuRkREREREEsXv91NcXBzPCHvT7UPSriF2Pp9PIUlERERERL5xGo4WbhAREREREWlFIUlERERERKQVhSQREREREZFWuv2cJBERERFJLqZpEg6HiUQiiS5Fuhm73Y7D4fjWl/5RSBIRERGRThMMBiktLaWpqSnRpUg35fF4KCoqwuVyHfQxFJJEREREpFNEo1E2bdqE3W6nR48euFyub/0Xf5FdTNMkGAxSWVnJpk2bGDRo0D4vGLsvCkkiIiIi0imCwSDRaJTi4mI8Hk+iy5FuKDU1FafTyZYtWwgGg6SkpBzUcbRwg4iIiIh0qoP9677I/miP80tnqIiIiIiISCsKSSIiIiIiIq0oJImIiIiIJEDfvn158MEHE12G7IFCkoiIiIjIPhiGsc/bHXfccVDH/eyzz7jiiiu+VW2TJk3iuuuu+1bHkN1pdbtO1hQM43Hpxy4iIiLSVZSWlsbvP/fcc9x+++2sXbs2vs3r9cbvm6ZJJBLB4fjmz3t5eXntW6i0G3WSOkltU5CfPb+Mkx94n5aQri4tIiIiAlaoaAqGE3IzTXO/aiwsLIzfMjIyMAwj/v2aNWtIT0/nzTff5IgjjsDtdvPhhx+yYcMGzjrrLAoKCvB6vYwfP5533nmnzXG/PtzOMAz+9re/cc455+DxeBg0aBCvvvrqt/r5/uc//2HEiBG43W769u3LH/7whzaPP/LIIwwaNIiUlBQKCgo477zz4o/9+9//ZtSoUaSmppKTk8OUKVNobGz8VvV0FWppdJIUp52FG6vYXtvMEx9v5soTBiS6JBEREZGEaw5FGH77Wwl57S/umtpuI3x+8Ytf8Pvf/57+/fuTlZVFSUkJp512GnfffTdut5snn3ySM844g7Vr19K7d++9HufOO+/kvvvu4/777+fPf/4zM2bMYMuWLWRnZx9wTYsXL+aCCy7gjjvu4MILL+Tjjz/mqquuIicnh5kzZ7Jo0SKuvfZa/vnPf3L00UdTXV3NBx98AFjds4suuoj77ruPc845h/r6ej744IP9DpZdnUJSJ0lx2vnpyYO54YVl/P3DTVxxXH9sNl1hWkRERKQ7uOuuuzj55JPj32dnZzNmzJj497/+9a956aWXePXVV7n66qv3epyZM2dy0UUXAXDPPffwpz/9iU8//ZRTTz31gGt64IEHmDx5MrfddhsAgwcP5osvvuD+++9n5syZbN26lbS0NL7zne+Qnp5Onz59GDt2LGCFpHA4zLnnnkufPn0AGDVq1AHX0FUpJHWiM8f04FevrKSyPsDKHXWM7pWZ6JJEREREEirVaeeLu6Ym7LXby7hx49p839DQwB133MHrr78eDxzNzc1s3bp1n8cZPXp0/H5aWho+n4+KioqDqmn16tWcddZZbbYdc8wxPPjgg0QiEU4++WT69OlD//79OfXUUzn11FPjQ/3GjBnD5MmTGTVqFFOnTuWUU07hvPPOIysr66Bq6Wo0J6kTuRw2jh2UC8C7aw7uZBcRERHpTgzDwONyJORmGO03qictLa3N9zfccAMvvfQS99xzDx988AFLly5l1KhRBIPBfR7H6XTu9vOJRqPtVmdr6enpfP755zzzzDMUFRVx++23M2bMGGpra7Hb7cyZM4c333yT4cOH8+c//5khQ4awadOmDqkl2SgkdbKThuYDME8hSURERKTb+uijj5g5cybnnHMOo0aNorCwkM2bN3dqDcOGDeOjjz7ara7Bgwdjt1tdNIfDwZQpU7jvvvtYvnw5mzdv5t133wWsgHbMMcdw5513smTJElwuFy+99FKnvodE0XC7TjZpiBWSlm2ro7I+QF66O8EViYiIiEh7GzRoEC+++CJnnHEGhmFw2223dVhHqLKykqVLl7bZVlRUxM9+9jPGjx/Pr3/9ay688EIWLFjAQw89xCOPPALAa6+9xsaNGzn++OPJysrijTfeIBqNMmTIED755BPmzp3LKaecQn5+Pp988gmVlZUMGzasQ95DslEnqZMV+FIYXuQDYMHGqgRXIyIiIiId4YEHHiArK4ujjz6aM844g6lTp3L44Yd3yGs9/fTTjB07ts3tr3/9K4cffjjPP/88zz77LCNHjuT222/nrrvuYubMmQBkZmby4osvctJJJzFs2DD+8pe/8MwzzzBixAh8Ph/vv/8+p512GoMHD+bWW2/lD3/4A9OmTeuQ95BsDLObr+Pn9/vJyMigrq4On8+X6HIAuP2VlTy5YAs/PKYft58xPNHliIiIiHSKlpYWNm3aRL9+/UhJSUl0OdJN7es8299soE5SAhxWnAnA0pKaxBYiIiIiIiK7UUhKgF0haeUOP+FIx4xNFRERERGRg6OQlAB9c9JIcdoIhqOU1DQnuhwREREREWlFISkBbDaD/rleANZXNCS4GhERERERaU0hKUEG5iskiYiIiIgkI4WkBNkVkr6sqE9wJSIiIiIi0ppCUoLsCkkb1EkSEREREUkqCkkJEg9JlY1080tViYiIiIh0KQpJnSUagS/fgdk3g2nSNycNu82gIRCmzN+S6OpERERERCRGIamzBOrhuRmw8BHY/jkuh40+2R5AizeIiIiIHAomTZrEddddF/++b9++PPjgg/t8jmEYvPzyy9/6tdvrOIcKhaTOkpoJw8+y7i95EoD+edaQu42VjQkqSkRERES+yRlnnMGpp566x8c++OADDMNg+fLlB3zczz77jCuuuOLbltfGHXfcwWGHHbbb9tLSUqZNm9aur/V1TzzxBJmZmR36Gp1FIakzjb3Y+rrqJYiE6B3rJG2v1QVlRURERJLVZZddxpw5c9i2bdtujz3++OOMGzeO0aNHH/Bx8/Ly8Hg87VHiNyosLMTtdnfKa3UHCkmdqc/R4MmBljrYupBeWakAbKtpSnBhIiIiIglimhBsTMxtPxfP+s53vkNeXh5PPPFEm+0NDQ288MILXHbZZVRVVXHRRRfRs2dPPB4Po0aN4plnntnncb8+3O7LL7/k+OOPJyUlheHDhzNnzpzdnnPTTTcxePBgPB4P/fv357bbbiMUCgFWJ+fOO+9k2bJlGIaBYRjxmr8+3G7FihWcdNJJpKamkpOTwxVXXEFDw1dTQGbOnMnZZ5/N73//e4qKisjJyWHWrFnx1zoYW7du5ayzzsLr9eLz+bjgggsoLy+PP75s2TJOPPFE0tPT8fl8HHHEESxatAiALVu2cMYZZ5CVlUVaWhojRozgjTfeOOhavomjw44su7PZYdBUWPY0fPkWPXteDcC2GnWSRERE5BAVaoJ7eiTmtX+5A1xp37ibw+HgBz/4AU888QS33HILhmEA8MILLxCJRLjoootoaGjgiCOO4KabbsLn8/H6669z8cUXM2DAAI488shvfI1oNMq5555LQUEBn3zyCXV1dW3mL+2Snp7OE088QY8ePVixYgU/+tGPSE9P58Ybb+TCCy9k5cqVzJ49m3feeQeAjIyM3Y7R2NjI1KlTmThxIp999hkVFRVcfvnlXH311W2C4Lx58ygqKmLevHmsX7+eCy+8kMMOO4wf/ehH3/h+9vT+dgWk+fPnEw6HmTVrFhdeeCHvvfceADNmzGDs2LE8+uij2O12li5ditPpBGDWrFkEg0Hef/990tLS+OKLL/B6vQdcx/5SSOpsA060QtKWj+k18ucAbFdIEhEREUlqP/zhD7n//vuZP38+kyZNAqyhdtOnTycjI4OMjAxuuOGG+P7XXHMNb731Fs8///x+haR33nmHNWvW8NZbb9GjhxUa77nnnt3mEd16663x+3379uWGG27g2Wef5cYbbyQ1NRWv14vD4aCwsHCvr/X000/T0tLCk08+SVqaFRIfeughzjjjDH73u99RUFAAQFZWFg899BB2u52hQ4dy+umnM3fu3IMKSXPnzmXFihVs2rSJ4uJiAJ588klGjBjBZ599xvjx49m6dSs///nPGTp0KACDBg2KP3/r1q1Mnz6dUaNGAdC/f/8DruFAKCR1tt4Tra+ly+iVZrV4qxqDNAXDeFz6dYiIiMghxumxOjqJeu39NHToUI4++mgee+wxJk2axPr16/nggw+46667AIhEItxzzz08//zzbN++nWAwSCAQ2O85R6tXr6a4uDgekAAmTpy4237PPfccf/rTn9iwYQMNDQ2Ew2F8Pt9+v49drzVmzJh4QAI45phjiEajrF27Nh6SRowYgd1uj+9TVFTEihUrDui1Wr9mcXFxPCABDB8+nMzMTFavXs348eO5/vrrufzyy/nnP//JlClTOP/88xkwYAAA1157LT/+8Y95++23mTJlCtOnTz+oeWD7S3OSOltmMfh6QTRMRvVy0lOsYKRukoiIiBySDMMa8paIW2zY3P667LLL+M9//kN9fT2PP/44AwYM4IQTTgDg/vvv53//93+56aabmDdvHkuXLmXq1KkEg8F2+1EtWLCAGTNmcNppp/Haa6+xZMkSbrnllnZ9jdZ2DXXbxTAMotFoh7wWWCvzrVq1itNPP513332X4cOH89JLLwFw+eWXs3HjRi6++GJWrFjBuHHj+POf/9xhtSgkJULPsdbX0uX0zIwt3qAV7kRERESS2gUXXIDNZuPpp5/mySef5Ic//GF8ftJHH33EWWedxfe//33GjBlD//79Wbdu3X4fe9iwYZSUlFBaWhrftnDhwjb7fPzxx/Tp04dbbrmFcePGMWjQILZs2dJmH5fLRSQS+cbXWrZsGY2NX12G5qOPPsJmszFkyJD9rvlA7Hp/JSUl8W1ffPEFtbW1DB8+PL5t8ODB/PSnP+Xtt9/m3HPP5fHHH48/VlxczJVXXsmLL77Iz372M/761792SK2gkJQYhbHWYNkKemVZLVgt3iAiIiKS3LxeLxdeeCE333wzpaWlzJw5M/7YoEGDmDNnDh9//DGrV6/mf/7nf9qs3PZNpkyZwuDBg7nkkktYtmwZH3zwAbfcckubfQYNGsTWrVt59tln2bBhA3/605/inZZd+vbty6ZNm1i6dCk7d+4kEAjs9lozZswgJSWFSy65hJUrVzJv3jyuueYaLr744vhQu4MViURYunRpm9vq1auZMmUKo0aNYsaMGXz++ed8+umn/OAHP+CEE05g3LhxNDc3c/XVV/Pee++xZcsWPvroIz777DOGDRsGwHXXXcdbb73Fpk2b+Pzzz5k3b178sY6gkJQIhdaEM8pXahlwERERkS7ksssuo6amhqlTp7aZP3Trrbdy+OGHM3XqVCZNmkRhYSFnn332fh/XZrPx0ksv0dzczJFHHsnll1/O3Xff3WafM888k5/+9KdcffXVHHbYYXz88cfcdtttbfaZPn06p556KieeeCJ5eXl7XIbc4/Hw1ltvUV1dzfjx4znvvPOYPHkyDz300IH9MPagoaGBsWPHtrmdccYZGIbBK6+8QlZWFscffzxTpkyhf//+PPfccwDY7Xaqqqr4wQ9+wODBg7nggguYNm0ad955J2CFr1mzZjFs2DBOPfVUBg8ezCOPPPKt690bwzT3c4H4Lsrv95ORkUFdXd0BT2rrMHXb4I8jwObgsRM+5q431/Od0UU89L3DE12ZiIiISIdpaWlh06ZN9OvXj5SUlESXI93Uvs6z/c0G6iQlgq8nuLwQDTPIuRPQcDsRERERkWShkJQIhgE51nKGPaPbASj3tySyIhERERERiUloSLr33nsZP3486enp5Ofnc/bZZ7N27do2+0yaNAnDMNrcrrzyygRV3I5yB1tfWqwVSSrrA0Sj3Xrko4iIiIhIl5DQkDR//nxmzZrFwoULmTNnDqFQiFNOOaXNcoQAP/rRjygtLY3f7rvvvgRV3I5yrCsIe+s3ARCOmtQ0dcwa9yIiIiIisv8ciXzx2bNnt/n+iSeeID8/n8WLF3P88cfHt3s8HgoLCzu7vI4VG25nq91MTpqLqsYg5f4AOV53ggsTERER6VjdfN0wSbD2OL+Sak5SXV0dANnZ2W22P/XUU+Tm5jJy5Ehuvvlmmpr2vlx2IBDA7/e3uSWlzN7W19oS8tKtYFRRr3lJIiIi0n05nU6AfX6WE/m2dp1fu863g5HQTlJr0WiU6667jmOOOYaRI0fGt3/ve9+jT58+9OjRg+XLl3PTTTexdu1aXnzxxT0e5957742vp57UMoqtr/7tFPVysqYMKup3v9iXiIiISHdht9vJzMykoqICsEYLGYaR4KqkuzBNk6amJioqKsjMzMRutx/0sZImJM2aNYuVK1fy4Ycfttl+xRVXxO+PGjWKoqIiJk+ezIYNGxgwYMBux7n55pu5/vrr49/7/X6Ki4s7rvCD5S0AuwsiQQam+JmHtXiDiIiISHe2awrFrqAk0t4yMzO/9VSdpAhJV199Na+99hrvv/8+vXr12ue+EyZMAGD9+vV7DElutxu3uwvM67HZIKMXVG+kv7MKyNAy4CIiItLtGYZBUVER+fn5hEKhRJcj3YzT6fxWHaRdEhqSTNPkmmuu4aWXXuK9996jX79+3/icpUuXAlBUVNTB1XWCzN5QvZFimxWSKvzqJImIiMihwW63t8uHWZGOkNCQNGvWLJ5++mleeeUV0tPTKSsrAyAjI4PU1FQ2bNjA008/zWmnnUZOTg7Lly/npz/9KccffzyjR49OZOntIzYvqSBaDvTXwg0iIiIiIkkgoSHp0UcfBawLxrb2+OOPM3PmTFwuF++88w4PPvggjY2NFBcXM336dG699dYEVNsBMvsAkBUqB6BcnSQRERERkYRL+HC7fSkuLmb+/PmdVE0CZFqdJG/zDsBauME0Ta3yIiIiIiKSQEl1naRDTuxaSe7G7QAEI1HqmjWBUUREREQkkRSSEik2J8mo20ZWqjVxUUPuREREREQSSyEpkdKLwLBDNMRQr3VlYC3eICIiIiKSWApJiWR3QLp1oatBqQ0AWgZcRERERCTBFJISLRaS+rrqAKioV0gSEREREUkkhaRES7cuitvTYYWkcr+G24mIiIiIJJJCUqLFQlKhUQNYy4CLiIiIiEjiKCQlWmy4XXakCtDCDSIiIiIiiaaQlGixTpIvvBPQEuAiIiIiIommkJRoPiskpbZUArCzQSFJRERERCSRFJISLdZJcjSVA9AUjNASiiSyIhERERGRQ5pCUqLF5iTZWmrw2EIA1DaFElmRiIiIiMghTSEp0VIywZEKfHVB2erGYAILEhERERE5tCkkJZphxLtJ/dz1ANQ2KSSJiIiIiCSKQlIyiM1L6uOyLihbrZAkIiIiIpIwCknJILbCXU97LQA1mpMkIiIiIpIwCknJwGsNtys0agCo0ZwkEREREZGEUUhKBt48ALKJDbdTSBIRERERSRiFpGSQlg9AZrQW0MINIiIiIiKJpJCUDLxWSPKGqwGo1pwkEREREZGEUUhKBmnWcLvUoBWS1EkSEREREUkchaRk4C0AwBWoxiCqOUkiIiIiIgnkSHQBAqTlAmCYEbJooKbRmeCCREREREQOXeokJQO7E1KzAcg16mgMRgiEIwkuSkRERETk0KSQlCxiizcU2PwA1GrxBhERERGRhFBIShaxxRt6uxoAXStJRERERCRRFJKSRayT1CsWkmq0wp2IiIiISEIoJCWL2AVlixzWcLuaRg23ExERERFJBIWkZOG1htvlGVZIqmtWSBIRERERSQSFpGQR6yRlUwsoJImIiIiIJIpCUrKIzUnKiNYC4G9RSBIRERERSQSFpGQRW90uPVwDqJMkIiIiIpIoCknJIhaSPKEawFRIEhERERFJEIWkZOHJBsBuhvAQwK+QJCIiIiKSEApJycLpAbsbgCzqFZJERERERBJEISlZGEa8m5RpNGi4nYiIiIhIgigkJZNUKyRlGQ34W8IJLkZERERE5NCkkJRMYp2kLOqpaw5hmmaCCxIREREROfQoJCWT1CzAGm4XiZo0BiMJLkhERERE5NCjkJRMYp2kXFsDoGsliYiIiIgkgkJSMonNSSpwNAJohTsRERERkQRQSEomuzpJdiskqZMkIiIiItL5FJKSSayTlG1TSBIRERERSRSFpGSy6zpJ1AMabiciIiIikggKScnEkwOAz7RCkjpJIiIiIiKdTyEpmcSG23kjfkCdJBERERGRRFBISiax4XYp0UYchNVJEhERERFJAIWkZJKSARgAZNKIvyWc2HpERERERA5BCknJxGaH1EwAMo16dZJERERERBJAISnZ7FoGHIUkEREREZFEUEhKNrF5SVlGgxZuEBERERFJAIWkZJOaBYDPaFQnSUREREQkARSSkk1KBgA+FJJERERERBJBISnZ7ApJRhOBcJSWUCTBBYmIiIiIHFoSGpLuvfdexo8fT3p6Ovn5+Zx99tmsXbu2zT4tLS3MmjWLnJwcvF4v06dPp7y8PEEVd4KUTAAyaALA36JukoiIiIhIZ0poSJo/fz6zZs1i4cKFzJkzh1AoxCmnnEJjY2N8n5/+9Kf897//5YUXXmD+/Pns2LGDc889N4FVd7BYJynXEQtJGnInIiIiItKpHIl88dmzZ7f5/oknniA/P5/Fixdz/PHHU1dXx9///neefvppTjrpJAAef/xxhg0bxsKFCznqqKMSUXbHioWkLFszgOYliYiIiIh0sqSak1RXVwdAdra1DPbixYsJhUJMmTIlvs/QoUPp3bs3CxYs2OMxAoEAfr+/za1L2XUxWduuTlI4gcWIiIiIiBx6kiYkRaNRrrvuOo455hhGjhwJQFlZGS6Xi8zMzDb7FhQUUFZWtsfj3HvvvWRkZMRvxcXFHV16+2q1uh2okyQiIiIi0tmSJiTNmjWLlStX8uyzz36r49x8883U1dXFbyUlJe1UYSeJhSSvQpKIiIiISEIkdE7SLldffTWvvfYa77//Pr169YpvLywsJBgMUltb26abVF5eTmFh4R6P5Xa7cbvdHV1yx4mtbueJWiGptkkhSURERESkMyW0k2SaJldffTUvvfQS7777Lv369Wvz+BFHHIHT6WTu3LnxbWvXrmXr1q1MnDixs8vtHLFOkjvajIMw1Y2BBBckIiIiInJoSWgnadasWTz99NO88sorpKenx+cZZWRkkJqaSkZGBpdddhnXX3892dnZ+Hw+rrnmGiZOnNg9V7aDeEgC8NFEtTpJIiIiIiKdKqEh6dFHHwVg0qRJbbY//vjjzJw5E4A//vGP2Gw2pk+fTiAQYOrUqTzyyCOdXGknstnB7YOAH5/RqE6SiIiIiEgnS2hIMk3zG/dJSUnh4Ycf5uGHH+6EipJESgYE/GTQSHWjOkkiIiIiIp0paVa3k1Z2LQNuNKmTJCIiIiLSyRSSklFshTsfTdQ0hvar4yYiIiIiIu1DISkZxTpJGUYjwUiUhkA4wQWJiIiIiBw6FJKSUSwk5dibAahuDCayGhERERGRQ4pCUjKKhaR8ZwugC8qKiIiIiHQmhaRklJoJQLa9CYDaZoUkEREREZHOopCUjGKdpCybNdyuTiFJRERERKTTKCQlo10LN9isTlJdk+YkiYiIiIh0FoWkZBRbAjzdbAA0J0lEREREpDMpJCWjWCcpzWwENCdJRERERKQzKSQlo1hISo1YnSTNSRIRERER6TwKSckotrqdO+wHTA23ExERERHpRApJySjWSbKbYVIIUteshRtERERERDqLQlIycnnBsAPgo4kadZJERERERDqNQlIyMox4N8lnNFLTqE6SiIiIiEhnUUhKVruulUQj1U1BIlEzwQWJiIiIiBwaFJKSVasLypomVKubJCIiIiLSKRSSklVshbsiVwCAnQ2BBBYjIiIiInLoUEhKVrFOUpG7BVBIEhERERHpLApJySo1C4BCZzMAVQ0abiciIiIi0hkUkpKVJweAPHsDoE6SiIiIiEhnUUhKVp5cAHKMegAqFZJERERERDqFQlKySrNCUqZZB8DOeg23ExERERHpDApJycqTDYA3YoWkqkZ1kkREREREOoNCUrKKDbdLDdUCmpMkIiIiItJZFJKSVWy4nTNYA5gabiciIiIi0kkciS5A9iK2up0tGsJHE1WNNkzTxDCMBBcmIiIiItK9qZOUrJyp4EwDIMuoJxQx8TeHE1yUiIiIiEj3p5CUzNKsblKxuwnQMuAiIiIiIp1BISmZxRZv6JtihSQt3iAiIiIi0vEUkpJZbF5ST5cVkqoatHiDiIiIiEhHU0hKZrEV7gqdjYA6SSIiIiIinUEhKZnFOkl5tgZAIUlEREREpDMoJCWzWCcp2/ADsFPD7UREREREOpxCUjKLdZIyonWAOkkiIiIiIp1BISmZxVa3S4tYIalKIUlEREREpMMpJCWz2HC71GA1oOF2IiIiIiKdQSEpmcVCkjNQBZgabiciIiIi0gkUkpJZWj4AtnALabTQFIzQFAwnuCgRERERke5NISmZub3g9ADQw1EP6IKyIiIiIiIdTSEp2aXlAdDf0wxohTsRERERkY6mkJTsYiGpr3vXBWXVSRIRERER6UgKScnOa81L6uncFZLUSRIRERER6UgKScku1kkqdPgBXStJRERERKSjKSQlu1gnKc+wQpKG24mIiIiIdCyFpGQXWwY806wDoFKdJBERERGRDqWQlOy81nA7X6QGgMp6hSQRERERkY6kkJTsYnOS0kJVAFT4WxJZjYiIiIhIt6eQlOxiw+1cLVZIKvcHME0zkRWJiIiIiHRrCknJLjbczhasx02Q5lCEhkA4wUWJiIiIiHRfCknJLiUT7C4Aeqc0AVY3SUREREREOoZCUrIzjPi8pEEeKyRpXpKIiIiISMdRSOoK0nIB6JfSCECFVrgTEREREekwCkldQWzxhmK3FZLK1UkSEREREekwCkldgdcKSYX2ekBzkkREREREOlJCQ9L777/PGWecQY8ePTAMg5dffrnN4zNnzsQwjDa3U089NTHFJlJsTlKuUQdARb06SSIiIiIiHSWhIamxsZExY8bw8MMP73WfU089ldLS0vjtmWee6cQKk0Ssk5Rl1gJQoU6SiIiIiEiHcRzMk0pKSjAMg169egHw6aef8vTTTzN8+HCuuOKK/T7OtGnTmDZt2j73cbvdFBYWHkyZ3Uesk5QergGgXJ0kEREREZEOc1CdpO9973vMmzcPgLKyMk4++WQ+/fRTbrnlFu666652LfC9994jPz+fIUOG8OMf/5iqqqp97h8IBPD7/W1uXV4sJKUErfde4Q9gmmYiKxIRERER6bYOKiStXLmSI488EoDnn3+ekSNH8vHHH/PUU0/xxBNPtFtxp556Kk8++SRz587ld7/7HfPnz2fatGlEIpG9Pufee+8lIyMjfisuLm63ehImNtzO2WyFpOZQhPpAOJEViYiIiIh0Wwc13C4UCuF2uwF45513OPPMMwEYOnQopaWl7Vbcd7/73fj9UaNGMXr0aAYMGMB7773H5MmT9/icm2++meuvvz7+vd/v7/pByVsAgNFcRXYKVLdYF5T1pTgTXJiIiIiISPdzUJ2kESNG8Je//IUPPviAOXPmxFec27FjBzk5Oe1aYGv9+/cnNzeX9evX73Uft9uNz+drc+vyUrPBZgWiId5mQIs3iIiIiIh0lIMKSb/73e/4v//7PyZNmsRFF13EmDFjAHj11Vfjw/A6wrZt26iqqqKoqKjDXiMp2WyQbi1eMSi1AdDiDSIiIiIiHeWghttNmjSJnTt34vf7ycrKim+/4oor8Hg8+32choaGNl2hTZs2sXTpUrKzs8nOzubOO+9k+vTpFBYWsmHDBm688UYGDhzI1KlTD6bsri29EOpK6OfyA3m6oKyIiIiISAc5qE5Sc3MzgUAgHpC2bNnCgw8+yNq1a8nPz9/v4yxatIixY8cyduxYAK6//nrGjh3L7bffjt1uZ/ny5Zx55pkMHjyYyy67jCOOOIIPPvggPh/qkBLrJPVwxC4oq5AkIiIiItIhDqqTdNZZZ3Huuedy5ZVXUltby4QJE3A6nezcuZMHHniAH//4x/t1nEmTJu1zKeu33nrrYMrrntKtIYaFhq6VJCIiIiLSkQ6qk/T5559z3HHHAfDvf/+bgoICtmzZwpNPPsmf/vSndi1QYmIr3GVHqwFrdTsREREREWl/BxWSmpqaSE9PB+Dtt9/m3HPPxWazcdRRR7Fly5Z2LVBiYp0kX3gnAGUKSSIiIiIiHeKgQtLAgQN5+eWXKSkp4a233uKUU04BoKKionssuZ2MYnOSUgNWSCr3B/Y5VFFERERERA7OQYWk22+/nRtuuIG+ffty5JFHMnHiRMDqKu1ahEHaWayT5GwqByAYjlLTFEpkRSIiIiIi3dJBLdxw3nnnceyxx1JaWhq/RhLA5MmTOeecc9qtOGkl1kkymqspSjMobTQprWsmO82V4MJERERERLqXgwpJAIWFhRQWFrJt2zYAevXq1aEXkj3kpWaB3Q2RAEO9TZQ2plLub2FEj4xEVyYiIiIi0q0c1HC7aDTKXXfdRUZGBn369KFPnz5kZmby61//mmg02t41CoBhxLtJgz0NAJTWafEGEREREZH2dlCdpFtuuYW///3v/Pa3v+WYY44B4MMPP+SOO+6gpaWFu+++u12LlJj0IqjdQh+XH8ijXCFJRERERKTdHVRI+sc//sHf/vY3zjzzzPi20aNH07NnT6666iqFpI4S6yT1tNcBWgZcRERERKQjHNRwu+rqaoYOHbrb9qFDh1JdXf2ti5K9iK1wV2DUABpuJyIiIiLSEQ4qJI0ZM4aHHnpot+0PPfQQo0eP/tZFyV7EOklZ0SoAytVJEhERERFpdwc13O6+++7j9NNP55133olfI2nBggWUlJTwxhtvtGuB0kqsk5QetC4oq06SiIiIiEj7O6hO0gknnMC6des455xzqK2tpba2lnPPPZdVq1bxz3/+s71rlF1inSR3SwUA9S1hmoLhRFYkIiIiItLtGKZpmu11sGXLlnH44YcTiUTa65Dfmt/vJyMjg7q6Onw+X6LL+XYq18HD4zHdPkY2/5XGYIR3f3YC/fO8ia5MRERERCTp7W82OKhOkiRIrJNkBPz0zzAAKKlpTmRFIiIiIiLdjkJSV+JOB5fVNRqd0QTAlqrGRFYkIiIiItLtKCR1JYYBGb0AGO6xrpW0aadCkoiIiIhIezqg1e3OPffcfT5eW1v7bWqR/ZHRCyrX0N9VC+SxWSFJRERERKRdHVBIysjI+MbHf/CDH3yrguQbZBQD0NPYCQxiS1VTYusREREREelmDigkPf744x1Vh+yv2HC7nIi1DPjW6ibCkSgOu0ZOioiIiIi0B32y7mpinSRPUyluh41w1GR7rVa4ExERERFpLwpJXU2sk2T4t9EnxwNo8QYRERERkfakkNTVxEISddvom50KoHlJIiIiIiLtSCGpq/H1AMMGkSAjMoKAOkkiIiIiIu1JIamrsTshvQiAoanWtZI264KyIiIiIiLtRiGpK4oNuevrrAbQtZJERERERNqRQlJXFAtJRVQCUFLTTCgSTWRFIiIiIiLdhkJSV5TZG4D05h2kOG1EoibbarQMuIiIiIhIe1BI6oqy+gJg1G6hb04aAJt2NiSwIBERERGR7kMhqSuKhSRqNtMvd1dI0jLgIiIiIiLtQSGpK4qHpC30zbGulaTFG0RERERE2odCUlfk6wU2B0QCDPdaHSQtAy4iIiIi0j4UkroiuwMyigEY4NwJ6IKyIiIiIiLtRSGpq4oNuetllgGwvbaZllAkgQWJiIiIiHQPCkldVSwkpTdvw5fiwDRhY6W6SSIiIiIi35ZCUle1axnwmi0MLkgH4MuK+gQWJCIiIiLSPSgkdVWtlgEfFAtJ68oVkkREREREvi2FpK4qu5/1tXojQwq8AKwt0wVlRURERES+LYWkrip7gPW1aSfDMqOAhtuJiIiIiLQHhaSuyu0FX08ABjusFe62VjfRHNQKdyIiIiIi34ZCUleWOwiAzKZNZHmcmCZsqNSQOxERERGRb0MhqSvLHQyAsfPL+OINa8s05E5ERERE5NtQSOrKYiGJnV8yrNAKSWvK/AksSERERESk61NI6spyBlpfd65jRM8MAFZuV0gSEREREfk2FJK6sl2dpJpNjChMBWDljjpM00xgUSIiIiIiXZtCUlfm6wHONIiGGeTYictuo74lzOaqpkRXJiIiIiLSZSkkdWWGEV/hzlXzJYcVZwLwycaqBBYlIiIiItK1KSR1dfnDra/lXzBxQA4AH29QSBIREREROVgKSV1dwQjra/lKjupvhaRFm6sTWJCIiIiISNemkNTVxUPSKoYX+QDYUdeCvyWUwKJERERERLouhaSubldIqt5IhiNEoS8FgC/LdVFZEREREZGDoZDU1XnzIS0PMKFyNYNjF5VdW9aQ2LpERERERLoohaTuoNWQu6GxkPRFaV0CCxIRERER6boUkrqDgpHW1/JVjI0tA75oc03i6hERERER6cIUkrqDXZ2kshWM65sNwNryeuqatHiDiIiIiMiBSmhIev/99znjjDPo0aMHhmHw8ssvt3ncNE1uv/12ioqKSE1NZcqUKXz55ZeJKTaZFY2xvpYuIy/NQb/cNEwTFm/VUuAiIiIiIgcqoSGpsbGRMWPG8PDDD+/x8fvuu48//elP/OUvf+GTTz4hLS2NqVOn0tLS0smVJrncIeD0QLABdn7J+L5ZAHy6SUPuREREREQOVEJD0rRp0/jNb37DOeecs9tjpmny4IMPcuutt3LWWWcxevRonnzySXbs2LFbx+mQZ3d81U3asSQ+5E4XlRUREREROXBJOydp06ZNlJWVMWXKlPi2jIwMJkyYwIIFC/b6vEAggN/vb3M7JPQ43Pq643OOjIWk5dvqaAlFEliUiIiIiEjXk7QhqaysDICCgoI22wsKCuKP7cm9995LRkZG/FZcXNyhdSaNHmOtr9s/p0+Oh1yvi2AkyortWgpcRERERORAJG1IOlg333wzdXV18VtJSUmiS+ocPWOdpLIVGJEQR/Sx5iVpKXARERERkQOTtCGpsLAQgPLy8jbby8vL44/tidvtxufztbkdErL7Q0omRAJQvoJxfawhdws3ViW2LhERERGRLiZpQ1K/fv0oLCxk7ty58W1+v59PPvmEiRMnJrCyJGUYUDzBur91IccPzgNgwcYqmoLhBBYmIiIiItK1JDQkNTQ0sHTpUpYuXQpYizUsXbqUrVu3YhgG1113Hb/5zW949dVXWbFiBT/4wQ/o0aMHZ599diLLTl59YuFxy8cMLvDSMzOVYDjKx+vVTRIRERER2V8JDUmLFi1i7NixjB1rLTpw/fXXM3bsWG6//XYAbrzxRq655hquuOIKxo8fT0NDA7NnzyYlJSWRZSev3kdbX7cuwABOGpoPwLtrKxJXk4iIiIhIF2OYpmkmuoiO5Pf7ycjIoK6urvvPTwoH4bfFEG6BWZ8yrzqLSx//jKKMFD7+xUkYhpHoCkVEREREEmZ/s0HSzkmSg+BwQc9x1v0tHzOxfw4pThuldS2sLq1PbG0iIiIiIl2EQlJ30yc25G7zB6Q47Rw7MBeAd9eU7+NJIiIiIiKyi0JSdzPgROvrxvcgGuXEXfOS1mhekoiIiIjI/lBI6m56jQeXF5qqoGx5fPGGJSW1VDUEElyciIiIiEjyU0jqbuxO6He8dX/DuxRlpDK8yIdpwntrKxNbm4iIiIhIF6CQ1B313zXkbh4AU4ZZ3aTZq8oSVZGIiIiISJehkNQdDTjJ+rplAbT4mTaqCID56yqpbwklsDARERERkeSnkNQd5QyAnIEQDcH6dxhamE7/3DSC4agWcBARERER+QYKSd2RYcDQ0637a17HMAxOi3WTXl9emsDCRERERESSn0JSdzUkFpK+fBvCwXhIem9dJQ2BcAILExERERFJbgpJ3VWvcZCWDwE/bH6fYUXp9IsNuZu7WheWFRERERHZG4Wk7spmh2Hfse4vfwHDMPjOaKub9Pu311LXrAUcRERERET2RCGpOxv9Xevr6lch0MDlx/anODuVkupmnv+sJLG1iYiIiIgkKYWk7qz4SMjuD6EmWP1fMjxOfnzCQACeX1SCaZoJLlBEREREJPkoJHVnhgFjLrLuL3sGgO+MKSLFaePLigaWltQmrjYRERERkSSlkNTdjb7Q+rrpfajbhi/FybSR1tyk5xdtS2BhIiIiIiLJSSGpu8vqA32OBUxYanWTLhhXDMArS7dT36IFHEREREREWlNIOhQccYn1ddHfIRLiqP7ZDMhLoykY4eUl2xNbm4iIiIhIklFIOhQMPxu8BVBfCqtfxTAMZkzoA8A/F24hGtUCDiIiIiIiuygkHQocLhj3Q+v+wr8AMP2IXqQ67awrb+D3b69NYHEiIiIiIslFIelQccSlYHPCtk9h+2IyUp38+uyRAPzf+xvZvLMxwQWKiIiIiCQHhaRDRXoBjDzXuv/BAwCcd0QvThySRyRq8uA76xJYnIiIiIhI8lBIOpQc+1MwbLDmNSj5DICfnTIEgFeW7WBdeX0iqxMRERERSQoKSYeS/GEw5nvW/QUPATCyZwbTRhZimvDHOeomiYiIiIgoJB1qJl5lfV39KlSsBuCnJw/GMODNlWWs3F6XwOJERERERBJPIelQUzAChp0JZhTevhWAwQXpnDWmBwB/0Ep3IiIiInKIU0g6FJ18p7XS3fp34Mt3ALhuymDsNoN5aytZsKEqwQWKiIiIiCSOQtKhKLs/TPgf6/7bt0IkTN/cNL47vhiAm/6znFAkmsACRUREREQSRyHpUHX8zyE1GypXw+f/AOAX04aSk+Zia3UTH6ubJCIiIiKHKIWkQ1VqJkz6hXV/3j3QUkd6ipNTRxYC8MrS7YmrTUREREQkgRSSDmXjfgg5A6FpJ3zwBwDOHtsTgBc/3878dZWJrE5EREREJCEUkg5ldieccrd1f+GjULWB8X2z+f5RvQH46XNLqahvSWCBIiIiIiKdTyHpUDd4KgyYDJEgvH0bALeePpzhRT6qG4Pc+tJKTNNMcJEiIiIiIp1HIelQZxhw6r1g2GHt67DhXVKcdv5wwRicdoO3vyjnv8tLE12liIiIiEinUUgSyBsCR15h3X/5KmioZFiRj6tPHATAr15ZSWV9IIEFioiIiIh0HoUksZx0C+QOgfpSmP87AK46cQDDi3zUNIW4/ZWVCS5QRERERKRzKCSJxZ0Op1sr3LH4CahYjdNu4/7zR+OwGby5sowFunaSiIiIiBwCFJLkK/2OgyGnQTQEr1wN0QgjemRw0ZHWane/fXO1FnEQERERkW5PIUnaOv0P4PbB9kXWsuDAtZMHkeays2xbHW+sKEtwgSIiIiIiHUshSdry9YCpsWsnvfsbqNpAXrqbHx3fH4D731pDSyiSwAJFRERERDqWQpLsbuzF0H8ShJvh1WshGuVHx/UnL93N5qom7n59daIrFBERERHpMApJsjvDgDP+F5we2PIhLH6cNLeDBy4YA8BTn2xhfUVDgosUEREREekYCkmyZ1l9YfKvrPtzfgV12zhuUB4nDy8gasLVT39OUzCc0BJFRERERDqCQpLs3ZFXQPEECNbDf68D0+RXZwwn1+tmTVk9D7y9LtEVioiIiIi0O4Uk2TubDc58COxuWD8Hlj1LrywP9583GoC/fbiJ15bvSHCRIiIiIiLtSyFJ9i1vMEz6hXV/9i+gvpwTh+Zz2bH9ALhv9loiUV07SURERES6D4Uk+WZHXwtFY6ClFt74GZgmPztlML4UB1urm3jx822JrlBEREREpN0oJMk3szvgrIfB5oDV/4X5v8PjcvA/JwwA4FevrmJjpVa7ExEREZHuQSFJ9k/hKJh2n3X/gz9A3XauPGEAR/XPpikY4eK/f8rWqqbE1igiIiIi0g4UkmT/jb8M+hwDkSC8eSN2A/73u2Ppk+Nhe20zx98/j7Vl9YmuUkRERETkW1FIkgNzym/A7oI1r8Hn/6DAl8LffjAu/vAPHvtECzmIiIiISJemkCQHpufhMPl26/7sX8L2zxlUkM6tpw8DoNwfYMnWmgQWKCIiIiLy7SgkyYE76irofyKEGuHlH0MkzOXH9eesw3oA8NPnl1LVEEhwkSIiIiIiB0chSQ6czQ7nPw6eHKhcAx89CMD/HD+A9BQHJdXN3P366sTWKCIiIiJykJI6JN1xxx0YhtHmNnTo0ESXJQCpWXDK3db99+6F7Z8zvIePf/zwSABeXLKdfy7cksACRUREREQOTlKHJIARI0ZQWloav3344YeJLkl2GfNdGH42RMPwn8sh2MjhvbP4+dQhANz9+hesr9D1k0RERESka0n6kORwOCgsLIzfcnNzE12S7GIY8J0/gq8nVG+AN24E0+SqSQOY2D+HllCUGX9bSE1jMNGVioiIiIjst6QPSV9++SU9evSgf//+zJgxg61bt+5z/0AggN/vb3OTDuTJhnP+Ahiw9F/w4hUYhsFD3xtL/9w0yv0Bfv3aF5imlgUXERERka4hqUPShAkTeOKJJ5g9ezaPPvoomzZt4rjjjqO+fu8XLL333nvJyMiI34qLizux4kNUv+PhtPut+yueh62fkON189vpozEMa37S799em9gaRURERET2k2F2oT/x19bW0qdPHx544AEuu+yyPe4TCAQIBL5aftrv91NcXExdXR0+n6+zSj00vTILlvwLMnvD5e+CN49/LdzCrS+vBOBnJw/mmsmDElykiIiIiByq/H4/GRkZ35gNkrqT9HWZmZkMHjyY9evX73Uft9uNz+drc5NOMvkOyOoHtVvh1avBNPn+UX345WnWioR/mLOOW15aQSgSTWydIiIiIiL70KVCUkNDAxs2bKCoqCjRpcieePPgwn+B3Q3rZsNnfwPgiuMHcPoo63f21CdbeeKjzQksUkRERERk35I6JN1www3Mnz+fzZs38/HHH3POOedgt9u56KKLEl2a7E3hSDj5Tuv+27dC2QoA7jhzBIW+FAB+N3sNs1eWJqpCEREREZF9SuqQtG3bNi666CKGDBnCBRdcQE5ODgsXLiQvLy/Rpcm+TLgSBp4M4RZ46gKo205eupv3bzyRYUU+wlGTq59ewpMLNmvVOxERERFJOl1q4YaDsb+Ts6SdNdfAY6dC5RrIHw4/nA0pGQTCEa5/fhmvL7c6SQ9eeBhnj+2Z4GJFRERE5FDQLRdukC4kNQtmvADeQqj4Ap77PkRCuB12/vTdsVx2bD8AfvHict75ojzBxYqIiIiIfEUhSTpOZm8rKLm8sOl9eOcOAOw2g5unDeXEIXm0hKJc/uQiFmyoSmytIiIiIiIxCknSsYpGw9mPWvcXPATzrYvOOuw2Hv3+EUwdUQDADS8sY/m22gQVKSIiIiLyFYUk6XjDz4Qpd1j35/0G3vsdAClOO3eeORKv28H22mbOevgjbn9lJdFot54mJyIiIiJJTiFJOsexP4UpsaXB37sH5t0LQGFGCq9efQznjO2JacKTC7bwx3fWadU7EREREUkYhSTpPMdeByf/2ro//7cw7x4wTfrnefnjhYdx9zkjAfjzu+u5/B+LqGoIJK5WERERETlkKSRJ5zrmWjjlbuv+/N/BO7+CaBSA7x3ZmzvPHIHLYWPumgqO/d08rn1mCZ9vrUlgwSIiIiJyqNF1kiQxFjwMb/3Sut/jcPje8+C1LhK8utTPz55fxhelfgAcNoPXrj2WoYX6/YmIiIjIwdN1kiS5TZwF5/wfONNgx+fw1HTY+SUAw4p8vH7tsfxi2lAAwlGTa55ewhc7/ImsWEREREQOEeokSWKVrYC/nQzhZkjLh/Meg37HxR8urWvmO3/6kKrGIDYDfjxpAOP7ZnPC4DwMw0hg4SIiIiLS1exvNlBIksSrXAfP/wAqV4Nhg3P/CqPOiz+8utTPnf9dxcKN1W2e9scLx3DO2F6dXa2IiIiIdFEabiddR95guPQNGHEOmFH4z2Xwn8uhsQqwht8986OjuG/6aPrmeOJPu+k/K3ht+Q4tFy4iIiIi7UqdJEkekTC8exd8/GcrLHly4Zy/wKCT47uYpsl/Pt/ODS8si2+b0C+baycP4piBuYmoWkRERES6CA23i1FI6oK2L4aXZ301/G785TDpZvBkx3dpCUX4v/kbeeS99QTC1hLiQwvTOWVEIacML2Bkz4xEVS8iIiIiSUohKUYhqYsKB+CNn8Pn/7C+T82GybfB4ZeAzR7fbVtNE4+8t4GnP9ka32a3GTw2czwnDM7r7KpFREREJIkpJMUoJHVxG+fDmzdZXSWAwlEw7X7oM7HNbuvK67n15ZV8uumrxR0uPqoPI3pYv/PzxxVjt2k1PBEREZFDmUJSjEJSNxAJwWd/h3n3QKDO2jbqfDj5LvD1iO9mmib+5jB3vfYF//l8W5tDDMz3cmS/bK6aNIBeWR5ERERE5NCjkBSjkNSNNO6EuXfB508CpnUh2mOuhXE/BG9+m13/vXgb73xRzvrKBtZXNMS3pzhtHNEni++M7sHkYfnkp6d08psQERERkURRSIpRSOqGdiyBN26EbZ9a39scMPxsOOlWyO632+6fbqrm4Xnr+XRTNc2hSHy7024wplcmgwq8XDVpIMXZ6jCJiIiIdGcKSTEKSd2UacLK/8Anf4Ftn1nb7C4YdiaMnQEDTtrtKdGoyccbqnh9xQ4+Wl/F1uqm+GO+FAdje2dx4pA8Zh6ze9ASERERka5PISlGIekQsGMpvHMHbJz31bZe42HcZTDibHCm7vFpS0tqWbylhhcWlbCmrD6+fdKQPNwOG0cPyOW7Rxbjdtj3+HwRERER6VoUkmIUkg4RpmldX2nZs7D4CYiGrO0pmXDY92DYGdBzHDhcuz21MRDmv8t28M+FW1i1w9/msfQUB31z0rhgXC8mDcnXkDwRERGRLkwhKUYh6RBUXwZL/gmLn4S6r66fhLcAjrgUek+A3keDc/dFG1Zur+PjDTupagjy0pLtVNQH2jyek+bCl+pkRA8fRRkpTB1RyLi+2bsdR0RERESSj0JSjELSISwagfVzrQvSbl0ATVVfPZaWB4OnwqBTYNDUPQamllCE15eXcu+ba6huDGBiNaxaMww4ekAO2WluCn1ujh6QyzEDc3E5bB373kRERETkgCkkxSgkCQDhIHzxCiz9F5SvgsbKrx5zZ1jD8foeC8VHQnZ/K/3E7Pon4m8O88mmKp79rIR311Ts9aWy01wc3juT8X2z8bgd9MhIoU9OGk3BMKN7ZXbUOxQRERGRb6CQFKOQJLuJhGDdbCj5BFa+BP62F56laAwUjoK+x8PgUyA1a7dDNAXDNAcjLNtWS1ldAH9LiK3VTbyxopTaptBeX3pwgRev28GkIflMP6IXPTOtRSWiUZMlJbWM6ZWBw64ulIiIiEhHUEiKUUiSfYpGYevHsPZN2LYIdnwOkWCrHQwoGg19j4P8YdbXrD57PVxVQ4D31lZS2xzi5SXbWbG9bq/7OmwGWWkuTNNkZ4P1mlkeJ7efMRyv28mJQ/Iorw+wZWcjEwfkYLTqbomIiIjIgVNIilFIkgPSUAnLn4Wd62DLx1C1fvd9iidYK+UZBmT1hRHnQlrOHg9nmib1gTB1TSFqm0J8vrWGivoW3vmigrXl9Xt8zi6jemawtqyeYCTKmWN6EI5G2dkQ5JThBWza2chxg3I5fnAeHpcD0zQVokRERES+gUJSjEKSfCv+Utj8IWz5CCrXWgtA8PXVG+zWQhD5Q62het5CKBgOhaPBs+eV78KRKG+tKicUidIvN423VpWxYGMVOxsClFQ3H1CJ/XLTKPe3UOhLoXeOh8EF6RzeOxN/S5hhhT6GFKbjctiorA+QkerUohIiIiJyyFJIilFIknblL4W1b0D1Rgg1wfbPoXTp3vfP6A2FI8Htg4IR1lyntDxr6J5tzxepjUZNVpf5eWNFKU67jb45acxeWcb22ma21TThtNt2W5p8f7nsNo4akMPRA3KIRE0WbKjCaTfol+ulJRzhlOEFDClMx+NykJHqPKjXEBEREUlWCkkxCknS4ao2WKvlla2w7vu3WfdrNu/9Oe4McHnA19PqPuUOBrvTClO9J0B6kfX9XkSjJsu317F5ZyMLN1bRHIowMM9LttfFvDUVbK1uwmYYbKlqojkUOeC3ZLcZHFacyaB8LxkeJ83BCF+WN9AUDDOyZwY/O2UIJdVNrCuvZ1iRj8EF6eyobWZ7bTP989Ioykg94NcUERER6WgKSTEKSZIwLXVWWKpYDc21ULbMGrLnL4XgvucjgWFd/NZXZAUphxta/NZ1nXw9wO6yvvp6gGGD1Mw9HqUpGGZ9RQNbq5sYWphOKGLy3Gcl7GwIsKWqiZE9fYQiJrVNQZZsraWqMbjH4xyM8X2zqG8J0y83jdG9MumT46GqIUA4ajKkIJ3a5hA5aS4GFaSzakcdK7f7mTggh8OKd38vmnMlIiIi7UEhKUYhSZJOJAyVayASsAJU5Vqo3QrRsNV9qlwL0b0vI75HjlTI6GmFqOYaK0TlDYHsAWBzgMMFKZngzYf0wj0ewjRNTBP8LSGqG4Os2F7Hu2sqqG8J43bYiJomRRmpLNxYxZqyehw2gzHFmazaUUdLKEqK04bTZqM+EP5WP55CXwo1TUEKfCkUZaQQjpos31bL2N5ZjOuTRZbHhcdtp7yuhcKMVNLcdib0y6GmKUhxtgev20FjIMynm6vpkZHKkML0b1WPiIiIdB8KSTEKSdLlRKPQtBP8O2K37dBUBaFmqzMVqIdwizW0L9R44Mf39YKUDHCng9sb++qzjhlstEJU32MhNdtawa/XeDBNa/if3YlpmlTUB0hzO/C6HbSEItS3hMn1uthS1cT9b69lcH46OV4X6SkOyupaWL6tjjJ/C9lpLnbUNlPuD1CcncrGykbqmg8wEO5DitNGmsvRpiN2eO9M8tLd8XlWvbJSWbChiuXb6zhmQA5H9M2mtjFIbrqbfrlpeN0OAALhCGDQEopwzMBcYM8drZZQhEjUJC32PBEREUleCkkxCknSbQUbIdAAZtRaRGLrQihdBukFEA7A9sXQUGFdPLeuxFooosXPbqvz7S+b05o7ld3P6lbZ7NZQwOwB1jHTcq0w5Uy1ulb5w6zOVTgAjhRrDtbXBMIRVmyrw5viwGGzsa2mCdOEHK+Lldv9bKhsID/dzdjeWcxbW0GFP0BdcwjDAJsBO2pb2LyzcY/dK6/bQcO37Grt4rQbHN47i1U7/ERNkz45aRRlpLC+ooFtNU0YhsEpwwswDGtxjBE9MqhtDhKKmKS5HJx1WA9qmoKU1DQzplcG22ub6ZmZSlFGKrVNQaoagwzK92K3GYQi1u9HqxCKiIi0P4WkGIUkEazwAtYCE7UlEPBbHalAPQQboKnaeiwagrpt1v1wwApDjZXf/vXtLsgfboW1tHxIzYKcAVbQcnqszlZarrXdNK2vNodVW68jwZliBTxfD2iptTpfsdUB65pDvLWyjJOG5fNleQMbdzYwoV82/XO9rNxRx/qKBhqDEZqDYSr8ASrqA3hTHAwr8vHZpmqaghHcDhvLt9fGl19PT3HgsBnUNLVfl2t/pLsdBMJRHHaDAl8KVQ0BfKlOPC47I3tk4LAbmCaEoyY9MlOoaQoxskcGaW47K7fXsWlnE75UB74UJw6bgd1uMHd1BUMK05nQLxsDGNs7i2AkSlVDkFE9M9hW08RhxZkYhkFNU5D0FKsj5nbsefVFERGRrkwhKUYhSeRbMM3YHCentfhExRfWPCqbwxr+V7MZDAAjNiSwCRqroLECGneCeeAr6+2TM80aYuj0WJ2q9CJwpUF9KWT2gYxeVk02O/Q+Gta/YwXBvsdY87XSi6y6Mntbc8LsLqvzFVPVECDVZcfjchCORKmoD5DitLNqRx0rttfRP9fLkMJ0Vpf62dkQYGdDkKGF6RT4Unh16XY+21xDIBxhQ2UjI3r4yEt3s7WqiY07vxoW6bLbyPW62FHX0r4/m2/JZkA09n8Dl93GlOH5+JvDZKQ6CUejlPsDuB02crwuJvbPwe2089mmahoCYT7ZVM3AfC/HDMilT46HbTVNLNlay9ryegble6lpCnHcoFx6ZaUSCEcZ1yebQDhCIBwlFIlyZL9sXHYboYiJ026tyuh02GgMhLHbDPrnptEcirChopFBBV42VjbSJ8dDmtsazrmlqpEj+2UTipjqwImIyD4pJMUoJIkkUHMtYFrBqXzFV3OfardaC1S40qyOVTT0VYcr1GKFKzMK9WVW56ijOFKtC/+CNTSxaIy1WqDLa60YmJIZ62rZrLpSfBCNWHO2MKw6nalWrWl54EjBxGB9ZSMD8rzYbNb8pQ2VDUSjJnnpbtwOO6kuO3VNIUxMvG4HNU0htlQ1YrcZ1DWHcNlt2GwGWR4XVY0BGlrCrNhex+rSekzTpG9uGpWxa2WtLavny4p6+ud5SXHa2FTZyNjeWXjdDppCETbtbGBgnhe3w06pv4VV2+vI9DjZ2dB+Kxl+WzlpLhx2g3J/gFSnfbdl630pDlpCUYKRaHxbeoqDwQXpLN5SY33vdtAcinBkv2yaQxGiUZOB+em0hCJsq20m1WnD63bidtiobAjQO9tD72wPOV4Xg/LTcdoNttc2k+VxUd0YZHSvDGyGwaebqjmiTxZ2m0HPzFR2Ngbwuh1srGwk1WWnrK6F4UU+bIbBsm21uB02+uWlxZbgb2RgXjqrSuuY0C+HQDhCisMePy92WV9RT3aam8xUJ7XNIbI8Tq3mKCLSQRSSYhSSRLow07QWr0jxgWG3hut5C6xAU/GF1b1qqbOG69WXWsur15VAJGh9v69rVXUEm8NapTAtHzzZVgfOk2N13RxuK2Bl9raCoiPVmt8VbLSCmMNtLZph2KzwWLfdugBxc621UmH1Buu5rtiCG5GQ1TFzpdESsoYMxj9Ym6a16MYe7Fp8IhI1aWgJs6OumcVbauibk0YgHMFmGERN60LDRZmphCNR1pTVs72mmWmjCmloCfPcohL8zSEm9M9hQJ6XYUXplNa18OrSHWyvbSYvtgjG/HWVBMNfBZshBdaCHiu215HmcuBvCREIR4lE9/y/Ia/bQTDcNhwlUprLTmPwm7ujhvHVCNdd0lMc1LeEcdoN8tNT6JWVisth44MvdwLWHDSnzaAxGKFvjgfDsBYNiZomQwp9HN47k9qmEKtL/USiJukp1kIk3hQHlfXWXL3mYIThPXz0yvKQ5XFRmOGmtK6FdWX1NAUjGAb4Upzk+9xMGVbAvxZuZWt1I5OHFVDdGKSuOcQXO/wMzPcyqMBLqtPO4IJ0BhV4AWsOYFVDgEA4ysbKBtJTnAwuSKe8voXirFSKsz0s2VpLcbaHgnQ3dptBOGpiAA671eGLRk3K61vwpTh3W+zENE0iUROH3bbbIinBcBSn3VB4FJFvTSEpRiFJ5BAWjX7VBTIjVqDy5FgLXGT1teZiVa7BWszCsDpczlRrLlRzrTXUsKXWCjLRsBVyardYAQasDpJ1p3Pfl931VUiyu8HusEJXNGx15oL1VpjK6gM9xn61qEbtFmtuV1oe5A2O/YwiVkhLL7Te565QV19m7dNSZ/1sgg3WvkNPh5Y6zGAjht1lBbpo2PpZFY7CNKwPw0Y0jBlowChfCcUTCGDHZQat0ZmthjiGQkEWbq4jEIoysmcG22ubGFLow2EzcDts7GwIsnhLdXzbF6V+Jg3JY+HGat5fV8mK7XWcNDQfl91GcbaHsrpmstPchKNRFm2uYU2Zn88211Dgc3PeEb1IcdjjQyjtNhslNU1U1geobwlhml/9JqtbrZBotxl7DXJfl5fujnf5DjV7Coet+VIcBCNRWkJR7DaD4wbl0tASjs+R29kQIBI1SXVa8+EGF6YztDCduuYQs1eWket1MyA/jRSHHV+qE6/bwbryeoYUpjOkMJ2PN1ThtBms2uFncEE6R/XPpqoxSG1TiLVl9aS5HfTKSiUv3c22mmaC4SgnDc0nEI4QDEfxuB1UNQT4aH0V4/pmcdygXBZurGbR5mpOHJpPQ0uYbTXNZKQ6ueakgTSHIoSjJmtK/ZT5reGzxw/KIxw1WbWjjo2VjfTPS8Nlt/HSku2cNqqIVJedjFQnfXPS2FDZgMthI9Vpx+2w4Ut1EghFWVdRT//cNErrWsj3uflihx+bYf28ttU0k+Fx4kvZ/WLjpmnSEAjjdTv2K0zuuuzDrs7mro+DBxNES6qb9lqXSLJRSIpRSBKRdrfrP5uRkPXJsKnK6l6ZptURqttuhatoBJqrrW1N1VY4qN1qBYvmGqhabw3pqy+1gk99mdUli4as0FKz2QoukaDVLdsV1pJZWp4V1AL+PT/u8kLf46zQVfKp1W0bPNV6f4bNCqfhFmtlxNRsKwgadqubmNnbWkjE7bN+vjaHteJiU5X1ujaHdT9nAGz+0Hq+rwgKR1uv01BhPRfTWq0x2GC9biRk/Yzd3niZDQErFKf5N0DuYOpDJuvK6umd4yEYjtIjI5WWWOftrVVljO6VSe9sD3abwY7aZqobgwQjURoDYYoyUli53c+Y4kzcDhuldS0s3FiFvyXEUf1yGJjvZcX2OvzNIU4YksfCjVVEo7BoSw1ry6yLLG/a2UhzMILDbuP4wXm47TbqmkNsrmpk5fY6+uamETUhM9VJQyDM6lI/a8rq6ZebxtQRhaSnOAjF5tmt2uFnWUktLrst3uEKRqxOza7VFfvlplHoS2FpSW18+KPLYaPQl0Jdc6jN0v1et4NAOBJ/7jf5pjAle5aR6qSuOYTNgCyPC1+qk9qmIFkeF8N7+Fi1w8+mnVYwG98n2wqfjUFSHDacDhsfrKtkSGE6hxVnsr22mXfXVJCe4uT4QXmsLfezaocfr8vBScPyiZrgsBlkp7nY2RBgY2UjHped847oRU1TkFeW7qAoI5W+OR6aQxGe+XQrGalOJg3JZ3Wpn8OKM4lETVKcdvrkeCipbsKE+KUYSmqasBsGHredYDjKsEIfxwzKJTPVSXMowuvLS1m4sYohhelUNwbpne3BYTOobwlTmJFCcyhCRqqTnDQ3OV4XKU47S7bWkOZ24HHZWb6tjqZgmH65Xo7ok8WO2mZME9aW19M/L41Q2JoLmZHqpKoxiN0w8KY42FrdRIrTTs/MVLZWNeF0GFQ3BinKSMVuM6hpDLJ8ex0LN1YxIM/L94/qjb85TKbHidNuIxSJEjXN+MI3X5bXU9scIj/djS/FSXl9C+GIyftfVnLG6B7ket2EolGagxEq6wNkpDopzm67EuzXwyxYHdmapiDrKxoY2TPjgC9BcTAXaA+EIzQHI2R6XLsdC9qG69bHT8aLwSskxSgkiUiXF2yKdbgarY5YU5UVHAzDCmShRkjJspZZN2yw/fOvVg7cNB8wrO/TC8GTa4Wvqi+tLpTDZR0j4Ldeo3qzdbxg41crD9qd1pyxSCDWPTOssBOsT+zP5UA4UiHcjLXSSKv/7XlyrJ9vJGD9bNzpVqh1plrDN+t3gLfQCmEpPusrpvWza6mDnWshoxh6H2UtCgJWCPYWWGE3Eo6txGjC6tes8Nd/krXIidMDOQOtUBlusa6D5smGfsdDfTlk97ee27jT+j1hWKG7xW9tLxxtzZ0LB2DTB9DrCOs5AKZJdX0TGfVfYl/xvNVRHH2+dazUbDbtKKMgLxeP0wE2G8FwFMOA5lCElmCE/Eg51G6lucdEKhoCRKMmOelufGYjUYeHpqgttthGlDS3g6ZgmJLqZvrkeGgMhKlpClJWF2DxlhpawhGyPS6OHphDmstBz6xUlm+r45NNVThtVudxRE8fgXCUQl8KjtjcvO21zSzZWktjIMy0UYVUN4aoqG+hKRChKRihvL6F2SvLyPI46Z3t4YTB+TQFrfl7wXCUTI+TvPQUdtQ2M39dJf3z0jiidxYlNU30zPSQ5rbz0fqduB12stKcbN7ZRCAc4bDiLJaW1FLVGGgT5o4blBtbtKXtfD67zaDQl0JLKEJVYxDDgP65afTP8/LFDj/ba2OrZrodZHic1LeE24RMm2GdkV//NOZy2NoMV5X25bLbcNqNPQ6h3d/usSM2pNRpN/C4HNQ1h7DbDAbkpWG32Vhdupc/Fu1DdporPi8xJ83F1uomqhqD9M3x0BiIUOZvaVNbrtdNUUYKHpedzVWNlPsDuBw2PC47vhQnkahJdpqLYGyhnLx0N+vK66lpCllB0+vCZbeRFxsiW5SRQiAcpb4lzLAiH163HZth8PSnW9lS1cSpIwrZXNXIl+UN9MpOpdIfwG43mDaykAKfdWmM+Wsr6ZPrYWCel7mrK+id4+G8I3oxqmcG4/pmH/DPpL0pJMUoJImItKNgoxWUXF7ra0O51ZWxO2LDE2PD85qqYotamNay8ikZULPJCnGmaQW6yrVWN8fmsLZHI1a4MCNWx2znl1+trmhGrQ/46UVWwGiutbpKdqc1nLC+3AolKRlQvTHRP6XEMWxWB62lzvp5tJZeZHUtvQXWz86MWr+7nAFWJ83mtH7ukaDV1YyGrAAI1ly/rL7WHEGX11pdMtxiBciMnlZ4rC+DNa9Bn6OhYCSsn2uFT19Pa/6dt8AKcTuWWB09h9s6XkMFDDsDMK1zINRs3TdsVofVW2A93zS/Wjlz+XNWMB1+lvW6lWutPwLkDraCrhm1Lrjt8lj1puVCOAifPGp1bwtGWMHRsH3V2tr11+7yLzANG9HcIdhtBoGWRuqCdvJTrevAbdrZSNQ0rUBnN7AZBs7mneDJobIxjMdlj/9l3zRNKusDZKe54vOyTNNka3UT+ekphKNRHDYbboeNhmAYA2v5/XXl9fGhhnabEe+CjOyZQXMwQlVjgLqmEOkpVldmXVk93hQHp44sZOHGKhZsqCLFaSfP68Zht1HbFGRkzwxqm4Ks3O6nV1YqI3tZx1pd6qdfbhoT+uewoaKB/y7bQWrsA3YoGo0PD1xTVs+7a8rJ9bpJcdgpykzBNCFqmhzRJ4stVU2sLa8nz+tmZ0MAj8tOqtPO0m11+FIcDMjz0hgI0xSKEAhF8bjsNAbCNATCbK1uoszfEg+KfXI89MpKJdfrxt8cinU6rZ/T+ooGbIZBKBJlR20LwUgUl91Gr+xUtlQ1keay0ycnjRE9fMxfV0lpbCVRp91gXJ9sqhuDVDcF9zgsdk9dztYdVpfdxrAePgrS3SzeUtPmwuV7YjOgZ1YqO2pbdgtdh2JHdXzfLF648uhEl6GQtItCkojIISbUbAW0Fv9XQxtb6qwP5s3VVojwb7cCQN1W63FnmvWBuWln7JNLbPn7XuOtDg9Yn2oaKq39gvVWIMvsA2XLoXqT1dXxl1ohA9PqInmyv5rfVr7KutaXy2N9baiMLeKRYh2/vtQKjeGANbSwco31Ad+TYw0JNKPWccLNifm5dhW2WKhufQkCT671+/v6dd98vawOYcUX1vcpmV+tqJk9wPpd+LdZ8/aarZUUsbut+X4urxXMwi2w4V0rABZPsF6juda6X73BGlbq8kJOfyvw5Q6yzg1vnnVeVm+yOoN5w6xzLRK0zo+y5ZDVDzKLYekzVofR7bWOlzPAqt2VZr0vm9P6GgnBihesc/GoWVbnsqXO+jeR1cf6uax6GYqPjIVEAzCs97xtkfV+DcPqUrq9VrB0eWJ/DHHE/sCRZh136ydWeE3JgKVPQc4ga87iznVWl9SdDuUrrTmhPQ6zArDNbv07bNpp/cGlfBW40jAHTiFSU0KjM4uozU1WWmxIVzRqBWO3b48XJAdoaWnGtmEurn5H0xKO4t72MUbvibBpPuaAkwi5MmkMhAlFouSnu8EwME0zFnahODuVuqYQhmHEL3lQ4Q+Q6XGSEpsvVlrXgi/VWh3TGQu7LQ21bG+25rlV+AO0hCLket0EwlFWl/lpDIQ5vHcWPTJT8beE2BkbThcIR+mRmRrvPIbCUXpnewhGosz5wgqhdc1BXA5rSG12mhunzaCqMYjTbsOX4sCX6iTVaSPfl8Jbq8oJR6I47Da2VjexfFstJw8vID89hdWlfoLhKP1y08jxulhTVs+qHX76ZHtw2A2OHpDL/HUVfLqpmu+M7kFLKEJpXQuBcJSiDOv5DruNCn8LaW4HU0cUsLSkDq/bzmmjilhWUkswEqU5GOXjDTvpne2hKCOF7DQXLeEoJdVNrC2rpzEYocDnZmxxFj+ZMujb/gv/1hSSYhSSRESkS9rbKoUtdVaoC7dY3Z7mWutD9dYFVvALNcXmbdVZH3QNGwQarBC2q+vmTLW6OPnDrA/AuzqD0bC1364Q11hhdQV3rrO6Oobd6uAEG6F0qRUkgo3Wa9qd1gdj/w6o2WJ9qM3sY9VZvcl6zV3HBuuDtNNjfZBurLQCR6jF+tCNadXZUmeFwkjsL/ap2V8twvJNnB6rLulgXxvCejA8OdZ5BlbHsrHKCpH+0q/+KOBIsS5KHg5YnU1naqwzudTax+W1/sjQ5ri5sVVCa6zzsG6b9TxfT+vfV1oOVK6DPhOt83LTB9Y5bLNboa73ROscCtRb7zHYZP17iYSgZKH1GkNOt4YrBxusYb27AmG42Qqkvh5WwN3ysTXUufdEa8XS5lpoKINtn8UW2ulrhdfaLda/g/yhVoc2e4D1OmbE+vdTWwLbF1v/3geeDIddZNVXvcnq4noLYn9wabT+0FK51vpjT99jrOflDLLeY2qW9Uec9XOt7z051rUFB51sHa9oTNs/zrTUWv8mUzPh0/9n/R5Ous36t7nkX9bxM4qtPzjUbYdh37FCfqu5nslCISlGIUlERKQL2/UxZU+BMdhofXg2bFaQSy+yht+5vdb9SND6gFe3zfoQXnSY9YGweqMVCJuqrA+3mX2++t7htj6cuzzWB8ecgVbHIxywOiC5Q6BytfUBvL7U+hCZN9TqTjaUW52maNi6v+tDe3Z/a/+GMqtbFGqx5v6l97C6hv7tVp35w6z3UrbC+oDs32F9YHekWIu/GIb1IXvje9aH1pQMq0sUarLuu7zWh+/UTOsDeaDe6vzY7Nb2UHNsXqHZanXOmIJRsQ/7jV+tkrnLrgDiSrdey4x8dXFviA3V/NrwTrA6cykZ1gd/OQQZscVysM7d/pPggn8ktCLY/2xwYMthiIiIiHSmfa2M5Ur76n7eEOtrSqsPPbuuP5Ze2PZ5hSMPrIavP7/3hAN7fns76ZaDe96uyyJEo63CUqxjaf/a8t2maQUjM2oFnXDQCnAtdVYnJ3+4FfoiISsEhpqs1Tu9BVYXL1Bv/S5sTqvrmDPQen7tFitottRa++8Kg3aHNV8td7AVrhorrE5ERi9Y+R/ruZGgFfTcPqumaMgKl3lDre5NU5XV8Wyusea5rX3DCn6eXGt7006rE7Nrfl00ZB033BKrN9P62lgRuzxC5lev1VQFGFYwrNseu4h4rhXG/dutQJ3Z+6vhk821MHCKVXPpMivE9xoP2z61frYZxVbYbdpp7dPvBCsMlyy0fj8DT7JqaaqKzZ2Lvf+d660hm85U62dftw2cKdbPoGKN9d4zesUW8rFbrwfW+8/sHVsIJrbiajRkBV8z8lXX1bBZQf/rw3pd6dYwz5pN39zJTc22hjZjQqDVvsHGgzhpE0edJBERERGRrmBX0D3Q55iRtkE4Ghu+l5YfC0nN1vC7cMAKts3VVtc13GIFJ3e69bxQsxWwfD2sxVGcqVZYbNxpBd7mGkgvsI5Ts8UKYo4U6/WcKVZQSzANt4tRSBIREREREdj/bHCAUVRERERERKR7U0gSERERERFpRSFJRERERESkFYUkERERERGRVhSSREREREREWlFIEhERERERaaVLhKSHH36Yvn37kpKSwoQJE/j0008TXZKIiIiIiHRTSR+SnnvuOa6//np+9atf8fnnnzNmzBimTp1KRUVFoksTEREREZFuKOlD0gMPPMCPfvQjLr30UoYPH85f/vIXPB4Pjz32WKJLExERERGRbiipQ1IwGGTx4sVMmTIlvs1mszFlyhQWLFiwx+cEAgH8fn+bm4iIiIiIyP5K6pC0c+dOIpEIBQUFbbYXFBRQVla2x+fce++9ZGRkxG/FxcWdUaqIiIiIiHQTSR2SDsbNN99MXV1d/FZSUpLokkREREREpAtxJLqAfcnNzcVut1NeXt5me3l5OYWFhXt8jtvtxu12d0Z5IiIiIiLSDSV1J8nlcnHEEUcwd+7c+LZoNMrcuXOZOHFiAisTEREREZHuKqk7SQDXX389l1xyCePGjePII4/kwQcfpLGxkUsvvXS/nm+aJoAWcBAREREROcTtygS7MsLeJH1IuvDCC6msrOT222+nrKyMww47jNmzZ++2mMPe1NfXA2gBBxERERERAayMkJGRsdfHDfObYlQXF41G2bFjB+np6RiGkdBa/H4/xcXFlJSU4PP5ElqLdA06Z+RA6ZyRA6VzRg6Uzhk5UMl0zpimSX19PT169MBm2/vMo6TvJH1bNpuNXr16JbqMNnw+X8JPEOladM7IgdI5IwdK54wcKJ0zcqCS5ZzZVwdpl6ReuEFERERERKSzKSSJiIiIiIi0opDUidxuN7/61a90HSfZbzpn5EDpnJEDpXNGDpTOGTlQXfGc6fYLN4iIiIiIiBwIdZJERERERERaUUgSERERERFpRSFJRERERESkFYUkERERERGRVhSSOtHDDz9M3759SUlJYcKECXz66aeJLkkS4N5772X8+PGkp6eTn5/P2Wefzdq1a9vs09LSwqxZs8jJycHr9TJ9+nTKy8vb7LN161ZOP/10PB4P+fn5/PznPyccDnfmW5EE+e1vf4thGFx33XXxbTpn5Ou2b9/O97//fXJyckhNTWXUqFEsWrQo/rhpmtx+++0UFRWRmprKlClT+PLLL9sco7q6mhkzZuDz+cjMzOSyyy6joaGhs9+KdIJIJMJtt91Gv379SE1NZcCAAfz617+m9fpeOmcObe+//z5nnHEGPXr0wDAMXn755TaPt9f5sXz5co477jhSUlIoLi7mvvvu6+i3tmemdIpnn33WdLlc5mOPPWauWrXK/NGPfmRmZmaa5eXliS5NOtnUqVPNxx9/3Fy5cqW5dOlS87TTTjN79+5tNjQ0xPe58sorzeLiYnPu3LnmokWLzKOOOso8+uij44+Hw2Fz5MiR5pQpU8wlS5aYb7zxhpmbm2vefPPNiXhL0ok+/fRTs2/fvubo0aPNn/zkJ/HtOmekterqarNPnz7mzJkzzU8++cTcuHGj+dZbb5nr16+P7/Pb3/7WzMjIMF9++WVz2bJl5plnnmn269fPbG5uju9z6qmnmmPGjDEXLlxofvDBB+bAgQPNiy66KBFvSTrY3Xffbebk5JivvfaauWnTJvOFF14wvV6v+b//+7/xfXTOHNreeOMN85ZbbjFffPFFEzBfeumlNo+3x/lRV1dnFhQUmDNmzDBXrlxpPvPMM2Zqaqr5f//3f531NuMUkjrJkUceac6aNSv+fSQSMXv06GHee++9CaxKkkFFRYUJmPPnzzdN0zRra2tNp9NpvvDCC/F9Vq9ebQLmggULTNO0/kNls9nMsrKy+D6PPvqo6fP5zEAg0LlvQDpNfX29OWjQIHPOnDnmCSecEA9JOmfk62666Sbz2GOP3evj0WjULCwsNO+///74ttraWtPtdpvPPPOMaZqm+cUXX5iA+dlnn8X3efPNN03DMMzt27d3XPGSEKeffrr5wx/+sM22c88915wxY4ZpmjpnpK2vh6T2Oj8eeeQRMysrq83/l2666SZzyJAhHfyOdqfhdp0gGAyyePFipkyZEt9ms9mYMmUKCxYsSGBlkgzq6uoAyM7OBmDx4sWEQqE258vQoUPp3bt3/HxZsGABo0aNoqCgIL7P1KlT8fv9rFq1qhOrl840a9YsTj/99DbnBuickd29+uqrjBs3jvPPP5/8/HzGjh3LX//61/jjmzZtoqysrM05k5GRwYQJE9qcM5mZmYwbNy6+z5QpU7DZbHzyySed92akUxx99NHMnTuXdevWAbBs2TI+/PBDpk2bBuickX1rr/NjwYIFHH/88bhcrvg+U6dOZe3atdTU1HTSu7E4OvXVDlE7d+4kEom0+XACUFBQwJo1axJUlSSDaDTKddddxzHHHMPIkSMBKCsrw+VykZmZ2WbfgoICysrK4vvs6Xza9Zh0P88++yyff/45n3322W6P6ZyRr9u4cSOPPvoo119/Pb/85S/57LPPuPbaa3G5XFxyySXx3/mezonW50x+fn6bxx0OB9nZ2TpnuqFf/OIX+P1+hg4dit1uJxKJcPfddzNjxgwAnTOyT+11fpSVldGvX7/djrHrsaysrA6pf08UkkQSaNasWaxcuZIPP/ww0aVIEispKeEnP/kJc+bMISUlJdHlSBcQjUYZN24c99xzDwBjx45l5cqV/OUvf+GSSy5JcHWSjJ5//nmeeuopnn76aUaMGMHSpUu57rrr6NGjh84ZOSRpuF0nyM3NxW6377bSVHl5OYWFhQmqShLt6quv5rXXXmPevHn06tUrvr2wsJBgMEhtbW2b/VufL4WFhXs8n3Y9Jt3L4sWLqaio4PDDD8fhcOBwOJg/fz5/+tOfcDgcFBQU6JyRNoqKihg+fHibbcOGDWPr1q3AV7/zff1/qbCwkIqKijaPh8Nhqqurdc50Qz//+c/5xS9+wXe/+11GjRrFxRdfzE9/+lPuvfdeQOeM7Ft7nR/J9P8qhaRO4HK5OOKII5g7d258WzQaZe7cuUycODGBlUkimKbJ1VdfzUsvvcS77767W1v5iCOOwOl0tjlf1q5dy9atW+Pny8SJE1mxYkWb/9jMmTMHn8+32wcj6fomT57MihUrWLp0afw2btw4ZsyYEb+vc0ZaO+aYY3a7tMC6devo06cPAP369aOwsLDNOeP3+/nkk0/anDO1tbUsXrw4vs+7775LNBplwoQJnfAupDM1NTVhs7X9WGi324lGo4DOGdm39jo/Jk6cyPvvv08oFIrvM2fOHIYMGdKpQ+0ALQHeWZ599lnT7XabTzzxhPnFF1+YV1xxhZmZmdlmpSk5NPz4xz82MzIyzPfee88sLS2N35qamuL7XHnllWbv3r3Nd99911y0aJE5ceJEc+LEifHHdy3nfMopp5hLly41Z8+ebebl5Wk550NI69XtTFPnjLT16aefmg6Hw7z77rvNL7/80nzqqadMj8dj/utf/4rv89vf/tbMzMw0X3nlFXP58uXmWWedtcfleseOHWt+8skn5ocffmgOGjRIyzl3U5dcconZs2fP+BLgL774opmbm2veeOON8X10zhza6uvrzSVLlphLliwxAfOBBx4wlyxZYm7ZssU0zfY5P2pra82CggLz4osvNleuXGk+++yzpsfj0RLg3d2f//xns3fv3qbL5TKPPPJIc+HChYkuSRIA2OPt8ccfj+/T3NxsXnXVVWZWVpbp8XjMc845xywtLW1znM2bN5vTpk0zU1NTzdzcXPNnP/uZGQqFOvndSKJ8PSTpnJGv++9//2uOHDnSdLvd5tChQ83/9//+X5vHo9Goedttt5kFBQWm2+02J0+ebK5du7bNPlVVVeZFF11ker1e0+fzmZdeeqlZX1/fmW9DOonf7zd/8pOfmL179zZTUlLM/v37m7fcckubpZh1zhza5s2bt8fPL5dccolpmu13fixbtsw89thjTbfbbfbs2dP87W9/21lvsQ3DNFtdSllEREREROQQpzlJIiIiIiIirSgkiYiIiIiItKKQJCIiIiIi0opCkoiIiIiISCsKSSIiIiIiIq0oJImIiIiIiLSikCQiIiIiItKKQpKIiIiIiEgrCkkiIiL7YBgGL7/8cqLLEBGRTqSQJCIiSWvmzJkYhrHb7dRTT010aSIi0o05El2AiIjIvpx66qk8/vjjbba53e4EVSMiIocCdZJERCSpud1uCgsL29yysrIAayjco48+yrRp00hNTaV///78+9//bvP8FStWcNJJJ5GamkpOTg5XXHEFDQ0NbfZ57LHHGDFiBG63m6KiIq6++uo2j+/cuZNzzjkHj8fDoEGDePXVVzv2TYuISEIpJImISJd22223MX36dJYtW8aMGTP47ne/y+rVqwFobGxk6tSpZGVl8dlnn/HCCy/wzjvvtAlBjz76KLNmzeKKK65gxYoVvPrqqwwcOLDNa9x5551ccMEFLF++nNNOO40ZM2ZQXV3dqe9TREQ6j2GappnoIkRERPZk5syZ/Otf/yIlJaXN9l/+8pf88pe/xDAMrrzySh599NH4Y0cddRSHH344jzzyCH/961+56aabKCkpIS0tDYA33niDM844gx07dlBQUEDPnj259NJL+c1vfrPHGgzD4NZbb+XXv/41YAUvr9fLm2++qblRIiLdlOYkiYhIUjvxxBPbhCCA7Ozs+P2JEye2eWzixIksXboUgNWrVzNmzJh4QAI45phjiEajrF27FsMw2LFjB5MnT95nDaNHj47fT0tLw+fzUVFRcbBvSUREkpxCkoiIJLW0tLTdhr+1l9TU1P3az+l0tvneMAyi0WhHlCQiIklAc5JERKRLW7hw4W7fDxs2DIBhw4axbNkyGhsb449/9NFH2Gw2hgwZQnp6On379mXu3LmdWrOIiCQ3dZJERCSpBQIBysrK2mxzOBzk5uYC8MILLzBu3DiOPfZYnnrqKT799FP+/ve/AzBjxgx+9atfcckll3DHHXdQWVnJNddcw8UXX0xBQQEAd9xxB1deeSX5+flMmzaN+vp6PvroI6655prOfaMiIpI0FJJERCSpzZ49m6KiojbbhgwZwpo1awBr5blnn32Wq666iqKiIp555hmGDx8OgMfj4a233uInP/kJ48ePx+PxMH36dB544IH4sS655BJaWlr44x//yA033EBubi7nnXde571BERFJOlrdTkREuizDMHjppZc4++yzE12KiIh0I5qTJCIiIiIi0opCkoiIiIiISCuakyQiIl2WRoyLiEhHUCdJRERERESkFYUkERERERGRVhSSREREREREWlFIEhERERERaUUhSUREREREpBWFJBERERERkVYUkkRERERERFpRSBIREREREWnl/wOE3762mIwziwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training and validation loss\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(finetuning_train_losses, label='Train Loss')\n",
    "plt.plot(finetuning_val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss Curve')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
