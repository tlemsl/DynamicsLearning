{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from RobotModel import RobotDynamicsModel, TransformerDecoderModel2D\n",
    "\n",
    "\n",
    "# Ensure matplotlib inline mode for Jupyter\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_paths = [\"../RC/Data/Mujoco_less_friction_track_mppi.csv\",\n",
    "#               \"../RC/Data/Mujoco_less_friction_track_mppi2.csv\",\n",
    "#               \"../RC/Data/Mujoco_less_friction_track_manual.csv\",\n",
    "#               \"../RC/Data/Mujoco_less_friction_track_manual2.csv\",\n",
    "#               \"../RC/Data/Mujoco_less_friction_track_manual3.csv\",\n",
    "#               \"../RC/Data/Mujoco_less_friction_track_manual4.csv\",\n",
    "#               \"../RC/Data/Mujoco_less_friction_track_manual5.csv\",\n",
    "#               \"../RC/Data/Mujoco_less_friction_track_manual6.csv\",\n",
    "#               \"../RC/Data/Mujoco_less_friction_track_NNmppi.csv\",\n",
    "#               \"../RC/Data/Mujoco_less_friction_track_NNmppi2.csv\",\n",
    "#               \"../RC/Data/Mujoco_less_friction_track_NNmppi3.csv\",\n",
    "#               \"../RC/Data/Mujoco_less_friction_random.csv\",\n",
    "#               \"../RC/Data/Mujoco_less_friction_random2.csv\",\n",
    "#               \"../RC/Data/Mujoco_less_friction_random3.csv\",\n",
    "#               \"../RC/Data/Mujoco_less_friction_random4.csv\",\n",
    "#               \"../RC/Data/Mujoco_less_friction_random5.csv\"]\n",
    "\n",
    "file_paths = [\"../RC/Data/Mujoco_less_friction_random5.csv\"]\n",
    "\n",
    "# file_paths = [\"Data/Mujoco_less_friction_track_manual.csv\", \"Data/Mujoco_less_friction_track_manual2.csv\", \"Data/Mujoco_less_friction_track_manual3.csv\", \"Data/Mujoco_less_friction_track_manual4.csv\", \"Data/Mujoco_less_friction_track_manual5.csv\", \"Data/Mujoco_less_friction_track_manual6.csv\"]\n",
    "# file_paths = [\"Data/Mujoco_less_friction_track_mppi.csv\", \"Data/Mujoco_less_friction_track_mppi2.csv\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_time = pd.Timestamp.now()\n",
    "tag = f\"{cur_time.year}_{cur_time.month}_{cur_time.day}_{cur_time.hour}_{cur_time.minute}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_path(states):\n",
    "    x = states[:,0]\n",
    "    y = states[:,1]\n",
    "    yaw = states[:, 2]\n",
    "    # Create a figure for the plot\n",
    "    plt.figure(figsize=(10, 10))\n",
    "\n",
    "    # Plot the robot's trajectory\n",
    "    plt.plot(x, y, label=\"Trajectory\")\n",
    "\n",
    "    # Add quiver plot to show yaw at different points\n",
    "    skip = 1  # Plot yaw every 'skip' points to avoid clutter\n",
    "    plt.quiver(x[::skip], y[::skip], np.cos(yaw[::skip]), np.sin(yaw[::skip]), \n",
    "            color='r', scale=50, label=\"Yaw\")\n",
    "\n",
    "    # Add labels and title\n",
    "    plt.xlabel(\"X position\")\n",
    "    plt.ylabel(\"Y position\")\n",
    "    plt.title(\"Robot Pose (Trajectory and Yaw)\")\n",
    "    plt.legend()\n",
    "\n",
    "    # Show the plot\n",
    "    plt.grid(True)\n",
    "    plt.axis('equal')  # Ensure equal scaling for both axes\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sophuspy as sp\n",
    "def pi2pi(angle):\n",
    "    \"\"\"\n",
    "    Normalize angle to [-π, π] range using modulo operation.\n",
    "    \n",
    "    Args:\n",
    "        angle (float): Input angle in radians\n",
    "    \n",
    "    Returns:\n",
    "        float: Normalized angle in radians between -π and π\n",
    "    \"\"\"\n",
    "    return ((angle + np.pi) % (2 * np.pi)) - np.pi\n",
    "\n",
    "def rotation_matrix_SO2(yaw):\n",
    "    return np.array([[np.cos(yaw), - np.sin(yaw)], [np.sin(yaw), np.cos(yaw)]])\n",
    "    \n",
    "# Assume sophuspy provides SE2 for pose manipulation and log/exp mapping\n",
    "def apply_relative_transformation(states):\n",
    "    \"\"\"Transform all states with respect to the last pose using SE(2) log and exp.\"\"\"\n",
    "    transformed_states = []\n",
    "    \n",
    "    pivot_pose = sp.SE2(rotation_matrix_SO2(states[-2, 2]), states[-2, 0:2])\n",
    "    \n",
    "    # Transform each pose relative to the last one\n",
    "    for x, y, yaw in states:\n",
    "        current_pose = sp.SE2(rotation_matrix_SO2(yaw), np.array([x, y]))\n",
    "        relative_pose = pivot_pose.inverse() * current_pose  # relative transformation\n",
    "        # print(relative_pose.log())\n",
    "        transformed_states.append( (relative_pose).log())\n",
    "    return transformed_states\n",
    "\n",
    "def apply_simple_deletion_transformation(states):\n",
    "    transformed_states = []\n",
    "    pivot_pose = states[-2]\n",
    "    for i in range(len(states)):\n",
    "        transformed_states.append(states[i] - pivot_pose)\n",
    "    return transformed_states\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../RC/Data/Mujoco_less_friction_random5.csv is 69.79429014921189m\n",
      "Total duration is 69.79429014921189m\n"
     ]
    }
   ],
   "source": [
    "# Constants\n",
    "h = 20  # history length\n",
    "batch_size = 500 # Define batch size for DataLoader\n",
    "train_val_split_ratio = 0.8  # 80% train, 20% validation\n",
    "state_columns = ['x', 'y', 'yaw']\n",
    "states_dof = len(state_columns)  # x, y, yaw\n",
    "# Prepare the data\n",
    "action_columns = ['accel', 'steer']\n",
    "\n",
    "# Create sequences with history length h\n",
    "input_sequences = []\n",
    "output_sequences = []\n",
    "tot_duration = 0\n",
    "num_of_augmentation = 1\n",
    "# file_paths = [\"Data/Mujoco_less_friction_track_mppi.csv\"]\n",
    "for file_path in file_paths:\n",
    "    path_data = pd.read_csv(file_path)\n",
    "\n",
    "    # Display the first few rows\n",
    "    path_data.head()\n",
    "    times = np.array(path_data[\"timestamp\"])\n",
    "    dataset_duration = times[-1] - times[0]\n",
    "    tot_duration += dataset_duration\n",
    "    print(f\"{file_path} is {dataset_duration/60}m\")\n",
    "    states = path_data[state_columns].values\n",
    "    actions = path_data[action_columns].values\n",
    "    # plot_path(states)\n",
    "    # cnt = 0\n",
    "    for _ in range(num_of_augmentation):\n",
    "        # plot_path(augmented_states)\n",
    "        for i in range(len(states) - h - 20 * 30):\n",
    "            # Original sequence\n",
    "            # plot_path(states[i:i + h + 1])\n",
    "            if times[i+h] - times[i+h - 1] > 1/18:\n",
    "                # cnt+=1\n",
    "                continue\n",
    "\n",
    "            transformed_state = apply_relative_transformation(states[i:i + h + 1])\n",
    "            # transformed_state = states[i:i + h + 1]\n",
    "            # plot_path(np.array(transformed_state))\n",
    "            # break\n",
    "            # plot_path(np.array(transformed_state))\n",
    "            input_seq = np.concatenate((transformed_state[:h], actions[i:i + h]), axis=1).flatten()\n",
    "            output_seq = transformed_state[h]\n",
    "            input_sequences.append(input_seq)\n",
    "            output_sequences.append(output_seq)\n",
    "    # print(len(times) -  cnt)\n",
    "print(f\"Total duration is {tot_duration/60}m\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([83133, 100]) torch.Size([83133, 3])\n"
     ]
    }
   ],
   "source": [
    "# Convert to NumPy arrays and then to PyTorch tensors\n",
    "input_sequences = np.array(input_sequences)\n",
    "output_sequences = np.array(output_sequences)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "inputs = torch.tensor(input_sequences, dtype=torch.float32)\n",
    "outputs = torch.tensor(output_sequences, dtype=torch.float32)\n",
    "# Check shapes\n",
    "print(inputs.shape, outputs.shape)  # (samples, h * (|x| + |a|)), (samples, |x|)\n",
    "\n",
    "# Dataset and DataLoader Setup\n",
    "dataset = TensorDataset(inputs, outputs)\n",
    "\n",
    "# Split dataset into train, validation, and test sets (80-10-10 split)\n",
    "train_size = int(len(dataset) * train_val_split_ratio)\n",
    "val_size = (len(dataset) - train_size) // 2\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "\n",
    "train_set, val_set, test_set = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerDecoderModel2D(\n",
       "  (input_projection): Linear(in_features=100, out_features=128, bias=True)\n",
       "  (transformer_decoder): TransformerDecoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-1): 2 x TransformerDecoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (multihead_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=128, out_features=256, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=256, out_features=128, bias=True)\n",
       "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (output_projection): Linear(in_features=128, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Instantiate the model\n",
    "input_size = h * (len(state_columns) + len(action_columns))  # h * (|x| + |a|)\n",
    "\n",
    "# model = RobotDynamicsModel(input_size, len(state_columns))\n",
    "# model\n",
    "\n",
    "model = TransformerDecoderModel2D(input_size, len(state_columns))\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "# Define the evaluate function to calculate loss on validation/test sets\n",
    "def evaluate(loader):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    total_loss, total_samples = 0, 0\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient calculation for evaluation\n",
    "        for inputs, targets in loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            predictions = model(inputs)\n",
    "            loss = criterion(predictions, targets)\n",
    "            total_loss += loss.item() * len(targets)\n",
    "            total_samples += len(targets)\n",
    "\n",
    "    return total_loss / total_samples  # Return average loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Training w {device}\")\n",
    "# Training loop with validation\n",
    "best_val_loss = float('inf')  # Initialize best validation loss to infinity\n",
    "train_losses, val_losses = [], []\n",
    "epochs = 100\n",
    "last_saved_epoch = - 10\n",
    "for epoch in range(epochs):\n",
    "    model.train()  # Set model to training mode\n",
    "\n",
    "    train_loss = 0  # Accumulate training loss\n",
    "    for inputs, targets in train_loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        \n",
    "        # print(inputs.shape)\n",
    "\n",
    "        # Forward pass\n",
    "        optimizer.zero_grad()  # Clear previous gradients\n",
    "        predictions = model(inputs)\n",
    "        # print(predictions.shape, targets.shape)\n",
    "        loss = criterion(predictions, targets)  # Compute loss\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()  # Backpropagate gradients\n",
    "        optimizer.step()  # Update model parameters\n",
    "\n",
    "        train_loss += loss.item() * len(targets)  # Accumulate loss\n",
    "\n",
    "    # Calculate average train loss for the epoch\n",
    "    train_loss /= len(train_set)\n",
    "\n",
    "    # Evaluate on validation set\n",
    "    val_loss = evaluate(val_loader)\n",
    "    # Track losses per epoch\n",
    "    if val_loss < 10 and train_loss < 10:\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "    # Save the best model based on validation loss\n",
    "    if val_loss < best_val_loss and epoch - last_saved_epoch > 10:\n",
    "        last_saved_epoch = epoch\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), f'Mujoco_model_v2.pth')\n",
    "        print(f\"Saved Best Model at Epoch {epoch + 1} with Validation Loss: {val_loss:.4f}\")\n",
    "\n",
    "    # Print progress every 1000 epochs\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch + 1}/{epochs}], Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}')\n",
    "\n",
    "# Evaluate on the test set after training completes\n",
    "test_loss = evaluate(test_loader)\n",
    "print(f'Test Loss: {test_loss:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training and validation loss\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss Curve')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
