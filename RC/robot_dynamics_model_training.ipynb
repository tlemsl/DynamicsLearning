{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86addc13",
   "metadata": {},
   "source": [
    "# Robot Dynamics Model Training\n",
    "This notebook trains a robot dynamics model using the architecture specified. The model will predict the next state of the robot given a sequence of previous states and actions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72051a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Ensure matplotlib inline mode for Jupyter\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754d7240",
   "metadata": {},
   "source": [
    "### Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82b8ca36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>yaw</th>\n",
       "      <th>v_horizontal</th>\n",
       "      <th>v_vertical</th>\n",
       "      <th>accel</th>\n",
       "      <th>steer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2048.004209</td>\n",
       "      <td>452197.462912</td>\n",
       "      <td>3.949667e+06</td>\n",
       "      <td>88.468085</td>\n",
       "      <td>-0.390413</td>\n",
       "      <td>0.011836</td>\n",
       "      <td>0.030021</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2048.104465</td>\n",
       "      <td>452197.467826</td>\n",
       "      <td>3.949667e+06</td>\n",
       "      <td>88.463231</td>\n",
       "      <td>-0.393374</td>\n",
       "      <td>0.038694</td>\n",
       "      <td>-0.091738</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2048.207218</td>\n",
       "      <td>452197.465972</td>\n",
       "      <td>3.949667e+06</td>\n",
       "      <td>88.469801</td>\n",
       "      <td>-0.385135</td>\n",
       "      <td>0.049873</td>\n",
       "      <td>0.043076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2048.304435</td>\n",
       "      <td>452197.465861</td>\n",
       "      <td>3.949667e+06</td>\n",
       "      <td>88.467945</td>\n",
       "      <td>-0.380474</td>\n",
       "      <td>0.034952</td>\n",
       "      <td>-0.009294</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2048.404340</td>\n",
       "      <td>452197.465777</td>\n",
       "      <td>3.949667e+06</td>\n",
       "      <td>88.468571</td>\n",
       "      <td>-0.386001</td>\n",
       "      <td>0.013054</td>\n",
       "      <td>-0.024935</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-38.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     timestamp              x             y          z       yaw  \\\n",
       "0  2048.004209  452197.462912  3.949667e+06  88.468085 -0.390413   \n",
       "1  2048.104465  452197.467826  3.949667e+06  88.463231 -0.393374   \n",
       "2  2048.207218  452197.465972  3.949667e+06  88.469801 -0.385135   \n",
       "3  2048.304435  452197.465861  3.949667e+06  88.467945 -0.380474   \n",
       "4  2048.404340  452197.465777  3.949667e+06  88.468571 -0.386001   \n",
       "\n",
       "   v_horizontal  v_vertical  accel  steer  \n",
       "0      0.011836    0.030021    0.0  -38.0  \n",
       "1      0.038694   -0.091738    0.0  -38.0  \n",
       "2      0.049873    0.043076    0.0  -38.0  \n",
       "3      0.034952   -0.009294    0.0  -38.0  \n",
       "4      0.013054   -0.024935    0.0  -38.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "file_path = 'tile_data_v2.csv'  # replace with the actual path to your dataset\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2365bf42",
   "metadata": {},
   "source": [
    "### Data Preprocessing\n",
    "We will create input sequences of length `h` for both the state and action variables, and output sequences for the corresponding next state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2cf35b62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3118, 70]), torch.Size([3118, 5]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract state and action data\n",
    "state_columns = ['x', 'y', 'yaw', 'v_horizontal', 'v_vertical']\n",
    "action_columns = ['accel', 'steer']\n",
    "\n",
    "states = data[state_columns].values\n",
    "actions = data[action_columns].values\n",
    "\n",
    "# Create sequences with history length h\n",
    "h = 10  # history length\n",
    "input_sequences = []\n",
    "output_sequences = []\n",
    "\n",
    "for i in range(len(states) - h):\n",
    "    input_seq = np.concatenate((states[i:i+h], actions[i:i+h]), axis=1).flatten()\n",
    "    output_seq = states[i+h]  # the next state to predict\n",
    "    input_sequences.append(input_seq)\n",
    "    output_sequences.append(output_seq)\n",
    "\n",
    "input_sequences = np.array(input_sequences)\n",
    "output_sequences = np.array(output_sequences)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "inputs = torch.tensor(input_sequences, dtype=torch.float32)\n",
    "outputs = torch.tensor(output_sequences, dtype=torch.float32)\n",
    "\n",
    "inputs.shape, outputs.shape  # Check the shapes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b87c58",
   "metadata": {},
   "source": [
    "### Define the Model\n",
    "The model architecture is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff6a843f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobotDynamicsModel(\n",
       "  (fc1): Linear(in_features=70, out_features=140, bias=True)\n",
       "  (fc2): Linear(in_features=140, out_features=280, bias=True)\n",
       "  (fc3): Linear(in_features=280, out_features=420, bias=True)\n",
       "  (fc4): Linear(in_features=420, out_features=140, bias=True)\n",
       "  (output_layer): Linear(in_features=140, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the model\n",
    "class RobotDynamicsModel(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(RobotDynamicsModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 2 * input_size)\n",
    "        self.fc2 = nn.Linear(2 * input_size, 4 * input_size)\n",
    "        self.fc3 = nn.Linear(4 * input_size, 6 * input_size)\n",
    "        self.fc4 = nn.Linear(6 * input_size, 2 * input_size)\n",
    "        self.output_layer = nn.Linear(2 * input_size, len(state_columns))  # Output size is |x| = 3\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        x = torch.relu(self.fc4(x))\n",
    "        x = self.output_layer(x)\n",
    "        return x\n",
    "\n",
    "# Instantiate the model\n",
    "input_size = h * (len(state_columns) + len(action_columns))  # h * (|x| + |a|)\n",
    "model = RobotDynamicsModel(input_size)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56da75b1",
   "metadata": {},
   "source": [
    "### Training the Model\n",
    "We'll now train the model using the Mean Squared Error (MSE) loss function and the Adam optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f012c242",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for CUDA\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Move the model to the GPU\n",
    "model = RobotDynamicsModel(input_size).to(device)\n",
    "\n",
    "# Move the data to the GPU\n",
    "inputs = inputs.to(device)\n",
    "outputs = outputs.to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "# Training settings\n",
    "epochs = 100000\n",
    "loss_threshold = 10  # Define your loss threshold\n",
    "min_loss = float('inf')\n",
    "losses = []  # To store the loss values\n",
    "filtered_losses = []  # To store non-outlier loss values for plotting\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f377c161-9583-42f4-b0cc-85c7dde2aa71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100000], Loss: 2830183170048.0000\n",
      "Epoch [20/100000], Loss: 2481241980928.0000\n",
      "Epoch [30/100000], Loss: 1992459550720.0000\n",
      "Epoch [40/100000], Loss: 1312099139584.0000\n",
      "Epoch [50/100000], Loss: 544867123200.0000\n",
      "Epoch [60/100000], Loss: 64767680512.0000\n",
      "Epoch [70/100000], Loss: 42582917120.0000\n",
      "Epoch [80/100000], Loss: 8727603200.0000\n",
      "Epoch [90/100000], Loss: 5161734656.0000\n",
      "Epoch [100/100000], Loss: 2212307200.0000\n",
      "Epoch [110/100000], Loss: 163283136.0000\n",
      "Epoch [120/100000], Loss: 353987776.0000\n",
      "Epoch [130/100000], Loss: 32281926.0000\n",
      "Epoch [140/100000], Loss: 34303268.0000\n",
      "Epoch [150/100000], Loss: 6817307.0000\n",
      "Epoch [160/100000], Loss: 4106782.5000\n",
      "Epoch [170/100000], Loss: 771038.6875\n",
      "Epoch [180/100000], Loss: 507101.3438\n",
      "Epoch [190/100000], Loss: 137952.4688\n",
      "Epoch [200/100000], Loss: 35279.1406\n",
      "Epoch [210/100000], Loss: 30286.7422\n",
      "Epoch [220/100000], Loss: 1491.0051\n",
      "Epoch [230/100000], Loss: 4861.3838\n",
      "Epoch [240/100000], Loss: 1132.2386\n",
      "Epoch [250/100000], Loss: 1050.8783\n",
      "Epoch [260/100000], Loss: 906.8512\n",
      "Epoch [270/100000], Loss: 783.8498\n",
      "Epoch [280/100000], Loss: 792.2751\n",
      "Epoch [290/100000], Loss: 773.3403\n",
      "Epoch [300/100000], Loss: 773.7397\n",
      "Epoch [310/100000], Loss: 773.1859\n",
      "Epoch [320/100000], Loss: 772.5543\n",
      "Epoch [330/100000], Loss: 772.2810\n",
      "Epoch [340/100000], Loss: 772.0919\n",
      "Epoch [350/100000], Loss: 771.9279\n",
      "Epoch [360/100000], Loss: 771.5326\n",
      "Epoch [370/100000], Loss: 771.1918\n",
      "Epoch [380/100000], Loss: 770.8742\n",
      "Epoch [390/100000], Loss: 770.5529\n",
      "Epoch [400/100000], Loss: 770.2407\n",
      "Epoch [410/100000], Loss: 769.8813\n",
      "Epoch [420/100000], Loss: 769.6119\n",
      "Epoch [430/100000], Loss: 769.3715\n",
      "Epoch [440/100000], Loss: 768.9764\n",
      "Epoch [450/100000], Loss: 768.6268\n",
      "Epoch [460/100000], Loss: 768.2775\n",
      "Epoch [470/100000], Loss: 767.8983\n",
      "Epoch [480/100000], Loss: 767.5330\n",
      "Epoch [490/100000], Loss: 767.1027\n",
      "Epoch [500/100000], Loss: 766.6649\n",
      "Epoch [510/100000], Loss: 766.3375\n",
      "Epoch [520/100000], Loss: 765.9747\n",
      "Epoch [530/100000], Loss: 765.6011\n",
      "Epoch [540/100000], Loss: 765.2145\n",
      "Epoch [550/100000], Loss: 764.7083\n",
      "Epoch [560/100000], Loss: 764.3414\n",
      "Epoch [570/100000], Loss: 763.9471\n",
      "Epoch [580/100000], Loss: 763.5112\n",
      "Epoch [590/100000], Loss: 762.9938\n",
      "Epoch [600/100000], Loss: 762.5219\n",
      "Epoch [610/100000], Loss: 762.2208\n",
      "Epoch [620/100000], Loss: 761.8007\n",
      "Epoch [630/100000], Loss: 761.3315\n",
      "Epoch [640/100000], Loss: 760.8251\n",
      "Epoch [650/100000], Loss: 760.4290\n",
      "Epoch [660/100000], Loss: 759.9350\n",
      "Epoch [670/100000], Loss: 759.4552\n",
      "Epoch [680/100000], Loss: 759.0274\n",
      "Epoch [690/100000], Loss: 758.5015\n",
      "Epoch [700/100000], Loss: 758.0925\n",
      "Epoch [710/100000], Loss: 757.6493\n",
      "Epoch [720/100000], Loss: 757.1537\n",
      "Epoch [730/100000], Loss: 756.5598\n",
      "Epoch [740/100000], Loss: 756.2823\n",
      "Epoch [750/100000], Loss: 755.6519\n",
      "Epoch [760/100000], Loss: 755.2255\n",
      "Epoch [770/100000], Loss: 754.6868\n",
      "Epoch [780/100000], Loss: 754.1505\n",
      "Epoch [790/100000], Loss: 753.6203\n",
      "Epoch [800/100000], Loss: 753.0737\n",
      "Epoch [810/100000], Loss: 752.4879\n",
      "Epoch [820/100000], Loss: 752.0139\n",
      "Epoch [830/100000], Loss: 751.3602\n",
      "Epoch [840/100000], Loss: 750.9379\n",
      "Epoch [850/100000], Loss: 750.4083\n",
      "Epoch [860/100000], Loss: 749.9022\n",
      "Epoch [870/100000], Loss: 749.3930\n",
      "Epoch [880/100000], Loss: 748.8584\n",
      "Epoch [890/100000], Loss: 748.3054\n",
      "Epoch [900/100000], Loss: 747.8252\n",
      "Epoch [910/100000], Loss: 747.1760\n",
      "Epoch [920/100000], Loss: 746.5991\n",
      "Epoch [930/100000], Loss: 746.0529\n",
      "Epoch [940/100000], Loss: 745.4666\n",
      "Epoch [950/100000], Loss: 744.7716\n",
      "Epoch [960/100000], Loss: 744.1922\n",
      "Epoch [970/100000], Loss: 743.6072\n",
      "Epoch [980/100000], Loss: 743.1182\n",
      "Epoch [990/100000], Loss: 742.5308\n",
      "Epoch [1000/100000], Loss: 741.8120\n",
      "Epoch [1010/100000], Loss: 741.2234\n",
      "Epoch [1020/100000], Loss: 740.6968\n",
      "Epoch [1030/100000], Loss: 740.0898\n",
      "Epoch [1040/100000], Loss: 739.3408\n",
      "Epoch [1050/100000], Loss: 738.8571\n",
      "Epoch [1060/100000], Loss: 738.1846\n",
      "Epoch [1070/100000], Loss: 737.5436\n",
      "Epoch [1080/100000], Loss: 736.9264\n",
      "Epoch [1090/100000], Loss: 736.2516\n",
      "Epoch [1100/100000], Loss: 735.5035\n",
      "Epoch [1110/100000], Loss: 734.9586\n",
      "Epoch [1120/100000], Loss: 734.4704\n",
      "Epoch [1130/100000], Loss: 733.6575\n",
      "Epoch [1140/100000], Loss: 733.0651\n",
      "Epoch [1150/100000], Loss: 732.4947\n",
      "Epoch [1160/100000], Loss: 731.7048\n",
      "Epoch [1170/100000], Loss: 730.9667\n",
      "Epoch [1180/100000], Loss: 730.4457\n",
      "Epoch [1190/100000], Loss: 729.6898\n",
      "Epoch [1200/100000], Loss: 729.1053\n",
      "Epoch [1210/100000], Loss: 728.2299\n",
      "Epoch [1220/100000], Loss: 727.5157\n",
      "Epoch [1230/100000], Loss: 726.8254\n",
      "Epoch [1240/100000], Loss: 726.2786\n",
      "Epoch [1250/100000], Loss: 725.4251\n",
      "Epoch [1260/100000], Loss: 724.5941\n",
      "Epoch [1270/100000], Loss: 723.9011\n",
      "Epoch [1280/100000], Loss: 723.1675\n",
      "Epoch [1290/100000], Loss: 722.3882\n",
      "Epoch [1300/100000], Loss: 721.7034\n",
      "Epoch [1310/100000], Loss: 720.8776\n",
      "Epoch [1320/100000], Loss: 720.2186\n",
      "Epoch [1330/100000], Loss: 719.3805\n",
      "Epoch [1340/100000], Loss: 718.6947\n",
      "Epoch [1350/100000], Loss: 717.9329\n",
      "Epoch [1360/100000], Loss: 717.1218\n",
      "Epoch [1370/100000], Loss: 716.2833\n",
      "Epoch [1380/100000], Loss: 715.5410\n",
      "Epoch [1390/100000], Loss: 714.8450\n",
      "Epoch [1400/100000], Loss: 713.9627\n",
      "Epoch [1410/100000], Loss: 713.3168\n",
      "Epoch [1420/100000], Loss: 712.5098\n",
      "Epoch [1430/100000], Loss: 711.8062\n",
      "Epoch [1440/100000], Loss: 710.8745\n",
      "Epoch [1450/100000], Loss: 710.1924\n",
      "Epoch [1460/100000], Loss: 709.3476\n",
      "Epoch [1470/100000], Loss: 708.7605\n",
      "Epoch [1480/100000], Loss: 707.8690\n",
      "Epoch [1490/100000], Loss: 706.9656\n",
      "Epoch [1500/100000], Loss: 706.2697\n",
      "Epoch [1510/100000], Loss: 705.4203\n",
      "Epoch [1520/100000], Loss: 704.6111\n",
      "Epoch [1530/100000], Loss: 703.8063\n",
      "Epoch [1540/100000], Loss: 703.0264\n",
      "Epoch [1550/100000], Loss: 702.2469\n",
      "Epoch [1560/100000], Loss: 701.3282\n",
      "Epoch [1570/100000], Loss: 700.5338\n",
      "Epoch [1580/100000], Loss: 699.7545\n",
      "Epoch [1590/100000], Loss: 698.9818\n",
      "Epoch [1600/100000], Loss: 698.1511\n",
      "Epoch [1610/100000], Loss: 697.2375\n",
      "Epoch [1620/100000], Loss: 696.4241\n",
      "Epoch [1630/100000], Loss: 695.5404\n",
      "Epoch [1640/100000], Loss: 694.6667\n",
      "Epoch [1650/100000], Loss: 693.7903\n",
      "Epoch [1660/100000], Loss: 692.8553\n",
      "Epoch [1670/100000], Loss: 691.9958\n",
      "Epoch [1680/100000], Loss: 691.1151\n",
      "Epoch [1690/100000], Loss: 690.2609\n",
      "Epoch [1700/100000], Loss: 689.5519\n",
      "Epoch [1710/100000], Loss: 688.5128\n",
      "Epoch [1720/100000], Loss: 687.5773\n",
      "Epoch [1730/100000], Loss: 686.8423\n",
      "Epoch [1740/100000], Loss: 685.9485\n",
      "Epoch [1750/100000], Loss: 684.9178\n",
      "Epoch [1760/100000], Loss: 684.0950\n",
      "Epoch [1770/100000], Loss: 683.2166\n",
      "Epoch [1780/100000], Loss: 682.2734\n",
      "Epoch [1790/100000], Loss: 681.2596\n",
      "Epoch [1800/100000], Loss: 680.3187\n",
      "Epoch [1810/100000], Loss: 679.5338\n",
      "Epoch [1820/100000], Loss: 678.5925\n",
      "Epoch [1830/100000], Loss: 677.4886\n",
      "Epoch [1840/100000], Loss: 676.7173\n",
      "Epoch [1850/100000], Loss: 675.9562\n",
      "Epoch [1860/100000], Loss: 674.8592\n",
      "Epoch [1870/100000], Loss: 673.9128\n",
      "Epoch [1880/100000], Loss: 672.8676\n",
      "Epoch [1890/100000], Loss: 671.9160\n",
      "Epoch [1900/100000], Loss: 670.8804\n",
      "Epoch [1910/100000], Loss: 669.9645\n",
      "Epoch [1920/100000], Loss: 668.8968\n",
      "Epoch [1930/100000], Loss: 667.8929\n",
      "Epoch [1940/100000], Loss: 666.9675\n",
      "Epoch [1950/100000], Loss: 666.0272\n",
      "Epoch [1960/100000], Loss: 664.9016\n",
      "Epoch [1970/100000], Loss: 663.9368\n",
      "Epoch [1980/100000], Loss: 662.8849\n",
      "Epoch [1990/100000], Loss: 661.8672\n",
      "Epoch [2000/100000], Loss: 660.8867\n",
      "Epoch [2010/100000], Loss: 659.8312\n",
      "Epoch [2020/100000], Loss: 658.7686\n",
      "Epoch [2030/100000], Loss: 657.7914\n",
      "Epoch [2040/100000], Loss: 656.7152\n",
      "Epoch [2050/100000], Loss: 655.7491\n",
      "Epoch [2060/100000], Loss: 654.6579\n",
      "Epoch [2070/100000], Loss: 653.6511\n",
      "Epoch [2080/100000], Loss: 652.5537\n",
      "Epoch [2090/100000], Loss: 651.4670\n",
      "Epoch [2100/100000], Loss: 650.5839\n",
      "Epoch [2110/100000], Loss: 649.4769\n",
      "Epoch [2120/100000], Loss: 648.5272\n",
      "Epoch [2130/100000], Loss: 647.4072\n",
      "Epoch [2140/100000], Loss: 646.2456\n",
      "Epoch [2150/100000], Loss: 645.2113\n",
      "Epoch [2160/100000], Loss: 644.0052\n",
      "Epoch [2170/100000], Loss: 642.8295\n",
      "Epoch [2180/100000], Loss: 641.7086\n",
      "Epoch [2190/100000], Loss: 640.6050\n",
      "Epoch [2200/100000], Loss: 639.4085\n",
      "Epoch [2210/100000], Loss: 638.4314\n",
      "Epoch [2220/100000], Loss: 637.2354\n",
      "Epoch [2230/100000], Loss: 636.0626\n",
      "Epoch [2240/100000], Loss: 635.0452\n",
      "Epoch [2250/100000], Loss: 633.9137\n",
      "Epoch [2260/100000], Loss: 632.6882\n",
      "Epoch [2270/100000], Loss: 631.6409\n",
      "Epoch [2280/100000], Loss: 630.5353\n",
      "Epoch [2290/100000], Loss: 629.2340\n",
      "Epoch [2300/100000], Loss: 628.1489\n",
      "Epoch [2310/100000], Loss: 627.0039\n",
      "Epoch [2320/100000], Loss: 625.9979\n",
      "Epoch [2330/100000], Loss: 624.7835\n",
      "Epoch [2340/100000], Loss: 623.6199\n",
      "Epoch [2350/100000], Loss: 622.3901\n",
      "Epoch [2360/100000], Loss: 621.3333\n",
      "Epoch [2370/100000], Loss: 620.2103\n",
      "Epoch [2380/100000], Loss: 619.0787\n",
      "Epoch [2390/100000], Loss: 617.9276\n",
      "Epoch [2400/100000], Loss: 616.8840\n",
      "Epoch [2410/100000], Loss: 615.6265\n",
      "Epoch [2420/100000], Loss: 614.5620\n",
      "Epoch [2430/100000], Loss: 613.2250\n",
      "Epoch [2440/100000], Loss: 612.2125\n",
      "Epoch [2450/100000], Loss: 610.8633\n",
      "Epoch [2460/100000], Loss: 609.6804\n",
      "Epoch [2470/100000], Loss: 608.5615\n",
      "Epoch [2480/100000], Loss: 607.3624\n",
      "Epoch [2490/100000], Loss: 606.1269\n",
      "Epoch [2500/100000], Loss: 604.9083\n",
      "Epoch [2510/100000], Loss: 603.6528\n",
      "Epoch [2520/100000], Loss: 602.5184\n",
      "Epoch [2530/100000], Loss: 601.3106\n",
      "Epoch [2540/100000], Loss: 600.0648\n",
      "Epoch [2550/100000], Loss: 598.8108\n",
      "Epoch [2560/100000], Loss: 597.4835\n",
      "Epoch [2570/100000], Loss: 596.3056\n",
      "Epoch [2580/100000], Loss: 595.0839\n",
      "Epoch [2590/100000], Loss: 593.8657\n",
      "Epoch [2600/100000], Loss: 592.4406\n",
      "Epoch [2610/100000], Loss: 591.0708\n",
      "Epoch [2620/100000], Loss: 589.9364\n",
      "Epoch [2630/100000], Loss: 588.6884\n",
      "Epoch [2640/100000], Loss: 587.3099\n",
      "Epoch [2650/100000], Loss: 586.0032\n",
      "Epoch [2660/100000], Loss: 584.7985\n",
      "Epoch [2670/100000], Loss: 583.4986\n",
      "Epoch [2680/100000], Loss: 582.1946\n",
      "Epoch [2690/100000], Loss: 580.7790\n",
      "Epoch [2700/100000], Loss: 579.4585\n",
      "Epoch [2710/100000], Loss: 578.1395\n",
      "Epoch [2720/100000], Loss: 576.8108\n",
      "Epoch [2730/100000], Loss: 575.5533\n",
      "Epoch [2740/100000], Loss: 574.1808\n",
      "Epoch [2750/100000], Loss: 573.0216\n",
      "Epoch [2760/100000], Loss: 571.5475\n",
      "Epoch [2770/100000], Loss: 570.2161\n",
      "Epoch [2780/100000], Loss: 568.8000\n",
      "Epoch [2790/100000], Loss: 567.4438\n",
      "Epoch [2800/100000], Loss: 566.2372\n",
      "Epoch [2810/100000], Loss: 564.7706\n",
      "Epoch [2820/100000], Loss: 563.3063\n",
      "Epoch [2830/100000], Loss: 562.2257\n",
      "Epoch [2840/100000], Loss: 560.7631\n",
      "Epoch [2850/100000], Loss: 559.4116\n",
      "Epoch [2860/100000], Loss: 557.9402\n",
      "Epoch [2870/100000], Loss: 556.5713\n",
      "Epoch [2880/100000], Loss: 555.1943\n",
      "Epoch [2890/100000], Loss: 553.8557\n",
      "Epoch [2900/100000], Loss: 552.3738\n",
      "Epoch [2910/100000], Loss: 551.0014\n",
      "Epoch [2920/100000], Loss: 549.6325\n",
      "Epoch [2930/100000], Loss: 548.2905\n",
      "Epoch [2940/100000], Loss: 546.8571\n",
      "Epoch [2950/100000], Loss: 545.5201\n",
      "Epoch [2960/100000], Loss: 544.1028\n",
      "Epoch [2970/100000], Loss: 542.6187\n",
      "Epoch [2980/100000], Loss: 541.0675\n",
      "Epoch [2990/100000], Loss: 539.7834\n",
      "Epoch [3000/100000], Loss: 538.4037\n",
      "Epoch [3010/100000], Loss: 537.0236\n",
      "Epoch [3020/100000], Loss: 535.6290\n",
      "Epoch [3030/100000], Loss: 534.2030\n",
      "Epoch [3040/100000], Loss: 532.7634\n",
      "Epoch [3050/100000], Loss: 531.4454\n",
      "Epoch [3060/100000], Loss: 529.9492\n",
      "Epoch [3070/100000], Loss: 528.5654\n",
      "Epoch [3080/100000], Loss: 527.1000\n",
      "Epoch [3090/100000], Loss: 525.6223\n",
      "Epoch [3100/100000], Loss: 524.0851\n",
      "Epoch [3110/100000], Loss: 522.4380\n",
      "Epoch [3120/100000], Loss: 521.1166\n",
      "Epoch [3130/100000], Loss: 519.6711\n",
      "Epoch [3140/100000], Loss: 518.0992\n",
      "Epoch [3150/100000], Loss: 516.6761\n",
      "Epoch [3160/100000], Loss: 515.3324\n",
      "Epoch [3170/100000], Loss: 513.9230\n",
      "Epoch [3180/100000], Loss: 512.4025\n",
      "Epoch [3190/100000], Loss: 511.1101\n",
      "Epoch [3200/100000], Loss: 509.6058\n",
      "Epoch [3210/100000], Loss: 508.0909\n",
      "Epoch [3220/100000], Loss: 506.6050\n",
      "Epoch [3230/100000], Loss: 505.1158\n",
      "Epoch [3240/100000], Loss: 503.5734\n",
      "Epoch [3250/100000], Loss: 502.0566\n",
      "Epoch [3260/100000], Loss: 500.5618\n",
      "Epoch [3270/100000], Loss: 498.9372\n",
      "Epoch [3280/100000], Loss: 497.5159\n",
      "Epoch [3290/100000], Loss: 495.9304\n",
      "Epoch [3300/100000], Loss: 494.4884\n",
      "Epoch [3310/100000], Loss: 492.8929\n",
      "Epoch [3320/100000], Loss: 491.3900\n",
      "Epoch [3330/100000], Loss: 489.8751\n",
      "Epoch [3340/100000], Loss: 488.3444\n",
      "Epoch [3350/100000], Loss: 486.8705\n",
      "Epoch [3360/100000], Loss: 485.3783\n",
      "Epoch [3370/100000], Loss: 483.8221\n",
      "Epoch [3380/100000], Loss: 482.2060\n",
      "Epoch [3390/100000], Loss: 480.6224\n",
      "Epoch [3400/100000], Loss: 479.1814\n",
      "Epoch [3410/100000], Loss: 477.6529\n",
      "Epoch [3420/100000], Loss: 476.0811\n",
      "Epoch [3430/100000], Loss: 474.6016\n",
      "Epoch [3440/100000], Loss: 473.1132\n",
      "Epoch [3450/100000], Loss: 471.6258\n",
      "Epoch [3460/100000], Loss: 470.0742\n",
      "Epoch [3470/100000], Loss: 468.6034\n",
      "Epoch [3480/100000], Loss: 466.9529\n",
      "Epoch [3490/100000], Loss: 465.4977\n",
      "Epoch [3500/100000], Loss: 463.9453\n",
      "Epoch [3510/100000], Loss: 462.4049\n",
      "Epoch [3520/100000], Loss: 460.8222\n",
      "Epoch [3530/100000], Loss: 459.1984\n",
      "Epoch [3540/100000], Loss: 457.5474\n",
      "Epoch [3550/100000], Loss: 456.0901\n",
      "Epoch [3560/100000], Loss: 454.3861\n",
      "Epoch [3570/100000], Loss: 453.0136\n",
      "Epoch [3580/100000], Loss: 451.3693\n",
      "Epoch [3590/100000], Loss: 449.8355\n",
      "Epoch [3600/100000], Loss: 448.2596\n",
      "Epoch [3610/100000], Loss: 446.6521\n",
      "Epoch [3620/100000], Loss: 7151.1455\n",
      "Epoch [3630/100000], Loss: 1767187.0000\n",
      "Epoch [3640/100000], Loss: 1168895.6250\n",
      "Epoch [3650/100000], Loss: 937057.5000\n",
      "Epoch [3660/100000], Loss: 173773.9844\n",
      "Epoch [3670/100000], Loss: 2761.5442\n",
      "Epoch [3680/100000], Loss: 28202.3047\n",
      "Epoch [3690/100000], Loss: 13694.7402\n",
      "Epoch [3700/100000], Loss: 1566.6182\n",
      "Epoch [3710/100000], Loss: 584.4174\n",
      "Epoch [3720/100000], Loss: 894.5007\n",
      "Epoch [3730/100000], Loss: 631.6820\n",
      "Epoch [3740/100000], Loss: 454.7129\n",
      "Epoch [3750/100000], Loss: 424.5117\n",
      "Epoch [3760/100000], Loss: 426.2465\n",
      "Epoch [3770/100000], Loss: 423.9263\n",
      "Epoch [3780/100000], Loss: 419.7931\n",
      "Epoch [3790/100000], Loss: 417.8000\n",
      "Epoch [3800/100000], Loss: 416.3377\n",
      "Epoch [3810/100000], Loss: 414.5734\n",
      "Epoch [3820/100000], Loss: 412.9669\n",
      "Epoch [3830/100000], Loss: 411.4141\n",
      "Epoch [3840/100000], Loss: 409.8523\n",
      "Epoch [3850/100000], Loss: 408.2152\n",
      "Epoch [3860/100000], Loss: 406.6736\n",
      "Epoch [3870/100000], Loss: 405.0960\n",
      "Epoch [3880/100000], Loss: 403.3501\n",
      "Epoch [3890/100000], Loss: 401.6084\n",
      "Epoch [3900/100000], Loss: 400.1206\n",
      "Epoch [3910/100000], Loss: 398.3882\n",
      "Epoch [3920/100000], Loss: 396.8550\n",
      "Epoch [3930/100000], Loss: 395.3031\n",
      "Epoch [3940/100000], Loss: 393.7695\n",
      "Epoch [3950/100000], Loss: 392.1098\n",
      "Epoch [3960/100000], Loss: 390.3914\n",
      "Epoch [3970/100000], Loss: 388.8016\n",
      "Epoch [3980/100000], Loss: 387.1839\n",
      "Epoch [3990/100000], Loss: 385.6596\n",
      "Epoch [4000/100000], Loss: 384.0074\n",
      "Epoch [4010/100000], Loss: 382.2693\n",
      "Epoch [4020/100000], Loss: 380.6677\n",
      "Epoch [4030/100000], Loss: 378.9888\n",
      "Epoch [4040/100000], Loss: 377.3232\n",
      "Epoch [4050/100000], Loss: 375.6363\n",
      "Epoch [4060/100000], Loss: 374.0632\n",
      "Epoch [4070/100000], Loss: 372.2926\n",
      "Epoch [4080/100000], Loss: 370.6914\n",
      "Epoch [4090/100000], Loss: 369.0921\n",
      "Epoch [4100/100000], Loss: 367.3979\n",
      "Epoch [4110/100000], Loss: 365.6815\n",
      "Epoch [4120/100000], Loss: 364.0780\n",
      "Epoch [4130/100000], Loss: 362.3230\n",
      "Epoch [4140/100000], Loss: 360.8184\n",
      "Epoch [4150/100000], Loss: 359.0891\n",
      "Epoch [4160/100000], Loss: 357.5392\n",
      "Epoch [4170/100000], Loss: 355.9041\n",
      "Epoch [4180/100000], Loss: 354.2791\n",
      "Epoch [4190/100000], Loss: 352.5549\n",
      "Epoch [4200/100000], Loss: 350.9361\n",
      "Epoch [4210/100000], Loss: 349.3869\n",
      "Epoch [4220/100000], Loss: 347.7311\n",
      "Epoch [4230/100000], Loss: 346.0647\n",
      "Epoch [4240/100000], Loss: 344.5991\n",
      "Epoch [4250/100000], Loss: 342.9489\n",
      "Epoch [4260/100000], Loss: 341.3187\n",
      "Epoch [4270/100000], Loss: 339.6777\n",
      "Epoch [4280/100000], Loss: 338.0477\n",
      "Epoch [4290/100000], Loss: 336.4293\n",
      "Epoch [4300/100000], Loss: 334.7538\n",
      "Epoch [4310/100000], Loss: 333.2666\n",
      "Epoch [4320/100000], Loss: 331.5582\n",
      "Epoch [4330/100000], Loss: 329.9822\n",
      "Epoch [4340/100000], Loss: 328.2710\n",
      "Epoch [4350/100000], Loss: 326.6889\n",
      "Epoch [4360/100000], Loss: 324.8879\n",
      "Epoch [4370/100000], Loss: 323.2976\n",
      "Epoch [4380/100000], Loss: 321.5525\n",
      "Epoch [4390/100000], Loss: 319.8750\n",
      "Epoch [4400/100000], Loss: 318.3503\n",
      "Epoch [4410/100000], Loss: 316.6821\n",
      "Epoch [4420/100000], Loss: 315.1018\n",
      "Epoch [4430/100000], Loss: 313.3591\n",
      "Epoch [4440/100000], Loss: 311.8083\n",
      "Epoch [4450/100000], Loss: 310.1285\n",
      "Epoch [4460/100000], Loss: 308.5954\n",
      "Epoch [4470/100000], Loss: 306.9184\n",
      "Epoch [4480/100000], Loss: 305.3358\n",
      "Epoch [4490/100000], Loss: 303.7087\n",
      "Epoch [4500/100000], Loss: 302.0291\n",
      "Epoch [4510/100000], Loss: 300.4992\n",
      "Epoch [4520/100000], Loss: 298.8557\n",
      "Epoch [4530/100000], Loss: 297.2640\n",
      "Epoch [4540/100000], Loss: 295.7142\n",
      "Epoch [4550/100000], Loss: 294.0199\n",
      "Epoch [4560/100000], Loss: 292.4876\n",
      "Epoch [4570/100000], Loss: 290.8820\n",
      "Epoch [4580/100000], Loss: 289.3855\n",
      "Epoch [4590/100000], Loss: 287.8811\n",
      "Epoch [4600/100000], Loss: 286.2395\n",
      "Epoch [4610/100000], Loss: 284.6938\n",
      "Epoch [4620/100000], Loss: 283.2193\n",
      "Epoch [4630/100000], Loss: 281.5734\n",
      "Epoch [4640/100000], Loss: 280.0934\n",
      "Epoch [4650/100000], Loss: 278.5666\n",
      "Epoch [4660/100000], Loss: 276.9914\n",
      "Epoch [4670/100000], Loss: 275.4461\n",
      "Epoch [4680/100000], Loss: 273.9059\n",
      "Epoch [4690/100000], Loss: 272.3542\n",
      "Epoch [4700/100000], Loss: 270.7064\n",
      "Epoch [4710/100000], Loss: 269.2145\n",
      "Epoch [4720/100000], Loss: 267.4671\n",
      "Epoch [4730/100000], Loss: 265.9164\n",
      "Epoch [4740/100000], Loss: 264.4036\n",
      "Epoch [4750/100000], Loss: 262.8340\n",
      "Epoch [4760/100000], Loss: 261.2642\n",
      "Epoch [4770/100000], Loss: 259.7264\n",
      "Epoch [4780/100000], Loss: 258.1046\n",
      "Epoch [4790/100000], Loss: 256.5739\n",
      "Epoch [4800/100000], Loss: 255.0624\n",
      "Epoch [4810/100000], Loss: 253.5685\n",
      "Epoch [4820/100000], Loss: 251.9873\n",
      "Epoch [4830/100000], Loss: 250.4974\n",
      "Epoch [4840/100000], Loss: 248.9980\n",
      "Epoch [4850/100000], Loss: 247.3181\n",
      "Epoch [4860/100000], Loss: 245.9229\n",
      "Epoch [4870/100000], Loss: 244.3589\n",
      "Epoch [4880/100000], Loss: 242.8836\n",
      "Epoch [4890/100000], Loss: 241.3812\n",
      "Epoch [4900/100000], Loss: 239.8702\n",
      "Epoch [4910/100000], Loss: 238.3962\n",
      "Epoch [4920/100000], Loss: 236.9245\n",
      "Epoch [4930/100000], Loss: 235.4110\n",
      "Epoch [4940/100000], Loss: 233.9504\n",
      "Epoch [4950/100000], Loss: 232.4308\n",
      "Epoch [4960/100000], Loss: 230.9225\n",
      "Epoch [4970/100000], Loss: 229.5609\n",
      "Epoch [4980/100000], Loss: 228.0100\n",
      "Epoch [4990/100000], Loss: 226.5327\n",
      "Epoch [5000/100000], Loss: 224.9667\n",
      "Epoch [5010/100000], Loss: 223.6382\n",
      "Epoch [5020/100000], Loss: 222.0828\n",
      "Epoch [5030/100000], Loss: 220.5909\n",
      "Epoch [5040/100000], Loss: 219.1883\n",
      "Epoch [5050/100000], Loss: 217.7350\n",
      "Epoch [5060/100000], Loss: 216.3652\n",
      "Epoch [5070/100000], Loss: 214.9408\n",
      "Epoch [5080/100000], Loss: 213.4824\n",
      "Epoch [5090/100000], Loss: 212.1516\n",
      "Epoch [5100/100000], Loss: 210.5902\n",
      "Epoch [5110/100000], Loss: 209.1632\n",
      "Epoch [5120/100000], Loss: 207.7941\n",
      "Epoch [5130/100000], Loss: 206.3526\n",
      "Epoch [5140/100000], Loss: 204.8761\n",
      "Epoch [5150/100000], Loss: 203.5023\n",
      "Epoch [5160/100000], Loss: 202.1453\n",
      "Epoch [5170/100000], Loss: 200.8411\n",
      "Epoch [5180/100000], Loss: 199.4853\n",
      "Epoch [5190/100000], Loss: 198.1228\n",
      "Epoch [5200/100000], Loss: 196.6998\n",
      "Epoch [5210/100000], Loss: 195.3890\n",
      "Epoch [5220/100000], Loss: 193.9598\n",
      "Epoch [5230/100000], Loss: 192.5286\n",
      "Epoch [5240/100000], Loss: 191.1491\n",
      "Epoch [5250/100000], Loss: 189.8115\n",
      "Epoch [5260/100000], Loss: 188.4415\n",
      "Epoch [5270/100000], Loss: 187.1290\n",
      "Epoch [5280/100000], Loss: 185.7861\n",
      "Epoch [5290/100000], Loss: 184.5480\n",
      "Epoch [5300/100000], Loss: 183.2161\n",
      "Epoch [5310/100000], Loss: 181.8535\n",
      "Epoch [5320/100000], Loss: 180.6178\n",
      "Epoch [5330/100000], Loss: 179.2826\n",
      "Epoch [5340/100000], Loss: 177.9835\n",
      "Epoch [5350/100000], Loss: 176.6901\n",
      "Epoch [5360/100000], Loss: 175.4308\n",
      "Epoch [5370/100000], Loss: 174.2143\n",
      "Epoch [5380/100000], Loss: 172.9006\n",
      "Epoch [5390/100000], Loss: 171.6222\n",
      "Epoch [5400/100000], Loss: 170.3417\n",
      "Epoch [5410/100000], Loss: 169.1028\n",
      "Epoch [5420/100000], Loss: 167.8592\n",
      "Epoch [5430/100000], Loss: 166.5947\n",
      "Epoch [5440/100000], Loss: 165.3793\n",
      "Epoch [5450/100000], Loss: 164.1311\n",
      "Epoch [5460/100000], Loss: 162.8577\n",
      "Epoch [5470/100000], Loss: 161.7062\n",
      "Epoch [5480/100000], Loss: 160.5511\n",
      "Epoch [5490/100000], Loss: 159.3160\n",
      "Epoch [5500/100000], Loss: 158.1018\n",
      "Epoch [5510/100000], Loss: 157.0145\n",
      "Epoch [5520/100000], Loss: 155.7798\n",
      "Epoch [5530/100000], Loss: 154.5688\n",
      "Epoch [5540/100000], Loss: 153.3807\n",
      "Epoch [5550/100000], Loss: 152.2387\n",
      "Epoch [5560/100000], Loss: 151.0932\n",
      "Epoch [5570/100000], Loss: 149.9326\n",
      "Epoch [5580/100000], Loss: 148.8575\n",
      "Epoch [5590/100000], Loss: 147.7475\n",
      "Epoch [5600/100000], Loss: 146.6406\n",
      "Epoch [5610/100000], Loss: 145.4924\n",
      "Epoch [5620/100000], Loss: 144.3055\n",
      "Epoch [5630/100000], Loss: 143.1997\n",
      "Epoch [5640/100000], Loss: 142.1328\n",
      "Epoch [5650/100000], Loss: 140.9938\n",
      "Epoch [5660/100000], Loss: 139.8816\n",
      "Epoch [5670/100000], Loss: 138.7707\n",
      "Epoch [5680/100000], Loss: 137.6684\n",
      "Epoch [5690/100000], Loss: 136.5997\n",
      "Epoch [5700/100000], Loss: 135.5354\n",
      "Epoch [5710/100000], Loss: 134.4532\n",
      "Epoch [5720/100000], Loss: 133.3834\n",
      "Epoch [5730/100000], Loss: 132.3627\n",
      "Epoch [5740/100000], Loss: 131.3197\n",
      "Epoch [5750/100000], Loss: 130.2812\n",
      "Epoch [5760/100000], Loss: 129.2188\n",
      "Epoch [5770/100000], Loss: 128.2094\n",
      "Epoch [5780/100000], Loss: 127.2098\n",
      "Epoch [5790/100000], Loss: 126.2256\n",
      "Epoch [5800/100000], Loss: 125.1968\n",
      "Epoch [5810/100000], Loss: 124.1842\n",
      "Epoch [5820/100000], Loss: 123.1942\n",
      "Epoch [5830/100000], Loss: 122.1724\n",
      "Epoch [5840/100000], Loss: 121.1688\n",
      "Epoch [5850/100000], Loss: 120.2109\n",
      "Epoch [5860/100000], Loss: 119.1936\n",
      "Epoch [5870/100000], Loss: 118.2569\n",
      "Epoch [5880/100000], Loss: 117.3197\n",
      "Epoch [5890/100000], Loss: 116.3843\n",
      "Epoch [5900/100000], Loss: 115.4065\n",
      "Epoch [5910/100000], Loss: 114.5173\n",
      "Epoch [5920/100000], Loss: 113.5716\n",
      "Epoch [5930/100000], Loss: 112.6476\n",
      "Epoch [5940/100000], Loss: 111.7064\n",
      "Epoch [5950/100000], Loss: 110.8158\n",
      "Epoch [5960/100000], Loss: 109.9016\n",
      "Epoch [5970/100000], Loss: 109.0209\n",
      "Epoch [5980/100000], Loss: 108.0846\n",
      "Epoch [5990/100000], Loss: 107.2647\n",
      "Epoch [6000/100000], Loss: 106.4533\n",
      "Epoch [6010/100000], Loss: 105.5263\n",
      "Epoch [6020/100000], Loss: 104.6254\n",
      "Epoch [6030/100000], Loss: 103.8019\n",
      "Epoch [6040/100000], Loss: 102.9770\n",
      "Epoch [6050/100000], Loss: 102.1178\n",
      "Epoch [6060/100000], Loss: 101.2791\n",
      "Epoch [6070/100000], Loss: 100.4635\n",
      "Epoch [6080/100000], Loss: 99.6332\n",
      "Epoch [6090/100000], Loss: 98.8594\n",
      "Epoch [6100/100000], Loss: 98.0067\n",
      "Epoch [6110/100000], Loss: 97.2375\n",
      "Epoch [6120/100000], Loss: 96.4135\n",
      "Epoch [6130/100000], Loss: 95.6216\n",
      "Epoch [6140/100000], Loss: 94.8593\n",
      "Epoch [6150/100000], Loss: 94.0374\n",
      "Epoch [6160/100000], Loss: 93.3199\n",
      "Epoch [6170/100000], Loss: 92.5258\n",
      "Epoch [6180/100000], Loss: 91.7877\n",
      "Epoch [6190/100000], Loss: 91.0650\n",
      "Epoch [6200/100000], Loss: 90.3478\n",
      "Epoch [6210/100000], Loss: 89.5821\n",
      "Epoch [6220/100000], Loss: 88.8799\n",
      "Epoch [6230/100000], Loss: 88.2275\n",
      "Epoch [6240/100000], Loss: 87.4816\n",
      "Epoch [6250/100000], Loss: 86.7751\n",
      "Epoch [6260/100000], Loss: 86.0836\n",
      "Epoch [6270/100000], Loss: 85.3294\n",
      "Epoch [6280/100000], Loss: 84.7260\n",
      "Epoch [6290/100000], Loss: 84.0770\n",
      "Epoch [6300/100000], Loss: 83.3948\n",
      "Epoch [6310/100000], Loss: 82.7223\n",
      "Epoch [6320/100000], Loss: 82.0658\n",
      "Epoch [6330/100000], Loss: 37161920.0000\n",
      "Epoch [6340/100000], Loss: 392276.7500\n",
      "Epoch [6350/100000], Loss: 1209795.8750\n",
      "Epoch [6360/100000], Loss: 1018545.4375\n",
      "Epoch [6370/100000], Loss: 489429.0000\n",
      "Epoch [6380/100000], Loss: 181878.0938\n",
      "Epoch [6390/100000], Loss: 48108.2344\n",
      "Epoch [6400/100000], Loss: 8417.7246\n",
      "Epoch [6410/100000], Loss: 837.6512\n",
      "Epoch [6420/100000], Loss: 547.6961\n",
      "Epoch [6430/100000], Loss: 593.2360\n",
      "Epoch [6440/100000], Loss: 359.2036\n",
      "Epoch [6450/100000], Loss: 167.1898\n",
      "Epoch [6460/100000], Loss: 88.5105\n",
      "Epoch [6470/100000], Loss: 73.9181\n",
      "Epoch [6480/100000], Loss: 74.9448\n",
      "Epoch [6490/100000], Loss: 73.5427\n",
      "Epoch [6500/100000], Loss: 72.0364\n",
      "Epoch [6510/100000], Loss: 71.0419\n",
      "Epoch [6520/100000], Loss: 70.5682\n",
      "Epoch [6530/100000], Loss: 70.0108\n",
      "Epoch [6540/100000], Loss: 69.4809\n",
      "Epoch [6550/100000], Loss: 68.9609\n",
      "Epoch [6560/100000], Loss: 68.5197\n",
      "Epoch [6570/100000], Loss: 67.9595\n",
      "Epoch [6580/100000], Loss: 67.5058\n",
      "Epoch [6590/100000], Loss: 67.0320\n",
      "Epoch [6600/100000], Loss: 66.5010\n",
      "Epoch [6610/100000], Loss: 66.0547\n",
      "Epoch [6620/100000], Loss: 65.5850\n",
      "Epoch [6630/100000], Loss: 65.1154\n",
      "Epoch [6640/100000], Loss: 64.6530\n",
      "Epoch [6650/100000], Loss: 64.1789\n",
      "Epoch [6660/100000], Loss: 63.7068\n",
      "Epoch [6670/100000], Loss: 63.2884\n",
      "Epoch [6680/100000], Loss: 62.8300\n",
      "Epoch [6690/100000], Loss: 62.3771\n",
      "Epoch [6700/100000], Loss: 61.8671\n",
      "Epoch [6710/100000], Loss: 61.4989\n",
      "Epoch [6720/100000], Loss: 61.0934\n",
      "Epoch [6730/100000], Loss: 60.6848\n",
      "Epoch [6740/100000], Loss: 60.2447\n",
      "Epoch [6750/100000], Loss: 59.8406\n",
      "Epoch [6760/100000], Loss: 59.4736\n",
      "Epoch [6770/100000], Loss: 59.0414\n",
      "Epoch [6780/100000], Loss: 58.7166\n",
      "Epoch [6790/100000], Loss: 58.3058\n",
      "Epoch [6800/100000], Loss: 57.9368\n",
      "Epoch [6810/100000], Loss: 57.5851\n",
      "Epoch [6820/100000], Loss: 57.2226\n",
      "Epoch [6830/100000], Loss: 56.8910\n",
      "Epoch [6840/100000], Loss: 56.5533\n",
      "Epoch [6850/100000], Loss: 56.1718\n",
      "Epoch [6860/100000], Loss: 55.8551\n",
      "Epoch [6870/100000], Loss: 55.5295\n",
      "Epoch [6880/100000], Loss: 55.1748\n",
      "Epoch [6890/100000], Loss: 54.8418\n",
      "Epoch [6900/100000], Loss: 54.5050\n",
      "Epoch [6910/100000], Loss: 54.2023\n",
      "Epoch [6920/100000], Loss: 53.8712\n",
      "Epoch [6930/100000], Loss: 53.5506\n",
      "Epoch [6940/100000], Loss: 53.2387\n",
      "Epoch [6950/100000], Loss: 52.9714\n",
      "Epoch [6960/100000], Loss: 52.6954\n",
      "Epoch [6970/100000], Loss: 52.3833\n",
      "Epoch [6980/100000], Loss: 52.0604\n",
      "Epoch [6990/100000], Loss: 51.7776\n",
      "Epoch [7000/100000], Loss: 51.4976\n",
      "Epoch [7010/100000], Loss: 51.2259\n",
      "Epoch [7020/100000], Loss: 50.9603\n",
      "Epoch [7030/100000], Loss: 50.7167\n",
      "Epoch [7040/100000], Loss: 50.4164\n",
      "Epoch [7050/100000], Loss: 50.1538\n",
      "Epoch [7060/100000], Loss: 49.8685\n",
      "Epoch [7070/100000], Loss: 49.6179\n",
      "Epoch [7080/100000], Loss: 49.3822\n",
      "Epoch [7090/100000], Loss: 49.1304\n",
      "Epoch [7100/100000], Loss: 48.8808\n",
      "Epoch [7110/100000], Loss: 48.6433\n",
      "Epoch [7120/100000], Loss: 48.4022\n",
      "Epoch [7130/100000], Loss: 48.1815\n",
      "Epoch [7140/100000], Loss: 47.9568\n",
      "Epoch [7150/100000], Loss: 47.7538\n",
      "Epoch [7160/100000], Loss: 47.5236\n",
      "Epoch [7170/100000], Loss: 47.3032\n",
      "Epoch [7180/100000], Loss: 47.1165\n",
      "Epoch [7190/100000], Loss: 46.8965\n",
      "Epoch [7200/100000], Loss: 46.6786\n",
      "Epoch [7210/100000], Loss: 46.5048\n",
      "Epoch [7220/100000], Loss: 46.2931\n",
      "Epoch [7230/100000], Loss: 46.1126\n",
      "Epoch [7240/100000], Loss: 45.8947\n",
      "Epoch [7250/100000], Loss: 45.7320\n",
      "Epoch [7260/100000], Loss: 45.5306\n",
      "Epoch [7270/100000], Loss: 45.3496\n",
      "Epoch [7280/100000], Loss: 45.1983\n",
      "Epoch [7290/100000], Loss: 45.0076\n",
      "Epoch [7300/100000], Loss: 44.8221\n",
      "Epoch [7310/100000], Loss: 44.6628\n",
      "Epoch [7320/100000], Loss: 44.4914\n",
      "Epoch [7330/100000], Loss: 44.3250\n",
      "Epoch [7340/100000], Loss: 44.1668\n",
      "Epoch [7350/100000], Loss: 44.0232\n",
      "Epoch [7360/100000], Loss: 43.8271\n",
      "Epoch [7370/100000], Loss: 43.7134\n",
      "Epoch [7380/100000], Loss: 43.5452\n",
      "Epoch [7390/100000], Loss: 43.4054\n",
      "Epoch [7400/100000], Loss: 43.2415\n",
      "Epoch [7410/100000], Loss: 43.1022\n",
      "Epoch [7420/100000], Loss: 42.9655\n",
      "Epoch [7430/100000], Loss: 42.7942\n",
      "Epoch [7440/100000], Loss: 42.6746\n",
      "Epoch [7450/100000], Loss: 42.5357\n",
      "Epoch [7460/100000], Loss: 42.4245\n",
      "Epoch [7470/100000], Loss: 42.2661\n",
      "Epoch [7480/100000], Loss: 42.1256\n",
      "Epoch [7490/100000], Loss: 42.0202\n",
      "Epoch [7500/100000], Loss: 41.9005\n",
      "Epoch [7510/100000], Loss: 41.7953\n",
      "Epoch [7520/100000], Loss: 41.6618\n",
      "Epoch [7530/100000], Loss: 41.5349\n",
      "Epoch [7540/100000], Loss: 41.4364\n",
      "Epoch [7550/100000], Loss: 41.3217\n",
      "Epoch [7560/100000], Loss: 41.2128\n",
      "Epoch [7570/100000], Loss: 41.1043\n",
      "Epoch [7580/100000], Loss: 40.9747\n",
      "Epoch [7590/100000], Loss: 40.8661\n",
      "Epoch [7600/100000], Loss: 40.7761\n",
      "Epoch [7610/100000], Loss: 40.6886\n",
      "Epoch [7620/100000], Loss: 40.5847\n",
      "Epoch [7630/100000], Loss: 40.4793\n",
      "Epoch [7640/100000], Loss: 40.3995\n",
      "Epoch [7650/100000], Loss: 40.3019\n",
      "Epoch [7660/100000], Loss: 40.1806\n",
      "Epoch [7670/100000], Loss: 40.1057\n",
      "Epoch [7680/100000], Loss: 39.9979\n",
      "Epoch [7690/100000], Loss: 39.9408\n",
      "Epoch [7700/100000], Loss: 39.8401\n",
      "Epoch [7710/100000], Loss: 39.7715\n",
      "Epoch [7720/100000], Loss: 39.6856\n",
      "Epoch [7730/100000], Loss: 39.5909\n",
      "Epoch [7740/100000], Loss: 39.4955\n",
      "Epoch [7750/100000], Loss: 39.4046\n",
      "Epoch [7760/100000], Loss: 39.3159\n",
      "Epoch [7770/100000], Loss: 39.2231\n",
      "Epoch [7780/100000], Loss: 39.1874\n",
      "Epoch [7790/100000], Loss: 39.0990\n",
      "Epoch [7800/100000], Loss: 38.9860\n",
      "Epoch [7810/100000], Loss: 38.9132\n",
      "Epoch [7820/100000], Loss: 38.8489\n",
      "Epoch [7830/100000], Loss: 38.7756\n",
      "Epoch [7840/100000], Loss: 38.7046\n",
      "Epoch [7850/100000], Loss: 38.6409\n",
      "Epoch [7860/100000], Loss: 38.5720\n",
      "Epoch [7870/100000], Loss: 38.5157\n",
      "Epoch [7880/100000], Loss: 38.4173\n",
      "Epoch [7890/100000], Loss: 38.3775\n",
      "Epoch [7900/100000], Loss: 38.3154\n",
      "Epoch [7910/100000], Loss: 38.2320\n",
      "Epoch [7920/100000], Loss: 38.1885\n",
      "Epoch [7930/100000], Loss: 38.1360\n",
      "Epoch [7940/100000], Loss: 38.0659\n",
      "Epoch [7950/100000], Loss: 38.0031\n",
      "Epoch [7960/100000], Loss: 37.9420\n",
      "Epoch [7970/100000], Loss: 37.9049\n",
      "Epoch [7980/100000], Loss: 37.8291\n",
      "Epoch [7990/100000], Loss: 37.7579\n",
      "Epoch [8000/100000], Loss: 37.6866\n",
      "Epoch [8010/100000], Loss: 37.6499\n",
      "Epoch [8020/100000], Loss: 37.6054\n",
      "Epoch [8030/100000], Loss: 37.5338\n",
      "Epoch [8040/100000], Loss: 37.4762\n",
      "Epoch [8050/100000], Loss: 37.4185\n",
      "Epoch [8060/100000], Loss: 37.3624\n",
      "Epoch [8070/100000], Loss: 37.3395\n",
      "Epoch [8080/100000], Loss: 37.2798\n",
      "Epoch [8090/100000], Loss: 37.2110\n",
      "Epoch [8100/100000], Loss: 37.1674\n",
      "Epoch [8110/100000], Loss: 37.0984\n",
      "Epoch [8120/100000], Loss: 37.0458\n",
      "Epoch [8130/100000], Loss: 36.9906\n",
      "Epoch [8140/100000], Loss: 36.9661\n",
      "Epoch [8150/100000], Loss: 36.8876\n",
      "Epoch [8160/100000], Loss: 36.8561\n",
      "Epoch [8170/100000], Loss: 36.7999\n",
      "Epoch [8180/100000], Loss: 36.7422\n",
      "Epoch [8190/100000], Loss: 36.7023\n",
      "Epoch [8200/100000], Loss: 36.6366\n",
      "Epoch [8210/100000], Loss: 36.5984\n",
      "Epoch [8220/100000], Loss: 36.5508\n",
      "Epoch [8230/100000], Loss: 36.5037\n",
      "Epoch [8240/100000], Loss: 36.4510\n",
      "Epoch [8250/100000], Loss: 36.4082\n",
      "Epoch [8260/100000], Loss: 36.3717\n",
      "Epoch [8270/100000], Loss: 36.3201\n",
      "Epoch [8280/100000], Loss: 36.2609\n",
      "Epoch [8290/100000], Loss: 36.2117\n",
      "Epoch [8300/100000], Loss: 36.1699\n",
      "Epoch [8310/100000], Loss: 36.1316\n",
      "Epoch [8320/100000], Loss: 36.0811\n",
      "Epoch [8330/100000], Loss: 36.0147\n",
      "Epoch [8340/100000], Loss: 35.9880\n",
      "Epoch [8350/100000], Loss: 35.9384\n",
      "Epoch [8360/100000], Loss: 35.8891\n",
      "Epoch [8370/100000], Loss: 35.8655\n",
      "Epoch [8380/100000], Loss: 35.8109\n",
      "Epoch [8390/100000], Loss: 35.7781\n",
      "Epoch [8400/100000], Loss: 35.7313\n",
      "Epoch [8410/100000], Loss: 35.6789\n",
      "Epoch [8420/100000], Loss: 35.6431\n",
      "Epoch [8430/100000], Loss: 35.6229\n",
      "Epoch [8440/100000], Loss: 35.5611\n",
      "Epoch [8450/100000], Loss: 35.5192\n",
      "Epoch [8460/100000], Loss: 35.4982\n",
      "Epoch [8470/100000], Loss: 35.4221\n",
      "Epoch [8480/100000], Loss: 35.3899\n",
      "Epoch [8490/100000], Loss: 35.3388\n",
      "Epoch [8500/100000], Loss: 35.2909\n",
      "Epoch [8510/100000], Loss: 35.2730\n",
      "Epoch [8520/100000], Loss: 35.2042\n",
      "Epoch [8530/100000], Loss: 35.1468\n",
      "Epoch [8540/100000], Loss: 35.1626\n",
      "Epoch [8550/100000], Loss: 35.0960\n",
      "Epoch [8560/100000], Loss: 35.0565\n",
      "Epoch [8570/100000], Loss: 35.0210\n",
      "Epoch [8580/100000], Loss: 34.9800\n",
      "Epoch [8590/100000], Loss: 34.9181\n",
      "Epoch [8600/100000], Loss: 34.8679\n",
      "Epoch [8610/100000], Loss: 34.8085\n",
      "Epoch [8620/100000], Loss: 34.7873\n",
      "Epoch [8630/100000], Loss: 34.7447\n",
      "Epoch [8640/100000], Loss: 34.7206\n",
      "Epoch [8650/100000], Loss: 34.6825\n",
      "Epoch [8660/100000], Loss: 34.6247\n",
      "Epoch [8670/100000], Loss: 34.5939\n",
      "Epoch [8680/100000], Loss: 34.5414\n",
      "Epoch [8690/100000], Loss: 34.4914\n",
      "Epoch [8700/100000], Loss: 34.4626\n",
      "Epoch [8710/100000], Loss: 34.4224\n",
      "Epoch [8720/100000], Loss: 34.3536\n",
      "Epoch [8730/100000], Loss: 34.3387\n",
      "Epoch [8740/100000], Loss: 34.2823\n",
      "Epoch [8750/100000], Loss: 34.2371\n",
      "Epoch [8760/100000], Loss: 34.1924\n",
      "Epoch [8770/100000], Loss: 34.1638\n",
      "Epoch [8780/100000], Loss: 34.1163\n",
      "Epoch [8790/100000], Loss: 34.0756\n",
      "Epoch [8800/100000], Loss: 34.0168\n",
      "Epoch [8810/100000], Loss: 33.9703\n",
      "Epoch [8820/100000], Loss: 33.9448\n",
      "Epoch [8830/100000], Loss: 33.8946\n",
      "Epoch [8840/100000], Loss: 33.8540\n",
      "Epoch [8850/100000], Loss: 33.8190\n",
      "Epoch [8860/100000], Loss: 33.7723\n",
      "Epoch [8870/100000], Loss: 33.7312\n",
      "Epoch [8880/100000], Loss: 33.6758\n",
      "Epoch [8890/100000], Loss: 33.6340\n",
      "Epoch [8900/100000], Loss: 33.5986\n",
      "Epoch [8910/100000], Loss: 33.5413\n",
      "Epoch [8920/100000], Loss: 33.5162\n",
      "Epoch [8930/100000], Loss: 33.4554\n",
      "Epoch [8940/100000], Loss: 33.4072\n",
      "Epoch [8950/100000], Loss: 33.3619\n",
      "Epoch [8960/100000], Loss: 33.3289\n",
      "Epoch [8970/100000], Loss: 33.3076\n",
      "Epoch [8980/100000], Loss: 33.2381\n",
      "Epoch [8990/100000], Loss: 33.1893\n",
      "Epoch [9000/100000], Loss: 33.1559\n",
      "Epoch [9010/100000], Loss: 33.1245\n",
      "Epoch [9020/100000], Loss: 33.0500\n",
      "Epoch [9030/100000], Loss: 33.0054\n",
      "Epoch [9040/100000], Loss: 32.9606\n",
      "Epoch [9050/100000], Loss: 32.9314\n",
      "Epoch [9060/100000], Loss: 32.9068\n",
      "Epoch [9070/100000], Loss: 32.8482\n",
      "Epoch [9080/100000], Loss: 32.8109\n",
      "Epoch [9090/100000], Loss: 32.7512\n",
      "Epoch [9100/100000], Loss: 32.7024\n",
      "Epoch [9110/100000], Loss: 32.6675\n",
      "Epoch [9120/100000], Loss: 32.6298\n",
      "Epoch [9130/100000], Loss: 249395.9375\n",
      "Epoch [9140/100000], Loss: 2002584576.0000\n",
      "Epoch [9150/100000], Loss: 727714176.0000\n",
      "Epoch [9160/100000], Loss: 246522128.0000\n",
      "Epoch [9170/100000], Loss: 83253640.0000\n",
      "Epoch [9180/100000], Loss: 16459060.0000\n",
      "Epoch [9190/100000], Loss: 402596.2812\n",
      "Epoch [9200/100000], Loss: 786015.2500\n",
      "Epoch [9210/100000], Loss: 777902.5625\n",
      "Epoch [9220/100000], Loss: 310212.5938\n",
      "Epoch [9230/100000], Loss: 141705.2500\n",
      "Epoch [9240/100000], Loss: 67090.4766\n",
      "Epoch [9250/100000], Loss: 21857.0137\n",
      "Epoch [9260/100000], Loss: 5610.8066\n",
      "Epoch [9270/100000], Loss: 1921.7400\n",
      "Epoch [9280/100000], Loss: 757.2275\n",
      "Epoch [9290/100000], Loss: 239.7659\n",
      "Epoch [9300/100000], Loss: 78.5507\n",
      "Epoch [9310/100000], Loss: 46.3274\n",
      "Epoch [9320/100000], Loss: 40.6971\n",
      "Epoch [9330/100000], Loss: 35.1758\n",
      "Epoch [9340/100000], Loss: 32.4589\n",
      "Epoch [9350/100000], Loss: 32.5564\n",
      "Epoch [9360/100000], Loss: 32.2368\n",
      "Epoch [9370/100000], Loss: 32.1461\n",
      "Epoch [9380/100000], Loss: 32.1090\n",
      "Epoch [9390/100000], Loss: 32.0815\n",
      "Epoch [9400/100000], Loss: 32.0794\n",
      "Epoch [9410/100000], Loss: 32.0796\n",
      "Epoch [9420/100000], Loss: 32.0708\n",
      "Epoch [9430/100000], Loss: 32.0534\n",
      "Epoch [9440/100000], Loss: 32.0557\n",
      "Epoch [9450/100000], Loss: 32.0525\n",
      "Epoch [9460/100000], Loss: 32.0362\n",
      "Epoch [9470/100000], Loss: 32.0247\n",
      "Epoch [9480/100000], Loss: 32.0245\n",
      "Epoch [9490/100000], Loss: 32.0104\n",
      "Epoch [9500/100000], Loss: 32.0224\n",
      "Epoch [9510/100000], Loss: 31.9864\n",
      "Epoch [9520/100000], Loss: 31.9803\n",
      "Epoch [9530/100000], Loss: 31.9611\n",
      "Epoch [9540/100000], Loss: 31.9760\n",
      "Epoch [9550/100000], Loss: 31.9556\n",
      "Epoch [9560/100000], Loss: 31.9387\n",
      "Epoch [9570/100000], Loss: 31.9265\n",
      "Epoch [9580/100000], Loss: 31.9115\n",
      "Epoch [9590/100000], Loss: 31.8920\n",
      "Epoch [9600/100000], Loss: 31.8833\n",
      "Epoch [9610/100000], Loss: 31.8868\n",
      "Epoch [9620/100000], Loss: 31.8904\n",
      "Epoch [9630/100000], Loss: 31.8585\n",
      "Epoch [9640/100000], Loss: 31.8471\n",
      "Epoch [9650/100000], Loss: 31.8554\n",
      "Epoch [9660/100000], Loss: 31.8532\n",
      "Epoch [9670/100000], Loss: 31.8384\n",
      "Epoch [9680/100000], Loss: 31.8135\n",
      "Epoch [9690/100000], Loss: 31.8017\n",
      "Epoch [9700/100000], Loss: 31.8003\n",
      "Epoch [9710/100000], Loss: 31.7951\n",
      "Epoch [9720/100000], Loss: 31.7861\n",
      "Epoch [9730/100000], Loss: 31.7928\n",
      "Epoch [9740/100000], Loss: 31.7731\n",
      "Epoch [9750/100000], Loss: 31.7437\n",
      "Epoch [9760/100000], Loss: 31.7430\n",
      "Epoch [9770/100000], Loss: 31.7556\n",
      "Epoch [9780/100000], Loss: 31.7455\n",
      "Epoch [9790/100000], Loss: 31.7290\n",
      "Epoch [9800/100000], Loss: 31.7107\n",
      "Epoch [9810/100000], Loss: 31.7066\n",
      "Epoch [9820/100000], Loss: 31.7104\n",
      "Epoch [9830/100000], Loss: 31.6959\n",
      "Epoch [9840/100000], Loss: 31.6880\n",
      "Epoch [9850/100000], Loss: 31.6790\n",
      "Epoch [9860/100000], Loss: 31.6517\n",
      "Epoch [9870/100000], Loss: 31.6404\n",
      "Epoch [9880/100000], Loss: 31.6419\n",
      "Epoch [9890/100000], Loss: 31.6315\n",
      "Epoch [9900/100000], Loss: 31.6233\n",
      "Epoch [9910/100000], Loss: 31.6039\n",
      "Epoch [9920/100000], Loss: 31.5831\n",
      "Epoch [9930/100000], Loss: 31.5805\n",
      "Epoch [9940/100000], Loss: 31.5592\n",
      "Epoch [9950/100000], Loss: 31.5530\n",
      "Epoch [9960/100000], Loss: 31.5501\n",
      "Epoch [9970/100000], Loss: 31.5374\n",
      "Epoch [9980/100000], Loss: 31.5258\n",
      "Epoch [9990/100000], Loss: 31.5152\n",
      "Epoch [10000/100000], Loss: 31.5088\n",
      "Epoch [10010/100000], Loss: 31.4923\n",
      "Epoch [10020/100000], Loss: 31.5072\n",
      "Epoch [10030/100000], Loss: 31.4793\n",
      "Epoch [10040/100000], Loss: 31.4600\n",
      "Epoch [10050/100000], Loss: 31.4415\n",
      "Epoch [10060/100000], Loss: 31.4414\n",
      "Epoch [10070/100000], Loss: 31.4166\n",
      "Epoch [10080/100000], Loss: 31.4122\n",
      "Epoch [10090/100000], Loss: 31.4057\n",
      "Epoch [10100/100000], Loss: 31.3869\n",
      "Epoch [10110/100000], Loss: 31.3817\n",
      "Epoch [10120/100000], Loss: 31.3691\n",
      "Epoch [10130/100000], Loss: 31.3578\n",
      "Epoch [10140/100000], Loss: 31.3535\n",
      "Epoch [10150/100000], Loss: 31.3259\n",
      "Epoch [10160/100000], Loss: 31.3378\n",
      "Epoch [10170/100000], Loss: 31.3339\n",
      "Epoch [10180/100000], Loss: 31.3278\n",
      "Epoch [10190/100000], Loss: 31.3122\n",
      "Epoch [10200/100000], Loss: 31.2941\n",
      "Epoch [10210/100000], Loss: 31.2908\n",
      "Epoch [10220/100000], Loss: 31.2858\n",
      "Epoch [10230/100000], Loss: 31.2777\n",
      "Epoch [10240/100000], Loss: 31.2507\n",
      "Epoch [10250/100000], Loss: 31.2465\n",
      "Epoch [10260/100000], Loss: 31.2209\n",
      "Epoch [10270/100000], Loss: 31.2177\n",
      "Epoch [10280/100000], Loss: 31.2076\n",
      "Epoch [10290/100000], Loss: 31.1884\n",
      "Epoch [10300/100000], Loss: 31.1822\n",
      "Epoch [10310/100000], Loss: 31.1516\n",
      "Epoch [10320/100000], Loss: 31.1374\n",
      "Epoch [10330/100000], Loss: 31.1126\n",
      "Epoch [10340/100000], Loss: 31.1073\n",
      "Epoch [10350/100000], Loss: 31.0963\n",
      "Epoch [10360/100000], Loss: 31.0983\n",
      "Epoch [10370/100000], Loss: 31.0871\n",
      "Epoch [10380/100000], Loss: 31.0729\n",
      "Epoch [10390/100000], Loss: 31.0550\n",
      "Epoch [10400/100000], Loss: 31.0340\n",
      "Epoch [10410/100000], Loss: 31.0265\n",
      "Epoch [10420/100000], Loss: 31.0099\n",
      "Epoch [10430/100000], Loss: 31.0043\n",
      "Epoch [10440/100000], Loss: 30.9776\n",
      "Epoch [10450/100000], Loss: 30.9690\n",
      "Epoch [10460/100000], Loss: 30.9734\n",
      "Epoch [10470/100000], Loss: 30.9603\n",
      "Epoch [10480/100000], Loss: 30.9343\n",
      "Epoch [10490/100000], Loss: 30.9235\n",
      "Epoch [10500/100000], Loss: 30.9060\n",
      "Epoch [10510/100000], Loss: 30.8902\n",
      "Epoch [10520/100000], Loss: 30.8943\n",
      "Epoch [10530/100000], Loss: 30.8760\n",
      "Epoch [10540/100000], Loss: 30.8461\n",
      "Epoch [10550/100000], Loss: 30.8304\n",
      "Epoch [10560/100000], Loss: 30.8419\n",
      "Epoch [10570/100000], Loss: 30.8150\n",
      "Epoch [10580/100000], Loss: 30.8002\n",
      "Epoch [10590/100000], Loss: 30.7931\n",
      "Epoch [10600/100000], Loss: 30.7766\n",
      "Epoch [10610/100000], Loss: 30.7572\n",
      "Epoch [10620/100000], Loss: 30.7320\n",
      "Epoch [10630/100000], Loss: 30.7392\n",
      "Epoch [10640/100000], Loss: 30.7122\n",
      "Epoch [10650/100000], Loss: 30.6829\n",
      "Epoch [10660/100000], Loss: 30.6643\n",
      "Epoch [10670/100000], Loss: 30.6571\n",
      "Epoch [10680/100000], Loss: 30.6453\n",
      "Epoch [10690/100000], Loss: 30.6342\n",
      "Epoch [10700/100000], Loss: 30.6199\n",
      "Epoch [10710/100000], Loss: 30.6097\n",
      "Epoch [10720/100000], Loss: 30.5882\n",
      "Epoch [10730/100000], Loss: 30.5723\n",
      "Epoch [10740/100000], Loss: 30.5660\n",
      "Epoch [10750/100000], Loss: 30.5605\n",
      "Epoch [10760/100000], Loss: 30.5310\n",
      "Epoch [10770/100000], Loss: 30.5188\n",
      "Epoch [10780/100000], Loss: 30.5101\n",
      "Epoch [10790/100000], Loss: 30.4921\n",
      "Epoch [10800/100000], Loss: 30.4744\n",
      "Epoch [10810/100000], Loss: 30.4645\n",
      "Epoch [10820/100000], Loss: 30.4485\n",
      "Epoch [10830/100000], Loss: 30.4227\n",
      "Epoch [10840/100000], Loss: 30.4123\n",
      "Epoch [10850/100000], Loss: 30.3906\n",
      "Epoch [10860/100000], Loss: 30.3802\n",
      "Epoch [10870/100000], Loss: 30.3692\n",
      "Epoch [10880/100000], Loss: 30.3472\n",
      "Epoch [10890/100000], Loss: 30.3307\n",
      "Epoch [10900/100000], Loss: 30.2732\n",
      "Epoch [10910/100000], Loss: 30.2712\n",
      "Epoch [10920/100000], Loss: 30.2635\n",
      "Epoch [10930/100000], Loss: 30.2355\n",
      "Epoch [10940/100000], Loss: 30.2513\n",
      "Epoch [10950/100000], Loss: 30.2406\n",
      "Epoch [10960/100000], Loss: 30.2136\n",
      "Epoch [10970/100000], Loss: 30.2016\n",
      "Epoch [10980/100000], Loss: 30.1886\n",
      "Epoch [10990/100000], Loss: 30.1683\n",
      "Epoch [11000/100000], Loss: 30.1396\n",
      "Epoch [11010/100000], Loss: 30.1073\n",
      "Epoch [11020/100000], Loss: 30.1004\n",
      "Epoch [11030/100000], Loss: 30.0933\n",
      "Epoch [11040/100000], Loss: 30.0631\n",
      "Epoch [11050/100000], Loss: 30.0533\n",
      "Epoch [11060/100000], Loss: 30.0326\n",
      "Epoch [11070/100000], Loss: 30.0278\n",
      "Epoch [11080/100000], Loss: 30.0035\n",
      "Epoch [11090/100000], Loss: 29.9975\n",
      "Epoch [11100/100000], Loss: 29.9736\n",
      "Epoch [11110/100000], Loss: 29.9364\n",
      "Epoch [11120/100000], Loss: 29.9292\n",
      "Epoch [11130/100000], Loss: 29.9154\n",
      "Epoch [11140/100000], Loss: 29.9051\n",
      "Epoch [11150/100000], Loss: 29.8760\n",
      "Epoch [11160/100000], Loss: 29.8698\n",
      "Epoch [11170/100000], Loss: 29.8647\n",
      "Epoch [11180/100000], Loss: 29.8501\n",
      "Epoch [11190/100000], Loss: 29.8403\n",
      "Epoch [11200/100000], Loss: 29.8110\n",
      "Epoch [11210/100000], Loss: 29.7936\n",
      "Epoch [11220/100000], Loss: 29.7627\n",
      "Epoch [11230/100000], Loss: 29.7381\n",
      "Epoch [11240/100000], Loss: 29.7116\n",
      "Epoch [11250/100000], Loss: 29.6876\n",
      "Epoch [11260/100000], Loss: 29.6667\n",
      "Epoch [11270/100000], Loss: 29.6388\n",
      "Epoch [11280/100000], Loss: 29.6216\n",
      "Epoch [11290/100000], Loss: 29.5990\n",
      "Epoch [11300/100000], Loss: 29.5953\n",
      "Epoch [11310/100000], Loss: 29.5616\n",
      "Epoch [11320/100000], Loss: 29.5658\n",
      "Epoch [11330/100000], Loss: 29.5491\n",
      "Epoch [11340/100000], Loss: 29.5194\n",
      "Epoch [11350/100000], Loss: 29.5109\n",
      "Epoch [11360/100000], Loss: 29.4884\n",
      "Epoch [11370/100000], Loss: 29.4572\n",
      "Epoch [11380/100000], Loss: 29.4508\n",
      "Epoch [11390/100000], Loss: 29.4293\n",
      "Epoch [11400/100000], Loss: 29.4140\n",
      "Epoch [11410/100000], Loss: 29.3870\n",
      "Epoch [11420/100000], Loss: 29.3766\n",
      "Epoch [11430/100000], Loss: 29.3550\n",
      "Epoch [11440/100000], Loss: 29.3380\n",
      "Epoch [11450/100000], Loss: 29.3151\n",
      "Epoch [11460/100000], Loss: 29.2966\n",
      "Epoch [11470/100000], Loss: 29.2624\n",
      "Epoch [11480/100000], Loss: 29.2521\n",
      "Epoch [11490/100000], Loss: 29.2268\n",
      "Epoch [11500/100000], Loss: 29.2057\n",
      "Epoch [11510/100000], Loss: 29.1774\n",
      "Epoch [11520/100000], Loss: 29.1850\n",
      "Epoch [11530/100000], Loss: 29.1597\n",
      "Epoch [11540/100000], Loss: 29.1339\n",
      "Epoch [11550/100000], Loss: 29.1392\n",
      "Epoch [11560/100000], Loss: 29.1063\n",
      "Epoch [11570/100000], Loss: 29.0815\n",
      "Epoch [11580/100000], Loss: 29.0637\n",
      "Epoch [11590/100000], Loss: 29.0289\n",
      "Epoch [11600/100000], Loss: 29.0098\n",
      "Epoch [11610/100000], Loss: 28.9854\n",
      "Epoch [11620/100000], Loss: 28.9656\n",
      "Epoch [11630/100000], Loss: 28.9555\n",
      "Epoch [11640/100000], Loss: 28.9327\n",
      "Epoch [11650/100000], Loss: 28.9110\n",
      "Epoch [11660/100000], Loss: 28.8852\n",
      "Epoch [11670/100000], Loss: 28.8606\n",
      "Epoch [11680/100000], Loss: 28.8475\n",
      "Epoch [11690/100000], Loss: 28.8200\n",
      "Epoch [11700/100000], Loss: 28.7881\n",
      "Epoch [11710/100000], Loss: 28.7884\n",
      "Epoch [11720/100000], Loss: 28.7781\n",
      "Epoch [11730/100000], Loss: 28.7605\n",
      "Epoch [11740/100000], Loss: 28.7164\n",
      "Epoch [11750/100000], Loss: 28.6936\n",
      "Epoch [11760/100000], Loss: 28.6791\n",
      "Epoch [11770/100000], Loss: 28.6708\n",
      "Epoch [11780/100000], Loss: 28.6463\n",
      "Epoch [11790/100000], Loss: 28.6121\n",
      "Epoch [11800/100000], Loss: 28.5888\n",
      "Epoch [11810/100000], Loss: 28.5738\n",
      "Epoch [11820/100000], Loss: 28.5354\n",
      "Epoch [11830/100000], Loss: 28.5257\n",
      "Epoch [11840/100000], Loss: 28.5000\n",
      "Epoch [11850/100000], Loss: 28.4776\n",
      "Epoch [11860/100000], Loss: 28.4809\n",
      "Epoch [11870/100000], Loss: 28.4251\n",
      "Epoch [11880/100000], Loss: 28.4228\n",
      "Epoch [11890/100000], Loss: 28.3829\n",
      "Epoch [11900/100000], Loss: 28.3687\n",
      "Epoch [11910/100000], Loss: 28.3528\n",
      "Epoch [11920/100000], Loss: 28.3138\n",
      "Epoch [11930/100000], Loss: 28.3118\n",
      "Epoch [11940/100000], Loss: 28.2757\n",
      "Epoch [11950/100000], Loss: 28.2457\n",
      "Epoch [11960/100000], Loss: 28.2142\n",
      "Epoch [11970/100000], Loss: 28.1982\n",
      "Epoch [11980/100000], Loss: 28.1488\n",
      "Epoch [11990/100000], Loss: 28.1532\n",
      "Epoch [12000/100000], Loss: 28.1214\n",
      "Epoch [12010/100000], Loss: 28.0909\n",
      "Epoch [12020/100000], Loss: 28.0425\n",
      "Epoch [12030/100000], Loss: 28.0281\n",
      "Epoch [12040/100000], Loss: 28.0085\n",
      "Epoch [12050/100000], Loss: 28.0199\n",
      "Epoch [12060/100000], Loss: 27.9903\n",
      "Epoch [12070/100000], Loss: 27.9507\n",
      "Epoch [12080/100000], Loss: 27.9229\n",
      "Epoch [12090/100000], Loss: 27.9030\n",
      "Epoch [12100/100000], Loss: 27.8814\n",
      "Epoch [12110/100000], Loss: 27.8575\n",
      "Epoch [12120/100000], Loss: 27.8336\n",
      "Epoch [12130/100000], Loss: 27.7957\n",
      "Epoch [12140/100000], Loss: 27.7629\n",
      "Epoch [12150/100000], Loss: 27.7568\n",
      "Epoch [12160/100000], Loss: 27.7371\n",
      "Epoch [12170/100000], Loss: 27.6986\n",
      "Epoch [12180/100000], Loss: 27.6811\n",
      "Epoch [12190/100000], Loss: 27.6645\n",
      "Epoch [12200/100000], Loss: 27.6392\n",
      "Epoch [12210/100000], Loss: 27.5986\n",
      "Epoch [12220/100000], Loss: 27.5817\n",
      "Epoch [12230/100000], Loss: 27.5559\n",
      "Epoch [12240/100000], Loss: 27.5229\n",
      "Epoch [12250/100000], Loss: 27.4924\n",
      "Epoch [12260/100000], Loss: 27.4598\n",
      "Epoch [12270/100000], Loss: 27.4450\n",
      "Epoch [12280/100000], Loss: 27.3984\n",
      "Epoch [12290/100000], Loss: 27.3956\n",
      "Epoch [12300/100000], Loss: 27.3576\n",
      "Epoch [12310/100000], Loss: 27.3340\n",
      "Epoch [12320/100000], Loss: 27.3178\n",
      "Epoch [12330/100000], Loss: 27.2752\n",
      "Epoch [12340/100000], Loss: 27.2535\n",
      "Epoch [12350/100000], Loss: 27.2236\n",
      "Epoch [12360/100000], Loss: 27.2081\n",
      "Epoch [12370/100000], Loss: 27.1719\n",
      "Epoch [12380/100000], Loss: 27.1475\n",
      "Epoch [12390/100000], Loss: 27.1150\n",
      "Epoch [12400/100000], Loss: 27.1005\n",
      "Epoch [12410/100000], Loss: 27.0783\n",
      "Epoch [12420/100000], Loss: 27.0375\n",
      "Epoch [12430/100000], Loss: 27.0268\n",
      "Epoch [12440/100000], Loss: 26.9864\n",
      "Epoch [12450/100000], Loss: 26.9488\n",
      "Epoch [12460/100000], Loss: 26.9305\n",
      "Epoch [12470/100000], Loss: 26.9095\n",
      "Epoch [12480/100000], Loss: 26.8899\n",
      "Epoch [12490/100000], Loss: 26.8524\n",
      "Epoch [12500/100000], Loss: 26.8348\n",
      "Epoch [12510/100000], Loss: 26.7737\n",
      "Epoch [12520/100000], Loss: 26.7595\n",
      "Epoch [12530/100000], Loss: 26.7306\n",
      "Epoch [12540/100000], Loss: 26.7053\n",
      "Epoch [12550/100000], Loss: 26.6927\n",
      "Epoch [12560/100000], Loss: 26.6399\n",
      "Epoch [12570/100000], Loss: 26.6261\n",
      "Epoch [12580/100000], Loss: 26.5943\n",
      "Epoch [12590/100000], Loss: 26.5708\n",
      "Epoch [12600/100000], Loss: 26.5367\n",
      "Epoch [12610/100000], Loss: 26.5087\n",
      "Epoch [12620/100000], Loss: 26.4918\n",
      "Epoch [12630/100000], Loss: 26.4454\n",
      "Epoch [12640/100000], Loss: 26.4282\n",
      "Epoch [12650/100000], Loss: 26.3966\n",
      "Epoch [12660/100000], Loss: 26.3877\n",
      "Epoch [12670/100000], Loss: 26.3382\n",
      "Epoch [12680/100000], Loss: 26.3232\n",
      "Epoch [12690/100000], Loss: 26.2827\n",
      "Epoch [12700/100000], Loss: 26.2652\n",
      "Epoch [12710/100000], Loss: 26.2290\n",
      "Epoch [12720/100000], Loss: 26.1931\n",
      "Epoch [12730/100000], Loss: 26.1699\n",
      "Epoch [12740/100000], Loss: 26.1329\n",
      "Epoch [12750/100000], Loss: 26.1002\n",
      "Epoch [12760/100000], Loss: 26.0869\n",
      "Epoch [12770/100000], Loss: 26.0398\n",
      "Epoch [12780/100000], Loss: 26.0183\n",
      "Epoch [12790/100000], Loss: 25.9840\n",
      "Epoch [12800/100000], Loss: 25.9688\n",
      "Epoch [12810/100000], Loss: 25.9304\n",
      "Epoch [12820/100000], Loss: 25.8896\n",
      "Epoch [12830/100000], Loss: 25.8765\n",
      "Epoch [12840/100000], Loss: 25.8193\n",
      "Epoch [12850/100000], Loss: 25.8135\n",
      "Epoch [12860/100000], Loss: 25.8041\n",
      "Epoch [12870/100000], Loss: 25.7571\n",
      "Epoch [12880/100000], Loss: 25.7183\n",
      "Epoch [12890/100000], Loss: 25.6911\n",
      "Epoch [12900/100000], Loss: 25.6575\n",
      "Epoch [12910/100000], Loss: 25.6272\n",
      "Epoch [12920/100000], Loss: 25.6114\n",
      "Epoch [12930/100000], Loss: 25.5804\n",
      "Epoch [12940/100000], Loss: 25.5414\n",
      "Epoch [12950/100000], Loss: 25.5167\n",
      "Epoch [12960/100000], Loss: 25.4681\n",
      "Epoch [12970/100000], Loss: 25.4488\n",
      "Epoch [12980/100000], Loss: 25.4137\n",
      "Epoch [12990/100000], Loss: 25.3941\n",
      "Epoch [13000/100000], Loss: 25.3537\n",
      "Epoch [13010/100000], Loss: 25.3176\n",
      "Epoch [13020/100000], Loss: 25.2729\n",
      "Epoch [13030/100000], Loss: 25.2441\n",
      "Epoch [13040/100000], Loss: 25.2119\n",
      "Epoch [13050/100000], Loss: 25.1823\n",
      "Epoch [13060/100000], Loss: 25.1512\n",
      "Epoch [13070/100000], Loss: 25.1366\n",
      "Epoch [13080/100000], Loss: 25.1105\n",
      "Epoch [13090/100000], Loss: 25.0619\n",
      "Epoch [13100/100000], Loss: 25.0201\n",
      "Epoch [13110/100000], Loss: 25.0108\n",
      "Epoch [13120/100000], Loss: 24.9567\n",
      "Epoch [13130/100000], Loss: 24.9191\n",
      "Epoch [13140/100000], Loss: 24.8980\n",
      "Epoch [13150/100000], Loss: 24.8680\n",
      "Epoch [13160/100000], Loss: 24.8487\n",
      "Epoch [13170/100000], Loss: 24.8109\n",
      "Epoch [13180/100000], Loss: 24.7761\n",
      "Epoch [13190/100000], Loss: 24.7252\n",
      "Epoch [13200/100000], Loss: 24.6888\n",
      "Epoch [13210/100000], Loss: 24.6800\n",
      "Epoch [13220/100000], Loss: 24.6360\n",
      "Epoch [13230/100000], Loss: 24.5959\n",
      "Epoch [13240/100000], Loss: 24.5761\n",
      "Epoch [13250/100000], Loss: 24.5467\n",
      "Epoch [13260/100000], Loss: 24.4927\n",
      "Epoch [13270/100000], Loss: 24.4724\n",
      "Epoch [13280/100000], Loss: 24.4348\n",
      "Epoch [13290/100000], Loss: 24.4272\n",
      "Epoch [13300/100000], Loss: 24.3679\n",
      "Epoch [13310/100000], Loss: 24.3465\n",
      "Epoch [13320/100000], Loss: 24.3082\n",
      "Epoch [13330/100000], Loss: 24.2647\n",
      "Epoch [13340/100000], Loss: 24.2261\n",
      "Epoch [13350/100000], Loss: 24.2024\n",
      "Epoch [13360/100000], Loss: 24.1482\n",
      "Epoch [13370/100000], Loss: 24.1473\n",
      "Epoch [13380/100000], Loss: 24.1058\n",
      "Epoch [13390/100000], Loss: 24.0603\n",
      "Epoch [13400/100000], Loss: 24.0200\n",
      "Epoch [13410/100000], Loss: 24.0055\n",
      "Epoch [13420/100000], Loss: 23.9780\n",
      "Epoch [13430/100000], Loss: 23.9236\n",
      "Epoch [13440/100000], Loss: 23.8838\n",
      "Epoch [13450/100000], Loss: 23.8599\n",
      "Epoch [13460/100000], Loss: 23.8041\n",
      "Epoch [13470/100000], Loss: 23.7821\n",
      "Epoch [13480/100000], Loss: 23.7521\n",
      "Epoch [13490/100000], Loss: 23.7128\n",
      "Epoch [13500/100000], Loss: 23.6692\n",
      "Epoch [13510/100000], Loss: 23.6467\n",
      "Epoch [13520/100000], Loss: 23.6209\n",
      "Epoch [13530/100000], Loss: 23.5567\n",
      "Epoch [13540/100000], Loss: 23.5396\n",
      "Epoch [13550/100000], Loss: 23.5203\n",
      "Epoch [13560/100000], Loss: 23.4656\n",
      "Epoch [13570/100000], Loss: 23.4373\n",
      "Epoch [13580/100000], Loss: 23.3981\n",
      "Epoch [13590/100000], Loss: 23.3538\n",
      "Epoch [13600/100000], Loss: 23.3070\n",
      "Epoch [13610/100000], Loss: 23.2656\n",
      "Epoch [13620/100000], Loss: 23.2319\n",
      "Epoch [13630/100000], Loss: 23.2027\n",
      "Epoch [13640/100000], Loss: 23.1550\n",
      "Epoch [13650/100000], Loss: 23.1546\n",
      "Epoch [13660/100000], Loss: 23.1054\n",
      "Epoch [13670/100000], Loss: 23.0538\n",
      "Epoch [13680/100000], Loss: 23.0270\n",
      "Epoch [13690/100000], Loss: 22.9963\n",
      "Epoch [13700/100000], Loss: 22.9510\n",
      "Epoch [13710/100000], Loss: 22.9184\n",
      "Epoch [13720/100000], Loss: 22.8851\n",
      "Epoch [13730/100000], Loss: 22.8550\n",
      "Epoch [13740/100000], Loss: 22.8109\n",
      "Epoch [13750/100000], Loss: 22.7792\n",
      "Epoch [13760/100000], Loss: 22.7313\n",
      "Epoch [13770/100000], Loss: 22.6996\n",
      "Epoch [13780/100000], Loss: 22.6460\n",
      "Epoch [13790/100000], Loss: 22.6211\n",
      "Epoch [13800/100000], Loss: 22.5867\n",
      "Epoch [13810/100000], Loss: 22.5479\n",
      "Epoch [13820/100000], Loss: 22.5080\n",
      "Epoch [13830/100000], Loss: 22.4778\n",
      "Epoch [13840/100000], Loss: 22.4334\n",
      "Epoch [13850/100000], Loss: 22.4070\n",
      "Epoch [13860/100000], Loss: 22.3715\n",
      "Epoch [13870/100000], Loss: 22.3301\n",
      "Epoch [13880/100000], Loss: 22.3094\n",
      "Epoch [13890/100000], Loss: 22.2557\n",
      "Epoch [13900/100000], Loss: 22.2160\n",
      "Epoch [13910/100000], Loss: 22.1740\n",
      "Epoch [13920/100000], Loss: 22.1466\n",
      "Epoch [13930/100000], Loss: 22.1075\n",
      "Epoch [13940/100000], Loss: 22.0828\n",
      "Epoch [13950/100000], Loss: 22.0362\n",
      "Epoch [13960/100000], Loss: 22.0012\n",
      "Epoch [13970/100000], Loss: 21.9794\n",
      "Epoch [13980/100000], Loss: 21.9235\n",
      "Epoch [13990/100000], Loss: 21.8751\n",
      "Epoch [14000/100000], Loss: 21.8596\n",
      "Epoch [14010/100000], Loss: 21.8116\n",
      "Epoch [14020/100000], Loss: 21.7767\n",
      "Epoch [14030/100000], Loss: 21.7359\n",
      "Epoch [14040/100000], Loss: 21.6972\n",
      "Epoch [14050/100000], Loss: 21.6713\n",
      "Epoch [14060/100000], Loss: 21.6214\n",
      "Epoch [14070/100000], Loss: 21.5922\n",
      "Epoch [14080/100000], Loss: 21.5476\n",
      "Epoch [14090/100000], Loss: 21.5153\n",
      "Epoch [14100/100000], Loss: 21.4711\n",
      "Epoch [14110/100000], Loss: 21.4329\n",
      "Epoch [14120/100000], Loss: 21.3984\n",
      "Epoch [14130/100000], Loss: 21.3638\n",
      "Epoch [14140/100000], Loss: 21.3262\n",
      "Epoch [14150/100000], Loss: 21.2934\n",
      "Epoch [14160/100000], Loss: 21.2466\n",
      "Epoch [14170/100000], Loss: 21.1891\n",
      "Epoch [14180/100000], Loss: 21.1605\n",
      "Epoch [14190/100000], Loss: 21.1331\n",
      "Epoch [14200/100000], Loss: 21.1033\n",
      "Epoch [14210/100000], Loss: 21.0485\n",
      "Epoch [14220/100000], Loss: 21.0164\n",
      "Epoch [14230/100000], Loss: 20.9929\n",
      "Epoch [14240/100000], Loss: 20.9318\n",
      "Epoch [14250/100000], Loss: 20.9052\n",
      "Epoch [14260/100000], Loss: 20.8575\n",
      "Epoch [14270/100000], Loss: 20.8208\n",
      "Epoch [14280/100000], Loss: 20.7948\n",
      "Epoch [14290/100000], Loss: 20.7522\n",
      "Epoch [14300/100000], Loss: 20.7239\n",
      "Epoch [14310/100000], Loss: 20.6864\n",
      "Epoch [14320/100000], Loss: 20.6560\n",
      "Epoch [14330/100000], Loss: 20.6099\n",
      "Epoch [14340/100000], Loss: 20.5729\n",
      "Epoch [14350/100000], Loss: 20.5273\n",
      "Epoch [14360/100000], Loss: 20.4961\n",
      "Epoch [14370/100000], Loss: 20.4492\n",
      "Epoch [14380/100000], Loss: 20.4216\n",
      "Epoch [14390/100000], Loss: 20.3777\n",
      "Epoch [14400/100000], Loss: 20.3357\n",
      "Epoch [14410/100000], Loss: 20.3170\n",
      "Epoch [14420/100000], Loss: 20.2642\n",
      "Epoch [14430/100000], Loss: 20.2243\n",
      "Epoch [14440/100000], Loss: 20.1756\n",
      "Epoch [14450/100000], Loss: 20.1405\n",
      "Epoch [14460/100000], Loss: 20.0993\n",
      "Epoch [14470/100000], Loss: 20.0850\n",
      "Epoch [14480/100000], Loss: 20.0236\n",
      "Epoch [14490/100000], Loss: 19.9790\n",
      "Epoch [14500/100000], Loss: 19.9614\n",
      "Epoch [14510/100000], Loss: 19.9192\n",
      "Epoch [14520/100000], Loss: 19.8739\n",
      "Epoch [14530/100000], Loss: 19.8311\n",
      "Epoch [14540/100000], Loss: 19.8018\n",
      "Epoch [14550/100000], Loss: 19.7461\n",
      "Epoch [14560/100000], Loss: 19.7271\n",
      "Epoch [14570/100000], Loss: 19.6771\n",
      "Epoch [14580/100000], Loss: 19.6327\n",
      "Epoch [14590/100000], Loss: 19.5985\n",
      "Epoch [14600/100000], Loss: 19.5546\n",
      "Epoch [14610/100000], Loss: 19.5120\n",
      "Epoch [14620/100000], Loss: 19.4751\n",
      "Epoch [14630/100000], Loss: 19.4312\n",
      "Epoch [14640/100000], Loss: 19.3930\n",
      "Epoch [14650/100000], Loss: 19.3531\n",
      "Epoch [14660/100000], Loss: 19.3212\n",
      "Epoch [14670/100000], Loss: 1459992.6250\n",
      "Epoch [14680/100000], Loss: 1025389568.0000\n",
      "Epoch [14690/100000], Loss: 1260152960.0000\n",
      "Epoch [14700/100000], Loss: 459450112.0000\n",
      "Epoch [14710/100000], Loss: 103598544.0000\n",
      "Epoch [14720/100000], Loss: 14791755.0000\n",
      "Epoch [14730/100000], Loss: 4112840.7500\n",
      "Epoch [14740/100000], Loss: 3842822.7500\n",
      "Epoch [14750/100000], Loss: 2351581.2500\n",
      "Epoch [14760/100000], Loss: 847696.0000\n",
      "Epoch [14770/100000], Loss: 168992.0312\n",
      "Epoch [14780/100000], Loss: 18882.8398\n",
      "Epoch [14790/100000], Loss: 13964.0781\n",
      "Epoch [14800/100000], Loss: 11602.2627\n",
      "Epoch [14810/100000], Loss: 4256.2788\n",
      "Epoch [14820/100000], Loss: 727.7773\n",
      "Epoch [14830/100000], Loss: 187.0753\n",
      "Epoch [14840/100000], Loss: 163.7330\n",
      "Epoch [14850/100000], Loss: 82.4314\n",
      "Epoch [14860/100000], Loss: 29.8431\n",
      "Epoch [14870/100000], Loss: 21.7108\n",
      "Epoch [14880/100000], Loss: 20.0811\n",
      "Epoch [14890/100000], Loss: 18.9841\n",
      "Epoch [14900/100000], Loss: 18.9380\n",
      "Epoch [14910/100000], Loss: 18.7982\n",
      "Epoch [14920/100000], Loss: 18.7973\n",
      "Epoch [14930/100000], Loss: 18.7874\n",
      "Epoch [14940/100000], Loss: 18.7689\n",
      "Epoch [14950/100000], Loss: 18.7732\n",
      "Epoch [14960/100000], Loss: 18.7592\n",
      "Epoch [14970/100000], Loss: 18.7531\n",
      "Epoch [14980/100000], Loss: 18.7520\n",
      "Epoch [14990/100000], Loss: 18.7559\n",
      "Epoch [15000/100000], Loss: 18.7444\n",
      "Epoch [15010/100000], Loss: 18.7388\n",
      "Epoch [15020/100000], Loss: 18.7557\n",
      "Epoch [15030/100000], Loss: 18.7573\n",
      "Epoch [15040/100000], Loss: 18.7568\n",
      "Epoch [15050/100000], Loss: 18.7591\n",
      "Epoch [15060/100000], Loss: 18.7550\n",
      "Epoch [15070/100000], Loss: 18.7605\n",
      "Epoch [15080/100000], Loss: 18.7692\n",
      "Epoch [15090/100000], Loss: 18.7535\n",
      "Epoch [15100/100000], Loss: 18.7428\n",
      "Epoch [15110/100000], Loss: 18.7437\n",
      "Epoch [15120/100000], Loss: 18.7408\n",
      "Epoch [15130/100000], Loss: 18.7423\n",
      "Epoch [15140/100000], Loss: 18.7359\n",
      "Epoch [15150/100000], Loss: 18.7260\n",
      "Epoch [15160/100000], Loss: 18.7264\n",
      "Epoch [15170/100000], Loss: 18.7210\n",
      "Epoch [15180/100000], Loss: 18.7215\n",
      "Epoch [15190/100000], Loss: 18.7203\n",
      "Epoch [15200/100000], Loss: 18.7153\n",
      "Epoch [15210/100000], Loss: 18.7153\n",
      "Epoch [15220/100000], Loss: 18.7115\n",
      "Epoch [15230/100000], Loss: 18.7150\n",
      "Epoch [15240/100000], Loss: 18.7172\n",
      "Epoch [15250/100000], Loss: 18.7070\n",
      "Epoch [15260/100000], Loss: 18.7017\n",
      "Epoch [15270/100000], Loss: 18.7019\n",
      "Epoch [15280/100000], Loss: 18.6942\n",
      "Epoch [15290/100000], Loss: 18.6995\n",
      "Epoch [15300/100000], Loss: 18.6957\n",
      "Epoch [15310/100000], Loss: 18.6966\n",
      "Epoch [15320/100000], Loss: 18.7021\n",
      "Epoch [15330/100000], Loss: 18.6962\n",
      "Epoch [15340/100000], Loss: 18.6897\n",
      "Epoch [15350/100000], Loss: 18.6891\n",
      "Epoch [15360/100000], Loss: 18.6829\n",
      "Epoch [15370/100000], Loss: 18.6904\n",
      "Epoch [15380/100000], Loss: 18.6853\n",
      "Epoch [15390/100000], Loss: 18.6885\n",
      "Epoch [15400/100000], Loss: 18.6687\n",
      "Epoch [15410/100000], Loss: 18.6579\n",
      "Epoch [15420/100000], Loss: 18.6700\n",
      "Epoch [15430/100000], Loss: 18.6620\n",
      "Epoch [15440/100000], Loss: 18.6695\n",
      "Epoch [15450/100000], Loss: 18.6607\n",
      "Epoch [15460/100000], Loss: 18.6478\n",
      "Epoch [15470/100000], Loss: 18.6344\n",
      "Epoch [15480/100000], Loss: 18.6477\n",
      "Epoch [15490/100000], Loss: 18.6514\n",
      "Epoch [15500/100000], Loss: 18.6513\n",
      "Epoch [15510/100000], Loss: 18.6532\n",
      "Epoch [15520/100000], Loss: 18.6399\n",
      "Epoch [15530/100000], Loss: 18.6481\n",
      "Epoch [15540/100000], Loss: 18.6252\n",
      "Epoch [15550/100000], Loss: 18.6267\n",
      "Epoch [15560/100000], Loss: 18.6257\n",
      "Epoch [15570/100000], Loss: 18.6230\n",
      "Epoch [15580/100000], Loss: 18.6138\n",
      "Epoch [15590/100000], Loss: 18.6053\n",
      "Epoch [15600/100000], Loss: 18.6071\n",
      "Epoch [15610/100000], Loss: 18.6040\n",
      "Epoch [15620/100000], Loss: 18.5955\n",
      "Epoch [15630/100000], Loss: 18.5898\n",
      "Epoch [15640/100000], Loss: 18.6028\n",
      "Epoch [15650/100000], Loss: 18.6014\n",
      "Epoch [15660/100000], Loss: 18.5972\n",
      "Epoch [15670/100000], Loss: 18.5975\n",
      "Epoch [15680/100000], Loss: 18.5836\n",
      "Epoch [15690/100000], Loss: 18.5862\n",
      "Epoch [15700/100000], Loss: 18.5943\n",
      "Epoch [15710/100000], Loss: 18.5920\n",
      "Epoch [15720/100000], Loss: 18.5779\n",
      "Epoch [15730/100000], Loss: 18.5810\n",
      "Epoch [15740/100000], Loss: 18.5792\n",
      "Epoch [15750/100000], Loss: 18.5689\n",
      "Epoch [15760/100000], Loss: 18.5616\n",
      "Epoch [15770/100000], Loss: 18.5591\n",
      "Epoch [15780/100000], Loss: 18.5578\n",
      "Epoch [15790/100000], Loss: 18.5539\n",
      "Epoch [15800/100000], Loss: 18.5593\n",
      "Epoch [15810/100000], Loss: 18.5530\n",
      "Epoch [15820/100000], Loss: 18.5469\n",
      "Epoch [15830/100000], Loss: 18.5520\n",
      "Epoch [15840/100000], Loss: 18.5460\n",
      "Epoch [15850/100000], Loss: 18.5465\n",
      "Epoch [15860/100000], Loss: 18.5401\n",
      "Epoch [15870/100000], Loss: 18.5401\n",
      "Epoch [15880/100000], Loss: 18.5496\n",
      "Epoch [15890/100000], Loss: 18.5463\n",
      "Epoch [15900/100000], Loss: 18.5392\n",
      "Epoch [15910/100000], Loss: 18.5314\n",
      "Epoch [15920/100000], Loss: 18.5249\n",
      "Epoch [15930/100000], Loss: 18.5240\n",
      "Epoch [15940/100000], Loss: 18.5112\n",
      "Epoch [15950/100000], Loss: 18.5041\n",
      "Epoch [15960/100000], Loss: 18.4937\n",
      "Epoch [15970/100000], Loss: 18.5022\n",
      "Epoch [15980/100000], Loss: 18.5031\n",
      "Epoch [15990/100000], Loss: 18.4956\n",
      "Epoch [16000/100000], Loss: 18.4914\n",
      "Epoch [16010/100000], Loss: 18.4981\n",
      "Epoch [16020/100000], Loss: 18.4869\n",
      "Epoch [16030/100000], Loss: 18.4783\n",
      "Epoch [16040/100000], Loss: 18.4790\n",
      "Epoch [16050/100000], Loss: 18.4671\n",
      "Epoch [16060/100000], Loss: 18.4570\n",
      "Epoch [16070/100000], Loss: 18.4543\n",
      "Epoch [16080/100000], Loss: 18.4517\n",
      "Epoch [16090/100000], Loss: 18.4533\n",
      "Epoch [16100/100000], Loss: 18.4463\n",
      "Epoch [16110/100000], Loss: 18.4409\n",
      "Epoch [16120/100000], Loss: 18.4375\n",
      "Epoch [16130/100000], Loss: 18.4428\n",
      "Epoch [16140/100000], Loss: 18.4404\n",
      "Epoch [16150/100000], Loss: 18.4521\n",
      "Epoch [16160/100000], Loss: 18.4285\n",
      "Epoch [16170/100000], Loss: 18.4310\n",
      "Epoch [16180/100000], Loss: 18.4196\n",
      "Epoch [16190/100000], Loss: 18.4254\n",
      "Epoch [16200/100000], Loss: 18.4356\n",
      "Epoch [16210/100000], Loss: 18.4239\n",
      "Epoch [16220/100000], Loss: 18.4199\n",
      "Epoch [16230/100000], Loss: 18.4238\n",
      "Epoch [16240/100000], Loss: 18.4264\n",
      "Epoch [16250/100000], Loss: 18.4123\n",
      "Epoch [16260/100000], Loss: 18.4100\n",
      "Epoch [16270/100000], Loss: 18.4031\n",
      "Epoch [16280/100000], Loss: 18.4003\n",
      "Epoch [16290/100000], Loss: 18.3871\n",
      "Epoch [16300/100000], Loss: 18.3802\n",
      "Epoch [16310/100000], Loss: 18.3841\n",
      "Epoch [16320/100000], Loss: 18.3848\n",
      "Epoch [16330/100000], Loss: 18.3777\n",
      "Epoch [16340/100000], Loss: 18.3828\n",
      "Epoch [16350/100000], Loss: 18.3787\n",
      "Epoch [16360/100000], Loss: 18.3703\n",
      "Epoch [16370/100000], Loss: 18.3632\n",
      "Epoch [16380/100000], Loss: 18.3562\n",
      "Epoch [16390/100000], Loss: 18.3612\n",
      "Epoch [16400/100000], Loss: 18.3453\n",
      "Epoch [16410/100000], Loss: 18.3423\n",
      "Epoch [16420/100000], Loss: 18.3318\n",
      "Epoch [16430/100000], Loss: 18.3265\n",
      "Epoch [16440/100000], Loss: 18.3254\n",
      "Epoch [16450/100000], Loss: 18.3326\n",
      "Epoch [16460/100000], Loss: 18.3189\n",
      "Epoch [16470/100000], Loss: 18.3109\n",
      "Epoch [16480/100000], Loss: 18.3022\n",
      "Epoch [16490/100000], Loss: 18.3020\n",
      "Epoch [16500/100000], Loss: 18.2979\n",
      "Epoch [16510/100000], Loss: 18.2873\n",
      "Epoch [16520/100000], Loss: 18.2919\n",
      "Epoch [16530/100000], Loss: 18.2953\n",
      "Epoch [16540/100000], Loss: 18.2820\n",
      "Epoch [16550/100000], Loss: 18.2804\n",
      "Epoch [16560/100000], Loss: 18.2691\n",
      "Epoch [16570/100000], Loss: 18.2781\n",
      "Epoch [16580/100000], Loss: 18.2632\n",
      "Epoch [16590/100000], Loss: 18.2689\n",
      "Epoch [16600/100000], Loss: 18.2578\n",
      "Epoch [16610/100000], Loss: 18.2649\n",
      "Epoch [16620/100000], Loss: 18.2542\n",
      "Epoch [16630/100000], Loss: 18.2549\n",
      "Epoch [16640/100000], Loss: 18.2416\n",
      "Epoch [16650/100000], Loss: 18.2467\n",
      "Epoch [16660/100000], Loss: 18.2452\n",
      "Epoch [16670/100000], Loss: 18.2341\n",
      "Epoch [16680/100000], Loss: 18.2241\n",
      "Epoch [16690/100000], Loss: 18.2265\n",
      "Epoch [16700/100000], Loss: 18.2179\n",
      "Epoch [16710/100000], Loss: 18.2039\n",
      "Epoch [16720/100000], Loss: 18.2115\n",
      "Epoch [16730/100000], Loss: 18.1989\n",
      "Epoch [16740/100000], Loss: 18.2130\n",
      "Epoch [16750/100000], Loss: 18.2069\n",
      "Epoch [16760/100000], Loss: 18.1868\n",
      "Epoch [16770/100000], Loss: 18.1859\n",
      "Epoch [16780/100000], Loss: 18.1815\n",
      "Epoch [16790/100000], Loss: 18.1831\n",
      "Epoch [16800/100000], Loss: 18.1734\n",
      "Epoch [16810/100000], Loss: 18.1675\n",
      "Epoch [16820/100000], Loss: 18.1521\n",
      "Epoch [16830/100000], Loss: 18.1684\n",
      "Epoch [16840/100000], Loss: 18.1576\n",
      "Epoch [16850/100000], Loss: 18.1389\n",
      "Epoch [16860/100000], Loss: 18.1453\n",
      "Epoch [16870/100000], Loss: 18.1404\n",
      "Epoch [16880/100000], Loss: 18.1352\n",
      "Epoch [16890/100000], Loss: 18.1245\n",
      "Epoch [16900/100000], Loss: 18.1242\n",
      "Epoch [16910/100000], Loss: 18.1052\n",
      "Epoch [16920/100000], Loss: 18.1144\n",
      "Epoch [16930/100000], Loss: 18.0993\n",
      "Epoch [16940/100000], Loss: 18.1084\n",
      "Epoch [16950/100000], Loss: 18.0910\n",
      "Epoch [16960/100000], Loss: 18.0993\n",
      "Epoch [16970/100000], Loss: 18.0823\n",
      "Epoch [16980/100000], Loss: 18.0693\n",
      "Epoch [16990/100000], Loss: 18.0574\n",
      "Epoch [17000/100000], Loss: 18.0601\n",
      "Epoch [17010/100000], Loss: 18.0520\n",
      "Epoch [17020/100000], Loss: 18.0514\n",
      "Epoch [17030/100000], Loss: 18.0510\n",
      "Epoch [17040/100000], Loss: 18.0440\n",
      "Epoch [17050/100000], Loss: 18.0444\n",
      "Epoch [17060/100000], Loss: 18.0290\n",
      "Epoch [17070/100000], Loss: 18.0271\n",
      "Epoch [17080/100000], Loss: 18.0188\n",
      "Epoch [17090/100000], Loss: 18.0179\n",
      "Epoch [17100/100000], Loss: 18.0253\n",
      "Epoch [17110/100000], Loss: 18.0062\n",
      "Epoch [17120/100000], Loss: 17.9989\n",
      "Epoch [17130/100000], Loss: 17.9931\n",
      "Epoch [17140/100000], Loss: 17.9884\n",
      "Epoch [17150/100000], Loss: 17.9872\n",
      "Epoch [17160/100000], Loss: 17.9791\n",
      "Epoch [17170/100000], Loss: 17.9775\n",
      "Epoch [17180/100000], Loss: 17.9552\n",
      "Epoch [17190/100000], Loss: 17.9715\n",
      "Epoch [17200/100000], Loss: 17.9655\n",
      "Epoch [17210/100000], Loss: 17.9647\n",
      "Epoch [17220/100000], Loss: 17.9485\n",
      "Epoch [17230/100000], Loss: 17.9287\n",
      "Epoch [17240/100000], Loss: 17.9340\n",
      "Epoch [17250/100000], Loss: 17.9452\n",
      "Epoch [17260/100000], Loss: 17.9173\n",
      "Epoch [17270/100000], Loss: 17.9207\n",
      "Epoch [17280/100000], Loss: 17.9210\n",
      "Epoch [17290/100000], Loss: 17.9139\n",
      "Epoch [17300/100000], Loss: 17.8978\n",
      "Epoch [17310/100000], Loss: 17.9029\n",
      "Epoch [17320/100000], Loss: 17.8950\n",
      "Epoch [17330/100000], Loss: 17.8826\n",
      "Epoch [17340/100000], Loss: 17.8655\n",
      "Epoch [17350/100000], Loss: 17.8715\n",
      "Epoch [17360/100000], Loss: 17.8702\n",
      "Epoch [17370/100000], Loss: 17.8567\n",
      "Epoch [17380/100000], Loss: 17.8654\n",
      "Epoch [17390/100000], Loss: 17.8571\n",
      "Epoch [17400/100000], Loss: 17.8499\n",
      "Epoch [17410/100000], Loss: 17.8491\n",
      "Epoch [17420/100000], Loss: 17.8337\n",
      "Epoch [17430/100000], Loss: 17.8304\n",
      "Epoch [17440/100000], Loss: 17.8222\n",
      "Epoch [17450/100000], Loss: 17.8167\n",
      "Epoch [17460/100000], Loss: 17.8097\n",
      "Epoch [17470/100000], Loss: 17.7980\n",
      "Epoch [17480/100000], Loss: 17.7892\n",
      "Epoch [17490/100000], Loss: 17.7775\n",
      "Epoch [17500/100000], Loss: 17.7811\n",
      "Epoch [17510/100000], Loss: 17.7730\n",
      "Epoch [17520/100000], Loss: 17.7722\n",
      "Epoch [17530/100000], Loss: 17.7681\n",
      "Epoch [17540/100000], Loss: 17.7598\n",
      "Epoch [17550/100000], Loss: 17.7433\n",
      "Epoch [17560/100000], Loss: 17.7409\n",
      "Epoch [17570/100000], Loss: 17.7339\n",
      "Epoch [17580/100000], Loss: 17.7306\n",
      "Epoch [17590/100000], Loss: 17.7354\n",
      "Epoch [17600/100000], Loss: 17.7250\n",
      "Epoch [17610/100000], Loss: 17.7217\n",
      "Epoch [17620/100000], Loss: 17.7182\n",
      "Epoch [17630/100000], Loss: 17.7041\n",
      "Epoch [17640/100000], Loss: 17.6910\n",
      "Epoch [17650/100000], Loss: 17.6866\n",
      "Epoch [17660/100000], Loss: 17.6741\n",
      "Epoch [17670/100000], Loss: 17.6654\n",
      "Epoch [17680/100000], Loss: 17.6650\n",
      "Epoch [17690/100000], Loss: 17.6540\n",
      "Epoch [17700/100000], Loss: 17.6546\n",
      "Epoch [17710/100000], Loss: 17.6421\n",
      "Epoch [17720/100000], Loss: 17.6375\n",
      "Epoch [17730/100000], Loss: 17.6399\n",
      "Epoch [17740/100000], Loss: 17.6228\n",
      "Epoch [17750/100000], Loss: 17.6115\n",
      "Epoch [17760/100000], Loss: 17.6124\n",
      "Epoch [17770/100000], Loss: 17.6015\n",
      "Epoch [17780/100000], Loss: 17.6037\n",
      "Epoch [17790/100000], Loss: 17.5846\n",
      "Epoch [17800/100000], Loss: 17.5830\n",
      "Epoch [17810/100000], Loss: 17.5841\n",
      "Epoch [17820/100000], Loss: 17.5776\n",
      "Epoch [17830/100000], Loss: 17.5709\n",
      "Epoch [17840/100000], Loss: 17.5596\n",
      "Epoch [17850/100000], Loss: 17.5587\n",
      "Epoch [17860/100000], Loss: 17.5552\n",
      "Epoch [17870/100000], Loss: 17.5427\n",
      "Epoch [17880/100000], Loss: 17.5277\n",
      "Epoch [17890/100000], Loss: 17.5227\n",
      "Epoch [17900/100000], Loss: 17.5077\n",
      "Epoch [17910/100000], Loss: 17.5136\n",
      "Epoch [17920/100000], Loss: 17.4958\n",
      "Epoch [17930/100000], Loss: 17.4974\n",
      "Epoch [17940/100000], Loss: 17.4821\n",
      "Epoch [17950/100000], Loss: 17.4790\n",
      "Epoch [17960/100000], Loss: 17.4648\n",
      "Epoch [17970/100000], Loss: 17.4614\n",
      "Epoch [17980/100000], Loss: 17.4644\n",
      "Epoch [17990/100000], Loss: 17.4491\n",
      "Epoch [18000/100000], Loss: 17.4321\n",
      "Epoch [18010/100000], Loss: 17.4322\n",
      "Epoch [18020/100000], Loss: 17.4262\n",
      "Epoch [18030/100000], Loss: 17.4191\n",
      "Epoch [18040/100000], Loss: 17.4145\n",
      "Epoch [18050/100000], Loss: 17.3977\n",
      "Epoch [18060/100000], Loss: 17.3926\n",
      "Epoch [18070/100000], Loss: 17.3871\n",
      "Epoch [18080/100000], Loss: 17.3893\n",
      "Epoch [18090/100000], Loss: 17.3780\n",
      "Epoch [18100/100000], Loss: 17.3751\n",
      "Epoch [18110/100000], Loss: 17.3599\n",
      "Epoch [18120/100000], Loss: 17.3375\n",
      "Epoch [18130/100000], Loss: 17.3394\n",
      "Epoch [18140/100000], Loss: 17.3297\n",
      "Epoch [18150/100000], Loss: 17.3344\n",
      "Epoch [18160/100000], Loss: 17.3306\n",
      "Epoch [18170/100000], Loss: 17.3160\n",
      "Epoch [18180/100000], Loss: 17.3068\n",
      "Epoch [18190/100000], Loss: 17.2978\n",
      "Epoch [18200/100000], Loss: 17.2725\n",
      "Epoch [18210/100000], Loss: 17.2775\n",
      "Epoch [18220/100000], Loss: 17.2685\n",
      "Epoch [18230/100000], Loss: 17.2694\n",
      "Epoch [18240/100000], Loss: 17.2706\n",
      "Epoch [18250/100000], Loss: 17.2502\n",
      "Epoch [18260/100000], Loss: 17.2400\n",
      "Epoch [18270/100000], Loss: 17.2207\n",
      "Epoch [18280/100000], Loss: 17.2230\n",
      "Epoch [18290/100000], Loss: 17.2163\n",
      "Epoch [18300/100000], Loss: 17.1940\n",
      "Epoch [18310/100000], Loss: 17.1866\n",
      "Epoch [18320/100000], Loss: 17.1842\n",
      "Epoch [18330/100000], Loss: 17.1769\n",
      "Epoch [18340/100000], Loss: 17.1594\n",
      "Epoch [18350/100000], Loss: 17.1624\n",
      "Epoch [18360/100000], Loss: 17.1420\n",
      "Epoch [18370/100000], Loss: 17.1313\n",
      "Epoch [18380/100000], Loss: 17.1276\n",
      "Epoch [18390/100000], Loss: 17.1181\n",
      "Epoch [18400/100000], Loss: 17.1164\n",
      "Epoch [18410/100000], Loss: 17.1123\n",
      "Epoch [18420/100000], Loss: 17.0983\n",
      "Epoch [18430/100000], Loss: 17.0975\n",
      "Epoch [18440/100000], Loss: 17.0842\n",
      "Epoch [18450/100000], Loss: 17.0827\n",
      "Epoch [18460/100000], Loss: 17.0662\n",
      "Epoch [18470/100000], Loss: 17.0569\n",
      "Epoch [18480/100000], Loss: 17.0531\n",
      "Epoch [18490/100000], Loss: 17.0425\n",
      "Epoch [18500/100000], Loss: 17.0305\n",
      "Epoch [18510/100000], Loss: 17.0220\n",
      "Epoch [18520/100000], Loss: 17.0268\n",
      "Epoch [18530/100000], Loss: 17.0081\n",
      "Epoch [18540/100000], Loss: 16.9956\n",
      "Epoch [18550/100000], Loss: 16.9797\n",
      "Epoch [18560/100000], Loss: 16.9864\n",
      "Epoch [18570/100000], Loss: 16.9606\n",
      "Epoch [18580/100000], Loss: 16.9514\n",
      "Epoch [18590/100000], Loss: 16.9419\n",
      "Epoch [18600/100000], Loss: 16.9450\n",
      "Epoch [18610/100000], Loss: 16.9292\n",
      "Epoch [18620/100000], Loss: 16.9208\n",
      "Epoch [18630/100000], Loss: 16.9148\n",
      "Epoch [18640/100000], Loss: 16.9050\n",
      "Epoch [18650/100000], Loss: 16.8949\n",
      "Epoch [18660/100000], Loss: 16.8774\n",
      "Epoch [18670/100000], Loss: 16.8766\n",
      "Epoch [18680/100000], Loss: 16.8642\n",
      "Epoch [18690/100000], Loss: 16.8609\n",
      "Epoch [18700/100000], Loss: 16.8436\n",
      "Epoch [18710/100000], Loss: 16.8251\n",
      "Epoch [18720/100000], Loss: 16.8206\n",
      "Epoch [18730/100000], Loss: 16.7973\n",
      "Epoch [18740/100000], Loss: 16.7921\n",
      "Epoch [18750/100000], Loss: 16.7909\n",
      "Epoch [18760/100000], Loss: 16.7822\n",
      "Epoch [18770/100000], Loss: 16.7649\n",
      "Epoch [18780/100000], Loss: 16.7578\n",
      "Epoch [18790/100000], Loss: 16.7473\n",
      "Epoch [18800/100000], Loss: 16.7469\n",
      "Epoch [18810/100000], Loss: 16.7293\n",
      "Epoch [18820/100000], Loss: 16.7103\n",
      "Epoch [18830/100000], Loss: 16.7138\n",
      "Epoch [18840/100000], Loss: 16.7070\n",
      "Epoch [18850/100000], Loss: 16.6909\n",
      "Epoch [18860/100000], Loss: 16.6900\n",
      "Epoch [18870/100000], Loss: 16.6775\n",
      "Epoch [18880/100000], Loss: 16.6587\n",
      "Epoch [18890/100000], Loss: 16.6654\n",
      "Epoch [18900/100000], Loss: 16.6481\n",
      "Epoch [18910/100000], Loss: 16.6341\n",
      "Epoch [18920/100000], Loss: 16.6294\n",
      "Epoch [18930/100000], Loss: 16.6180\n",
      "Epoch [18940/100000], Loss: 16.6133\n",
      "Epoch [18950/100000], Loss: 16.5859\n",
      "Epoch [18960/100000], Loss: 16.5767\n",
      "Epoch [18970/100000], Loss: 16.5603\n",
      "Epoch [18980/100000], Loss: 16.5592\n",
      "Epoch [18990/100000], Loss: 16.5391\n",
      "Epoch [19000/100000], Loss: 16.5316\n",
      "Epoch [19010/100000], Loss: 16.5190\n",
      "Epoch [19020/100000], Loss: 16.5177\n",
      "Epoch [19030/100000], Loss: 16.5019\n",
      "Epoch [19040/100000], Loss: 16.4906\n",
      "Epoch [19050/100000], Loss: 16.4816\n",
      "Epoch [19060/100000], Loss: 16.4760\n",
      "Epoch [19070/100000], Loss: 16.4673\n",
      "Epoch [19080/100000], Loss: 16.4382\n",
      "Epoch [19090/100000], Loss: 16.4413\n",
      "Epoch [19100/100000], Loss: 16.4209\n",
      "Epoch [19110/100000], Loss: 16.4180\n",
      "Epoch [19120/100000], Loss: 16.4005\n",
      "Epoch [19130/100000], Loss: 16.3856\n",
      "Epoch [19140/100000], Loss: 16.3886\n",
      "Epoch [19150/100000], Loss: 16.3555\n",
      "Epoch [19160/100000], Loss: 16.3496\n",
      "Epoch [19170/100000], Loss: 16.3381\n",
      "Epoch [19180/100000], Loss: 16.3410\n",
      "Epoch [19190/100000], Loss: 16.3230\n",
      "Epoch [19200/100000], Loss: 16.3101\n",
      "Epoch [19210/100000], Loss: 16.2909\n",
      "Epoch [19220/100000], Loss: 16.2804\n",
      "Epoch [19230/100000], Loss: 16.2698\n",
      "Epoch [19240/100000], Loss: 16.2584\n",
      "Epoch [19250/100000], Loss: 16.2562\n",
      "Epoch [19260/100000], Loss: 16.2477\n",
      "Epoch [19270/100000], Loss: 16.2273\n",
      "Epoch [19280/100000], Loss: 16.2201\n",
      "Epoch [19290/100000], Loss: 16.1990\n",
      "Epoch [19300/100000], Loss: 16.1897\n",
      "Epoch [19310/100000], Loss: 16.1881\n",
      "Epoch [19320/100000], Loss: 16.1809\n",
      "Epoch [19330/100000], Loss: 16.1657\n",
      "Epoch [19340/100000], Loss: 16.1578\n",
      "Epoch [19350/100000], Loss: 16.1321\n",
      "Epoch [19360/100000], Loss: 16.1258\n",
      "Epoch [19370/100000], Loss: 16.1047\n",
      "Epoch [19380/100000], Loss: 16.1011\n",
      "Epoch [19390/100000], Loss: 16.0845\n",
      "Epoch [19400/100000], Loss: 16.0741\n",
      "Epoch [19410/100000], Loss: 16.0800\n",
      "Epoch [19420/100000], Loss: 16.0550\n",
      "Epoch [19430/100000], Loss: 16.0436\n",
      "Epoch [19440/100000], Loss: 16.0276\n",
      "Epoch [19450/100000], Loss: 16.0165\n",
      "Epoch [19460/100000], Loss: 15.9885\n",
      "Epoch [19470/100000], Loss: 15.9789\n",
      "Epoch [19480/100000], Loss: 15.9762\n",
      "Epoch [19490/100000], Loss: 15.9566\n",
      "Epoch [19500/100000], Loss: 15.9459\n",
      "Epoch [19510/100000], Loss: 15.9341\n",
      "Epoch [19520/100000], Loss: 15.9298\n",
      "Epoch [19530/100000], Loss: 15.9167\n",
      "Epoch [19540/100000], Loss: 15.8890\n",
      "Epoch [19550/100000], Loss: 15.8786\n",
      "Epoch [19560/100000], Loss: 15.8700\n",
      "Epoch [19570/100000], Loss: 15.8594\n",
      "Epoch [19580/100000], Loss: 15.8566\n",
      "Epoch [19590/100000], Loss: 15.8267\n",
      "Epoch [19600/100000], Loss: 15.8240\n",
      "Epoch [19610/100000], Loss: 15.8077\n",
      "Epoch [19620/100000], Loss: 15.7922\n",
      "Epoch [19630/100000], Loss: 15.7818\n",
      "Epoch [19640/100000], Loss: 15.7690\n",
      "Epoch [19650/100000], Loss: 15.7530\n",
      "Epoch [19660/100000], Loss: 15.7373\n",
      "Epoch [19670/100000], Loss: 15.7283\n",
      "Epoch [19680/100000], Loss: 15.7092\n",
      "Epoch [19690/100000], Loss: 15.7070\n",
      "Epoch [19700/100000], Loss: 15.6932\n",
      "Epoch [19710/100000], Loss: 15.6812\n",
      "Epoch [19720/100000], Loss: 15.6695\n",
      "Epoch [19730/100000], Loss: 15.6498\n",
      "Epoch [19740/100000], Loss: 15.6289\n",
      "Epoch [19750/100000], Loss: 15.6127\n",
      "Epoch [19760/100000], Loss: 15.6006\n",
      "Epoch [19770/100000], Loss: 15.5811\n",
      "Epoch [19780/100000], Loss: 15.5584\n",
      "Epoch [19790/100000], Loss: 15.5633\n",
      "Epoch [19800/100000], Loss: 15.5537\n",
      "Epoch [19810/100000], Loss: 15.5340\n",
      "Epoch [19820/100000], Loss: 15.5237\n",
      "Epoch [19830/100000], Loss: 15.5012\n",
      "Epoch [19840/100000], Loss: 15.4882\n",
      "Epoch [19850/100000], Loss: 15.4835\n",
      "Epoch [19860/100000], Loss: 15.4701\n",
      "Epoch [19870/100000], Loss: 15.4482\n",
      "Epoch [19880/100000], Loss: 15.4430\n",
      "Epoch [19890/100000], Loss: 15.4260\n",
      "Epoch [19900/100000], Loss: 15.4121\n",
      "Epoch [19910/100000], Loss: 15.3935\n",
      "Epoch [19920/100000], Loss: 15.3849\n",
      "Epoch [19930/100000], Loss: 15.3772\n",
      "Epoch [19940/100000], Loss: 15.3592\n",
      "Epoch [19950/100000], Loss: 15.3376\n",
      "Epoch [19960/100000], Loss: 15.3241\n",
      "Epoch [19970/100000], Loss: 15.3316\n",
      "Epoch [19980/100000], Loss: 15.2791\n",
      "Epoch [19990/100000], Loss: 15.2766\n",
      "Epoch [20000/100000], Loss: 15.2613\n",
      "Epoch [20010/100000], Loss: 15.2396\n",
      "Epoch [20020/100000], Loss: 15.2384\n",
      "Epoch [20030/100000], Loss: 15.2239\n",
      "Epoch [20040/100000], Loss: 15.2068\n",
      "Epoch [20050/100000], Loss: 15.1927\n",
      "Epoch [20060/100000], Loss: 15.1758\n",
      "Epoch [20070/100000], Loss: 15.1629\n",
      "Epoch [20080/100000], Loss: 15.1477\n",
      "Epoch [20090/100000], Loss: 15.1360\n",
      "Epoch [20100/100000], Loss: 15.1268\n",
      "Epoch [20110/100000], Loss: 15.1148\n",
      "Epoch [20120/100000], Loss: 15.0903\n",
      "Epoch [20130/100000], Loss: 15.0743\n",
      "Epoch [20140/100000], Loss: 15.0664\n",
      "Epoch [20150/100000], Loss: 15.0550\n",
      "Epoch [20160/100000], Loss: 15.0498\n",
      "Epoch [20170/100000], Loss: 15.0188\n",
      "Epoch [20180/100000], Loss: 15.0173\n",
      "Epoch [20190/100000], Loss: 14.9931\n",
      "Epoch [20200/100000], Loss: 14.9772\n",
      "Epoch [20210/100000], Loss: 14.9639\n",
      "Epoch [20220/100000], Loss: 14.9415\n",
      "Epoch [20230/100000], Loss: 14.9251\n",
      "Epoch [20240/100000], Loss: 14.9085\n",
      "Epoch [20250/100000], Loss: 14.8762\n",
      "Epoch [20260/100000], Loss: 14.8861\n",
      "Epoch [20270/100000], Loss: 14.8543\n",
      "Epoch [20280/100000], Loss: 14.8508\n",
      "Epoch [20290/100000], Loss: 14.8368\n",
      "Epoch [20300/100000], Loss: 14.8116\n",
      "Epoch [20310/100000], Loss: 14.8075\n",
      "Epoch [20320/100000], Loss: 14.7844\n",
      "Epoch [20330/100000], Loss: 14.7661\n",
      "Epoch [20340/100000], Loss: 14.7470\n",
      "Epoch [20350/100000], Loss: 14.7360\n",
      "Epoch [20360/100000], Loss: 14.7136\n",
      "Epoch [20370/100000], Loss: 14.7026\n",
      "Epoch [20380/100000], Loss: 14.6901\n",
      "Epoch [20390/100000], Loss: 14.6816\n",
      "Epoch [20400/100000], Loss: 14.6584\n",
      "Epoch [20410/100000], Loss: 14.6407\n",
      "Epoch [20420/100000], Loss: 14.6268\n",
      "Epoch [20430/100000], Loss: 14.6073\n",
      "Epoch [20440/100000], Loss: 14.5905\n",
      "Epoch [20450/100000], Loss: 14.5740\n",
      "Epoch [20460/100000], Loss: 14.5567\n",
      "Epoch [20470/100000], Loss: 14.5404\n",
      "Epoch [20480/100000], Loss: 14.5230\n",
      "Epoch [20490/100000], Loss: 14.5004\n",
      "Epoch [20500/100000], Loss: 14.4887\n",
      "Epoch [20510/100000], Loss: 14.4715\n",
      "Epoch [20520/100000], Loss: 14.4422\n",
      "Epoch [20530/100000], Loss: 14.4288\n",
      "Epoch [20540/100000], Loss: 14.4278\n",
      "Epoch [20550/100000], Loss: 14.4095\n",
      "Epoch [20560/100000], Loss: 14.3912\n",
      "Epoch [20570/100000], Loss: 14.3726\n",
      "Epoch [20580/100000], Loss: 14.3468\n",
      "Epoch [20590/100000], Loss: 268102.1250\n",
      "Epoch [20600/100000], Loss: 4709409280.0000\n",
      "Epoch [20610/100000], Loss: 1663611392.0000\n",
      "Epoch [20620/100000], Loss: 492257696.0000\n",
      "Epoch [20630/100000], Loss: 119002840.0000\n",
      "Epoch [20640/100000], Loss: 24087530.0000\n",
      "Epoch [20650/100000], Loss: 4634424.5000\n",
      "Epoch [20660/100000], Loss: 924988.5000\n",
      "Epoch [20670/100000], Loss: 1081055.6250\n",
      "Epoch [20680/100000], Loss: 789328.3125\n",
      "Epoch [20690/100000], Loss: 328873.0625\n",
      "Epoch [20700/100000], Loss: 124251.1406\n",
      "Epoch [20710/100000], Loss: 45539.8828\n",
      "Epoch [20720/100000], Loss: 17997.0742\n",
      "Epoch [20730/100000], Loss: 6812.6094\n",
      "Epoch [20740/100000], Loss: 1990.1199\n",
      "Epoch [20750/100000], Loss: 706.5842\n",
      "Epoch [20760/100000], Loss: 263.0286\n",
      "Epoch [20770/100000], Loss: 90.5159\n",
      "Epoch [20780/100000], Loss: 39.4575\n",
      "Epoch [20790/100000], Loss: 22.2204\n",
      "Epoch [20800/100000], Loss: 16.6956\n",
      "Epoch [20810/100000], Loss: 14.2364\n",
      "Epoch [20820/100000], Loss: 14.2649\n",
      "Epoch [20830/100000], Loss: 14.1810\n",
      "Epoch [20840/100000], Loss: 14.1168\n",
      "Epoch [20850/100000], Loss: 14.1073\n",
      "Epoch [20860/100000], Loss: 14.1072\n",
      "Epoch [20870/100000], Loss: 14.1042\n",
      "Epoch [20880/100000], Loss: 14.1069\n",
      "Epoch [20890/100000], Loss: 14.1015\n",
      "Epoch [20900/100000], Loss: 14.1011\n",
      "Epoch [20910/100000], Loss: 14.0994\n",
      "Epoch [20920/100000], Loss: 14.1006\n",
      "Epoch [20930/100000], Loss: 14.0975\n",
      "Epoch [20940/100000], Loss: 14.0992\n",
      "Epoch [20950/100000], Loss: 14.0939\n",
      "Epoch [20960/100000], Loss: 14.0935\n",
      "Epoch [20970/100000], Loss: 14.0847\n",
      "Epoch [20980/100000], Loss: 14.0880\n",
      "Epoch [20990/100000], Loss: 14.0980\n",
      "Epoch [21000/100000], Loss: 14.0995\n",
      "Epoch [21010/100000], Loss: 14.0940\n",
      "Epoch [21020/100000], Loss: 14.0921\n",
      "Epoch [21030/100000], Loss: 14.0853\n",
      "Epoch [21040/100000], Loss: 14.0751\n",
      "Epoch [21050/100000], Loss: 14.0802\n",
      "Epoch [21060/100000], Loss: 14.0873\n",
      "Epoch [21070/100000], Loss: 14.0825\n",
      "Epoch [21080/100000], Loss: 14.0793\n",
      "Epoch [21090/100000], Loss: 14.0872\n",
      "Epoch [21100/100000], Loss: 14.0811\n",
      "Epoch [21110/100000], Loss: 14.0723\n",
      "Epoch [21120/100000], Loss: 14.0806\n",
      "Epoch [21130/100000], Loss: 14.0789\n",
      "Epoch [21140/100000], Loss: 14.0736\n",
      "Epoch [21150/100000], Loss: 14.0787\n",
      "Epoch [21160/100000], Loss: 14.0765\n",
      "Epoch [21170/100000], Loss: 14.0693\n",
      "Epoch [21180/100000], Loss: 14.0771\n",
      "Epoch [21190/100000], Loss: 14.0719\n",
      "Epoch [21200/100000], Loss: 14.0716\n",
      "Epoch [21210/100000], Loss: 14.0659\n",
      "Epoch [21220/100000], Loss: 14.0680\n",
      "Epoch [21230/100000], Loss: 14.0658\n",
      "Epoch [21240/100000], Loss: 14.0693\n",
      "Epoch [21250/100000], Loss: 14.0693\n",
      "Epoch [21260/100000], Loss: 14.0683\n",
      "Epoch [21270/100000], Loss: 14.0665\n",
      "Epoch [21280/100000], Loss: 14.0638\n",
      "Epoch [21290/100000], Loss: 14.0611\n",
      "Epoch [21300/100000], Loss: 14.0592\n",
      "Epoch [21310/100000], Loss: 14.0577\n",
      "Epoch [21320/100000], Loss: 14.0514\n",
      "Epoch [21330/100000], Loss: 14.0484\n",
      "Epoch [21340/100000], Loss: 14.0492\n",
      "Epoch [21350/100000], Loss: 14.0441\n",
      "Epoch [21360/100000], Loss: 14.0473\n",
      "Epoch [21370/100000], Loss: 14.0422\n",
      "Epoch [21380/100000], Loss: 14.0409\n",
      "Epoch [21390/100000], Loss: 14.0385\n",
      "Epoch [21400/100000], Loss: 14.0222\n",
      "Epoch [21410/100000], Loss: 14.0249\n",
      "Epoch [21420/100000], Loss: 14.0243\n",
      "Epoch [21430/100000], Loss: 14.0277\n",
      "Epoch [21440/100000], Loss: 14.0295\n",
      "Epoch [21450/100000], Loss: 14.0333\n",
      "Epoch [21460/100000], Loss: 14.0283\n",
      "Epoch [21470/100000], Loss: 14.0286\n",
      "Epoch [21480/100000], Loss: 14.0248\n",
      "Epoch [21490/100000], Loss: 14.0207\n",
      "Epoch [21500/100000], Loss: 14.0257\n",
      "Epoch [21510/100000], Loss: 14.0214\n",
      "Epoch [21520/100000], Loss: 14.0202\n",
      "Epoch [21530/100000], Loss: 14.0210\n",
      "Epoch [21540/100000], Loss: 14.0120\n",
      "Epoch [21550/100000], Loss: 14.0092\n",
      "Epoch [21560/100000], Loss: 14.0107\n",
      "Epoch [21570/100000], Loss: 14.0079\n",
      "Epoch [21580/100000], Loss: 14.0163\n",
      "Epoch [21590/100000], Loss: 14.0102\n",
      "Epoch [21600/100000], Loss: 14.0076\n",
      "Epoch [21610/100000], Loss: 14.0048\n",
      "Epoch [21620/100000], Loss: 14.0035\n",
      "Epoch [21630/100000], Loss: 14.0065\n",
      "Epoch [21640/100000], Loss: 13.9971\n",
      "Epoch [21650/100000], Loss: 13.9975\n",
      "Epoch [21660/100000], Loss: 14.0006\n",
      "Epoch [21670/100000], Loss: 14.0069\n",
      "Epoch [21680/100000], Loss: 14.0021\n",
      "Epoch [21690/100000], Loss: 13.9937\n",
      "Epoch [21700/100000], Loss: 13.9898\n",
      "Epoch [21710/100000], Loss: 13.9789\n",
      "Epoch [21720/100000], Loss: 13.9896\n",
      "Epoch [21730/100000], Loss: 13.9942\n",
      "Epoch [21740/100000], Loss: 13.9917\n",
      "Epoch [21750/100000], Loss: 13.9915\n",
      "Epoch [21760/100000], Loss: 13.9943\n",
      "Epoch [21770/100000], Loss: 13.9936\n",
      "Epoch [21780/100000], Loss: 13.9901\n",
      "Epoch [21790/100000], Loss: 13.9926\n",
      "Epoch [21800/100000], Loss: 13.9825\n",
      "Epoch [21810/100000], Loss: 13.9828\n",
      "Epoch [21820/100000], Loss: 13.9855\n",
      "Epoch [21830/100000], Loss: 13.9827\n",
      "Epoch [21840/100000], Loss: 13.9812\n",
      "Epoch [21850/100000], Loss: 13.9753\n",
      "Epoch [21860/100000], Loss: 13.9670\n",
      "Epoch [21870/100000], Loss: 13.9595\n",
      "Epoch [21880/100000], Loss: 13.9674\n",
      "Epoch [21890/100000], Loss: 13.9611\n",
      "Epoch [21900/100000], Loss: 13.9659\n",
      "Epoch [21910/100000], Loss: 13.9702\n",
      "Epoch [21920/100000], Loss: 13.9696\n",
      "Epoch [21930/100000], Loss: 13.9750\n",
      "Epoch [21940/100000], Loss: 13.9683\n",
      "Epoch [21950/100000], Loss: 13.9680\n",
      "Epoch [21960/100000], Loss: 13.9640\n",
      "Epoch [21970/100000], Loss: 13.9556\n",
      "Epoch [21980/100000], Loss: 13.9517\n",
      "Epoch [21990/100000], Loss: 13.9482\n",
      "Epoch [22000/100000], Loss: 13.9496\n",
      "Epoch [22010/100000], Loss: 13.9482\n",
      "Epoch [22020/100000], Loss: 13.9497\n",
      "Epoch [22030/100000], Loss: 13.9495\n",
      "Epoch [22040/100000], Loss: 13.9453\n",
      "Epoch [22050/100000], Loss: 13.9488\n",
      "Epoch [22060/100000], Loss: 13.9433\n",
      "Epoch [22070/100000], Loss: 13.9436\n",
      "Epoch [22080/100000], Loss: 13.9514\n",
      "Epoch [22090/100000], Loss: 13.9426\n",
      "Epoch [22100/100000], Loss: 13.9459\n",
      "Epoch [22110/100000], Loss: 13.9377\n",
      "Epoch [22120/100000], Loss: 13.9357\n",
      "Epoch [22130/100000], Loss: 13.9369\n",
      "Epoch [22140/100000], Loss: 13.9284\n",
      "Epoch [22150/100000], Loss: 13.9383\n",
      "Epoch [22160/100000], Loss: 13.9252\n",
      "Epoch [22170/100000], Loss: 13.9289\n",
      "Epoch [22180/100000], Loss: 13.9261\n",
      "Epoch [22190/100000], Loss: 13.9206\n",
      "Epoch [22200/100000], Loss: 13.9164\n",
      "Epoch [22210/100000], Loss: 13.9123\n",
      "Epoch [22220/100000], Loss: 13.9152\n",
      "Epoch [22230/100000], Loss: 13.9140\n",
      "Epoch [22240/100000], Loss: 13.9101\n",
      "Epoch [22250/100000], Loss: 13.9099\n",
      "Epoch [22260/100000], Loss: 13.9153\n",
      "Epoch [22270/100000], Loss: 13.9136\n",
      "Epoch [22280/100000], Loss: 13.9047\n",
      "Epoch [22290/100000], Loss: 13.9067\n",
      "Epoch [22300/100000], Loss: 13.9060\n",
      "Epoch [22310/100000], Loss: 13.9046\n",
      "Epoch [22320/100000], Loss: 13.9048\n",
      "Epoch [22330/100000], Loss: 13.9087\n",
      "Epoch [22340/100000], Loss: 13.8985\n",
      "Epoch [22350/100000], Loss: 13.9051\n",
      "Epoch [22360/100000], Loss: 13.9033\n",
      "Epoch [22370/100000], Loss: 13.8930\n",
      "Epoch [22380/100000], Loss: 13.8898\n",
      "Epoch [22390/100000], Loss: 13.8933\n",
      "Epoch [22400/100000], Loss: 13.8867\n",
      "Epoch [22410/100000], Loss: 13.8864\n",
      "Epoch [22420/100000], Loss: 13.8867\n",
      "Epoch [22430/100000], Loss: 13.8937\n",
      "Epoch [22440/100000], Loss: 13.8880\n",
      "Epoch [22450/100000], Loss: 13.8896\n",
      "Epoch [22460/100000], Loss: 13.8873\n",
      "Epoch [22470/100000], Loss: 13.8845\n",
      "Epoch [22480/100000], Loss: 13.8751\n",
      "Epoch [22490/100000], Loss: 13.8678\n",
      "Epoch [22500/100000], Loss: 13.8624\n",
      "Epoch [22510/100000], Loss: 13.8721\n",
      "Epoch [22520/100000], Loss: 13.8754\n",
      "Epoch [22530/100000], Loss: 13.8720\n",
      "Epoch [22540/100000], Loss: 13.8670\n",
      "Epoch [22550/100000], Loss: 13.8660\n",
      "Epoch [22560/100000], Loss: 13.8641\n",
      "Epoch [22570/100000], Loss: 13.8564\n",
      "Epoch [22580/100000], Loss: 13.8579\n",
      "Epoch [22590/100000], Loss: 13.8555\n",
      "Epoch [22600/100000], Loss: 13.8523\n",
      "Epoch [22610/100000], Loss: 13.8513\n",
      "Epoch [22620/100000], Loss: 13.8542\n",
      "Epoch [22630/100000], Loss: 13.8617\n",
      "Epoch [22640/100000], Loss: 13.8535\n",
      "Epoch [22650/100000], Loss: 13.8586\n",
      "Epoch [22660/100000], Loss: 13.8512\n",
      "Epoch [22670/100000], Loss: 13.8599\n",
      "Epoch [22680/100000], Loss: 13.8428\n",
      "Epoch [22690/100000], Loss: 13.8415\n",
      "Epoch [22700/100000], Loss: 13.8489\n",
      "Epoch [22710/100000], Loss: 13.8459\n",
      "Epoch [22720/100000], Loss: 13.8471\n",
      "Epoch [22730/100000], Loss: 13.8418\n",
      "Epoch [22740/100000], Loss: 13.8371\n",
      "Epoch [22750/100000], Loss: 13.8312\n",
      "Epoch [22760/100000], Loss: 13.8380\n",
      "Epoch [22770/100000], Loss: 13.8347\n",
      "Epoch [22780/100000], Loss: 13.8259\n",
      "Epoch [22790/100000], Loss: 13.8222\n",
      "Epoch [22800/100000], Loss: 13.8262\n",
      "Epoch [22810/100000], Loss: 13.8284\n",
      "Epoch [22820/100000], Loss: 13.8194\n",
      "Epoch [22830/100000], Loss: 13.8086\n",
      "Epoch [22840/100000], Loss: 13.8142\n",
      "Epoch [22850/100000], Loss: 13.8078\n",
      "Epoch [22860/100000], Loss: 13.8013\n",
      "Epoch [22870/100000], Loss: 13.8005\n",
      "Epoch [22880/100000], Loss: 13.7980\n",
      "Epoch [22890/100000], Loss: 13.7983\n",
      "Epoch [22900/100000], Loss: 13.7960\n",
      "Epoch [22910/100000], Loss: 13.7951\n",
      "Epoch [22920/100000], Loss: 13.7916\n",
      "Epoch [22930/100000], Loss: 13.7897\n",
      "Epoch [22940/100000], Loss: 13.7883\n",
      "Epoch [22950/100000], Loss: 13.7858\n",
      "Epoch [22960/100000], Loss: 13.7820\n",
      "Epoch [22970/100000], Loss: 13.7810\n",
      "Epoch [22980/100000], Loss: 13.7796\n",
      "Epoch [22990/100000], Loss: 13.7780\n",
      "Epoch [23000/100000], Loss: 13.7714\n",
      "Epoch [23010/100000], Loss: 13.7718\n",
      "Epoch [23020/100000], Loss: 13.7642\n",
      "Epoch [23030/100000], Loss: 13.7725\n",
      "Epoch [23040/100000], Loss: 13.7694\n",
      "Epoch [23050/100000], Loss: 13.7658\n",
      "Epoch [23060/100000], Loss: 13.7624\n",
      "Epoch [23070/100000], Loss: 13.7509\n",
      "Epoch [23080/100000], Loss: 13.7575\n",
      "Epoch [23090/100000], Loss: 13.7426\n",
      "Epoch [23100/100000], Loss: 13.7413\n",
      "Epoch [23110/100000], Loss: 13.7493\n",
      "Epoch [23120/100000], Loss: 13.7371\n",
      "Epoch [23130/100000], Loss: 13.7326\n",
      "Epoch [23140/100000], Loss: 13.7291\n",
      "Epoch [23150/100000], Loss: 13.7201\n",
      "Epoch [23160/100000], Loss: 13.7209\n",
      "Epoch [23170/100000], Loss: 13.7240\n",
      "Epoch [23180/100000], Loss: 13.7273\n",
      "Epoch [23190/100000], Loss: 13.7253\n",
      "Epoch [23200/100000], Loss: 13.7229\n",
      "Epoch [23210/100000], Loss: 13.7173\n",
      "Epoch [23220/100000], Loss: 13.7129\n",
      "Epoch [23230/100000], Loss: 13.7033\n",
      "Epoch [23240/100000], Loss: 13.6991\n",
      "Epoch [23250/100000], Loss: 13.7035\n",
      "Epoch [23260/100000], Loss: 13.7048\n",
      "Epoch [23270/100000], Loss: 13.6981\n",
      "Epoch [23280/100000], Loss: 13.6860\n",
      "Epoch [23290/100000], Loss: 13.6955\n",
      "Epoch [23300/100000], Loss: 13.6816\n",
      "Epoch [23310/100000], Loss: 13.6879\n",
      "Epoch [23320/100000], Loss: 13.6794\n",
      "Epoch [23330/100000], Loss: 13.6810\n",
      "Epoch [23340/100000], Loss: 13.6822\n",
      "Epoch [23350/100000], Loss: 13.6764\n",
      "Epoch [23360/100000], Loss: 13.6823\n",
      "Epoch [23370/100000], Loss: 13.6713\n",
      "Epoch [23380/100000], Loss: 13.6710\n",
      "Epoch [23390/100000], Loss: 13.6658\n",
      "Epoch [23400/100000], Loss: 13.6720\n",
      "Epoch [23410/100000], Loss: 13.6618\n",
      "Epoch [23420/100000], Loss: 13.6713\n",
      "Epoch [23430/100000], Loss: 13.6597\n",
      "Epoch [23440/100000], Loss: 13.6622\n",
      "Epoch [23450/100000], Loss: 13.6489\n",
      "Epoch [23460/100000], Loss: 13.6366\n",
      "Epoch [23470/100000], Loss: 13.6483\n",
      "Epoch [23480/100000], Loss: 13.6365\n",
      "Epoch [23490/100000], Loss: 13.6448\n",
      "Epoch [23500/100000], Loss: 13.6351\n",
      "Epoch [23510/100000], Loss: 13.6400\n",
      "Epoch [23520/100000], Loss: 13.6448\n",
      "Epoch [23530/100000], Loss: 13.6317\n",
      "Epoch [23540/100000], Loss: 13.6328\n",
      "Epoch [23550/100000], Loss: 13.6185\n",
      "Epoch [23560/100000], Loss: 13.6256\n",
      "Epoch [23570/100000], Loss: 13.6193\n",
      "Epoch [23580/100000], Loss: 13.6148\n",
      "Epoch [23590/100000], Loss: 13.6111\n",
      "Epoch [23600/100000], Loss: 13.6146\n",
      "Epoch [23610/100000], Loss: 13.6079\n",
      "Epoch [23620/100000], Loss: 13.5996\n",
      "Epoch [23630/100000], Loss: 13.5848\n",
      "Epoch [23640/100000], Loss: 13.6015\n",
      "Epoch [23650/100000], Loss: 13.5936\n",
      "Epoch [23660/100000], Loss: 13.5936\n",
      "Epoch [23670/100000], Loss: 13.5828\n",
      "Epoch [23680/100000], Loss: 13.5811\n",
      "Epoch [23690/100000], Loss: 13.5934\n",
      "Epoch [23700/100000], Loss: 13.5857\n",
      "Epoch [23710/100000], Loss: 13.5807\n",
      "Epoch [23720/100000], Loss: 13.5770\n",
      "Epoch [23730/100000], Loss: 13.5795\n",
      "Epoch [23740/100000], Loss: 13.5712\n",
      "Epoch [23750/100000], Loss: 13.5712\n",
      "Epoch [23760/100000], Loss: 13.5593\n",
      "Epoch [23770/100000], Loss: 13.5554\n",
      "Epoch [23780/100000], Loss: 13.5514\n",
      "Epoch [23790/100000], Loss: 13.5501\n",
      "Epoch [23800/100000], Loss: 13.5431\n",
      "Epoch [23810/100000], Loss: 13.5437\n",
      "Epoch [23820/100000], Loss: 13.5451\n",
      "Epoch [23830/100000], Loss: 13.5447\n",
      "Epoch [23840/100000], Loss: 13.5377\n",
      "Epoch [23850/100000], Loss: 13.5411\n",
      "Epoch [23860/100000], Loss: 13.5398\n",
      "Epoch [23870/100000], Loss: 13.5292\n",
      "Epoch [23880/100000], Loss: 13.5217\n",
      "Epoch [23890/100000], Loss: 13.5295\n",
      "Epoch [23900/100000], Loss: 13.5238\n",
      "Epoch [23910/100000], Loss: 13.5332\n",
      "Epoch [23920/100000], Loss: 13.5196\n",
      "Epoch [23930/100000], Loss: 13.5186\n",
      "Epoch [23940/100000], Loss: 13.5244\n",
      "Epoch [23950/100000], Loss: 13.5160\n",
      "Epoch [23960/100000], Loss: 13.5077\n",
      "Epoch [23970/100000], Loss: 13.4971\n",
      "Epoch [23980/100000], Loss: 13.4990\n",
      "Epoch [23990/100000], Loss: 13.5014\n",
      "Epoch [24000/100000], Loss: 13.4953\n",
      "Epoch [24010/100000], Loss: 13.4874\n",
      "Epoch [24020/100000], Loss: 13.4797\n",
      "Epoch [24030/100000], Loss: 13.4784\n",
      "Epoch [24040/100000], Loss: 13.4735\n",
      "Epoch [24050/100000], Loss: 13.4825\n",
      "Epoch [24060/100000], Loss: 13.4807\n",
      "Epoch [24070/100000], Loss: 13.4788\n",
      "Epoch [24080/100000], Loss: 13.4733\n",
      "Epoch [24090/100000], Loss: 13.4720\n",
      "Epoch [24100/100000], Loss: 13.4650\n",
      "Epoch [24110/100000], Loss: 13.4572\n",
      "Epoch [24120/100000], Loss: 13.4503\n",
      "Epoch [24130/100000], Loss: 13.4515\n",
      "Epoch [24140/100000], Loss: 13.4529\n",
      "Epoch [24150/100000], Loss: 13.4395\n",
      "Epoch [24160/100000], Loss: 13.4446\n",
      "Epoch [24170/100000], Loss: 13.4414\n",
      "Epoch [24180/100000], Loss: 13.4367\n",
      "Epoch [24190/100000], Loss: 13.4208\n",
      "Epoch [24200/100000], Loss: 13.4300\n",
      "Epoch [24210/100000], Loss: 13.4276\n",
      "Epoch [24220/100000], Loss: 13.4075\n",
      "Epoch [24230/100000], Loss: 13.4216\n",
      "Epoch [24240/100000], Loss: 13.4158\n",
      "Epoch [24250/100000], Loss: 13.4126\n",
      "Epoch [24260/100000], Loss: 13.4132\n",
      "Epoch [24270/100000], Loss: 13.4186\n",
      "Epoch [24280/100000], Loss: 13.4104\n",
      "Epoch [24290/100000], Loss: 13.4075\n",
      "Epoch [24300/100000], Loss: 13.3995\n",
      "Epoch [24310/100000], Loss: 13.3982\n",
      "Epoch [24320/100000], Loss: 13.3964\n",
      "Epoch [24330/100000], Loss: 13.3927\n",
      "Epoch [24340/100000], Loss: 13.3863\n",
      "Epoch [24350/100000], Loss: 13.3675\n",
      "Epoch [24360/100000], Loss: 13.3747\n",
      "Epoch [24370/100000], Loss: 13.3598\n",
      "Epoch [24380/100000], Loss: 13.3729\n",
      "Epoch [24390/100000], Loss: 13.3647\n",
      "Epoch [24400/100000], Loss: 13.3642\n",
      "Epoch [24410/100000], Loss: 13.3639\n",
      "Epoch [24420/100000], Loss: 13.3491\n",
      "Epoch [24430/100000], Loss: 13.3491\n",
      "Epoch [24440/100000], Loss: 13.3389\n",
      "Epoch [24450/100000], Loss: 13.3351\n",
      "Epoch [24460/100000], Loss: 13.3308\n",
      "Epoch [24470/100000], Loss: 13.3224\n",
      "Epoch [24480/100000], Loss: 13.3191\n",
      "Epoch [24490/100000], Loss: 13.3197\n",
      "Epoch [24500/100000], Loss: 13.3078\n",
      "Epoch [24510/100000], Loss: 13.3074\n",
      "Epoch [24520/100000], Loss: 13.3109\n",
      "Epoch [24530/100000], Loss: 13.2928\n",
      "Epoch [24540/100000], Loss: 13.2968\n",
      "Epoch [24550/100000], Loss: 13.2973\n",
      "Epoch [24560/100000], Loss: 13.2978\n",
      "Epoch [24570/100000], Loss: 13.2814\n",
      "Epoch [24580/100000], Loss: 13.2881\n",
      "Epoch [24590/100000], Loss: 13.2722\n",
      "Epoch [24600/100000], Loss: 13.2708\n",
      "Epoch [24610/100000], Loss: 13.2697\n",
      "Epoch [24620/100000], Loss: 13.2646\n",
      "Epoch [24630/100000], Loss: 13.2483\n",
      "Epoch [24640/100000], Loss: 13.2453\n",
      "Epoch [24650/100000], Loss: 13.2434\n",
      "Epoch [24660/100000], Loss: 13.2426\n",
      "Epoch [24670/100000], Loss: 13.2379\n",
      "Epoch [24680/100000], Loss: 13.2396\n",
      "Epoch [24690/100000], Loss: 13.2253\n",
      "Epoch [24700/100000], Loss: 13.2233\n",
      "Epoch [24710/100000], Loss: 13.2125\n",
      "Epoch [24720/100000], Loss: 13.2171\n",
      "Epoch [24730/100000], Loss: 13.2131\n",
      "Epoch [24740/100000], Loss: 13.2039\n",
      "Epoch [24750/100000], Loss: 13.2093\n",
      "Epoch [24760/100000], Loss: 13.1999\n",
      "Epoch [24770/100000], Loss: 13.1954\n",
      "Epoch [24780/100000], Loss: 13.1947\n",
      "Epoch [24790/100000], Loss: 13.1816\n",
      "Epoch [24800/100000], Loss: 13.1692\n",
      "Epoch [24810/100000], Loss: 13.1681\n",
      "Epoch [24820/100000], Loss: 13.1639\n",
      "Epoch [24830/100000], Loss: 13.1532\n",
      "Epoch [24840/100000], Loss: 13.1517\n",
      "Epoch [24850/100000], Loss: 13.1609\n",
      "Epoch [24860/100000], Loss: 13.1505\n",
      "Epoch [24870/100000], Loss: 13.1433\n",
      "Epoch [24880/100000], Loss: 13.1378\n",
      "Epoch [24890/100000], Loss: 13.1265\n",
      "Epoch [24900/100000], Loss: 13.1304\n",
      "Epoch [24910/100000], Loss: 13.1266\n",
      "Epoch [24920/100000], Loss: 13.1300\n",
      "Epoch [24930/100000], Loss: 13.1226\n",
      "Epoch [24940/100000], Loss: 13.1012\n",
      "Epoch [24950/100000], Loss: 13.1170\n",
      "Epoch [24960/100000], Loss: 13.1128\n",
      "Epoch [24970/100000], Loss: 13.1050\n",
      "Epoch [24980/100000], Loss: 13.0943\n",
      "Epoch [24990/100000], Loss: 13.0853\n",
      "Epoch [25000/100000], Loss: 13.0821\n",
      "Epoch [25010/100000], Loss: 13.0713\n",
      "Epoch [25020/100000], Loss: 13.0741\n",
      "Epoch [25030/100000], Loss: 13.0590\n",
      "Epoch [25040/100000], Loss: 13.0573\n",
      "Epoch [25050/100000], Loss: 13.0484\n",
      "Epoch [25060/100000], Loss: 13.0413\n",
      "Epoch [25070/100000], Loss: 13.0435\n",
      "Epoch [25080/100000], Loss: 13.0375\n",
      "Epoch [25090/100000], Loss: 13.0215\n",
      "Epoch [25100/100000], Loss: 13.0311\n",
      "Epoch [25110/100000], Loss: 13.0262\n",
      "Epoch [25120/100000], Loss: 13.0204\n",
      "Epoch [25130/100000], Loss: 13.0069\n",
      "Epoch [25140/100000], Loss: 13.0161\n",
      "Epoch [25150/100000], Loss: 13.0020\n",
      "Epoch [25160/100000], Loss: 12.9944\n",
      "Epoch [25170/100000], Loss: 12.9952\n",
      "Epoch [25180/100000], Loss: 12.9881\n",
      "Epoch [25190/100000], Loss: 12.9741\n",
      "Epoch [25200/100000], Loss: 12.9704\n",
      "Epoch [25210/100000], Loss: 12.9775\n",
      "Epoch [25220/100000], Loss: 12.9682\n",
      "Epoch [25230/100000], Loss: 12.9668\n",
      "Epoch [25240/100000], Loss: 12.9525\n",
      "Epoch [25250/100000], Loss: 12.9534\n",
      "Epoch [25260/100000], Loss: 12.9535\n",
      "Epoch [25270/100000], Loss: 12.9453\n",
      "Epoch [25280/100000], Loss: 12.9433\n",
      "Epoch [25290/100000], Loss: 12.9379\n",
      "Epoch [25300/100000], Loss: 12.9207\n",
      "Epoch [25310/100000], Loss: 12.9176\n",
      "Epoch [25320/100000], Loss: 12.9167\n",
      "Epoch [25330/100000], Loss: 12.9055\n",
      "Epoch [25340/100000], Loss: 12.9175\n",
      "Epoch [25350/100000], Loss: 12.8962\n",
      "Epoch [25360/100000], Loss: 12.8869\n",
      "Epoch [25370/100000], Loss: 12.8937\n",
      "Epoch [25380/100000], Loss: 12.8922\n",
      "Epoch [25390/100000], Loss: 12.8739\n",
      "Epoch [25400/100000], Loss: 12.8687\n",
      "Epoch [25410/100000], Loss: 12.8706\n",
      "Epoch [25420/100000], Loss: 12.8540\n",
      "Epoch [25430/100000], Loss: 12.8566\n",
      "Epoch [25440/100000], Loss: 12.8507\n",
      "Epoch [25450/100000], Loss: 12.8456\n",
      "Epoch [25460/100000], Loss: 12.8376\n",
      "Epoch [25470/100000], Loss: 12.8297\n",
      "Epoch [25480/100000], Loss: 12.8236\n",
      "Epoch [25490/100000], Loss: 12.8267\n",
      "Epoch [25500/100000], Loss: 12.8184\n",
      "Epoch [25510/100000], Loss: 12.8084\n",
      "Epoch [25520/100000], Loss: 12.7932\n",
      "Epoch [25530/100000], Loss: 12.7875\n",
      "Epoch [25540/100000], Loss: 12.7751\n",
      "Epoch [25550/100000], Loss: 12.7803\n",
      "Epoch [25560/100000], Loss: 12.7763\n",
      "Epoch [25570/100000], Loss: 12.7687\n",
      "Epoch [25580/100000], Loss: 12.7596\n",
      "Epoch [25590/100000], Loss: 12.7505\n",
      "Epoch [25600/100000], Loss: 12.7422\n",
      "Epoch [25610/100000], Loss: 12.7355\n",
      "Epoch [25620/100000], Loss: 12.7265\n",
      "Epoch [25630/100000], Loss: 12.7247\n",
      "Epoch [25640/100000], Loss: 12.7251\n",
      "Epoch [25650/100000], Loss: 12.7106\n",
      "Epoch [25660/100000], Loss: 12.7093\n",
      "Epoch [25670/100000], Loss: 12.6948\n",
      "Epoch [25680/100000], Loss: 12.6891\n",
      "Epoch [25690/100000], Loss: 12.6866\n",
      "Epoch [25700/100000], Loss: 12.6776\n",
      "Epoch [25710/100000], Loss: 12.6693\n",
      "Epoch [25720/100000], Loss: 12.6585\n",
      "Epoch [25730/100000], Loss: 12.6606\n",
      "Epoch [25740/100000], Loss: 12.6598\n",
      "Epoch [25750/100000], Loss: 12.6456\n",
      "Epoch [25760/100000], Loss: 12.6423\n",
      "Epoch [25770/100000], Loss: 12.6321\n",
      "Epoch [25780/100000], Loss: 12.6360\n",
      "Epoch [25790/100000], Loss: 12.6219\n",
      "Epoch [25800/100000], Loss: 12.6110\n",
      "Epoch [25810/100000], Loss: 12.6010\n",
      "Epoch [25820/100000], Loss: 12.6039\n",
      "Epoch [25830/100000], Loss: 12.5934\n",
      "Epoch [25840/100000], Loss: 12.5905\n",
      "Epoch [25850/100000], Loss: 12.5799\n",
      "Epoch [25860/100000], Loss: 12.5769\n",
      "Epoch [25870/100000], Loss: 12.5692\n",
      "Epoch [25880/100000], Loss: 12.5673\n",
      "Epoch [25890/100000], Loss: 12.5628\n",
      "Epoch [25900/100000], Loss: 12.5549\n",
      "Epoch [25910/100000], Loss: 12.5434\n",
      "Epoch [25920/100000], Loss: 12.5289\n",
      "Epoch [25930/100000], Loss: 12.5355\n",
      "Epoch [25940/100000], Loss: 12.5263\n",
      "Epoch [25950/100000], Loss: 12.5104\n",
      "Epoch [25960/100000], Loss: 12.5035\n",
      "Epoch [25970/100000], Loss: 12.5065\n",
      "Epoch [25980/100000], Loss: 12.4964\n",
      "Epoch [25990/100000], Loss: 12.4915\n",
      "Epoch [26000/100000], Loss: 12.4805\n",
      "Epoch [26010/100000], Loss: 12.4686\n",
      "Epoch [26020/100000], Loss: 12.4643\n",
      "Epoch [26030/100000], Loss: 12.4538\n",
      "Epoch [26040/100000], Loss: 12.4546\n",
      "Epoch [26050/100000], Loss: 12.4512\n",
      "Epoch [26060/100000], Loss: 12.4378\n",
      "Epoch [26070/100000], Loss: 12.4266\n",
      "Epoch [26080/100000], Loss: 12.4163\n",
      "Epoch [26090/100000], Loss: 12.4132\n",
      "Epoch [26100/100000], Loss: 12.4050\n",
      "Epoch [26110/100000], Loss: 12.3870\n",
      "Epoch [26120/100000], Loss: 12.3823\n",
      "Epoch [26130/100000], Loss: 12.3794\n",
      "Epoch [26140/100000], Loss: 12.3789\n",
      "Epoch [26150/100000], Loss: 12.3763\n",
      "Epoch [26160/100000], Loss: 12.3576\n",
      "Epoch [26170/100000], Loss: 12.3578\n",
      "Epoch [26180/100000], Loss: 12.3479\n",
      "Epoch [26190/100000], Loss: 12.3319\n",
      "Epoch [26200/100000], Loss: 12.3358\n",
      "Epoch [26210/100000], Loss: 12.3208\n",
      "Epoch [26220/100000], Loss: 12.3130\n",
      "Epoch [26230/100000], Loss: 12.3030\n",
      "Epoch [26240/100000], Loss: 12.2974\n",
      "Epoch [26250/100000], Loss: 12.2908\n",
      "Epoch [26260/100000], Loss: 12.2856\n",
      "Epoch [26270/100000], Loss: 12.2745\n",
      "Epoch [26280/100000], Loss: 12.2729\n",
      "Epoch [26290/100000], Loss: 12.2572\n",
      "Epoch [26300/100000], Loss: 12.2455\n",
      "Epoch [26310/100000], Loss: 12.2402\n",
      "Epoch [26320/100000], Loss: 12.2388\n",
      "Epoch [26330/100000], Loss: 12.2366\n",
      "Epoch [26340/100000], Loss: 12.2221\n",
      "Epoch [26350/100000], Loss: 12.2152\n",
      "Epoch [26360/100000], Loss: 12.2185\n",
      "Epoch [26370/100000], Loss: 12.2020\n",
      "Epoch [26380/100000], Loss: 12.1941\n",
      "Epoch [26390/100000], Loss: 12.1831\n",
      "Epoch [26400/100000], Loss: 12.1764\n",
      "Epoch [26410/100000], Loss: 12.1607\n",
      "Epoch [26420/100000], Loss: 12.1581\n",
      "Epoch [26430/100000], Loss: 12.1566\n",
      "Epoch [26440/100000], Loss: 12.1452\n",
      "Epoch [26450/100000], Loss: 12.1408\n",
      "Epoch [26460/100000], Loss: 12.1267\n",
      "Epoch [26470/100000], Loss: 12.1234\n",
      "Epoch [26480/100000], Loss: 12.1136\n",
      "Epoch [26490/100000], Loss: 12.1013\n",
      "Epoch [26500/100000], Loss: 12.0797\n",
      "Epoch [26510/100000], Loss: 12.0767\n",
      "Epoch [26520/100000], Loss: 12.0718\n",
      "Epoch [26530/100000], Loss: 12.0587\n",
      "Epoch [26540/100000], Loss: 12.0474\n",
      "Epoch [26550/100000], Loss: 12.0410\n",
      "Epoch [26560/100000], Loss: 12.0374\n",
      "Epoch [26570/100000], Loss: 12.0361\n",
      "Epoch [26580/100000], Loss: 12.0210\n",
      "Epoch [26590/100000], Loss: 12.0184\n",
      "Epoch [26600/100000], Loss: 11.9974\n",
      "Epoch [26610/100000], Loss: 11.9831\n",
      "Epoch [26620/100000], Loss: 11.9793\n",
      "Epoch [26630/100000], Loss: 11.9769\n",
      "Epoch [26640/100000], Loss: 11.9620\n",
      "Epoch [26650/100000], Loss: 337768.6250\n",
      "Epoch [26660/100000], Loss: 2036065536.0000\n",
      "Epoch [26670/100000], Loss: 757059200.0000\n",
      "Epoch [26680/100000], Loss: 129366184.0000\n",
      "Epoch [26690/100000], Loss: 92065280.0000\n",
      "Epoch [26700/100000], Loss: 65463456.0000\n",
      "Epoch [26710/100000], Loss: 28279794.0000\n",
      "Epoch [26720/100000], Loss: 4448212.0000\n",
      "Epoch [26730/100000], Loss: 252115.2188\n",
      "Epoch [26740/100000], Loss: 560345.5625\n",
      "Epoch [26750/100000], Loss: 345483.5625\n",
      "Epoch [26760/100000], Loss: 152119.3438\n",
      "Epoch [26770/100000], Loss: 46116.5078\n",
      "Epoch [26780/100000], Loss: 4833.9351\n",
      "Epoch [26790/100000], Loss: 953.7639\n",
      "Epoch [26800/100000], Loss: 596.5473\n",
      "Epoch [26810/100000], Loss: 416.7719\n",
      "Epoch [26820/100000], Loss: 284.6375\n",
      "Epoch [26830/100000], Loss: 113.0183\n",
      "Epoch [26840/100000], Loss: 48.3569\n",
      "Epoch [26850/100000], Loss: 22.0614\n",
      "Epoch [26860/100000], Loss: 13.3914\n",
      "Epoch [26870/100000], Loss: 12.3771\n",
      "Epoch [26880/100000], Loss: 12.0180\n",
      "Epoch [26890/100000], Loss: 11.9399\n",
      "Epoch [26900/100000], Loss: 11.8757\n",
      "Epoch [26910/100000], Loss: 11.8735\n",
      "Epoch [26920/100000], Loss: 11.8666\n",
      "Epoch [26930/100000], Loss: 11.8667\n",
      "Epoch [26940/100000], Loss: 11.8522\n",
      "Epoch [26950/100000], Loss: 11.8549\n",
      "Epoch [26960/100000], Loss: 11.8519\n",
      "Epoch [26970/100000], Loss: 11.8583\n",
      "Epoch [26980/100000], Loss: 11.8585\n",
      "Epoch [26990/100000], Loss: 11.8613\n",
      "Epoch [27000/100000], Loss: 11.8556\n",
      "Epoch [27010/100000], Loss: 11.8569\n",
      "Epoch [27020/100000], Loss: 11.8532\n",
      "Epoch [27030/100000], Loss: 11.8541\n",
      "Epoch [27040/100000], Loss: 11.8513\n",
      "Epoch [27050/100000], Loss: 11.8475\n",
      "Epoch [27060/100000], Loss: 11.8557\n",
      "Epoch [27070/100000], Loss: 11.8507\n",
      "Epoch [27080/100000], Loss: 11.8545\n",
      "Epoch [27090/100000], Loss: 11.8525\n",
      "Epoch [27100/100000], Loss: 11.8527\n",
      "Epoch [27110/100000], Loss: 11.8480\n",
      "Epoch [27120/100000], Loss: 11.8457\n",
      "Epoch [27130/100000], Loss: 11.8450\n",
      "Epoch [27140/100000], Loss: 11.8447\n",
      "Epoch [27150/100000], Loss: 11.8453\n",
      "Epoch [27160/100000], Loss: 11.8451\n",
      "Epoch [27170/100000], Loss: 11.8470\n",
      "Epoch [27180/100000], Loss: 11.8493\n",
      "Epoch [27190/100000], Loss: 11.8491\n",
      "Epoch [27200/100000], Loss: 11.8429\n",
      "Epoch [27210/100000], Loss: 11.8457\n",
      "Epoch [27220/100000], Loss: 11.8425\n",
      "Epoch [27230/100000], Loss: 11.8383\n",
      "Epoch [27240/100000], Loss: 11.8380\n",
      "Epoch [27250/100000], Loss: 11.8406\n",
      "Epoch [27260/100000], Loss: 11.8405\n",
      "Epoch [27270/100000], Loss: 11.8378\n",
      "Epoch [27280/100000], Loss: 11.8369\n",
      "Epoch [27290/100000], Loss: 11.8378\n",
      "Epoch [27300/100000], Loss: 11.8341\n",
      "Epoch [27310/100000], Loss: 11.8386\n",
      "Epoch [27320/100000], Loss: 11.8418\n",
      "Epoch [27330/100000], Loss: 11.8357\n",
      "Epoch [27340/100000], Loss: 11.8383\n",
      "Epoch [27350/100000], Loss: 11.8358\n",
      "Epoch [27360/100000], Loss: 11.8324\n",
      "Epoch [27370/100000], Loss: 11.8272\n",
      "Epoch [27380/100000], Loss: 11.8273\n",
      "Epoch [27390/100000], Loss: 11.8188\n",
      "Epoch [27400/100000], Loss: 11.8141\n",
      "Epoch [27410/100000], Loss: 11.8221\n",
      "Epoch [27420/100000], Loss: 11.8271\n",
      "Epoch [27430/100000], Loss: 11.8230\n",
      "Epoch [27440/100000], Loss: 11.8205\n",
      "Epoch [27450/100000], Loss: 11.8198\n",
      "Epoch [27460/100000], Loss: 11.8218\n",
      "Epoch [27470/100000], Loss: 11.8214\n",
      "Epoch [27480/100000], Loss: 11.8173\n",
      "Epoch [27490/100000], Loss: 11.8167\n",
      "Epoch [27500/100000], Loss: 11.8179\n",
      "Epoch [27510/100000], Loss: 11.8163\n",
      "Epoch [27520/100000], Loss: 11.8182\n",
      "Epoch [27530/100000], Loss: 11.8185\n",
      "Epoch [27540/100000], Loss: 11.8136\n",
      "Epoch [27550/100000], Loss: 11.8063\n",
      "Epoch [27560/100000], Loss: 11.8072\n",
      "Epoch [27570/100000], Loss: 11.8138\n",
      "Epoch [27580/100000], Loss: 11.8078\n",
      "Epoch [27590/100000], Loss: 11.8061\n",
      "Epoch [27600/100000], Loss: 11.8092\n",
      "Epoch [27610/100000], Loss: 11.8121\n",
      "Epoch [27620/100000], Loss: 11.8042\n",
      "Epoch [27630/100000], Loss: 11.8028\n",
      "Epoch [27640/100000], Loss: 11.8020\n",
      "Epoch [27650/100000], Loss: 11.8049\n",
      "Epoch [27660/100000], Loss: 11.8065\n",
      "Epoch [27670/100000], Loss: 11.8076\n",
      "Epoch [27680/100000], Loss: 11.8034\n",
      "Epoch [27690/100000], Loss: 11.8069\n",
      "Epoch [27700/100000], Loss: 11.8065\n",
      "Epoch [27710/100000], Loss: 11.8058\n",
      "Epoch [27720/100000], Loss: 11.8059\n",
      "Epoch [27730/100000], Loss: 11.8052\n",
      "Epoch [27740/100000], Loss: 11.8025\n",
      "Epoch [27750/100000], Loss: 11.8014\n",
      "Epoch [27760/100000], Loss: 11.8013\n",
      "Epoch [27770/100000], Loss: 11.8037\n",
      "Epoch [27780/100000], Loss: 11.8016\n",
      "Epoch [27790/100000], Loss: 11.7975\n",
      "Epoch [27800/100000], Loss: 11.7979\n",
      "Epoch [27810/100000], Loss: 11.7950\n",
      "Epoch [27820/100000], Loss: 11.7896\n",
      "Epoch [27830/100000], Loss: 11.7815\n",
      "Epoch [27840/100000], Loss: 11.7771\n",
      "Epoch [27850/100000], Loss: 11.7797\n",
      "Epoch [27860/100000], Loss: 11.7860\n",
      "Epoch [27870/100000], Loss: 11.7898\n",
      "Epoch [27880/100000], Loss: 11.7871\n",
      "Epoch [27890/100000], Loss: 11.7827\n",
      "Epoch [27900/100000], Loss: 11.7839\n",
      "Epoch [27910/100000], Loss: 11.7848\n",
      "Epoch [27920/100000], Loss: 11.7891\n",
      "Epoch [27930/100000], Loss: 11.7816\n",
      "Epoch [27940/100000], Loss: 11.7801\n",
      "Epoch [27950/100000], Loss: 11.7857\n",
      "Epoch [27960/100000], Loss: 11.7831\n",
      "Epoch [27970/100000], Loss: 11.7814\n",
      "Epoch [27980/100000], Loss: 11.7749\n",
      "Epoch [27990/100000], Loss: 11.7726\n",
      "Epoch [28000/100000], Loss: 11.7753\n",
      "Epoch [28010/100000], Loss: 11.7770\n",
      "Epoch [28020/100000], Loss: 11.7701\n",
      "Epoch [28030/100000], Loss: 11.7706\n",
      "Epoch [28040/100000], Loss: 11.7685\n",
      "Epoch [28050/100000], Loss: 11.7650\n",
      "Epoch [28060/100000], Loss: 11.7616\n",
      "Epoch [28070/100000], Loss: 11.7611\n",
      "Epoch [28080/100000], Loss: 11.7607\n",
      "Epoch [28090/100000], Loss: 11.7655\n",
      "Epoch [28100/100000], Loss: 11.7688\n",
      "Epoch [28110/100000], Loss: 11.7672\n",
      "Epoch [28120/100000], Loss: 11.7654\n",
      "Epoch [28130/100000], Loss: 11.7601\n",
      "Epoch [28140/100000], Loss: 11.7623\n",
      "Epoch [28150/100000], Loss: 11.7643\n",
      "Epoch [28160/100000], Loss: 11.7597\n",
      "Epoch [28170/100000], Loss: 11.7560\n",
      "Epoch [28180/100000], Loss: 11.7529\n",
      "Epoch [28190/100000], Loss: 11.7517\n",
      "Epoch [28200/100000], Loss: 11.7557\n",
      "Epoch [28210/100000], Loss: 11.7574\n",
      "Epoch [28220/100000], Loss: 11.7557\n",
      "Epoch [28230/100000], Loss: 11.7566\n",
      "Epoch [28240/100000], Loss: 11.7555\n",
      "Epoch [28250/100000], Loss: 11.7520\n",
      "Epoch [28260/100000], Loss: 11.7500\n",
      "Epoch [28270/100000], Loss: 11.7439\n",
      "Epoch [28280/100000], Loss: 11.7456\n",
      "Epoch [28290/100000], Loss: 11.7445\n",
      "Epoch [28300/100000], Loss: 11.7450\n",
      "Epoch [28310/100000], Loss: 11.7510\n",
      "Epoch [28320/100000], Loss: 11.7472\n",
      "Epoch [28330/100000], Loss: 11.7473\n",
      "Epoch [28340/100000], Loss: 11.7415\n",
      "Epoch [28350/100000], Loss: 11.7478\n",
      "Epoch [28360/100000], Loss: 11.7419\n",
      "Epoch [28370/100000], Loss: 11.7387\n",
      "Epoch [28380/100000], Loss: 11.7383\n",
      "Epoch [28390/100000], Loss: 11.7404\n",
      "Epoch [28400/100000], Loss: 11.7458\n",
      "Epoch [28410/100000], Loss: 11.7407\n",
      "Epoch [28420/100000], Loss: 11.7432\n",
      "Epoch [28430/100000], Loss: 11.7372\n",
      "Epoch [28440/100000], Loss: 11.7379\n",
      "Epoch [28450/100000], Loss: 11.7434\n",
      "Epoch [28460/100000], Loss: 11.7315\n",
      "Epoch [28470/100000], Loss: 11.7331\n",
      "Epoch [28480/100000], Loss: 11.7275\n",
      "Epoch [28490/100000], Loss: 11.7258\n",
      "Epoch [28500/100000], Loss: 11.7228\n",
      "Epoch [28510/100000], Loss: 11.7158\n",
      "Epoch [28520/100000], Loss: 11.7119\n",
      "Epoch [28530/100000], Loss: 11.7199\n",
      "Epoch [28540/100000], Loss: 11.7172\n",
      "Epoch [28550/100000], Loss: 11.7176\n",
      "Epoch [28560/100000], Loss: 11.7158\n",
      "Epoch [28570/100000], Loss: 11.7143\n",
      "Epoch [28580/100000], Loss: 11.7159\n",
      "Epoch [28590/100000], Loss: 11.7200\n",
      "Epoch [28600/100000], Loss: 11.7193\n",
      "Epoch [28610/100000], Loss: 11.7175\n",
      "Epoch [28620/100000], Loss: 11.7170\n",
      "Epoch [28630/100000], Loss: 11.7161\n",
      "Epoch [28640/100000], Loss: 11.7099\n",
      "Epoch [28650/100000], Loss: 11.7071\n",
      "Epoch [28660/100000], Loss: 11.6982\n",
      "Epoch [28670/100000], Loss: 11.6995\n",
      "Epoch [28680/100000], Loss: 11.7080\n",
      "Epoch [28690/100000], Loss: 11.7015\n",
      "Epoch [28700/100000], Loss: 11.6998\n",
      "Epoch [28710/100000], Loss: 11.7026\n",
      "Epoch [28720/100000], Loss: 11.7085\n",
      "Epoch [28730/100000], Loss: 11.7013\n",
      "Epoch [28740/100000], Loss: 11.6870\n",
      "Epoch [28750/100000], Loss: 11.6957\n",
      "Epoch [28760/100000], Loss: 11.6917\n",
      "Epoch [28770/100000], Loss: 11.6910\n",
      "Epoch [28780/100000], Loss: 11.6906\n",
      "Epoch [28790/100000], Loss: 11.6937\n",
      "Epoch [28800/100000], Loss: 11.6881\n",
      "Epoch [28810/100000], Loss: 11.6860\n",
      "Epoch [28820/100000], Loss: 11.6835\n",
      "Epoch [28830/100000], Loss: 11.6787\n",
      "Epoch [28840/100000], Loss: 11.6752\n",
      "Epoch [28850/100000], Loss: 11.6689\n",
      "Epoch [28860/100000], Loss: 11.6751\n",
      "Epoch [28870/100000], Loss: 11.6718\n",
      "Epoch [28880/100000], Loss: 11.6717\n",
      "Epoch [28890/100000], Loss: 11.6761\n",
      "Epoch [28900/100000], Loss: 11.6721\n",
      "Epoch [28910/100000], Loss: 11.6731\n",
      "Epoch [28920/100000], Loss: 11.6765\n",
      "Epoch [28930/100000], Loss: 11.6744\n",
      "Epoch [28940/100000], Loss: 11.6665\n",
      "Epoch [28950/100000], Loss: 11.6711\n",
      "Epoch [28960/100000], Loss: 11.6666\n",
      "Epoch [28970/100000], Loss: 11.6692\n",
      "Epoch [28980/100000], Loss: 11.6603\n",
      "Epoch [28990/100000], Loss: 11.6615\n",
      "Epoch [29000/100000], Loss: 11.6661\n",
      "Epoch [29010/100000], Loss: 11.6713\n",
      "Epoch [29020/100000], Loss: 11.6732\n",
      "Epoch [29030/100000], Loss: 11.6648\n",
      "Epoch [29040/100000], Loss: 11.6643\n",
      "Epoch [29050/100000], Loss: 11.6613\n",
      "Epoch [29060/100000], Loss: 11.6593\n",
      "Epoch [29070/100000], Loss: 11.6554\n",
      "Epoch [29080/100000], Loss: 11.6599\n",
      "Epoch [29090/100000], Loss: 11.6596\n",
      "Epoch [29100/100000], Loss: 11.6603\n",
      "Epoch [29110/100000], Loss: 11.6534\n",
      "Epoch [29120/100000], Loss: 11.6557\n",
      "Epoch [29130/100000], Loss: 11.6479\n",
      "Epoch [29140/100000], Loss: 11.6439\n",
      "Epoch [29150/100000], Loss: 11.6343\n",
      "Epoch [29160/100000], Loss: 11.6367\n",
      "Epoch [29170/100000], Loss: 11.6360\n",
      "Epoch [29180/100000], Loss: 11.6361\n",
      "Epoch [29190/100000], Loss: 11.6373\n",
      "Epoch [29200/100000], Loss: 11.6356\n",
      "Epoch [29210/100000], Loss: 11.6334\n",
      "Epoch [29220/100000], Loss: 11.6349\n",
      "Epoch [29230/100000], Loss: 11.6246\n",
      "Epoch [29240/100000], Loss: 11.6291\n",
      "Epoch [29250/100000], Loss: 11.6333\n",
      "Epoch [29260/100000], Loss: 11.6293\n",
      "Epoch [29270/100000], Loss: 11.6315\n",
      "Epoch [29280/100000], Loss: 11.6256\n",
      "Epoch [29290/100000], Loss: 11.6211\n",
      "Epoch [29300/100000], Loss: 11.6205\n",
      "Epoch [29310/100000], Loss: 11.6148\n",
      "Epoch [29320/100000], Loss: 11.6165\n",
      "Epoch [29330/100000], Loss: 11.6171\n",
      "Epoch [29340/100000], Loss: 11.6153\n",
      "Epoch [29350/100000], Loss: 11.6190\n",
      "Epoch [29360/100000], Loss: 11.6098\n",
      "Epoch [29370/100000], Loss: 11.6108\n",
      "Epoch [29380/100000], Loss: 11.6132\n",
      "Epoch [29390/100000], Loss: 11.6039\n",
      "Epoch [29400/100000], Loss: 11.6058\n",
      "Epoch [29410/100000], Loss: 11.6042\n",
      "Epoch [29420/100000], Loss: 11.6068\n",
      "Epoch [29430/100000], Loss: 11.6050\n",
      "Epoch [29440/100000], Loss: 11.5995\n",
      "Epoch [29450/100000], Loss: 11.5984\n",
      "Epoch [29460/100000], Loss: 11.5958\n",
      "Epoch [29470/100000], Loss: 11.5912\n",
      "Epoch [29480/100000], Loss: 11.5865\n",
      "Epoch [29490/100000], Loss: 11.5856\n",
      "Epoch [29500/100000], Loss: 11.5842\n",
      "Epoch [29510/100000], Loss: 11.5818\n",
      "Epoch [29520/100000], Loss: 11.5825\n",
      "Epoch [29530/100000], Loss: 11.5894\n",
      "Epoch [29540/100000], Loss: 11.5866\n",
      "Epoch [29550/100000], Loss: 11.5822\n",
      "Epoch [29560/100000], Loss: 11.5765\n",
      "Epoch [29570/100000], Loss: 11.5821\n",
      "Epoch [29580/100000], Loss: 11.5837\n",
      "Epoch [29590/100000], Loss: 11.5770\n",
      "Epoch [29600/100000], Loss: 11.5727\n",
      "Epoch [29610/100000], Loss: 11.5708\n",
      "Epoch [29620/100000], Loss: 11.5732\n",
      "Epoch [29630/100000], Loss: 11.5698\n",
      "Epoch [29640/100000], Loss: 11.5651\n",
      "Epoch [29650/100000], Loss: 11.5604\n",
      "Epoch [29660/100000], Loss: 11.5568\n",
      "Epoch [29670/100000], Loss: 11.5521\n",
      "Epoch [29680/100000], Loss: 11.5514\n",
      "Epoch [29690/100000], Loss: 11.5563\n",
      "Epoch [29700/100000], Loss: 11.5613\n",
      "Epoch [29710/100000], Loss: 11.5538\n",
      "Epoch [29720/100000], Loss: 11.5533\n",
      "Epoch [29730/100000], Loss: 11.5539\n",
      "Epoch [29740/100000], Loss: 11.5547\n",
      "Epoch [29750/100000], Loss: 11.5438\n",
      "Epoch [29760/100000], Loss: 11.5432\n",
      "Epoch [29770/100000], Loss: 11.5451\n",
      "Epoch [29780/100000], Loss: 11.5395\n",
      "Epoch [29790/100000], Loss: 11.5392\n",
      "Epoch [29800/100000], Loss: 11.5413\n",
      "Epoch [29810/100000], Loss: 11.5373\n",
      "Epoch [29820/100000], Loss: 11.5324\n",
      "Epoch [29830/100000], Loss: 11.5335\n",
      "Epoch [29840/100000], Loss: 11.5260\n",
      "Epoch [29850/100000], Loss: 11.5310\n",
      "Epoch [29860/100000], Loss: 11.5348\n",
      "Epoch [29870/100000], Loss: 11.5293\n",
      "Epoch [29880/100000], Loss: 11.5235\n",
      "Epoch [29890/100000], Loss: 11.5174\n",
      "Epoch [29900/100000], Loss: 11.5243\n",
      "Epoch [29910/100000], Loss: 11.5189\n",
      "Epoch [29920/100000], Loss: 11.5189\n",
      "Epoch [29930/100000], Loss: 11.5226\n",
      "Epoch [29940/100000], Loss: 11.5215\n",
      "Epoch [29950/100000], Loss: 11.5178\n",
      "Epoch [29960/100000], Loss: 11.5144\n",
      "Epoch [29970/100000], Loss: 11.5109\n",
      "Epoch [29980/100000], Loss: 11.5082\n",
      "Epoch [29990/100000], Loss: 11.5022\n",
      "Epoch [30000/100000], Loss: 11.5111\n",
      "Epoch [30010/100000], Loss: 11.5083\n",
      "Epoch [30020/100000], Loss: 11.5080\n",
      "Epoch [30030/100000], Loss: 11.5051\n",
      "Epoch [30040/100000], Loss: 11.5064\n",
      "Epoch [30050/100000], Loss: 11.5052\n",
      "Epoch [30060/100000], Loss: 11.5006\n",
      "Epoch [30070/100000], Loss: 11.4955\n",
      "Epoch [30080/100000], Loss: 11.4963\n",
      "Epoch [30090/100000], Loss: 11.4923\n",
      "Epoch [30100/100000], Loss: 11.4968\n",
      "Epoch [30110/100000], Loss: 11.4844\n",
      "Epoch [30120/100000], Loss: 11.4832\n",
      "Epoch [30130/100000], Loss: 11.4827\n",
      "Epoch [30140/100000], Loss: 11.4785\n",
      "Epoch [30150/100000], Loss: 11.4810\n",
      "Epoch [30160/100000], Loss: 11.4800\n",
      "Epoch [30170/100000], Loss: 11.4750\n",
      "Epoch [30180/100000], Loss: 11.4803\n",
      "Epoch [30190/100000], Loss: 11.4744\n",
      "Epoch [30200/100000], Loss: 11.4681\n",
      "Epoch [30210/100000], Loss: 11.4690\n",
      "Epoch [30220/100000], Loss: 11.4654\n",
      "Epoch [30230/100000], Loss: 11.4682\n",
      "Epoch [30240/100000], Loss: 11.4727\n",
      "Epoch [30250/100000], Loss: 11.4732\n",
      "Epoch [30260/100000], Loss: 11.4709\n",
      "Epoch [30270/100000], Loss: 11.4643\n",
      "Epoch [30280/100000], Loss: 11.4556\n",
      "Epoch [30290/100000], Loss: 11.4561\n",
      "Epoch [30300/100000], Loss: 11.4560\n",
      "Epoch [30310/100000], Loss: 11.4533\n",
      "Epoch [30320/100000], Loss: 11.4517\n",
      "Epoch [30330/100000], Loss: 11.4490\n",
      "Epoch [30340/100000], Loss: 11.4412\n",
      "Epoch [30350/100000], Loss: 11.4431\n",
      "Epoch [30360/100000], Loss: 11.4393\n",
      "Epoch [30370/100000], Loss: 11.4340\n",
      "Epoch [30380/100000], Loss: 11.4333\n",
      "Epoch [30390/100000], Loss: 11.4342\n",
      "Epoch [30400/100000], Loss: 11.4322\n",
      "Epoch [30410/100000], Loss: 11.4336\n",
      "Epoch [30420/100000], Loss: 11.4293\n",
      "Epoch [30430/100000], Loss: 11.4335\n",
      "Epoch [30440/100000], Loss: 11.4344\n",
      "Epoch [30450/100000], Loss: 11.4259\n",
      "Epoch [30460/100000], Loss: 11.4241\n",
      "Epoch [30470/100000], Loss: 11.4084\n",
      "Epoch [30480/100000], Loss: 11.4098\n",
      "Epoch [30490/100000], Loss: 11.4049\n",
      "Epoch [30500/100000], Loss: 11.4093\n",
      "Epoch [30510/100000], Loss: 11.4044\n",
      "Epoch [30520/100000], Loss: 11.4023\n",
      "Epoch [30530/100000], Loss: 11.3976\n",
      "Epoch [30540/100000], Loss: 11.3986\n",
      "Epoch [30550/100000], Loss: 11.3960\n",
      "Epoch [30560/100000], Loss: 11.3989\n",
      "Epoch [30570/100000], Loss: 11.3911\n",
      "Epoch [30580/100000], Loss: 11.3894\n",
      "Epoch [30590/100000], Loss: 11.3845\n",
      "Epoch [30600/100000], Loss: 11.3791\n",
      "Epoch [30610/100000], Loss: 11.3822\n",
      "Epoch [30620/100000], Loss: 11.3812\n",
      "Epoch [30630/100000], Loss: 11.3755\n",
      "Epoch [30640/100000], Loss: 11.3818\n",
      "Epoch [30650/100000], Loss: 11.3747\n",
      "Epoch [30660/100000], Loss: 11.3705\n",
      "Epoch [30670/100000], Loss: 11.3696\n",
      "Epoch [30680/100000], Loss: 11.3658\n",
      "Epoch [30690/100000], Loss: 11.3654\n",
      "Epoch [30700/100000], Loss: 11.3582\n",
      "Epoch [30710/100000], Loss: 11.3526\n",
      "Epoch [30720/100000], Loss: 11.3553\n",
      "Epoch [30730/100000], Loss: 11.3461\n",
      "Epoch [30740/100000], Loss: 11.3422\n",
      "Epoch [30750/100000], Loss: 11.3484\n",
      "Epoch [30760/100000], Loss: 11.3394\n",
      "Epoch [30770/100000], Loss: 11.3400\n",
      "Epoch [30780/100000], Loss: 11.3441\n",
      "Epoch [30790/100000], Loss: 11.3414\n",
      "Epoch [30800/100000], Loss: 11.3346\n",
      "Epoch [30810/100000], Loss: 11.3392\n",
      "Epoch [30820/100000], Loss: 11.3240\n",
      "Epoch [30830/100000], Loss: 11.3239\n",
      "Epoch [30840/100000], Loss: 11.3199\n",
      "Epoch [30850/100000], Loss: 11.3209\n",
      "Epoch [30860/100000], Loss: 11.3204\n",
      "Epoch [30870/100000], Loss: 11.3115\n",
      "Epoch [30880/100000], Loss: 11.3198\n",
      "Epoch [30890/100000], Loss: 11.3150\n",
      "Epoch [30900/100000], Loss: 11.3093\n",
      "Epoch [30910/100000], Loss: 11.3071\n",
      "Epoch [30920/100000], Loss: 11.2956\n",
      "Epoch [30930/100000], Loss: 11.2984\n",
      "Epoch [30940/100000], Loss: 11.2949\n",
      "Epoch [30950/100000], Loss: 11.2986\n",
      "Epoch [30960/100000], Loss: 11.2928\n",
      "Epoch [30970/100000], Loss: 11.2904\n",
      "Epoch [30980/100000], Loss: 11.2822\n",
      "Epoch [30990/100000], Loss: 11.2830\n",
      "Epoch [31000/100000], Loss: 11.2787\n",
      "Epoch [31010/100000], Loss: 11.2713\n",
      "Epoch [31020/100000], Loss: 11.2691\n",
      "Epoch [31030/100000], Loss: 11.2715\n",
      "Epoch [31040/100000], Loss: 11.2717\n",
      "Epoch [31050/100000], Loss: 11.2695\n",
      "Epoch [31060/100000], Loss: 11.2710\n",
      "Epoch [31070/100000], Loss: 11.2717\n",
      "Epoch [31080/100000], Loss: 11.2663\n",
      "Epoch [31090/100000], Loss: 11.2577\n",
      "Epoch [31100/100000], Loss: 11.2570\n",
      "Epoch [31110/100000], Loss: 11.2555\n",
      "Epoch [31120/100000], Loss: 11.2562\n",
      "Epoch [31130/100000], Loss: 11.2485\n",
      "Epoch [31140/100000], Loss: 11.2421\n",
      "Epoch [31150/100000], Loss: 11.2484\n",
      "Epoch [31160/100000], Loss: 11.2398\n",
      "Epoch [31170/100000], Loss: 11.2357\n",
      "Epoch [31180/100000], Loss: 11.2249\n",
      "Epoch [31190/100000], Loss: 11.2309\n",
      "Epoch [31200/100000], Loss: 11.2258\n",
      "Epoch [31210/100000], Loss: 11.2217\n",
      "Epoch [31220/100000], Loss: 11.2100\n",
      "Epoch [31230/100000], Loss: 11.2206\n",
      "Epoch [31240/100000], Loss: 11.2172\n",
      "Epoch [31250/100000], Loss: 11.2126\n",
      "Epoch [31260/100000], Loss: 11.2124\n",
      "Epoch [31270/100000], Loss: 11.2120\n",
      "Epoch [31280/100000], Loss: 11.2077\n",
      "Epoch [31290/100000], Loss: 11.2082\n",
      "Epoch [31300/100000], Loss: 11.2069\n",
      "Epoch [31310/100000], Loss: 11.1936\n",
      "Epoch [31320/100000], Loss: 11.1908\n",
      "Epoch [31330/100000], Loss: 11.1882\n",
      "Epoch [31340/100000], Loss: 11.1908\n",
      "Epoch [31350/100000], Loss: 11.1879\n",
      "Epoch [31360/100000], Loss: 11.1753\n",
      "Epoch [31370/100000], Loss: 11.1739\n",
      "Epoch [31380/100000], Loss: 11.1750\n",
      "Epoch [31390/100000], Loss: 11.1778\n",
      "Epoch [31400/100000], Loss: 11.1750\n",
      "Epoch [31410/100000], Loss: 11.1717\n",
      "Epoch [31420/100000], Loss: 11.1687\n",
      "Epoch [31430/100000], Loss: 11.1634\n",
      "Epoch [31440/100000], Loss: 11.1622\n",
      "Epoch [31450/100000], Loss: 11.1525\n",
      "Epoch [31460/100000], Loss: 11.1466\n",
      "Epoch [31470/100000], Loss: 11.1456\n",
      "Epoch [31480/100000], Loss: 11.1403\n",
      "Epoch [31490/100000], Loss: 11.1439\n",
      "Epoch [31500/100000], Loss: 11.1403\n",
      "Epoch [31510/100000], Loss: 11.1301\n",
      "Epoch [31520/100000], Loss: 11.1244\n",
      "Epoch [31530/100000], Loss: 11.1260\n",
      "Epoch [31540/100000], Loss: 11.1176\n",
      "Epoch [31550/100000], Loss: 11.1192\n",
      "Epoch [31560/100000], Loss: 11.1112\n",
      "Epoch [31570/100000], Loss: 11.1170\n",
      "Epoch [31580/100000], Loss: 11.1087\n",
      "Epoch [31590/100000], Loss: 11.1046\n",
      "Epoch [31600/100000], Loss: 11.1037\n",
      "Epoch [31610/100000], Loss: 11.0950\n",
      "Epoch [31620/100000], Loss: 11.0915\n",
      "Epoch [31630/100000], Loss: 11.0914\n",
      "Epoch [31640/100000], Loss: 11.0758\n",
      "Epoch [31650/100000], Loss: 11.0724\n",
      "Epoch [31660/100000], Loss: 11.0686\n",
      "Epoch [31670/100000], Loss: 11.0745\n",
      "Epoch [31680/100000], Loss: 11.0663\n",
      "Epoch [31690/100000], Loss: 11.0669\n",
      "Epoch [31700/100000], Loss: 11.0672\n",
      "Epoch [31710/100000], Loss: 11.0592\n",
      "Epoch [31720/100000], Loss: 11.0558\n",
      "Epoch [31730/100000], Loss: 11.0617\n",
      "Epoch [31740/100000], Loss: 11.0571\n",
      "Epoch [31750/100000], Loss: 11.0492\n",
      "Epoch [31760/100000], Loss: 11.0428\n",
      "Epoch [31770/100000], Loss: 11.0491\n",
      "Epoch [31780/100000], Loss: 11.0470\n",
      "Epoch [31790/100000], Loss: 11.0414\n",
      "Epoch [31800/100000], Loss: 11.0293\n",
      "Epoch [31810/100000], Loss: 11.0257\n",
      "Epoch [31820/100000], Loss: 11.0292\n",
      "Epoch [31830/100000], Loss: 11.0260\n",
      "Epoch [31840/100000], Loss: 11.0132\n",
      "Epoch [31850/100000], Loss: 11.0159\n",
      "Epoch [31860/100000], Loss: 11.0014\n",
      "Epoch [31870/100000], Loss: 11.0018\n",
      "Epoch [31880/100000], Loss: 10.9991\n",
      "Epoch [31890/100000], Loss: 10.9941\n",
      "Epoch [31900/100000], Loss: 10.9925\n",
      "Epoch [31910/100000], Loss: 10.9931\n",
      "Epoch [31920/100000], Loss: 10.9814\n",
      "Epoch [31930/100000], Loss: 10.9826\n",
      "Epoch [31940/100000], Loss: 10.9752\n",
      "Epoch [31950/100000], Loss: 10.9691\n",
      "Epoch [31960/100000], Loss: 10.9582\n",
      "Epoch [31970/100000], Loss: 10.9690\n",
      "Epoch [31980/100000], Loss: 10.9675\n",
      "Epoch [31990/100000], Loss: 10.9619\n",
      "Epoch [32000/100000], Loss: 10.9473\n",
      "Epoch [32010/100000], Loss: 10.9391\n",
      "Epoch [32020/100000], Loss: 10.9445\n",
      "Epoch [32030/100000], Loss: 10.9431\n",
      "Epoch [32040/100000], Loss: 10.9330\n",
      "Epoch [32050/100000], Loss: 10.9309\n",
      "Epoch [32060/100000], Loss: 10.9264\n",
      "Epoch [32070/100000], Loss: 10.9237\n",
      "Epoch [32080/100000], Loss: 10.9164\n",
      "Epoch [32090/100000], Loss: 10.9094\n",
      "Epoch [32100/100000], Loss: 10.9094\n",
      "Epoch [32110/100000], Loss: 10.8937\n",
      "Epoch [32120/100000], Loss: 10.8956\n",
      "Epoch [32130/100000], Loss: 10.9003\n",
      "Epoch [32140/100000], Loss: 10.8948\n",
      "Epoch [32150/100000], Loss: 10.8939\n",
      "Epoch [32160/100000], Loss: 10.8862\n",
      "Epoch [32170/100000], Loss: 10.8806\n",
      "Epoch [32180/100000], Loss: 10.8730\n",
      "Epoch [32190/100000], Loss: 10.8729\n",
      "Epoch [32200/100000], Loss: 10.8595\n",
      "Epoch [32210/100000], Loss: 10.8621\n",
      "Epoch [32220/100000], Loss: 5876034560.0000\n",
      "Epoch [32230/100000], Loss: 1564256256.0000\n",
      "Epoch [32240/100000], Loss: 306009600.0000\n",
      "Epoch [32250/100000], Loss: 73556456.0000\n",
      "Epoch [32260/100000], Loss: 58812396.0000\n",
      "Epoch [32270/100000], Loss: 4916094.0000\n",
      "Epoch [32280/100000], Loss: 7882079.0000\n",
      "Epoch [32290/100000], Loss: 437187.7812\n",
      "Epoch [32300/100000], Loss: 798172.8750\n",
      "Epoch [32310/100000], Loss: 203394.2344\n",
      "Epoch [32320/100000], Loss: 37055.8477\n",
      "Epoch [32330/100000], Loss: 41340.6367\n",
      "Epoch [32340/100000], Loss: 4292.9297\n",
      "Epoch [32350/100000], Loss: 2976.9038\n",
      "Epoch [32360/100000], Loss: 1513.9454\n",
      "Epoch [32370/100000], Loss: 142.7110\n",
      "Epoch [32380/100000], Loss: 172.1568\n",
      "Epoch [32390/100000], Loss: 74.2385\n",
      "Epoch [32400/100000], Loss: 16.2944\n",
      "Epoch [32410/100000], Loss: 15.2342\n",
      "Epoch [32420/100000], Loss: 14.2646\n",
      "Epoch [32430/100000], Loss: 11.5762\n",
      "Epoch [32440/100000], Loss: 11.0465\n",
      "Epoch [32450/100000], Loss: 11.0244\n",
      "Epoch [32460/100000], Loss: 10.9522\n",
      "Epoch [32470/100000], Loss: 10.9396\n",
      "Epoch [32480/100000], Loss: 10.9414\n",
      "Epoch [32490/100000], Loss: 10.9225\n",
      "Epoch [32500/100000], Loss: 10.9243\n",
      "Epoch [32510/100000], Loss: 10.9299\n",
      "Epoch [32520/100000], Loss: 10.9203\n",
      "Epoch [32530/100000], Loss: 10.9217\n",
      "Epoch [32540/100000], Loss: 10.9218\n",
      "Epoch [32550/100000], Loss: 10.9228\n",
      "Epoch [32560/100000], Loss: 10.9196\n",
      "Epoch [32570/100000], Loss: 10.9148\n",
      "Epoch [32580/100000], Loss: 10.9178\n",
      "Epoch [32590/100000], Loss: 10.9202\n",
      "Epoch [32600/100000], Loss: 10.9253\n",
      "Epoch [32610/100000], Loss: 10.9236\n",
      "Epoch [32620/100000], Loss: 10.9174\n",
      "Epoch [32630/100000], Loss: 10.9185\n",
      "Epoch [32640/100000], Loss: 10.9153\n",
      "Epoch [32650/100000], Loss: 10.9179\n",
      "Epoch [32660/100000], Loss: 10.9139\n",
      "Epoch [32670/100000], Loss: 10.9176\n",
      "Epoch [32680/100000], Loss: 10.9159\n",
      "Epoch [32690/100000], Loss: 10.9146\n",
      "Epoch [32700/100000], Loss: 10.9094\n",
      "Epoch [32710/100000], Loss: 10.9057\n",
      "Epoch [32720/100000], Loss: 10.9078\n",
      "Epoch [32730/100000], Loss: 10.9110\n",
      "Epoch [32740/100000], Loss: 10.9137\n",
      "Epoch [32750/100000], Loss: 10.9062\n",
      "Epoch [32760/100000], Loss: 10.9050\n",
      "Epoch [32770/100000], Loss: 10.9058\n",
      "Epoch [32780/100000], Loss: 10.9010\n",
      "Epoch [32790/100000], Loss: 10.8987\n",
      "Epoch [32800/100000], Loss: 10.8996\n",
      "Epoch [32810/100000], Loss: 10.8993\n",
      "Epoch [32820/100000], Loss: 10.9005\n",
      "Epoch [32830/100000], Loss: 10.8951\n",
      "Epoch [32840/100000], Loss: 10.8957\n",
      "Epoch [32850/100000], Loss: 10.8940\n",
      "Epoch [32860/100000], Loss: 10.8930\n",
      "Epoch [32870/100000], Loss: 10.8916\n",
      "Epoch [32880/100000], Loss: 10.8892\n",
      "Epoch [32890/100000], Loss: 10.8863\n",
      "Epoch [32900/100000], Loss: 10.8854\n",
      "Epoch [32910/100000], Loss: 10.8833\n",
      "Epoch [32920/100000], Loss: 10.8849\n",
      "Epoch [32930/100000], Loss: 10.8855\n",
      "Epoch [32940/100000], Loss: 10.8816\n",
      "Epoch [32950/100000], Loss: 10.8811\n",
      "Epoch [32960/100000], Loss: 10.8824\n",
      "Epoch [32970/100000], Loss: 10.8820\n",
      "Epoch [32980/100000], Loss: 10.8800\n",
      "Epoch [32990/100000], Loss: 10.8756\n",
      "Epoch [33000/100000], Loss: 10.8845\n",
      "Epoch [33010/100000], Loss: 10.8817\n",
      "Epoch [33020/100000], Loss: 10.8807\n",
      "Epoch [33030/100000], Loss: 10.8786\n",
      "Epoch [33040/100000], Loss: 10.8771\n",
      "Epoch [33050/100000], Loss: 10.8749\n",
      "Epoch [33060/100000], Loss: 10.8751\n",
      "Epoch [33070/100000], Loss: 10.8747\n",
      "Epoch [33080/100000], Loss: 10.8755\n",
      "Epoch [33090/100000], Loss: 10.8753\n",
      "Epoch [33100/100000], Loss: 10.8789\n",
      "Epoch [33110/100000], Loss: 10.8767\n",
      "Epoch [33120/100000], Loss: 10.8760\n",
      "Epoch [33130/100000], Loss: 10.8778\n",
      "Epoch [33140/100000], Loss: 10.8823\n",
      "Epoch [33150/100000], Loss: 10.8818\n",
      "Epoch [33160/100000], Loss: 10.8740\n",
      "Epoch [33170/100000], Loss: 10.8767\n",
      "Epoch [33180/100000], Loss: 10.8720\n",
      "Epoch [33190/100000], Loss: 10.8698\n",
      "Epoch [33200/100000], Loss: 10.8742\n",
      "Epoch [33210/100000], Loss: 10.8712\n",
      "Epoch [33220/100000], Loss: 10.8660\n",
      "Epoch [33230/100000], Loss: 10.8690\n",
      "Epoch [33240/100000], Loss: 10.8664\n",
      "Epoch [33250/100000], Loss: 10.8680\n",
      "Epoch [33260/100000], Loss: 10.8652\n",
      "Epoch [33270/100000], Loss: 10.8616\n",
      "Epoch [33280/100000], Loss: 10.8629\n",
      "Epoch [33290/100000], Loss: 10.8619\n",
      "Epoch [33300/100000], Loss: 10.8581\n",
      "Epoch [33310/100000], Loss: 10.8580\n",
      "Epoch [33320/100000], Loss: 10.8601\n",
      "Epoch [33330/100000], Loss: 10.8562\n",
      "Epoch [33340/100000], Loss: 10.8585\n",
      "Epoch [33350/100000], Loss: 10.8575\n",
      "Epoch [33360/100000], Loss: 10.8536\n",
      "Epoch [33370/100000], Loss: 10.8575\n",
      "Epoch [33380/100000], Loss: 10.8513\n",
      "Epoch [33390/100000], Loss: 10.8514\n",
      "Epoch [33400/100000], Loss: 10.8517\n",
      "Epoch [33410/100000], Loss: 10.8483\n",
      "Epoch [33420/100000], Loss: 10.8449\n",
      "Epoch [33430/100000], Loss: 10.8442\n",
      "Epoch [33440/100000], Loss: 10.8471\n",
      "Epoch [33450/100000], Loss: 10.8472\n",
      "Epoch [33460/100000], Loss: 10.8430\n",
      "Epoch [33470/100000], Loss: 10.8376\n",
      "Epoch [33480/100000], Loss: 10.8366\n",
      "Epoch [33490/100000], Loss: 10.8330\n",
      "Epoch [33500/100000], Loss: 10.8325\n",
      "Epoch [33510/100000], Loss: 10.8402\n",
      "Epoch [33520/100000], Loss: 10.8336\n",
      "Epoch [33530/100000], Loss: 10.8372\n",
      "Epoch [33540/100000], Loss: 10.8332\n",
      "Epoch [33550/100000], Loss: 10.8291\n",
      "Epoch [33560/100000], Loss: 10.8329\n",
      "Epoch [33570/100000], Loss: 10.8335\n",
      "Epoch [33580/100000], Loss: 10.8288\n",
      "Epoch [33590/100000], Loss: 10.8321\n",
      "Epoch [33600/100000], Loss: 10.8301\n",
      "Epoch [33610/100000], Loss: 10.8296\n",
      "Epoch [33620/100000], Loss: 10.8300\n",
      "Epoch [33630/100000], Loss: 10.8295\n",
      "Epoch [33640/100000], Loss: 10.8321\n",
      "Epoch [33650/100000], Loss: 10.8291\n",
      "Epoch [33660/100000], Loss: 10.8245\n",
      "Epoch [33670/100000], Loss: 10.8282\n",
      "Epoch [33680/100000], Loss: 10.8233\n",
      "Epoch [33690/100000], Loss: 10.8219\n",
      "Epoch [33700/100000], Loss: 10.8250\n",
      "Epoch [33710/100000], Loss: 10.8238\n",
      "Epoch [33720/100000], Loss: 10.8240\n",
      "Epoch [33730/100000], Loss: 10.8195\n",
      "Epoch [33740/100000], Loss: 10.8161\n",
      "Epoch [33750/100000], Loss: 10.8169\n",
      "Epoch [33760/100000], Loss: 10.8147\n",
      "Epoch [33770/100000], Loss: 10.8130\n",
      "Epoch [33780/100000], Loss: 10.8118\n",
      "Epoch [33790/100000], Loss: 10.8113\n",
      "Epoch [33800/100000], Loss: 10.8091\n",
      "Epoch [33810/100000], Loss: 10.8105\n",
      "Epoch [33820/100000], Loss: 10.8075\n",
      "Epoch [33830/100000], Loss: 10.8080\n",
      "Epoch [33840/100000], Loss: 10.8071\n",
      "Epoch [33850/100000], Loss: 10.8043\n",
      "Epoch [33860/100000], Loss: 10.8047\n",
      "Epoch [33870/100000], Loss: 10.8070\n",
      "Epoch [33880/100000], Loss: 10.7993\n",
      "Epoch [33890/100000], Loss: 10.7976\n",
      "Epoch [33900/100000], Loss: 10.7995\n",
      "Epoch [33910/100000], Loss: 10.8032\n",
      "Epoch [33920/100000], Loss: 10.8065\n",
      "Epoch [33930/100000], Loss: 10.7950\n",
      "Epoch [33940/100000], Loss: 10.7958\n",
      "Epoch [33950/100000], Loss: 10.7894\n",
      "Epoch [33960/100000], Loss: 10.7868\n",
      "Epoch [33970/100000], Loss: 10.7838\n",
      "Epoch [33980/100000], Loss: 10.7871\n",
      "Epoch [33990/100000], Loss: 10.7847\n",
      "Epoch [34000/100000], Loss: 10.7870\n",
      "Epoch [34010/100000], Loss: 10.7865\n",
      "Epoch [34020/100000], Loss: 10.7838\n",
      "Epoch [34030/100000], Loss: 10.7820\n",
      "Epoch [34040/100000], Loss: 10.7870\n",
      "Epoch [34050/100000], Loss: 10.7850\n",
      "Epoch [34060/100000], Loss: 10.7858\n",
      "Epoch [34070/100000], Loss: 10.7828\n",
      "Epoch [34080/100000], Loss: 10.7800\n",
      "Epoch [34090/100000], Loss: 10.7753\n",
      "Epoch [34100/100000], Loss: 10.7743\n",
      "Epoch [34110/100000], Loss: 10.7769\n",
      "Epoch [34120/100000], Loss: 10.7765\n",
      "Epoch [34130/100000], Loss: 10.7774\n",
      "Epoch [34140/100000], Loss: 10.7751\n",
      "Epoch [34150/100000], Loss: 10.7724\n",
      "Epoch [34160/100000], Loss: 10.7661\n",
      "Epoch [34170/100000], Loss: 10.7647\n",
      "Epoch [34180/100000], Loss: 10.7683\n",
      "Epoch [34190/100000], Loss: 10.7698\n",
      "Epoch [34200/100000], Loss: 10.7675\n",
      "Epoch [34210/100000], Loss: 10.7677\n",
      "Epoch [34220/100000], Loss: 10.7621\n",
      "Epoch [34230/100000], Loss: 10.7553\n",
      "Epoch [34240/100000], Loss: 10.7554\n",
      "Epoch [34250/100000], Loss: 10.7554\n",
      "Epoch [34260/100000], Loss: 10.7613\n",
      "Epoch [34270/100000], Loss: 10.7566\n",
      "Epoch [34280/100000], Loss: 10.7593\n",
      "Epoch [34290/100000], Loss: 10.7563\n",
      "Epoch [34300/100000], Loss: 10.7551\n",
      "Epoch [34310/100000], Loss: 10.7591\n",
      "Epoch [34320/100000], Loss: 10.7541\n",
      "Epoch [34330/100000], Loss: 10.7578\n",
      "Epoch [34340/100000], Loss: 10.7566\n",
      "Epoch [34350/100000], Loss: 10.7540\n",
      "Epoch [34360/100000], Loss: 10.7515\n",
      "Epoch [34370/100000], Loss: 10.7496\n",
      "Epoch [34380/100000], Loss: 10.7473\n",
      "Epoch [34390/100000], Loss: 10.7425\n",
      "Epoch [34400/100000], Loss: 10.7439\n",
      "Epoch [34410/100000], Loss: 10.7467\n",
      "Epoch [34420/100000], Loss: 10.7471\n",
      "Epoch [34430/100000], Loss: 10.7426\n",
      "Epoch [34440/100000], Loss: 10.7321\n",
      "Epoch [34450/100000], Loss: 10.7364\n",
      "Epoch [34460/100000], Loss: 10.7354\n",
      "Epoch [34470/100000], Loss: 10.7398\n",
      "Epoch [34480/100000], Loss: 10.7356\n",
      "Epoch [34490/100000], Loss: 10.7291\n",
      "Epoch [34500/100000], Loss: 10.7223\n",
      "Epoch [34510/100000], Loss: 10.7267\n",
      "Epoch [34520/100000], Loss: 10.7255\n",
      "Epoch [34530/100000], Loss: 10.7225\n",
      "Epoch [34540/100000], Loss: 10.7241\n",
      "Epoch [34550/100000], Loss: 10.7201\n",
      "Epoch [34560/100000], Loss: 10.7219\n",
      "Epoch [34570/100000], Loss: 10.7226\n",
      "Epoch [34580/100000], Loss: 10.7207\n",
      "Epoch [34590/100000], Loss: 10.7184\n",
      "Epoch [34600/100000], Loss: 10.7146\n",
      "Epoch [34610/100000], Loss: 10.7156\n",
      "Epoch [34620/100000], Loss: 10.7152\n",
      "Epoch [34630/100000], Loss: 10.7165\n",
      "Epoch [34640/100000], Loss: 10.7140\n",
      "Epoch [34650/100000], Loss: 10.7106\n",
      "Epoch [34660/100000], Loss: 10.7059\n",
      "Epoch [34670/100000], Loss: 10.7078\n",
      "Epoch [34680/100000], Loss: 10.7082\n",
      "Epoch [34690/100000], Loss: 10.6959\n",
      "Epoch [34700/100000], Loss: 10.7030\n",
      "Epoch [34710/100000], Loss: 10.6974\n",
      "Epoch [34720/100000], Loss: 10.6960\n",
      "Epoch [34730/100000], Loss: 10.6992\n",
      "Epoch [34740/100000], Loss: 10.6910\n",
      "Epoch [34750/100000], Loss: 10.6916\n",
      "Epoch [34760/100000], Loss: 10.6963\n",
      "Epoch [34770/100000], Loss: 10.6891\n",
      "Epoch [34780/100000], Loss: 10.6896\n",
      "Epoch [34790/100000], Loss: 10.6853\n",
      "Epoch [34800/100000], Loss: 10.6865\n",
      "Epoch [34810/100000], Loss: 10.6839\n",
      "Epoch [34820/100000], Loss: 10.6856\n",
      "Epoch [34830/100000], Loss: 10.6825\n",
      "Epoch [34840/100000], Loss: 10.6777\n",
      "Epoch [34850/100000], Loss: 10.6854\n",
      "Epoch [34860/100000], Loss: 10.6787\n",
      "Epoch [34870/100000], Loss: 10.6799\n",
      "Epoch [34880/100000], Loss: 10.6733\n",
      "Epoch [34890/100000], Loss: 10.6794\n",
      "Epoch [34900/100000], Loss: 10.6820\n",
      "Epoch [34910/100000], Loss: 10.6783\n",
      "Epoch [34920/100000], Loss: 10.6796\n",
      "Epoch [34930/100000], Loss: 10.6692\n",
      "Epoch [34940/100000], Loss: 10.6645\n",
      "Epoch [34950/100000], Loss: 10.6742\n",
      "Epoch [34960/100000], Loss: 10.6728\n",
      "Epoch [34970/100000], Loss: 10.6653\n",
      "Epoch [34980/100000], Loss: 10.6604\n",
      "Epoch [34990/100000], Loss: 10.6610\n",
      "Epoch [35000/100000], Loss: 10.6570\n",
      "Epoch [35010/100000], Loss: 10.6570\n",
      "Epoch [35020/100000], Loss: 10.6554\n",
      "Epoch [35030/100000], Loss: 10.6532\n",
      "Epoch [35040/100000], Loss: 10.6521\n",
      "Epoch [35050/100000], Loss: 10.6554\n",
      "Epoch [35060/100000], Loss: 10.6484\n",
      "Epoch [35070/100000], Loss: 10.6468\n",
      "Epoch [35080/100000], Loss: 10.6469\n",
      "Epoch [35090/100000], Loss: 10.6448\n",
      "Epoch [35100/100000], Loss: 10.6446\n",
      "Epoch [35110/100000], Loss: 10.6440\n",
      "Epoch [35120/100000], Loss: 10.6409\n",
      "Epoch [35130/100000], Loss: 10.6373\n",
      "Epoch [35140/100000], Loss: 10.6320\n",
      "Epoch [35150/100000], Loss: 10.6331\n",
      "Epoch [35160/100000], Loss: 10.6339\n",
      "Epoch [35170/100000], Loss: 10.6321\n",
      "Epoch [35180/100000], Loss: 10.6331\n",
      "Epoch [35190/100000], Loss: 10.6267\n",
      "Epoch [35200/100000], Loss: 10.6227\n",
      "Epoch [35210/100000], Loss: 10.6248\n",
      "Epoch [35220/100000], Loss: 10.6181\n",
      "Epoch [35230/100000], Loss: 10.6268\n",
      "Epoch [35240/100000], Loss: 10.6202\n",
      "Epoch [35250/100000], Loss: 10.6138\n",
      "Epoch [35260/100000], Loss: 10.6178\n",
      "Epoch [35270/100000], Loss: 10.6104\n",
      "Epoch [35280/100000], Loss: 10.6072\n",
      "Epoch [35290/100000], Loss: 10.6088\n",
      "Epoch [35300/100000], Loss: 10.6121\n",
      "Epoch [35310/100000], Loss: 10.6152\n",
      "Epoch [35320/100000], Loss: 10.6192\n",
      "Epoch [35330/100000], Loss: 10.6133\n",
      "Epoch [35340/100000], Loss: 10.6041\n",
      "Epoch [35350/100000], Loss: 10.6053\n",
      "Epoch [35360/100000], Loss: 10.6107\n",
      "Epoch [35370/100000], Loss: 10.6006\n",
      "Epoch [35380/100000], Loss: 10.5950\n",
      "Epoch [35390/100000], Loss: 10.5969\n",
      "Epoch [35400/100000], Loss: 10.5948\n",
      "Epoch [35410/100000], Loss: 10.5966\n",
      "Epoch [35420/100000], Loss: 10.5865\n",
      "Epoch [35430/100000], Loss: 10.5901\n",
      "Epoch [35440/100000], Loss: 10.5929\n",
      "Epoch [35450/100000], Loss: 10.5842\n",
      "Epoch [35460/100000], Loss: 10.5869\n",
      "Epoch [35470/100000], Loss: 10.5853\n",
      "Epoch [35480/100000], Loss: 10.5840\n",
      "Epoch [35490/100000], Loss: 10.5812\n",
      "Epoch [35500/100000], Loss: 10.5807\n",
      "Epoch [35510/100000], Loss: 10.5776\n",
      "Epoch [35520/100000], Loss: 10.5746\n",
      "Epoch [35530/100000], Loss: 10.5693\n",
      "Epoch [35540/100000], Loss: 10.5673\n",
      "Epoch [35550/100000], Loss: 10.5626\n",
      "Epoch [35560/100000], Loss: 10.5602\n",
      "Epoch [35570/100000], Loss: 10.5538\n",
      "Epoch [35580/100000], Loss: 10.5557\n",
      "Epoch [35590/100000], Loss: 10.5515\n",
      "Epoch [35600/100000], Loss: 10.5560\n",
      "Epoch [35610/100000], Loss: 10.5478\n",
      "Epoch [35620/100000], Loss: 10.5454\n",
      "Epoch [35630/100000], Loss: 10.5466\n",
      "Epoch [35640/100000], Loss: 10.5477\n",
      "Epoch [35650/100000], Loss: 10.5388\n",
      "Epoch [35660/100000], Loss: 10.5374\n",
      "Epoch [35670/100000], Loss: 10.5291\n",
      "Epoch [35680/100000], Loss: 10.5355\n",
      "Epoch [35690/100000], Loss: 10.5385\n",
      "Epoch [35700/100000], Loss: 10.5265\n",
      "Epoch [35710/100000], Loss: 10.5267\n",
      "Epoch [35720/100000], Loss: 10.5265\n",
      "Epoch [35730/100000], Loss: 10.5172\n",
      "Epoch [35740/100000], Loss: 10.5193\n",
      "Epoch [35750/100000], Loss: 10.5181\n",
      "Epoch [35760/100000], Loss: 10.5166\n",
      "Epoch [35770/100000], Loss: 10.5123\n",
      "Epoch [35780/100000], Loss: 10.5166\n",
      "Epoch [35790/100000], Loss: 10.5067\n",
      "Epoch [35800/100000], Loss: 10.5082\n",
      "Epoch [35810/100000], Loss: 10.5037\n",
      "Epoch [35820/100000], Loss: 10.4963\n",
      "Epoch [35830/100000], Loss: 10.4997\n",
      "Epoch [35840/100000], Loss: 10.5036\n",
      "Epoch [35850/100000], Loss: 10.4968\n",
      "Epoch [35860/100000], Loss: 10.4878\n",
      "Epoch [35870/100000], Loss: 10.4826\n",
      "Epoch [35880/100000], Loss: 10.4928\n",
      "Epoch [35890/100000], Loss: 10.4853\n",
      "Epoch [35900/100000], Loss: 10.4814\n",
      "Epoch [35910/100000], Loss: 10.4791\n",
      "Epoch [35920/100000], Loss: 10.4811\n",
      "Epoch [35930/100000], Loss: 10.4776\n",
      "Epoch [35940/100000], Loss: 10.4794\n",
      "Epoch [35950/100000], Loss: 10.4738\n",
      "Epoch [35960/100000], Loss: 10.4668\n",
      "Epoch [35970/100000], Loss: 10.4594\n",
      "Epoch [35980/100000], Loss: 10.4607\n",
      "Epoch [35990/100000], Loss: 10.4549\n",
      "Epoch [36000/100000], Loss: 10.4490\n",
      "Epoch [36010/100000], Loss: 10.4549\n",
      "Epoch [36020/100000], Loss: 10.4567\n",
      "Epoch [36030/100000], Loss: 10.4542\n",
      "Epoch [36040/100000], Loss: 10.4504\n",
      "Epoch [36050/100000], Loss: 10.4471\n",
      "Epoch [36060/100000], Loss: 10.4469\n",
      "Epoch [36070/100000], Loss: 10.4416\n",
      "Epoch [36080/100000], Loss: 10.4362\n",
      "Epoch [36090/100000], Loss: 10.4378\n",
      "Epoch [36100/100000], Loss: 10.4348\n",
      "Epoch [36110/100000], Loss: 10.4313\n",
      "Epoch [36120/100000], Loss: 10.4257\n",
      "Epoch [36130/100000], Loss: 10.4226\n",
      "Epoch [36140/100000], Loss: 10.4293\n",
      "Epoch [36150/100000], Loss: 10.4218\n",
      "Epoch [36160/100000], Loss: 10.4198\n",
      "Epoch [36170/100000], Loss: 10.4271\n",
      "Epoch [36180/100000], Loss: 10.4208\n",
      "Epoch [36190/100000], Loss: 10.4181\n",
      "Epoch [36200/100000], Loss: 10.4112\n",
      "Epoch [36210/100000], Loss: 10.3991\n",
      "Epoch [36220/100000], Loss: 10.4070\n",
      "Epoch [36230/100000], Loss: 10.4012\n",
      "Epoch [36240/100000], Loss: 10.3988\n",
      "Epoch [36250/100000], Loss: 10.4023\n",
      "Epoch [36260/100000], Loss: 10.3968\n",
      "Epoch [36270/100000], Loss: 10.3935\n",
      "Epoch [36280/100000], Loss: 10.3944\n",
      "Epoch [36290/100000], Loss: 10.3832\n",
      "Epoch [36300/100000], Loss: 10.3802\n",
      "Epoch [36310/100000], Loss: 10.3801\n",
      "Epoch [36320/100000], Loss: 10.3858\n",
      "Epoch [36330/100000], Loss: 10.3817\n",
      "Epoch [36340/100000], Loss: 10.3786\n",
      "Epoch [36350/100000], Loss: 10.3816\n",
      "Epoch [36360/100000], Loss: 10.3777\n",
      "Epoch [36370/100000], Loss: 10.3786\n",
      "Epoch [36380/100000], Loss: 10.3720\n",
      "Epoch [36390/100000], Loss: 10.3659\n",
      "Epoch [36400/100000], Loss: 10.3623\n",
      "Epoch [36410/100000], Loss: 10.3578\n",
      "Epoch [36420/100000], Loss: 10.3488\n",
      "Epoch [36430/100000], Loss: 10.3514\n",
      "Epoch [36440/100000], Loss: 10.3472\n",
      "Epoch [36450/100000], Loss: 10.3514\n",
      "Epoch [36460/100000], Loss: 10.3489\n",
      "Epoch [36470/100000], Loss: 10.3390\n",
      "Epoch [36480/100000], Loss: 10.3362\n",
      "Epoch [36490/100000], Loss: 10.3353\n",
      "Epoch [36500/100000], Loss: 10.3284\n",
      "Epoch [36510/100000], Loss: 10.3296\n",
      "Epoch [36520/100000], Loss: 10.3220\n",
      "Epoch [36530/100000], Loss: 10.3309\n",
      "Epoch [36540/100000], Loss: 10.3248\n",
      "Epoch [36550/100000], Loss: 10.3262\n",
      "Epoch [36560/100000], Loss: 10.3169\n",
      "Epoch [36570/100000], Loss: 10.3157\n",
      "Epoch [36580/100000], Loss: 10.3059\n",
      "Epoch [36590/100000], Loss: 10.3074\n",
      "Epoch [36600/100000], Loss: 10.3118\n",
      "Epoch [36610/100000], Loss: 10.3042\n",
      "Epoch [36620/100000], Loss: 10.3059\n",
      "Epoch [36630/100000], Loss: 10.2996\n",
      "Epoch [36640/100000], Loss: 10.2959\n",
      "Epoch [36650/100000], Loss: 10.2911\n",
      "Epoch [36660/100000], Loss: 10.2870\n",
      "Epoch [36670/100000], Loss: 10.2925\n",
      "Epoch [36680/100000], Loss: 10.2906\n",
      "Epoch [36690/100000], Loss: 10.2859\n",
      "Epoch [36700/100000], Loss: 10.2778\n",
      "Epoch [36710/100000], Loss: 10.2788\n",
      "Epoch [36720/100000], Loss: 10.2762\n",
      "Epoch [36730/100000], Loss: 10.2668\n",
      "Epoch [36740/100000], Loss: 10.2700\n",
      "Epoch [36750/100000], Loss: 10.2647\n",
      "Epoch [36760/100000], Loss: 10.2594\n",
      "Epoch [36770/100000], Loss: 10.2550\n",
      "Epoch [36780/100000], Loss: 10.2492\n",
      "Epoch [36790/100000], Loss: 10.2520\n",
      "Epoch [36800/100000], Loss: 10.2458\n",
      "Epoch [36810/100000], Loss: 10.2370\n",
      "Epoch [36820/100000], Loss: 10.2385\n",
      "Epoch [36830/100000], Loss: 10.2442\n",
      "Epoch [36840/100000], Loss: 10.2380\n",
      "Epoch [36850/100000], Loss: 10.2380\n",
      "Epoch [36860/100000], Loss: 10.2313\n",
      "Epoch [36870/100000], Loss: 10.2312\n",
      "Epoch [36880/100000], Loss: 10.2286\n",
      "Epoch [36890/100000], Loss: 10.2189\n",
      "Epoch [36900/100000], Loss: 10.2131\n",
      "Epoch [36910/100000], Loss: 10.2131\n",
      "Epoch [36920/100000], Loss: 10.2067\n",
      "Epoch [36930/100000], Loss: 10.2108\n",
      "Epoch [36940/100000], Loss: 10.1990\n",
      "Epoch [36950/100000], Loss: 10.1946\n",
      "Epoch [36960/100000], Loss: 10.1932\n",
      "Epoch [36970/100000], Loss: 10.1846\n",
      "Epoch [36980/100000], Loss: 10.1802\n",
      "Epoch [36990/100000], Loss: 10.1836\n",
      "Epoch [37000/100000], Loss: 10.1807\n",
      "Epoch [37010/100000], Loss: 10.1816\n",
      "Epoch [37020/100000], Loss: 10.1753\n",
      "Epoch [37030/100000], Loss: 10.1792\n",
      "Epoch [37040/100000], Loss: 10.1718\n",
      "Epoch [37050/100000], Loss: 10.1695\n",
      "Epoch [37060/100000], Loss: 10.1597\n",
      "Epoch [37070/100000], Loss: 10.1654\n",
      "Epoch [37080/100000], Loss: 10.1593\n",
      "Epoch [37090/100000], Loss: 10.1503\n",
      "Epoch [37100/100000], Loss: 10.1531\n",
      "Epoch [37110/100000], Loss: 10.1504\n",
      "Epoch [37120/100000], Loss: 10.1511\n",
      "Epoch [37130/100000], Loss: 10.1384\n",
      "Epoch [37140/100000], Loss: 10.1337\n",
      "Epoch [37150/100000], Loss: 10.1301\n",
      "Epoch [37160/100000], Loss: 10.1298\n",
      "Epoch [37170/100000], Loss: 10.1219\n",
      "Epoch [37180/100000], Loss: 10.1176\n",
      "Epoch [37190/100000], Loss: 10.1124\n",
      "Epoch [37200/100000], Loss: 10.1106\n",
      "Epoch [37210/100000], Loss: 10.1094\n",
      "Epoch [37220/100000], Loss: 10.1086\n",
      "Epoch [37230/100000], Loss: 10.1048\n",
      "Epoch [37240/100000], Loss: 10.1039\n",
      "Epoch [37250/100000], Loss: 10.0987\n",
      "Epoch [37260/100000], Loss: 10.0938\n",
      "Epoch [37270/100000], Loss: 10.0816\n",
      "Epoch [37280/100000], Loss: 10.0821\n",
      "Epoch [37290/100000], Loss: 10.0828\n",
      "Epoch [37300/100000], Loss: 10.0753\n",
      "Epoch [37310/100000], Loss: 10.0766\n",
      "Epoch [37320/100000], Loss: 10.0736\n",
      "Epoch [37330/100000], Loss: 10.0689\n",
      "Epoch [37340/100000], Loss: 10.0660\n",
      "Epoch [37350/100000], Loss: 10.0561\n",
      "Epoch [37360/100000], Loss: 10.0512\n",
      "Epoch [37370/100000], Loss: 10.0472\n",
      "Epoch [37380/100000], Loss: 10.0510\n",
      "Epoch [37390/100000], Loss: 10.0393\n",
      "Epoch [37400/100000], Loss: 10.0315\n",
      "Epoch [37410/100000], Loss: 10.0235\n",
      "Epoch [37420/100000], Loss: 10.0288\n",
      "Epoch [37430/100000], Loss: 10.0298\n",
      "Epoch [37440/100000], Loss: 10.0327\n",
      "Epoch [37450/100000], Loss: 10.0192\n",
      "Epoch [37460/100000], Loss: 10.0151\n",
      "Epoch [37470/100000], Loss: 10.0140\n",
      "Epoch [37480/100000], Loss: 10.0102\n",
      "Epoch [37490/100000], Loss: 10.0107\n",
      "Model saved at epoch 37493 with loss: 9.9994\n",
      "Model saved at epoch 37494 with loss: 9.9982\n",
      "Model saved at epoch 37499 with loss: 9.9979\n",
      "Epoch [37500/100000], Loss: 9.9984\n",
      "Model saved at epoch 37502 with loss: 9.9958\n",
      "Model saved at epoch 37504 with loss: 9.9953\n",
      "Epoch [37510/100000], Loss: 9.9991\n",
      "Epoch [37520/100000], Loss: 10.0013\n",
      "Model saved at epoch 37523 with loss: 9.9920\n",
      "Epoch [37530/100000], Loss: 9.9953\n",
      "Model saved at epoch 37531 with loss: 9.9900\n",
      "Epoch [37540/100000], Loss: 9.9943\n",
      "Model saved at epoch 37544 with loss: 9.9861\n",
      "Model saved at epoch 37550 with loss: 9.9859\n",
      "Epoch [37550/100000], Loss: 9.9859\n",
      "Model saved at epoch 37551 with loss: 9.9851\n",
      "Epoch [37560/100000], Loss: 9.9881\n",
      "Model saved at epoch 37562 with loss: 9.9795\n",
      "Model saved at epoch 37564 with loss: 9.9753\n",
      "Epoch [37570/100000], Loss: 9.9804\n",
      "Model saved at epoch 37573 with loss: 9.9725\n",
      "Model saved at epoch 37574 with loss: 9.9707\n",
      "Model saved at epoch 37578 with loss: 9.9692\n",
      "Model saved at epoch 37579 with loss: 9.9675\n",
      "Epoch [37580/100000], Loss: 9.9741\n",
      "Model saved at epoch 37589 with loss: 9.9664\n",
      "Model saved at epoch 37590 with loss: 9.9627\n",
      "Epoch [37590/100000], Loss: 9.9627\n",
      "Model saved at epoch 37592 with loss: 9.9593\n",
      "Epoch [37600/100000], Loss: 9.9699\n",
      "Model saved at epoch 37606 with loss: 9.9561\n",
      "Epoch [37610/100000], Loss: 9.9566\n",
      "Model saved at epoch 37614 with loss: 9.9534\n",
      "Model saved at epoch 37617 with loss: 9.9488\n",
      "Epoch [37620/100000], Loss: 9.9535\n",
      "Epoch [37630/100000], Loss: 9.9584\n",
      "Epoch [37640/100000], Loss: 9.9555\n",
      "Model saved at epoch 37642 with loss: 9.9473\n",
      "Epoch [37650/100000], Loss: 9.9524\n",
      "Model saved at epoch 37652 with loss: 9.9461\n",
      "Model saved at epoch 37654 with loss: 9.9460\n",
      "Model saved at epoch 37655 with loss: 9.9457\n",
      "Model saved at epoch 37656 with loss: 9.9455\n",
      "Epoch [37660/100000], Loss: 9.9494\n",
      "Model saved at epoch 37664 with loss: 9.9446\n",
      "Model saved at epoch 37665 with loss: 9.9426\n",
      "Epoch [37670/100000], Loss: 9.9430\n",
      "Model saved at epoch 37673 with loss: 9.9385\n",
      "Model saved at epoch 37674 with loss: 9.9368\n",
      "Model saved at epoch 37675 with loss: 9.9338\n",
      "Model saved at epoch 37676 with loss: 9.9322\n",
      "Epoch [37680/100000], Loss: 9.9360\n",
      "Model saved at epoch 37682 with loss: 9.9306\n",
      "Model saved at epoch 37683 with loss: 9.9294\n",
      "Model saved at epoch 37685 with loss: 9.9279\n",
      "Model saved at epoch 37686 with loss: 9.9260\n",
      "Model saved at epoch 37688 with loss: 9.9218\n",
      "Model saved at epoch 37689 with loss: 9.9207\n",
      "Model saved at epoch 37690 with loss: 9.9195\n",
      "Epoch [37690/100000], Loss: 9.9195\n",
      "Model saved at epoch 37691 with loss: 9.9185\n",
      "Model saved at epoch 37692 with loss: 9.9165\n",
      "Model saved at epoch 37693 with loss: 9.9161\n",
      "Epoch [37700/100000], Loss: 9.9189\n",
      "Model saved at epoch 37708 with loss: 9.9142\n",
      "Epoch [37710/100000], Loss: 9.9186\n",
      "Model saved at epoch 37716 with loss: 9.9120\n",
      "Model saved at epoch 37717 with loss: 9.9119\n",
      "Model saved at epoch 37718 with loss: 9.9083\n",
      "Epoch [37720/100000], Loss: 9.9161\n",
      "Model saved at epoch 37722 with loss: 9.9066\n",
      "Model saved at epoch 37725 with loss: 9.9063\n",
      "Model saved at epoch 37726 with loss: 9.9026\n",
      "Model saved at epoch 37727 with loss: 9.9016\n",
      "Epoch [37730/100000], Loss: 9.9079\n",
      "Model saved at epoch 37733 with loss: 9.9008\n",
      "Model saved at epoch 37737 with loss: 9.8994\n",
      "Model saved at epoch 37738 with loss: 9.8992\n",
      "Model saved at epoch 37739 with loss: 9.8935\n",
      "Epoch [37740/100000], Loss: 9.8949\n",
      "Model saved at epoch 37741 with loss: 9.8904\n",
      "Epoch [37750/100000], Loss: 9.8909\n",
      "Model saved at epoch 37755 with loss: 9.8901\n",
      "Model saved at epoch 37759 with loss: 9.8877\n",
      "Model saved at epoch 37760 with loss: 9.8866\n",
      "Epoch [37760/100000], Loss: 9.8866\n",
      "Model saved at epoch 37762 with loss: 9.8864\n",
      "Epoch [37770/100000], Loss: 9.8886\n",
      "Model saved at epoch 37775 with loss: 9.8857\n",
      "Model saved at epoch 37776 with loss: 9.8856\n",
      "Model saved at epoch 37780 with loss: 9.8827\n",
      "Epoch [37780/100000], Loss: 9.8827\n",
      "Model saved at epoch 37783 with loss: 9.8786\n",
      "Model saved at epoch 37784 with loss: 9.8786\n",
      "Model saved at epoch 37785 with loss: 9.8763\n",
      "Model saved at epoch 37786 with loss: 9.8756\n",
      "Model saved at epoch 37787 with loss: 9.8748\n",
      "Epoch [37790/100000], Loss: 9.8791\n",
      "Model saved at epoch 37793 with loss: 9.8743\n",
      "Epoch [37800/100000], Loss: 9.8774\n",
      "Model saved at epoch 37805 with loss: 9.8739\n",
      "Model saved at epoch 37810 with loss: 9.8717\n",
      "Epoch [37810/100000], Loss: 9.8717\n",
      "Model saved at epoch 37812 with loss: 9.8705\n",
      "Model saved at epoch 37815 with loss: 9.8696\n",
      "Model saved at epoch 37817 with loss: 9.8691\n",
      "Model saved at epoch 37819 with loss: 9.8682\n",
      "Epoch [37820/100000], Loss: 9.8707\n",
      "Model saved at epoch 37822 with loss: 9.8663\n",
      "Model saved at epoch 37823 with loss: 9.8639\n",
      "Model saved at epoch 37824 with loss: 9.8618\n",
      "Model saved at epoch 37826 with loss: 9.8614\n",
      "Model saved at epoch 37827 with loss: 9.8583\n",
      "Model saved at epoch 37828 with loss: 9.8563\n",
      "Model saved at epoch 37829 with loss: 9.8514\n",
      "Model saved at epoch 37830 with loss: 9.8484\n",
      "Epoch [37830/100000], Loss: 9.8484\n",
      "Epoch [37840/100000], Loss: 9.8597\n",
      "Epoch [37850/100000], Loss: 9.8546\n",
      "Model saved at epoch 37852 with loss: 9.8471\n",
      "Model saved at epoch 37853 with loss: 9.8470\n",
      "Model saved at epoch 37856 with loss: 9.8469\n",
      "Model saved at epoch 37857 with loss: 9.8443\n",
      "Model saved at epoch 37858 with loss: 9.8428\n",
      "Epoch [37860/100000], Loss: 9.8498\n",
      "Model saved at epoch 37869 with loss: 9.8412\n",
      "Model saved at epoch 37870 with loss: 9.8402\n",
      "Epoch [37870/100000], Loss: 9.8402\n",
      "Model saved at epoch 37871 with loss: 9.8370\n",
      "Epoch [37880/100000], Loss: 9.8371\n",
      "Model saved at epoch 37884 with loss: 9.8351\n",
      "Model saved at epoch 37888 with loss: 9.8323\n",
      "Epoch [37890/100000], Loss: 9.8375\n",
      "Model saved at epoch 37893 with loss: 9.8309\n",
      "Model saved at epoch 37899 with loss: 9.8303\n",
      "Epoch [37900/100000], Loss: 9.8348\n",
      "Model saved at epoch 37902 with loss: 9.8285\n",
      "Model saved at epoch 37904 with loss: 9.8277\n",
      "Model saved at epoch 37905 with loss: 9.8205\n",
      "Epoch [37910/100000], Loss: 9.8259\n",
      "Epoch [37920/100000], Loss: 9.8249\n",
      "Model saved at epoch 37925 with loss: 9.8200\n",
      "Epoch [37930/100000], Loss: 9.8248\n",
      "Model saved at epoch 37932 with loss: 9.8192\n",
      "Model saved at epoch 37937 with loss: 9.8180\n",
      "Epoch [37940/100000], Loss: 9.8234\n",
      "Model saved at epoch 37950 with loss: 9.8179\n",
      "Epoch [37950/100000], Loss: 9.8179\n",
      "Model saved at epoch 37951 with loss: 9.8166\n",
      "Model saved at epoch 37952 with loss: 9.8130\n",
      "Model saved at epoch 37954 with loss: 9.8125\n",
      "Model saved at epoch 37955 with loss: 9.8100\n",
      "Model saved at epoch 37958 with loss: 9.8070\n",
      "Epoch [37960/100000], Loss: 9.8102\n",
      "Model saved at epoch 37962 with loss: 9.8064\n",
      "Model saved at epoch 37963 with loss: 9.8039\n",
      "Model saved at epoch 37966 with loss: 9.7952\n",
      "Epoch [37970/100000], Loss: 9.8001\n",
      "Model saved at epoch 37972 with loss: 9.7933\n",
      "Epoch [37980/100000], Loss: 9.7956\n",
      "Model saved at epoch 37987 with loss: 9.7919\n",
      "Model saved at epoch 37988 with loss: 9.7905\n",
      "Model saved at epoch 37990 with loss: 9.7901\n",
      "Epoch [37990/100000], Loss: 9.7901\n",
      "Model saved at epoch 37993 with loss: 9.7894\n",
      "Model saved at epoch 37997 with loss: 9.7890\n",
      "Epoch [38000/100000], Loss: 9.7902\n",
      "Model saved at epoch 38002 with loss: 9.7886\n",
      "Model saved at epoch 38006 with loss: 9.7877\n",
      "Model saved at epoch 38007 with loss: 9.7841\n",
      "Model saved at epoch 38008 with loss: 9.7822\n",
      "Epoch [38010/100000], Loss: 9.7823\n",
      "Model saved at epoch 38011 with loss: 9.7810\n",
      "Model saved at epoch 38018 with loss: 9.7782\n",
      "Epoch [38020/100000], Loss: 9.7831\n",
      "Model saved at epoch 38025 with loss: 9.7773\n",
      "Model saved at epoch 38026 with loss: 9.7723\n",
      "Epoch [38030/100000], Loss: 9.7731\n",
      "Model saved at epoch 38032 with loss: 9.7682\n",
      "Model saved at epoch 38033 with loss: 9.7617\n",
      "Epoch [38040/100000], Loss: 9.7709\n",
      "Epoch [38050/100000], Loss: 9.7663\n",
      "Model saved at epoch 38054 with loss: 9.7606\n",
      "Epoch [38060/100000], Loss: 9.7638\n",
      "Model saved at epoch 38061 with loss: 9.7594\n",
      "Model saved at epoch 38062 with loss: 9.7579\n",
      "Model saved at epoch 38068 with loss: 9.7553\n",
      "Epoch [38070/100000], Loss: 9.7561\n",
      "Model saved at epoch 38071 with loss: 9.7539\n",
      "Model saved at epoch 38074 with loss: 9.7519\n",
      "Model saved at epoch 38077 with loss: 9.7485\n",
      "Epoch [38080/100000], Loss: 9.7522\n",
      "Model saved at epoch 38082 with loss: 9.7475\n",
      "Model saved at epoch 38085 with loss: 9.7428\n",
      "Model saved at epoch 38086 with loss: 9.7410\n",
      "Model saved at epoch 38087 with loss: 9.7377\n",
      "Epoch [38090/100000], Loss: 9.7541\n",
      "Epoch [38100/100000], Loss: 9.7408\n",
      "Model saved at epoch 38101 with loss: 9.7370\n",
      "Model saved at epoch 38110 with loss: 9.7347\n",
      "Epoch [38110/100000], Loss: 9.7347\n",
      "Model saved at epoch 38111 with loss: 9.7340\n",
      "Model saved at epoch 38113 with loss: 9.7296\n",
      "Model saved at epoch 38114 with loss: 9.7294\n",
      "Epoch [38120/100000], Loss: 9.7306\n",
      "Epoch [38130/100000], Loss: 9.7296\n",
      "Model saved at epoch 38132 with loss: 9.7255\n",
      "Model saved at epoch 38138 with loss: 9.7226\n",
      "Epoch [38140/100000], Loss: 9.7265\n",
      "Model saved at epoch 38146 with loss: 9.7226\n",
      "Model saved at epoch 38147 with loss: 9.7170\n",
      "Model saved at epoch 38149 with loss: 9.7154\n",
      "Epoch [38150/100000], Loss: 9.7181\n",
      "Model saved at epoch 38151 with loss: 9.7103\n",
      "Model saved at epoch 38160 with loss: 9.7080\n",
      "Epoch [38160/100000], Loss: 9.7080\n",
      "Model saved at epoch 38167 with loss: 9.7080\n",
      "Model saved at epoch 38168 with loss: 9.7055\n",
      "Model saved at epoch 38169 with loss: 9.7039\n",
      "Model saved at epoch 38170 with loss: 9.7030\n",
      "Epoch [38170/100000], Loss: 9.7030\n",
      "Model saved at epoch 38173 with loss: 9.7030\n",
      "Model saved at epoch 38177 with loss: 9.7030\n",
      "Model saved at epoch 38178 with loss: 9.6946\n",
      "Epoch [38180/100000], Loss: 9.6976\n",
      "Model saved at epoch 38189 with loss: 9.6934\n",
      "Epoch [38190/100000], Loss: 9.6938\n",
      "Model saved at epoch 38194 with loss: 9.6926\n",
      "Model saved at epoch 38195 with loss: 9.6923\n",
      "Epoch [38200/100000], Loss: 9.6936\n",
      "Model saved at epoch 38201 with loss: 9.6912\n",
      "Model saved at epoch 38202 with loss: 9.6911\n",
      "Model saved at epoch 38203 with loss: 9.6895\n",
      "Model saved at epoch 38208 with loss: 9.6892\n",
      "Epoch [38210/100000], Loss: 9.6940\n",
      "Model saved at epoch 38218 with loss: 9.6861\n",
      "Model saved at epoch 38219 with loss: 9.6841\n",
      "Model saved at epoch 38220 with loss: 9.6832\n",
      "Epoch [38220/100000], Loss: 9.6832\n",
      "Model saved at epoch 38222 with loss: 9.6831\n",
      "Model saved at epoch 38227 with loss: 9.6825\n",
      "Epoch [38230/100000], Loss: 9.6826\n",
      "Model saved at epoch 38232 with loss: 9.6797\n",
      "Model saved at epoch 38233 with loss: 9.6772\n",
      "Model saved at epoch 38235 with loss: 9.6761\n",
      "Model saved at epoch 38237 with loss: 9.6759\n",
      "Model saved at epoch 38238 with loss: 9.6740\n",
      "Model saved at epoch 38240 with loss: 9.6706\n",
      "Epoch [38240/100000], Loss: 9.6706\n",
      "Model saved at epoch 38241 with loss: 9.6701\n",
      "Model saved at epoch 38242 with loss: 9.6658\n",
      "Epoch [38250/100000], Loss: 9.6751\n",
      "Epoch [38260/100000], Loss: 11338899456.0000\n",
      "Epoch [38270/100000], Loss: 398770912.0000\n",
      "Epoch [38280/100000], Loss: 94796064.0000\n",
      "Epoch [38290/100000], Loss: 50905644.0000\n",
      "Epoch [38300/100000], Loss: 43160684.0000\n",
      "Epoch [38310/100000], Loss: 24847426.0000\n",
      "Epoch [38320/100000], Loss: 11173262.0000\n",
      "Epoch [38330/100000], Loss: 4606519.0000\n",
      "Epoch [38340/100000], Loss: 1823294.3750\n",
      "Epoch [38350/100000], Loss: 643114.0625\n",
      "Epoch [38360/100000], Loss: 208874.7656\n",
      "Epoch [38370/100000], Loss: 70779.0938\n",
      "Epoch [38380/100000], Loss: 24409.2930\n",
      "Epoch [38390/100000], Loss: 8337.8096\n",
      "Epoch [38400/100000], Loss: 3207.6436\n",
      "Epoch [38410/100000], Loss: 1262.6265\n",
      "Epoch [38420/100000], Loss: 455.4885\n",
      "Epoch [38430/100000], Loss: 148.2434\n",
      "Epoch [38440/100000], Loss: 50.8964\n",
      "Epoch [38450/100000], Loss: 22.0196\n",
      "Epoch [38460/100000], Loss: 11.9504\n",
      "Epoch [38470/100000], Loss: 11.5279\n",
      "Epoch [38480/100000], Loss: 10.0484\n",
      "Model saved at epoch 38483 with loss: 9.6615\n",
      "Model saved at epoch 38488 with loss: 9.6275\n",
      "Epoch [38490/100000], Loss: 9.7453\n",
      "Model saved at epoch 38500 with loss: 9.6185\n",
      "Epoch [38500/100000], Loss: 9.6185\n",
      "Model saved at epoch 38504 with loss: 9.6167\n",
      "Model saved at epoch 38505 with loss: 9.6166\n",
      "Model saved at epoch 38506 with loss: 9.6098\n",
      "Epoch [38510/100000], Loss: 9.6108\n",
      "Model saved at epoch 38511 with loss: 9.6093\n",
      "Model saved at epoch 38517 with loss: 9.6001\n",
      "Model saved at epoch 38518 with loss: 9.5991\n",
      "Epoch [38520/100000], Loss: 9.6033\n",
      "Model saved at epoch 38529 with loss: 9.5988\n",
      "Epoch [38530/100000], Loss: 9.5995\n",
      "Model saved at epoch 38531 with loss: 9.5972\n",
      "Model saved at epoch 38532 with loss: 9.5969\n",
      "Model saved at epoch 38533 with loss: 9.5965\n",
      "Model saved at epoch 38534 with loss: 9.5931\n",
      "Model saved at epoch 38540 with loss: 9.5911\n",
      "Epoch [38540/100000], Loss: 9.5911\n",
      "Epoch [38550/100000], Loss: 9.5973\n",
      "Epoch [38560/100000], Loss: 9.5954\n",
      "Epoch [38570/100000], Loss: 9.5921\n",
      "Model saved at epoch 38574 with loss: 9.5909\n",
      "Model saved at epoch 38577 with loss: 9.5899\n",
      "Model saved at epoch 38580 with loss: 9.5899\n",
      "Epoch [38580/100000], Loss: 9.5899\n",
      "Model saved at epoch 38582 with loss: 9.5898\n",
      "Model saved at epoch 38585 with loss: 9.5894\n",
      "Epoch [38590/100000], Loss: 9.5920\n",
      "Epoch [38600/100000], Loss: 9.5959\n",
      "Epoch [38610/100000], Loss: 9.5980\n",
      "Epoch [38620/100000], Loss: 9.5970\n",
      "Epoch [38630/100000], Loss: 9.5986\n",
      "Epoch [38640/100000], Loss: 9.5966\n",
      "Epoch [38650/100000], Loss: 9.5944\n",
      "Epoch [38660/100000], Loss: 9.5952\n",
      "Epoch [38670/100000], Loss: 9.5935\n",
      "Epoch [38680/100000], Loss: 9.5911\n",
      "Model saved at epoch 38683 with loss: 9.5891\n",
      "Model saved at epoch 38686 with loss: 9.5888\n",
      "Model saved at epoch 38688 with loss: 9.5884\n",
      "Model saved at epoch 38689 with loss: 9.5883\n",
      "Model saved at epoch 38690 with loss: 9.5877\n",
      "Epoch [38690/100000], Loss: 9.5877\n",
      "Model saved at epoch 38692 with loss: 9.5877\n",
      "Model saved at epoch 38693 with loss: 9.5875\n",
      "Model saved at epoch 38694 with loss: 9.5871\n",
      "Epoch [38700/100000], Loss: 9.5879\n",
      "Epoch [38710/100000], Loss: 9.5910\n",
      "Epoch [38720/100000], Loss: 9.5906\n",
      "Epoch [38730/100000], Loss: 9.5893\n",
      "Model saved at epoch 38732 with loss: 9.5869\n",
      "Model saved at epoch 38734 with loss: 9.5862\n",
      "Model saved at epoch 38735 with loss: 9.5860\n",
      "Model saved at epoch 38736 with loss: 9.5850\n",
      "Epoch [38740/100000], Loss: 9.5887\n",
      "Epoch [38750/100000], Loss: 9.5901\n",
      "Epoch [38760/100000], Loss: 9.5954\n",
      "Epoch [38770/100000], Loss: 9.5950\n",
      "Epoch [38780/100000], Loss: 9.5943\n",
      "Epoch [38790/100000], Loss: 9.5927\n",
      "Epoch [38800/100000], Loss: 9.5928\n",
      "Epoch [38810/100000], Loss: 9.5933\n",
      "Epoch [38820/100000], Loss: 9.5882\n",
      "Epoch [38830/100000], Loss: 9.5889\n",
      "Epoch [38840/100000], Loss: 9.5880\n",
      "Model saved at epoch 38849 with loss: 9.5847\n",
      "Model saved at epoch 38850 with loss: 9.5833\n",
      "Epoch [38850/100000], Loss: 9.5833\n",
      "Model saved at epoch 38857 with loss: 9.5830\n",
      "Epoch [38860/100000], Loss: 9.5843\n",
      "Epoch [38870/100000], Loss: 9.5855\n",
      "Epoch [38880/100000], Loss: 9.5883\n",
      "Epoch [38890/100000], Loss: 9.5899\n",
      "Epoch [38900/100000], Loss: 9.5905\n",
      "Epoch [38910/100000], Loss: 9.5854\n",
      "Model saved at epoch 38918 with loss: 9.5829\n",
      "Epoch [38920/100000], Loss: 9.5834\n",
      "Model saved at epoch 38922 with loss: 9.5826\n",
      "Epoch [38930/100000], Loss: 9.5859\n",
      "Epoch [38940/100000], Loss: 9.5935\n",
      "Epoch [38950/100000], Loss: 9.5912\n",
      "Epoch [38960/100000], Loss: 9.5892\n",
      "Epoch [38970/100000], Loss: 9.5899\n",
      "Epoch [38980/100000], Loss: 9.5907\n",
      "Epoch [38990/100000], Loss: 9.5904\n",
      "Epoch [39000/100000], Loss: 9.5899\n",
      "Epoch [39010/100000], Loss: 9.5921\n",
      "Epoch [39020/100000], Loss: 9.5921\n",
      "Epoch [39030/100000], Loss: 9.5873\n",
      "Epoch [39040/100000], Loss: 9.5832\n",
      "Model saved at epoch 39042 with loss: 9.5823\n",
      "Model saved at epoch 39043 with loss: 9.5812\n",
      "Model saved at epoch 39044 with loss: 9.5810\n",
      "Model saved at epoch 39045 with loss: 9.5808\n",
      "Model saved at epoch 39046 with loss: 9.5807\n",
      "Model saved at epoch 39047 with loss: 9.5796\n",
      "Model saved at epoch 39049 with loss: 9.5792\n",
      "Epoch [39050/100000], Loss: 9.5792\n",
      "Epoch [39060/100000], Loss: 9.5810\n",
      "Epoch [39070/100000], Loss: 9.5819\n",
      "Epoch [39080/100000], Loss: 9.5848\n",
      "Epoch [39090/100000], Loss: 9.5852\n",
      "Epoch [39100/100000], Loss: 9.5825\n",
      "Epoch [39110/100000], Loss: 9.5851\n",
      "Epoch [39120/100000], Loss: 9.5844\n",
      "Epoch [39130/100000], Loss: 9.5847\n",
      "Epoch [39140/100000], Loss: 9.5822\n",
      "Epoch [39150/100000], Loss: 9.5847\n",
      "Epoch [39160/100000], Loss: 9.5819\n",
      "Epoch [39170/100000], Loss: 9.5832\n",
      "Epoch [39180/100000], Loss: 9.5827\n",
      "Epoch [39190/100000], Loss: 9.5822\n",
      "Epoch [39200/100000], Loss: 9.5840\n",
      "Epoch [39210/100000], Loss: 9.5821\n",
      "Epoch [39220/100000], Loss: 9.5866\n",
      "Epoch [39230/100000], Loss: 9.5826\n",
      "Epoch [39240/100000], Loss: 9.5817\n",
      "Epoch [39250/100000], Loss: 9.5825\n",
      "Epoch [39260/100000], Loss: 9.5825\n",
      "Model saved at epoch 39268 with loss: 9.5784\n",
      "Model saved at epoch 39269 with loss: 9.5768\n",
      "Model saved at epoch 39270 with loss: 9.5760\n",
      "Epoch [39270/100000], Loss: 9.5760\n",
      "Model saved at epoch 39271 with loss: 9.5759\n",
      "Model saved at epoch 39272 with loss: 9.5741\n",
      "Model saved at epoch 39274 with loss: 9.5740\n",
      "Model saved at epoch 39275 with loss: 9.5736\n",
      "Model saved at epoch 39277 with loss: 9.5735\n",
      "Model saved at epoch 39278 with loss: 9.5726\n",
      "Epoch [39280/100000], Loss: 9.5727\n",
      "Model saved at epoch 39281 with loss: 9.5718\n",
      "Model saved at epoch 39282 with loss: 9.5703\n",
      "Model saved at epoch 39283 with loss: 9.5700\n",
      "Epoch [39290/100000], Loss: 9.5738\n",
      "Epoch [39300/100000], Loss: 9.5741\n",
      "Epoch [39310/100000], Loss: 9.5775\n",
      "Epoch [39320/100000], Loss: 9.5796\n",
      "Epoch [39330/100000], Loss: 9.5796\n",
      "Epoch [39340/100000], Loss: 9.5764\n",
      "Epoch [39350/100000], Loss: 9.5709\n",
      "Model saved at epoch 39357 with loss: 9.5698\n",
      "Epoch [39360/100000], Loss: 9.5726\n",
      "Epoch [39370/100000], Loss: 9.5750\n",
      "Epoch [39380/100000], Loss: 9.5739\n",
      "Epoch [39390/100000], Loss: 9.5770\n",
      "Epoch [39400/100000], Loss: 9.5754\n",
      "Epoch [39410/100000], Loss: 9.5701\n",
      "Model saved at epoch 39411 with loss: 9.5694\n",
      "Model saved at epoch 39412 with loss: 9.5687\n",
      "Model saved at epoch 39417 with loss: 9.5686\n",
      "Model saved at epoch 39418 with loss: 9.5681\n",
      "Model saved at epoch 39420 with loss: 9.5681\n",
      "Epoch [39420/100000], Loss: 9.5681\n",
      "Model saved at epoch 39421 with loss: 9.5680\n",
      "Model saved at epoch 39425 with loss: 9.5665\n",
      "Model saved at epoch 39429 with loss: 9.5660\n",
      "Model saved at epoch 39430 with loss: 9.5651\n",
      "Epoch [39430/100000], Loss: 9.5651\n",
      "Epoch [39440/100000], Loss: 9.5691\n",
      "Epoch [39450/100000], Loss: 9.5722\n",
      "Epoch [39460/100000], Loss: 9.5706\n",
      "Epoch [39470/100000], Loss: 9.5673\n",
      "Model saved at epoch 39478 with loss: 9.5642\n",
      "Epoch [39480/100000], Loss: 9.5645\n",
      "Epoch [39490/100000], Loss: 9.5655\n",
      "Model saved at epoch 39492 with loss: 9.5641\n",
      "Model saved at epoch 39494 with loss: 9.5636\n",
      "Model saved at epoch 39495 with loss: 9.5635\n",
      "Model saved at epoch 39496 with loss: 9.5624\n",
      "Epoch [39500/100000], Loss: 9.5658\n",
      "Epoch [39510/100000], Loss: 9.5646\n",
      "Epoch [39520/100000], Loss: 9.5661\n",
      "Epoch [39530/100000], Loss: 9.5657\n",
      "Epoch [39540/100000], Loss: 9.5710\n",
      "Epoch [39550/100000], Loss: 9.5728\n",
      "Epoch [39560/100000], Loss: 9.5664\n",
      "Epoch [39570/100000], Loss: 9.5654\n",
      "Epoch [39580/100000], Loss: 9.5665\n",
      "Epoch [39590/100000], Loss: 9.5665\n",
      "Epoch [39600/100000], Loss: 9.5707\n",
      "Epoch [39610/100000], Loss: 9.5695\n",
      "Epoch [39620/100000], Loss: 9.5660\n",
      "Epoch [39630/100000], Loss: 9.5668\n",
      "Epoch [39640/100000], Loss: 9.5658\n",
      "Epoch [39650/100000], Loss: 9.5702\n",
      "Epoch [39660/100000], Loss: 9.5696\n",
      "Epoch [39670/100000], Loss: 9.5692\n",
      "Epoch [39680/100000], Loss: 9.5678\n",
      "Epoch [39690/100000], Loss: 9.5669\n",
      "Epoch [39700/100000], Loss: 9.5647\n",
      "Model saved at epoch 39705 with loss: 9.5612\n",
      "Model saved at epoch 39707 with loss: 9.5607\n",
      "Epoch [39710/100000], Loss: 9.5621\n",
      "Epoch [39720/100000], Loss: 9.5649\n",
      "Epoch [39730/100000], Loss: 9.5662\n",
      "Epoch [39740/100000], Loss: 9.5672\n",
      "Epoch [39750/100000], Loss: 9.5637\n",
      "Model saved at epoch 39751 with loss: 9.5604\n",
      "Model saved at epoch 39752 with loss: 9.5596\n",
      "Model saved at epoch 39753 with loss: 9.5583\n",
      "Model saved at epoch 39754 with loss: 9.5565\n",
      "Epoch [39760/100000], Loss: 9.5581\n",
      "Model saved at epoch 39769 with loss: 9.5556\n",
      "Epoch [39770/100000], Loss: 9.5568\n",
      "Model saved at epoch 39772 with loss: 9.5556\n",
      "Model saved at epoch 39773 with loss: 9.5540\n",
      "Model saved at epoch 39777 with loss: 9.5535\n",
      "Epoch [39780/100000], Loss: 9.5555\n",
      "Model saved at epoch 39783 with loss: 9.5531\n",
      "Epoch [39790/100000], Loss: 9.5562\n",
      "Epoch [39800/100000], Loss: 9.5603\n",
      "Epoch [39810/100000], Loss: 9.5607\n",
      "Epoch [39820/100000], Loss: 9.5577\n",
      "Epoch [39830/100000], Loss: 9.5600\n",
      "Epoch [39840/100000], Loss: 9.5614\n",
      "Epoch [39850/100000], Loss: 9.5618\n",
      "Epoch [39860/100000], Loss: 9.5577\n",
      "Epoch [39870/100000], Loss: 9.5550\n",
      "Epoch [39880/100000], Loss: 9.5570\n",
      "Epoch [39890/100000], Loss: 9.5596\n",
      "Epoch [39900/100000], Loss: 9.5600\n",
      "Epoch [39910/100000], Loss: 9.5552\n",
      "Model saved at epoch 39914 with loss: 9.5523\n",
      "Epoch [39920/100000], Loss: 9.5542\n",
      "Epoch [39930/100000], Loss: 9.5569\n",
      "Epoch [39940/100000], Loss: 9.5553\n",
      "Epoch [39950/100000], Loss: 9.5535\n",
      "Model saved at epoch 39953 with loss: 9.5521\n",
      "Model saved at epoch 39956 with loss: 9.5503\n",
      "Epoch [39960/100000], Loss: 9.5557\n",
      "Model saved at epoch 39967 with loss: 9.5501\n",
      "Epoch [39970/100000], Loss: 9.5532\n",
      "Epoch [39980/100000], Loss: 9.5542\n",
      "Epoch [39990/100000], Loss: 9.5515\n",
      "Epoch [40000/100000], Loss: 9.5550\n",
      "Epoch [40010/100000], Loss: 9.5539\n",
      "Model saved at epoch 40014 with loss: 9.5498\n",
      "Model saved at epoch 40016 with loss: 9.5497\n",
      "Epoch [40020/100000], Loss: 9.5540\n",
      "Epoch [40030/100000], Loss: 9.5546\n",
      "Epoch [40040/100000], Loss: 9.5510\n",
      "Epoch [40050/100000], Loss: 9.5566\n",
      "Epoch [40060/100000], Loss: 9.5507\n",
      "Model saved at epoch 40069 with loss: 9.5490\n",
      "Model saved at epoch 40070 with loss: 9.5481\n",
      "Epoch [40070/100000], Loss: 9.5481\n",
      "Model saved at epoch 40071 with loss: 9.5466\n",
      "Model saved at epoch 40072 with loss: 9.5464\n",
      "Model saved at epoch 40073 with loss: 9.5450\n",
      "Model saved at epoch 40074 with loss: 9.5442\n",
      "Model saved at epoch 40077 with loss: 9.5441\n",
      "Epoch [40080/100000], Loss: 9.5468\n",
      "Epoch [40090/100000], Loss: 9.5524\n",
      "Epoch [40100/100000], Loss: 9.5538\n",
      "Epoch [40110/100000], Loss: 9.5503\n",
      "Epoch [40120/100000], Loss: 9.5460\n",
      "Epoch [40130/100000], Loss: 9.5499\n",
      "Epoch [40140/100000], Loss: 9.5489\n",
      "Model saved at epoch 40143 with loss: 9.5436\n",
      "Epoch [40150/100000], Loss: 9.5486\n",
      "Epoch [40160/100000], Loss: 9.5453\n",
      "Epoch [40170/100000], Loss: 9.5460\n",
      "Epoch [40180/100000], Loss: 9.5480\n",
      "Model saved at epoch 40190 with loss: 9.5422\n",
      "Epoch [40190/100000], Loss: 9.5422\n",
      "Epoch [40200/100000], Loss: 9.5489\n",
      "Model saved at epoch 40210 with loss: 9.5408\n",
      "Epoch [40210/100000], Loss: 9.5408\n",
      "Model saved at epoch 40218 with loss: 9.5399\n",
      "Epoch [40220/100000], Loss: 9.5418\n",
      "Epoch [40230/100000], Loss: 9.5452\n",
      "Model saved at epoch 40240 with loss: 9.5395\n",
      "Epoch [40240/100000], Loss: 9.5395\n",
      "Epoch [40250/100000], Loss: 9.5438\n",
      "Model saved at epoch 40256 with loss: 9.5389\n",
      "Model saved at epoch 40257 with loss: 9.5385\n",
      "Model saved at epoch 40258 with loss: 9.5356\n",
      "Model saved at epoch 40259 with loss: 9.5338\n",
      "Model saved at epoch 40260 with loss: 9.5319\n",
      "Epoch [40260/100000], Loss: 9.5319\n",
      "Model saved at epoch 40261 with loss: 9.5318\n",
      "Epoch [40270/100000], Loss: 9.5378\n",
      "Epoch [40280/100000], Loss: 9.5367\n",
      "Epoch [40290/100000], Loss: 9.5352\n",
      "Epoch [40300/100000], Loss: 9.5402\n",
      "Epoch [40310/100000], Loss: 9.5391\n",
      "Epoch [40320/100000], Loss: 9.5409\n",
      "Epoch [40330/100000], Loss: 9.5368\n",
      "Epoch [40340/100000], Loss: 9.5389\n",
      "Epoch [40350/100000], Loss: 9.5376\n",
      "Epoch [40360/100000], Loss: 9.5334\n",
      "Epoch [40370/100000], Loss: 9.5348\n",
      "Epoch [40380/100000], Loss: 9.5336\n",
      "Epoch [40390/100000], Loss: 9.5333\n",
      "Model saved at epoch 40397 with loss: 9.5297\n",
      "Model saved at epoch 40399 with loss: 9.5285\n",
      "Epoch [40400/100000], Loss: 9.5285\n",
      "Model saved at epoch 40401 with loss: 9.5272\n",
      "Model saved at epoch 40403 with loss: 9.5272\n",
      "Model saved at epoch 40404 with loss: 9.5268\n",
      "Model saved at epoch 40405 with loss: 9.5263\n",
      "Model saved at epoch 40406 with loss: 9.5261\n",
      "Epoch [40410/100000], Loss: 9.5289\n",
      "Epoch [40420/100000], Loss: 9.5311\n",
      "Epoch [40430/100000], Loss: 9.5302\n",
      "Epoch [40440/100000], Loss: 9.5286\n",
      "Model saved at epoch 40448 with loss: 9.5258\n",
      "Model saved at epoch 40450 with loss: 9.5250\n",
      "Epoch [40450/100000], Loss: 9.5250\n",
      "Model saved at epoch 40451 with loss: 9.5245\n",
      "Epoch [40460/100000], Loss: 9.5309\n",
      "Epoch [40470/100000], Loss: 9.5371\n",
      "Epoch [40480/100000], Loss: 9.5328\n",
      "Epoch [40490/100000], Loss: 9.5268\n",
      "Epoch [40500/100000], Loss: 9.5266\n",
      "Epoch [40510/100000], Loss: 9.5294\n",
      "Model saved at epoch 40518 with loss: 9.5240\n",
      "Model saved at epoch 40519 with loss: 9.5220\n",
      "Epoch [40520/100000], Loss: 9.5222\n",
      "Model saved at epoch 40522 with loss: 9.5214\n",
      "Model saved at epoch 40524 with loss: 9.5208\n",
      "Model saved at epoch 40527 with loss: 9.5208\n",
      "Model saved at epoch 40528 with loss: 9.5193\n",
      "Model saved at epoch 40529 with loss: 9.5169\n",
      "Model saved at epoch 40530 with loss: 9.5167\n",
      "Epoch [40530/100000], Loss: 9.5167\n",
      "Epoch [40540/100000], Loss: 9.5213\n",
      "Epoch [40550/100000], Loss: 9.5230\n",
      "Epoch [40560/100000], Loss: 9.5205\n",
      "Epoch [40570/100000], Loss: 9.5205\n",
      "Epoch [40580/100000], Loss: 9.5216\n",
      "Epoch [40590/100000], Loss: 9.5230\n",
      "Epoch [40600/100000], Loss: 9.5243\n",
      "Epoch [40610/100000], Loss: 9.5207\n",
      "Model saved at epoch 40614 with loss: 9.5148\n",
      "Epoch [40620/100000], Loss: 9.5192\n",
      "Epoch [40630/100000], Loss: 9.5210\n",
      "Epoch [40640/100000], Loss: 9.5218\n",
      "Epoch [40650/100000], Loss: 9.5182\n",
      "Epoch [40660/100000], Loss: 9.5162\n",
      "Model saved at epoch 40661 with loss: 9.5141\n",
      "Model saved at epoch 40662 with loss: 9.5118\n",
      "Model saved at epoch 40663 with loss: 9.5116\n",
      "Epoch [40670/100000], Loss: 9.5152\n",
      "Epoch [40680/100000], Loss: 9.5134\n",
      "Model saved at epoch 40686 with loss: 9.5103\n",
      "Epoch [40690/100000], Loss: 9.5109\n",
      "Epoch [40700/100000], Loss: 9.5152\n",
      "Epoch [40710/100000], Loss: 9.5130\n",
      "Epoch [40720/100000], Loss: 9.5144\n",
      "Epoch [40730/100000], Loss: 9.5181\n",
      "Epoch [40740/100000], Loss: 9.5148\n",
      "Epoch [40750/100000], Loss: 9.5154\n",
      "Epoch [40760/100000], Loss: 9.5217\n",
      "Epoch [40770/100000], Loss: 9.5125\n",
      "Epoch [40780/100000], Loss: 9.5156\n",
      "Epoch [40790/100000], Loss: 9.5164\n",
      "Epoch [40800/100000], Loss: 9.5174\n",
      "Epoch [40810/100000], Loss: 9.5156\n",
      "Epoch [40820/100000], Loss: 9.5167\n",
      "Model saved at epoch 40824 with loss: 9.5097\n",
      "Model saved at epoch 40825 with loss: 9.5097\n",
      "Model saved at epoch 40828 with loss: 9.5092\n",
      "Model saved at epoch 40829 with loss: 9.5080\n",
      "Model saved at epoch 40830 with loss: 9.5073\n",
      "Epoch [40830/100000], Loss: 9.5073\n",
      "Model saved at epoch 40831 with loss: 9.5063\n",
      "Epoch [40840/100000], Loss: 9.5126\n",
      "Epoch [40850/100000], Loss: 9.5101\n",
      "Model saved at epoch 40854 with loss: 9.5061\n",
      "Model saved at epoch 40857 with loss: 9.5050\n",
      "Model saved at epoch 40858 with loss: 9.5042\n",
      "Epoch [40860/100000], Loss: 9.5080\n",
      "Epoch [40870/100000], Loss: 9.5069\n",
      "Model saved at epoch 40878 with loss: 9.5036\n",
      "Model saved at epoch 40879 with loss: 9.5034\n",
      "Epoch [40880/100000], Loss: 9.5045\n",
      "Model saved at epoch 40881 with loss: 9.5034\n",
      "Model saved at epoch 40882 with loss: 9.5032\n",
      "Model saved at epoch 40889 with loss: 9.5028\n",
      "Epoch [40890/100000], Loss: 9.5033\n",
      "Model saved at epoch 40891 with loss: 9.5025\n",
      "Model saved at epoch 40892 with loss: 9.4999\n",
      "Epoch [40900/100000], Loss: 9.5032\n",
      "Epoch [40910/100000], Loss: 9.5080\n",
      "Epoch [40920/100000], Loss: 9.5027\n",
      "Epoch [40930/100000], Loss: 9.5029\n",
      "Model saved at epoch 40934 with loss: 9.4994\n",
      "Epoch [40940/100000], Loss: 9.5022\n",
      "Model saved at epoch 40947 with loss: 9.4993\n",
      "Epoch [40950/100000], Loss: 9.5001\n",
      "Model saved at epoch 40956 with loss: 9.4989\n",
      "Model saved at epoch 40957 with loss: 9.4969\n",
      "Model saved at epoch 40958 with loss: 9.4967\n",
      "Model saved at epoch 40959 with loss: 9.4961\n",
      "Epoch [40960/100000], Loss: 9.4974\n",
      "Epoch [40970/100000], Loss: 9.5009\n",
      "Epoch [40980/100000], Loss: 9.5018\n",
      "Epoch [40990/100000], Loss: 9.4971\n",
      "Epoch [41000/100000], Loss: 9.5031\n",
      "Epoch [41010/100000], Loss: 9.5006\n",
      "Epoch [41020/100000], Loss: 9.4969\n",
      "Epoch [41030/100000], Loss: 9.4983\n",
      "Epoch [41040/100000], Loss: 9.4999\n",
      "Epoch [41050/100000], Loss: 9.5029\n",
      "Epoch [41060/100000], Loss: 9.4974\n",
      "Epoch [41070/100000], Loss: 9.4996\n",
      "Model saved at epoch 41080 with loss: 9.4957\n",
      "Epoch [41080/100000], Loss: 9.4957\n",
      "Model saved at epoch 41081 with loss: 9.4944\n",
      "Model saved at epoch 41082 with loss: 9.4943\n",
      "Model saved at epoch 41084 with loss: 9.4934\n",
      "Model saved at epoch 41085 with loss: 9.4925\n",
      "Epoch [41090/100000], Loss: 9.4985\n",
      "Model saved at epoch 41096 with loss: 9.4918\n",
      "Model saved at epoch 41098 with loss: 9.4910\n",
      "Model saved at epoch 41100 with loss: 9.4907\n",
      "Epoch [41100/100000], Loss: 9.4907\n",
      "Model saved at epoch 41101 with loss: 9.4901\n",
      "Model saved at epoch 41102 with loss: 9.4878\n",
      "Epoch [41110/100000], Loss: 9.4922\n",
      "Epoch [41120/100000], Loss: 9.4928\n",
      "Epoch [41130/100000], Loss: 9.4921\n",
      "Epoch [41140/100000], Loss: 9.4944\n",
      "Epoch [41150/100000], Loss: 9.4937\n",
      "Epoch [41160/100000], Loss: 9.4918\n",
      "Model saved at epoch 41170 with loss: 9.4875\n",
      "Epoch [41170/100000], Loss: 9.4875\n",
      "Model saved at epoch 41173 with loss: 9.4861\n",
      "Model saved at epoch 41174 with loss: 9.4847\n",
      "Epoch [41180/100000], Loss: 9.4875\n",
      "Model saved at epoch 41184 with loss: 9.4819\n",
      "Epoch [41190/100000], Loss: 9.4837\n",
      "Model saved at epoch 41192 with loss: 9.4812\n",
      "Model saved at epoch 41193 with loss: 9.4794\n",
      "Model saved at epoch 41194 with loss: 9.4766\n",
      "Epoch [41200/100000], Loss: 9.4826\n",
      "Epoch [41210/100000], Loss: 9.4836\n",
      "Epoch [41220/100000], Loss: 9.4857\n",
      "Epoch [41230/100000], Loss: 9.4869\n",
      "Epoch [41240/100000], Loss: 9.4797\n",
      "Epoch [41250/100000], Loss: 9.4836\n",
      "Epoch [41260/100000], Loss: 9.4789\n",
      "Model saved at epoch 41263 with loss: 9.4763\n",
      "Model saved at epoch 41266 with loss: 9.4758\n",
      "Epoch [41270/100000], Loss: 9.4763\n",
      "Model saved at epoch 41272 with loss: 9.4734\n",
      "Model saved at epoch 41279 with loss: 9.4728\n",
      "Model saved at epoch 41280 with loss: 9.4713\n",
      "Epoch [41280/100000], Loss: 9.4713\n",
      "Model saved at epoch 41282 with loss: 9.4705\n",
      "Model saved at epoch 41283 with loss: 9.4704\n",
      "Model saved at epoch 41284 with loss: 9.4693\n",
      "Model saved at epoch 41287 with loss: 9.4686\n",
      "Model saved at epoch 41288 with loss: 9.4679\n",
      "Model saved at epoch 41290 with loss: 9.4668\n",
      "Epoch [41290/100000], Loss: 9.4668\n",
      "Epoch [41300/100000], Loss: 9.4755\n",
      "Epoch [41310/100000], Loss: 9.4754\n",
      "Epoch [41320/100000], Loss: 9.4792\n",
      "Epoch [41330/100000], Loss: 9.4735\n",
      "Epoch [41340/100000], Loss: 9.4715\n",
      "Epoch [41350/100000], Loss: 9.4740\n",
      "Epoch [41360/100000], Loss: 9.4692\n",
      "Epoch [41370/100000], Loss: 9.4680\n",
      "Model saved at epoch 41372 with loss: 9.4656\n",
      "Model saved at epoch 41376 with loss: 9.4647\n",
      "Epoch [41380/100000], Loss: 9.4700\n",
      "Epoch [41390/100000], Loss: 9.4736\n",
      "Epoch [41400/100000], Loss: 9.4723\n",
      "Epoch [41410/100000], Loss: 9.4687\n",
      "Epoch [41420/100000], Loss: 9.4668\n",
      "Epoch [41430/100000], Loss: 9.4692\n",
      "Model saved at epoch 41437 with loss: 9.4631\n",
      "Model saved at epoch 41438 with loss: 9.4621\n",
      "Model saved at epoch 41439 with loss: 9.4615\n",
      "Model saved at epoch 41440 with loss: 9.4586\n",
      "Epoch [41440/100000], Loss: 9.4586\n",
      "Model saved at epoch 41441 with loss: 9.4578\n",
      "Model saved at epoch 41442 with loss: 9.4575\n",
      "Epoch [41450/100000], Loss: 9.4577\n",
      "Model saved at epoch 41451 with loss: 9.4564\n",
      "Model saved at epoch 41453 with loss: 9.4562\n",
      "Model saved at epoch 41458 with loss: 9.4556\n",
      "Model saved at epoch 41459 with loss: 9.4554\n",
      "Epoch [41460/100000], Loss: 9.4559\n",
      "Epoch [41470/100000], Loss: 9.4605\n",
      "Epoch [41480/100000], Loss: 9.4601\n",
      "Epoch [41490/100000], Loss: 9.4619\n",
      "Epoch [41500/100000], Loss: 9.4564\n",
      "Epoch [41510/100000], Loss: 9.4589\n",
      "Epoch [41520/100000], Loss: 9.4608\n",
      "Epoch [41530/100000], Loss: 9.4653\n",
      "Epoch [41540/100000], Loss: 9.4617\n",
      "Epoch [41550/100000], Loss: 9.4631\n",
      "Epoch [41560/100000], Loss: 9.4579\n",
      "Epoch [41570/100000], Loss: 9.4614\n",
      "Epoch [41580/100000], Loss: 9.4596\n",
      "Model saved at epoch 41587 with loss: 9.4532\n",
      "Epoch [41590/100000], Loss: 9.4554\n",
      "Epoch [41600/100000], Loss: 9.4622\n",
      "Epoch [41610/100000], Loss: 9.4577\n",
      "Model saved at epoch 41615 with loss: 9.4525\n",
      "Model saved at epoch 41616 with loss: 9.4518\n",
      "Model saved at epoch 41617 with loss: 9.4505\n",
      "Epoch [41620/100000], Loss: 9.4515\n",
      "Model saved at epoch 41627 with loss: 9.4499\n",
      "Model saved at epoch 41628 with loss: 9.4467\n",
      "Epoch [41630/100000], Loss: 9.4470\n",
      "Epoch [41640/100000], Loss: 9.4542\n",
      "Model saved at epoch 41648 with loss: 9.4461\n",
      "Model saved at epoch 41649 with loss: 9.4452\n",
      "Epoch [41650/100000], Loss: 9.4458\n",
      "Model saved at epoch 41651 with loss: 9.4431\n",
      "Model saved at epoch 41653 with loss: 9.4425\n",
      "Epoch [41660/100000], Loss: 9.4505\n",
      "Model saved at epoch 41665 with loss: 9.4420\n",
      "Epoch [41670/100000], Loss: 9.4432\n",
      "Epoch [41680/100000], Loss: 9.4423\n",
      "Epoch [41690/100000], Loss: 9.4504\n",
      "Epoch [41700/100000], Loss: 9.4481\n",
      "Epoch [41710/100000], Loss: 9.4451\n",
      "Model saved at epoch 41715 with loss: 9.4419\n",
      "Model saved at epoch 41719 with loss: 9.4407\n",
      "Model saved at epoch 41720 with loss: 9.4391\n",
      "Epoch [41720/100000], Loss: 9.4391\n",
      "Model saved at epoch 41721 with loss: 9.4378\n",
      "Epoch [41730/100000], Loss: 9.4436\n",
      "Model saved at epoch 41738 with loss: 9.4368\n",
      "Epoch [41740/100000], Loss: 9.4386\n",
      "Model saved at epoch 41745 with loss: 9.4364\n",
      "Model saved at epoch 41746 with loss: 9.4360\n",
      "Model saved at epoch 41750 with loss: 9.4360\n",
      "Epoch [41750/100000], Loss: 9.4360\n",
      "Model saved at epoch 41752 with loss: 9.4358\n",
      "Model saved at epoch 41753 with loss: 9.4358\n",
      "Model saved at epoch 41755 with loss: 9.4348\n",
      "Model saved at epoch 41756 with loss: 9.4344\n",
      "Model saved at epoch 41758 with loss: 9.4342\n",
      "Epoch [41760/100000], Loss: 9.4349\n",
      "Model saved at epoch 41763 with loss: 9.4324\n",
      "Model saved at epoch 41767 with loss: 9.4323\n",
      "Model saved at epoch 41769 with loss: 9.4313\n",
      "Epoch [41770/100000], Loss: 9.4318\n",
      "Model saved at epoch 41771 with loss: 9.4307\n",
      "Model saved at epoch 41774 with loss: 9.4303\n",
      "Model saved at epoch 41779 with loss: 9.4302\n",
      "Epoch [41780/100000], Loss: 9.4315\n",
      "Epoch [41790/100000], Loss: 9.4348\n",
      "Model saved at epoch 41798 with loss: 9.4301\n",
      "Epoch [41800/100000], Loss: 9.4349\n",
      "Epoch [41810/100000], Loss: 9.4384\n",
      "Epoch [41820/100000], Loss: 9.4357\n",
      "Epoch [41830/100000], Loss: 9.4329\n",
      "Epoch [41840/100000], Loss: 9.4308\n",
      "Model saved at epoch 41845 with loss: 9.4291\n",
      "Model saved at epoch 41846 with loss: 9.4285\n",
      "Model saved at epoch 41847 with loss: 9.4281\n",
      "Epoch [41850/100000], Loss: 9.4297\n",
      "Model saved at epoch 41852 with loss: 9.4265\n",
      "Epoch [41860/100000], Loss: 9.4358\n",
      "Epoch [41870/100000], Loss: 9.4342\n",
      "Epoch [41880/100000], Loss: 9.4288\n",
      "Model saved at epoch 41889 with loss: 9.4258\n",
      "Model saved at epoch 41890 with loss: 9.4253\n",
      "Epoch [41890/100000], Loss: 9.4253\n",
      "Epoch [41900/100000], Loss: 9.4277\n",
      "Model saved at epoch 41910 with loss: 9.4236\n",
      "Epoch [41910/100000], Loss: 9.4236\n",
      "Model saved at epoch 41911 with loss: 9.4223\n",
      "Model saved at epoch 41912 with loss: 9.4223\n",
      "Model saved at epoch 41913 with loss: 9.4214\n",
      "Epoch [41920/100000], Loss: 9.4253\n",
      "Epoch [41930/100000], Loss: 9.4269\n",
      "Epoch [41940/100000], Loss: 9.4286\n",
      "Epoch [41950/100000], Loss: 9.4237\n",
      "Model saved at epoch 41954 with loss: 9.4211\n",
      "Model saved at epoch 41960 with loss: 9.4195\n",
      "Epoch [41960/100000], Loss: 9.4195\n",
      "Model saved at epoch 41967 with loss: 9.4193\n",
      "Model saved at epoch 41968 with loss: 9.4183\n",
      "Epoch [41970/100000], Loss: 9.4215\n",
      "Model saved at epoch 41976 with loss: 9.4178\n",
      "Model saved at epoch 41977 with loss: 9.4159\n",
      "Epoch [41980/100000], Loss: 9.4200\n",
      "Model saved at epoch 41988 with loss: 9.4158\n",
      "Epoch [41990/100000], Loss: 9.4181\n",
      "Epoch [42000/100000], Loss: 9.4228\n",
      "Epoch [42010/100000], Loss: 9.4222\n",
      "Model saved at epoch 42020 with loss: 9.4151\n",
      "Epoch [42020/100000], Loss: 9.4151\n",
      "Model saved at epoch 42021 with loss: 9.4127\n",
      "Model saved at epoch 42022 with loss: 9.4107\n",
      "Model saved at epoch 42024 with loss: 9.4096\n",
      "Epoch [42030/100000], Loss: 9.4158\n",
      "Epoch [42040/100000], Loss: 9.4107\n",
      "Model saved at epoch 42045 with loss: 9.4092\n",
      "Epoch [42050/100000], Loss: 9.4127\n",
      "Model saved at epoch 42054 with loss: 9.4071\n",
      "Epoch [42060/100000], Loss: 9.4097\n",
      "Model saved at epoch 42069 with loss: 9.4062\n",
      "Model saved at epoch 42070 with loss: 9.4056\n",
      "Epoch [42070/100000], Loss: 9.4056\n",
      "Model saved at epoch 42076 with loss: 9.4022\n",
      "Model saved at epoch 42077 with loss: 9.4011\n",
      "Model saved at epoch 42078 with loss: 9.3980\n",
      "Epoch [42080/100000], Loss: 9.4047\n",
      "Epoch [42090/100000], Loss: 9.4083\n",
      "Epoch [42100/100000], Loss: 9.4032\n",
      "Epoch [42110/100000], Loss: 9.4032\n",
      "Epoch [42120/100000], Loss: 9.4045\n",
      "Epoch [42130/100000], Loss: 9.4034\n",
      "Epoch [42140/100000], Loss: 9.4014\n",
      "Epoch [42150/100000], Loss: 9.3992\n",
      "Model saved at epoch 42151 with loss: 9.3963\n",
      "Model saved at epoch 42153 with loss: 9.3962\n",
      "Model saved at epoch 42154 with loss: 9.3959\n",
      "Model saved at epoch 42155 with loss: 9.3959\n",
      "Model saved at epoch 42159 with loss: 9.3955\n",
      "Epoch [42160/100000], Loss: 9.3958\n",
      "Model saved at epoch 42168 with loss: 9.3947\n",
      "Model saved at epoch 42169 with loss: 9.3935\n",
      "Model saved at epoch 42170 with loss: 9.3926\n",
      "Epoch [42170/100000], Loss: 9.3926\n",
      "Model saved at epoch 42171 with loss: 9.3899\n",
      "Model saved at epoch 42172 with loss: 9.3877\n",
      "Epoch [42180/100000], Loss: 9.3982\n",
      "Epoch [42190/100000], Loss: 9.3941\n",
      "Epoch [42200/100000], Loss: 9.3973\n",
      "Epoch [42210/100000], Loss: 9.3947\n",
      "Model saved at epoch 42218 with loss: 9.3866\n",
      "Epoch [42220/100000], Loss: 9.3894\n",
      "Epoch [42230/100000], Loss: 9.3909\n",
      "Model saved at epoch 42236 with loss: 9.3856\n",
      "Epoch [42240/100000], Loss: 9.3876\n",
      "Model saved at epoch 42248 with loss: 9.3853\n",
      "Model saved at epoch 42249 with loss: 9.3827\n",
      "Model saved at epoch 42250 with loss: 9.3821\n",
      "Epoch [42250/100000], Loss: 9.3821\n",
      "Epoch [42260/100000], Loss: 9.3866\n",
      "Epoch [42270/100000], Loss: 9.3900\n",
      "Epoch [42280/100000], Loss: 9.3884\n",
      "Epoch [42290/100000], Loss: 9.3879\n",
      "Model saved at epoch 42297 with loss: 9.3819\n",
      "Epoch [42300/100000], Loss: 9.3830\n",
      "Model saved at epoch 42307 with loss: 9.3817\n",
      "Epoch [42310/100000], Loss: 9.3889\n",
      "Epoch [42320/100000], Loss: 9.3840\n",
      "Model saved at epoch 42322 with loss: 9.3808\n",
      "Model saved at epoch 42324 with loss: 9.3804\n",
      "Model saved at epoch 42328 with loss: 9.3775\n",
      "Epoch [42330/100000], Loss: 9.3779\n",
      "Epoch [42340/100000], Loss: 9.3795\n",
      "Model saved at epoch 42342 with loss: 9.3761\n",
      "Model saved at epoch 42343 with loss: 9.3759\n",
      "Model saved at epoch 42346 with loss: 9.3753\n",
      "Epoch [42350/100000], Loss: 9.3821\n",
      "Epoch [42360/100000], Loss: 9.3824\n",
      "Model saved at epoch 42367 with loss: 9.3748\n",
      "Epoch [42370/100000], Loss: 9.3788\n",
      "Model saved at epoch 42377 with loss: 9.3745\n",
      "Model saved at epoch 42378 with loss: 9.3740\n",
      "Model saved at epoch 42380 with loss: 9.3728\n",
      "Epoch [42380/100000], Loss: 9.3728\n",
      "Model saved at epoch 42385 with loss: 9.3726\n",
      "Epoch [42390/100000], Loss: 9.3791\n",
      "Model saved at epoch 42397 with loss: 9.3724\n",
      "Model saved at epoch 42400 with loss: 9.3720\n",
      "Epoch [42400/100000], Loss: 9.3720\n",
      "Model saved at epoch 42401 with loss: 9.3709\n",
      "Model saved at epoch 42405 with loss: 9.3703\n",
      "Model saved at epoch 42406 with loss: 9.3689\n",
      "Model saved at epoch 42408 with loss: 9.3682\n",
      "Epoch [42410/100000], Loss: 9.3714\n",
      "Epoch [42420/100000], Loss: 9.3772\n",
      "Epoch [42430/100000], Loss: 9.3722\n",
      "Epoch [42440/100000], Loss: 9.3710\n",
      "Model saved at epoch 42442 with loss: 9.3677\n",
      "Model saved at epoch 42443 with loss: 9.3673\n",
      "Epoch [42450/100000], Loss: 9.3715\n",
      "Model saved at epoch 42454 with loss: 9.3668\n",
      "Model saved at epoch 42457 with loss: 9.3667\n",
      "Epoch [42460/100000], Loss: 9.3672\n",
      "Model saved at epoch 42461 with loss: 9.3650\n",
      "Model saved at epoch 42463 with loss: 9.3631\n",
      "Model saved at epoch 42464 with loss: 9.3630\n",
      "Model saved at epoch 42470 with loss: 9.3594\n",
      "Epoch [42470/100000], Loss: 9.3594\n",
      "Model saved at epoch 42471 with loss: 9.3589\n",
      "Model saved at epoch 42472 with loss: 9.3570\n",
      "Model saved at epoch 42475 with loss: 9.3568\n",
      "Model saved at epoch 42477 with loss: 9.3529\n",
      "Model saved at epoch 42478 with loss: 9.3510\n",
      "Epoch [42480/100000], Loss: 9.3548\n",
      "Epoch [42490/100000], Loss: 9.3579\n",
      "Epoch [42500/100000], Loss: 9.3573\n",
      "Epoch [42510/100000], Loss: 9.3610\n",
      "Epoch [42520/100000], Loss: 9.3593\n",
      "Epoch [42530/100000], Loss: 9.3550\n",
      "Epoch [42540/100000], Loss: 9.3595\n",
      "Epoch [42550/100000], Loss: 9.3567\n",
      "Model saved at epoch 42559 with loss: 9.3500\n",
      "Model saved at epoch 42560 with loss: 9.3493\n",
      "Epoch [42560/100000], Loss: 9.3493\n",
      "Model saved at epoch 42567 with loss: 9.3483\n",
      "Model saved at epoch 42568 with loss: 9.3482\n",
      "Epoch [42570/100000], Loss: 9.3493\n",
      "Epoch [42580/100000], Loss: 9.3504\n",
      "Model saved at epoch 42581 with loss: 9.3466\n",
      "Model saved at epoch 42582 with loss: 9.3441\n",
      "Epoch [42590/100000], Loss: 9.3504\n",
      "Epoch [42600/100000], Loss: 9.3584\n",
      "Epoch [42610/100000], Loss: 9.3518\n",
      "Model saved at epoch 42615 with loss: 9.3409\n",
      "Epoch [42620/100000], Loss: 9.3426\n",
      "Model saved at epoch 42621 with loss: 9.3388\n",
      "Model saved at epoch 42623 with loss: 9.3380\n",
      "Epoch [42630/100000], Loss: 9.3460\n",
      "Epoch [42640/100000], Loss: 9.3384\n",
      "Model saved at epoch 42642 with loss: 9.3373\n",
      "Model saved at epoch 42645 with loss: 9.3362\n",
      "Epoch [42650/100000], Loss: 9.3448\n",
      "Epoch [42660/100000], Loss: 9.3395\n",
      "Model saved at epoch 42662 with loss: 9.3349\n",
      "Epoch [42670/100000], Loss: 9.3414\n",
      "Epoch [42680/100000], Loss: 9.3375\n",
      "Epoch [42690/100000], Loss: 9.3412\n",
      "Epoch [42700/100000], Loss: 9.3392\n",
      "Model saved at epoch 42704 with loss: 9.3347\n",
      "Model saved at epoch 42709 with loss: 9.3343\n",
      "Epoch [42710/100000], Loss: 9.3345\n",
      "Model saved at epoch 42713 with loss: 9.3315\n",
      "Model saved at epoch 42714 with loss: 9.3305\n",
      "Epoch [42720/100000], Loss: 9.3347\n",
      "Epoch [42730/100000], Loss: 9.3321\n",
      "Epoch [42740/100000], Loss: 9.3348\n",
      "Model saved at epoch 42743 with loss: 9.3303\n",
      "Model saved at epoch 42748 with loss: 9.3293\n",
      "Model saved at epoch 42749 with loss: 9.3281\n",
      "Epoch [42750/100000], Loss: 9.3285\n",
      "Model saved at epoch 42752 with loss: 9.3246\n",
      "Model saved at epoch 42754 with loss: 9.3219\n",
      "Epoch [42760/100000], Loss: 9.3276\n",
      "Epoch [42770/100000], Loss: 9.3222\n",
      "Model saved at epoch 42771 with loss: 9.3174\n",
      "Model saved at epoch 42777 with loss: 9.3149\n",
      "Model saved at epoch 42780 with loss: 9.3132\n",
      "Epoch [42780/100000], Loss: 9.3132\n",
      "Epoch [42790/100000], Loss: 9.3191\n",
      "Epoch [42800/100000], Loss: 9.3164\n",
      "Epoch [42810/100000], Loss: 9.3184\n",
      "Model saved at epoch 42820 with loss: 9.3125\n",
      "Epoch [42820/100000], Loss: 9.3125\n",
      "Model saved at epoch 42821 with loss: 9.3115\n",
      "Model saved at epoch 42829 with loss: 9.3102\n",
      "Epoch [42830/100000], Loss: 9.3147\n",
      "Epoch [42840/100000], Loss: 9.3144\n",
      "Model saved at epoch 42841 with loss: 9.3084\n",
      "Epoch [42850/100000], Loss: 9.3175\n",
      "Model saved at epoch 42857 with loss: 9.3083\n",
      "Epoch [42860/100000], Loss: 9.3108\n",
      "Model saved at epoch 42861 with loss: 9.3074\n",
      "Model saved at epoch 42863 with loss: 9.3061\n",
      "Epoch [42870/100000], Loss: 9.3072\n",
      "Model saved at epoch 42871 with loss: 9.3049\n",
      "Model saved at epoch 42877 with loss: 9.3029\n",
      "Epoch [42880/100000], Loss: 9.3049\n",
      "Model saved at epoch 42890 with loss: 9.3016\n",
      "Epoch [42890/100000], Loss: 9.3016\n",
      "Model saved at epoch 42897 with loss: 9.2976\n",
      "Epoch [42900/100000], Loss: 9.3045\n",
      "Epoch [42910/100000], Loss: 9.3056\n",
      "Model saved at epoch 42920 with loss: 9.2967\n",
      "Epoch [42920/100000], Loss: 9.2967\n",
      "Model saved at epoch 42923 with loss: 9.2954\n",
      "Model saved at epoch 42928 with loss: 9.2952\n",
      "Epoch [42930/100000], Loss: 9.2985\n",
      "Epoch [42940/100000], Loss: 9.2996\n",
      "Model saved at epoch 42943 with loss: 9.2935\n",
      "Model saved at epoch 42944 with loss: 9.2926\n",
      "Model saved at epoch 42949 with loss: 9.2919\n",
      "Model saved at epoch 42950 with loss: 9.2914\n",
      "Epoch [42950/100000], Loss: 9.2914\n",
      "Epoch [42960/100000], Loss: 9.2953\n",
      "Epoch [42970/100000], Loss: 9.2978\n",
      "Model saved at epoch 42975 with loss: 9.2901\n",
      "Model saved at epoch 42979 with loss: 9.2901\n",
      "Epoch [42980/100000], Loss: 9.2921\n",
      "Epoch [42990/100000], Loss: 9.2950\n",
      "Model saved at epoch 42997 with loss: 9.2896\n",
      "Model saved at epoch 42998 with loss: 9.2896\n",
      "Epoch [43000/100000], Loss: 9.2909\n",
      "Epoch [43010/100000], Loss: 9.2918\n",
      "Epoch [43020/100000], Loss: 9.2951\n",
      "Epoch [43030/100000], Loss: 9.2900\n",
      "Model saved at epoch 43031 with loss: 9.2877\n",
      "Model saved at epoch 43040 with loss: 9.2857\n",
      "Epoch [43040/100000], Loss: 9.2857\n",
      "Model saved at epoch 43042 with loss: 9.2840\n",
      "Epoch [43050/100000], Loss: 9.2874\n",
      "Epoch [43060/100000], Loss: 9.2898\n",
      "Model saved at epoch 43063 with loss: 9.2809\n",
      "Model saved at epoch 43064 with loss: 9.2794\n",
      "Epoch [43070/100000], Loss: 9.2869\n",
      "Epoch [43080/100000], Loss: 9.2818\n",
      "Model saved at epoch 43088 with loss: 9.2784\n",
      "Model saved at epoch 43089 with loss: 9.2778\n",
      "Epoch [43090/100000], Loss: 9.2812\n",
      "Model saved at epoch 43092 with loss: 9.2776\n",
      "Epoch [43100/100000], Loss: 9.2821\n",
      "Model saved at epoch 43110 with loss: 9.2756\n",
      "Epoch [43110/100000], Loss: 9.2756\n",
      "Model saved at epoch 43120 with loss: 9.2737\n",
      "Epoch [43120/100000], Loss: 9.2737\n",
      "Model saved at epoch 43123 with loss: 9.2727\n",
      "Model saved at epoch 43126 with loss: 9.2727\n",
      "Model saved at epoch 43127 with loss: 9.2708\n",
      "Model saved at epoch 43129 with loss: 9.2695\n",
      "Model saved at epoch 43130 with loss: 9.2694\n",
      "Epoch [43130/100000], Loss: 9.2694\n",
      "Model saved at epoch 43132 with loss: 9.2672\n",
      "Model saved at epoch 43135 with loss: 9.2665\n",
      "Model saved at epoch 43136 with loss: 9.2656\n",
      "Epoch [43140/100000], Loss: 9.2758\n",
      "Model saved at epoch 43148 with loss: 9.2625\n",
      "Epoch [43150/100000], Loss: 9.2662\n",
      "Epoch [43160/100000], Loss: 9.2665\n",
      "Epoch [43170/100000], Loss: 9.2658\n",
      "Model saved at epoch 43172 with loss: 9.2618\n",
      "Model saved at epoch 43178 with loss: 9.2614\n",
      "Model saved at epoch 43179 with loss: 9.2597\n",
      "Epoch [43180/100000], Loss: 9.2600\n",
      "Model saved at epoch 43181 with loss: 9.2596\n",
      "Model saved at epoch 43182 with loss: 9.2578\n",
      "Model saved at epoch 43183 with loss: 9.2551\n",
      "Model saved at epoch 43185 with loss: 9.2533\n",
      "Model saved at epoch 43186 with loss: 9.2529\n",
      "Model saved at epoch 43187 with loss: 9.2509\n",
      "Model saved at epoch 43188 with loss: 9.2504\n",
      "Model saved at epoch 43189 with loss: 9.2498\n",
      "Model saved at epoch 43190 with loss: 9.2492\n",
      "Epoch [43190/100000], Loss: 9.2492\n",
      "Epoch [43200/100000], Loss: 9.2587\n",
      "Epoch [43210/100000], Loss: 9.2582\n",
      "Epoch [43220/100000], Loss: 9.2572\n",
      "Model saved at epoch 43230 with loss: 9.2490\n",
      "Epoch [43230/100000], Loss: 9.2490\n",
      "Model saved at epoch 43238 with loss: 9.2475\n",
      "Epoch [43240/100000], Loss: 9.2548\n",
      "Epoch [43250/100000], Loss: 9.2514\n",
      "Epoch [43260/100000], Loss: 9.2495\n",
      "Epoch [43270/100000], Loss: 9.2528\n",
      "Model saved at epoch 43273 with loss: 9.2463\n",
      "Model saved at epoch 43274 with loss: 9.2454\n",
      "Epoch [43280/100000], Loss: 9.2504\n",
      "Model saved at epoch 43281 with loss: 9.2446\n",
      "Epoch [43290/100000], Loss: 9.2464\n",
      "Model saved at epoch 43291 with loss: 9.2445\n",
      "Model saved at epoch 43299 with loss: 9.2413\n",
      "Epoch [43300/100000], Loss: 9.2432\n",
      "Epoch [43310/100000], Loss: 9.2491\n",
      "Epoch [43320/100000], Loss: 9.2462\n",
      "Model saved at epoch 43329 with loss: 9.2404\n",
      "Model saved at epoch 43330 with loss: 9.2403\n",
      "Epoch [43330/100000], Loss: 9.2403\n",
      "Model saved at epoch 43334 with loss: 9.2394\n",
      "Epoch [43340/100000], Loss: 9.2424\n",
      "Model saved at epoch 43348 with loss: 9.2378\n",
      "Model saved at epoch 43350 with loss: 9.2367\n",
      "Epoch [43350/100000], Loss: 9.2367\n",
      "Model saved at epoch 43352 with loss: 9.2354\n",
      "Model saved at epoch 43357 with loss: 9.2352\n",
      "Epoch [43360/100000], Loss: 9.2418\n",
      "Epoch [43370/100000], Loss: 9.2379\n",
      "Epoch [43380/100000], Loss: 9.2389\n",
      "Model saved at epoch 43388 with loss: 9.2334\n",
      "Model saved at epoch 43389 with loss: 9.2310\n",
      "Model saved at epoch 43390 with loss: 9.2308\n",
      "Epoch [43390/100000], Loss: 9.2308\n",
      "Model saved at epoch 43391 with loss: 9.2299\n",
      "Model saved at epoch 43392 with loss: 9.2290\n",
      "Model saved at epoch 43393 with loss: 9.2278\n",
      "Model saved at epoch 43396 with loss: 9.2271\n",
      "Model saved at epoch 43397 with loss: 9.2252\n",
      "Epoch [43400/100000], Loss: 9.2262\n",
      "Epoch [43410/100000], Loss: 9.2277\n",
      "Model saved at epoch 43411 with loss: 9.2242\n",
      "Model saved at epoch 43418 with loss: 9.2230\n",
      "Model saved at epoch 43420 with loss: 9.2218\n",
      "Epoch [43420/100000], Loss: 9.2218\n",
      "Epoch [43430/100000], Loss: 9.2259\n",
      "Model saved at epoch 43440 with loss: 9.2162\n",
      "Epoch [43440/100000], Loss: 9.2162\n",
      "Model saved at epoch 43443 with loss: 9.2158\n",
      "Epoch [43450/100000], Loss: 9.2261\n",
      "Model saved at epoch 43455 with loss: 9.2145\n",
      "Model saved at epoch 43456 with loss: 9.2131\n",
      "Model saved at epoch 43457 with loss: 9.2109\n",
      "Epoch [43460/100000], Loss: 9.2118\n",
      "Epoch [43470/100000], Loss: 9.2182\n",
      "Model saved at epoch 43476 with loss: 9.2107\n",
      "Model saved at epoch 43478 with loss: 9.2101\n",
      "Epoch [43480/100000], Loss: 9.2125\n",
      "Model saved at epoch 43484 with loss: 9.2076\n",
      "Model saved at epoch 43486 with loss: 9.2062\n",
      "Model saved at epoch 43487 with loss: 9.2061\n",
      "Model saved at epoch 43488 with loss: 9.2058\n",
      "Model saved at epoch 43489 with loss: 9.2054\n",
      "Epoch [43490/100000], Loss: 9.2087\n",
      "Epoch [43500/100000], Loss: 9.2071\n",
      "Model saved at epoch 43503 with loss: 9.2046\n",
      "Epoch [43510/100000], Loss: 9.2050\n",
      "Model saved at epoch 43511 with loss: 9.2042\n",
      "Epoch [43520/100000], Loss: 9.2069\n",
      "Model saved at epoch 43525 with loss: 9.1996\n",
      "Model saved at epoch 43526 with loss: 9.1957\n",
      "Epoch [43530/100000], Loss: 9.1979\n",
      "Epoch [43540/100000], Loss: 9.2051\n",
      "Epoch [43550/100000], Loss: 9.1993\n",
      "Epoch [43560/100000], Loss: 9.1982\n",
      "Epoch [43570/100000], Loss: 9.2030\n",
      "Model saved at epoch 43573 with loss: 9.1955\n",
      "Model saved at epoch 43574 with loss: 9.1933\n",
      "Model saved at epoch 43576 with loss: 9.1917\n",
      "Model saved at epoch 43578 with loss: 9.1909\n",
      "Epoch [43580/100000], Loss: 9.1965\n",
      "Model saved at epoch 43584 with loss: 9.1903\n",
      "Epoch [43590/100000], Loss: 9.1957\n",
      "Epoch [43600/100000], Loss: 9.1954\n",
      "Model saved at epoch 43603 with loss: 9.1875\n",
      "Epoch [43610/100000], Loss: 9.1951\n",
      "Epoch [43620/100000], Loss: 9.1891\n",
      "Model saved at epoch 43627 with loss: 9.1866\n",
      "Model saved at epoch 43628 with loss: 9.1842\n",
      "Epoch [43630/100000], Loss: 9.1856\n",
      "Epoch [43640/100000], Loss: 9.1923\n",
      "Epoch [43650/100000], Loss: 9.1928\n",
      "Epoch [43660/100000], Loss: 9.1853\n",
      "Model saved at epoch 43664 with loss: 9.1828\n",
      "Model saved at epoch 43665 with loss: 9.1814\n",
      "Epoch [43670/100000], Loss: 9.1827\n",
      "Epoch [43680/100000], Loss: 9.1851\n",
      "Model saved at epoch 43684 with loss: 9.1805\n",
      "Model saved at epoch 43685 with loss: 9.1801\n",
      "Model saved at epoch 43686 with loss: 9.1770\n",
      "Model saved at epoch 43687 with loss: 9.1754\n",
      "Model saved at epoch 43689 with loss: 9.1748\n",
      "Model saved at epoch 43690 with loss: 9.1697\n",
      "Epoch [43690/100000], Loss: 9.1697\n",
      "Epoch [43700/100000], Loss: 9.1761\n",
      "Epoch [43710/100000], Loss: 9.1765\n",
      "Model saved at epoch 43717 with loss: 9.1697\n",
      "Model saved at epoch 43718 with loss: 9.1675\n",
      "Model saved at epoch 43719 with loss: 9.1652\n",
      "Epoch [43720/100000], Loss: 9.1702\n",
      "Epoch [43730/100000], Loss: 9.1718\n",
      "Model saved at epoch 43732 with loss: 9.1641\n",
      "Model saved at epoch 43736 with loss: 9.1626\n",
      "Epoch [43740/100000], Loss: 9.1649\n",
      "Model saved at epoch 43741 with loss: 9.1623\n",
      "Epoch [43750/100000], Loss: 9.1679\n",
      "Model saved at epoch 43752 with loss: 9.1620\n",
      "Model saved at epoch 43755 with loss: 9.1612\n",
      "Model saved at epoch 43758 with loss: 9.1607\n",
      "Model saved at epoch 43759 with loss: 9.1597\n",
      "Epoch [43760/100000], Loss: 9.1618\n",
      "Model saved at epoch 43767 with loss: 9.1596\n",
      "Model saved at epoch 43768 with loss: 9.1581\n",
      "Epoch [43770/100000], Loss: 9.1592\n",
      "Model saved at epoch 43773 with loss: 9.1575\n",
      "Epoch [43780/100000], Loss: 9.1590\n",
      "Model saved at epoch 43783 with loss: 9.1557\n",
      "Model saved at epoch 43785 with loss: 9.1533\n",
      "Epoch [43790/100000], Loss: 9.1581\n",
      "Epoch [43800/100000], Loss: 9.1607\n",
      "Model saved at epoch 43803 with loss: 9.1527\n",
      "Model saved at epoch 43804 with loss: 9.1504\n",
      "Epoch [43810/100000], Loss: 9.1584\n",
      "Model saved at epoch 43812 with loss: 9.1501\n",
      "Model saved at epoch 43818 with loss: 9.1490\n",
      "Model saved at epoch 43819 with loss: 9.1464\n",
      "Model saved at epoch 43820 with loss: 9.1459\n",
      "Epoch [43820/100000], Loss: 9.1459\n",
      "Epoch [43830/100000], Loss: 9.1509\n",
      "Epoch [43840/100000], Loss: 9.1511\n",
      "Epoch [43850/100000], Loss: 9.1486\n",
      "Epoch [43860/100000], Loss: 9.1470\n",
      "Model saved at epoch 43869 with loss: 9.1442\n",
      "Model saved at epoch 43870 with loss: 9.1429\n",
      "Epoch [43870/100000], Loss: 9.1429\n",
      "Model saved at epoch 43877 with loss: 9.1401\n",
      "Model saved at epoch 43879 with loss: 9.1392\n",
      "Epoch [43880/100000], Loss: 9.1417\n",
      "Model saved at epoch 43882 with loss: 9.1388\n",
      "Model saved at epoch 43883 with loss: 9.1363\n",
      "Model saved at epoch 43884 with loss: 9.1349\n",
      "Epoch [43890/100000], Loss: 9.1380\n",
      "Model saved at epoch 43899 with loss: 9.1345\n",
      "Model saved at epoch 43900 with loss: 9.1327\n",
      "Epoch [43900/100000], Loss: 9.1327\n",
      "Model saved at epoch 43904 with loss: 9.1324\n",
      "Model saved at epoch 43905 with loss: 9.1316\n",
      "Model saved at epoch 43906 with loss: 9.1284\n",
      "Epoch [43910/100000], Loss: 9.1342\n",
      "Epoch [43920/100000], Loss: 9.1325\n",
      "Epoch [43930/100000], Loss: 9.1319\n",
      "Model saved at epoch 43931 with loss: 9.1276\n",
      "Model saved at epoch 43932 with loss: 9.1240\n",
      "Model saved at epoch 43936 with loss: 9.1237\n",
      "Epoch [43940/100000], Loss: 9.1272\n",
      "Model saved at epoch 43949 with loss: 9.1222\n",
      "Epoch [43950/100000], Loss: 9.1246\n",
      "Model saved at epoch 43953 with loss: 9.1221\n",
      "Model saved at epoch 43956 with loss: 9.1221\n",
      "Model saved at epoch 43957 with loss: 9.1216\n",
      "Epoch [43960/100000], Loss: 9.1222\n",
      "Model saved at epoch 43969 with loss: 9.1187\n",
      "Model saved at epoch 43970 with loss: 9.1183\n",
      "Epoch [43970/100000], Loss: 9.1183\n",
      "Model saved at epoch 43975 with loss: 9.1168\n",
      "Model saved at epoch 43976 with loss: 9.1158\n",
      "Model saved at epoch 43979 with loss: 9.1145\n",
      "Epoch [43980/100000], Loss: 9.1218\n",
      "Model saved at epoch 43990 with loss: 9.1124\n",
      "Epoch [43990/100000], Loss: 9.1124\n",
      "Epoch [44000/100000], Loss: 9.1153\n",
      "Model saved at epoch 44001 with loss: 9.1116\n",
      "Model saved at epoch 44003 with loss: 9.1076\n",
      "Model saved at epoch 44006 with loss: 9.1070\n",
      "Epoch [44010/100000], Loss: 9.1104\n",
      "Model saved at epoch 44013 with loss: 9.1057\n",
      "Epoch [44020/100000], Loss: 9.1075\n",
      "Model saved at epoch 44021 with loss: 9.1031\n",
      "Model saved at epoch 44023 with loss: 9.1024\n",
      "Model saved at epoch 44026 with loss: 9.1015\n",
      "Model saved at epoch 44029 with loss: 9.0999\n",
      "Epoch [44030/100000], Loss: 9.1006\n",
      "Model saved at epoch 44038 with loss: 9.0983\n",
      "Epoch [44040/100000], Loss: 9.1013\n",
      "Model saved at epoch 44044 with loss: 9.0975\n",
      "Epoch [44050/100000], Loss: 9.1030\n",
      "Epoch [44060/100000], Loss: 9.1041\n",
      "Model saved at epoch 44067 with loss: 9.0958\n",
      "Model saved at epoch 44068 with loss: 9.0908\n",
      "Epoch [44070/100000], Loss: 9.0927\n",
      "Model saved at epoch 44080 with loss: 9.0882\n",
      "Epoch [44080/100000], Loss: 9.0882\n",
      "Model saved at epoch 44090 with loss: 9.0875\n",
      "Epoch [44090/100000], Loss: 9.0875\n",
      "Model saved at epoch 44091 with loss: 9.0870\n",
      "Epoch [44100/100000], Loss: 9.0934\n",
      "Model saved at epoch 44105 with loss: 9.0865\n",
      "Model saved at epoch 44106 with loss: 9.0844\n",
      "Model saved at epoch 44107 with loss: 9.0820\n",
      "Model saved at epoch 44108 with loss: 9.0815\n",
      "Epoch [44110/100000], Loss: 9.0905\n",
      "Epoch [44120/100000], Loss: 9.0865\n",
      "Model saved at epoch 44126 with loss: 9.0804\n",
      "Model saved at epoch 44129 with loss: 9.0802\n",
      "Epoch [44130/100000], Loss: 9.0825\n",
      "Model saved at epoch 44133 with loss: 9.0799\n",
      "Epoch [44140/100000], Loss: 9.0809\n",
      "Model saved at epoch 44141 with loss: 9.0796\n",
      "Model saved at epoch 44142 with loss: 9.0781\n",
      "Epoch [44150/100000], Loss: 9.0841\n",
      "Model saved at epoch 44153 with loss: 9.0778\n",
      "Model saved at epoch 44154 with loss: 9.0772\n",
      "Model saved at epoch 44155 with loss: 9.0770\n",
      "Model saved at epoch 44156 with loss: 9.0765\n",
      "Model saved at epoch 44157 with loss: 9.0736\n",
      "Model saved at epoch 44158 with loss: 9.0718\n",
      "Epoch [44160/100000], Loss: 9.0750\n",
      "Epoch [44170/100000], Loss: 9.0793\n",
      "Model saved at epoch 44176 with loss: 9.0700\n",
      "Epoch [44180/100000], Loss: 9.0713\n",
      "Model saved at epoch 44182 with loss: 9.0694\n",
      "Model saved at epoch 44184 with loss: 9.0675\n",
      "Model saved at epoch 44187 with loss: 9.0663\n",
      "Model saved at epoch 44188 with loss: 9.0636\n",
      "Epoch [44190/100000], Loss: 9.0698\n",
      "Model saved at epoch 44195 with loss: 9.0630\n",
      "Model saved at epoch 44196 with loss: 9.0604\n",
      "Epoch [44200/100000], Loss: 9.0648\n",
      "Epoch [44210/100000], Loss: 9.0630\n",
      "Model saved at epoch 44216 with loss: 9.0602\n",
      "Model saved at epoch 44217 with loss: 9.0587\n",
      "Model saved at epoch 44219 with loss: 9.0578\n",
      "Epoch [44220/100000], Loss: 9.0591\n",
      "Model saved at epoch 44221 with loss: 9.0570\n",
      "Model saved at epoch 44222 with loss: 9.0562\n",
      "Model saved at epoch 44224 with loss: 9.0555\n",
      "Model saved at epoch 44228 with loss: 9.0554\n",
      "Model saved at epoch 44229 with loss: 9.0547\n",
      "Model saved at epoch 44230 with loss: 9.0527\n",
      "Epoch [44230/100000], Loss: 9.0527\n",
      "Model saved at epoch 44231 with loss: 9.0494\n",
      "Epoch [44240/100000], Loss: 9.0532\n",
      "Model saved at epoch 44245 with loss: 9.0486\n",
      "Model saved at epoch 44247 with loss: 9.0482\n",
      "Epoch [44250/100000], Loss: 9.0533\n",
      "Epoch [44260/100000], Loss: 9.0554\n",
      "Epoch [44270/100000], Loss: 9.0519\n",
      "Model saved at epoch 44273 with loss: 9.0461\n",
      "Model saved at epoch 44274 with loss: 9.0460\n",
      "Model saved at epoch 44275 with loss: 9.0459\n",
      "Epoch [44280/100000], Loss: 9.0500\n",
      "Epoch [44290/100000], Loss: 9.0490\n",
      "Model saved at epoch 44296 with loss: 9.0446\n",
      "Model saved at epoch 44298 with loss: 9.0430\n",
      "Epoch [44300/100000], Loss: 9.0469\n",
      "Model saved at epoch 44303 with loss: 9.0416\n",
      "Model saved at epoch 44308 with loss: 9.0402\n",
      "Model saved at epoch 44310 with loss: 9.0396\n",
      "Epoch [44310/100000], Loss: 9.0396\n",
      "Model saved at epoch 44311 with loss: 9.0368\n",
      "Model saved at epoch 44312 with loss: 9.0363\n",
      "Epoch [44320/100000], Loss: 9.0373\n",
      "Model saved at epoch 44322 with loss: 9.0351\n",
      "Model saved at epoch 44324 with loss: 9.0346\n",
      "Model saved at epoch 44325 with loss: 9.0322\n",
      "Model saved at epoch 44329 with loss: 9.0304\n",
      "Epoch [44330/100000], Loss: 9.0344\n",
      "Epoch [44340/100000], Loss: 9.0392\n",
      "Epoch [44350/100000], Loss: 9.0358\n",
      "Epoch [44360/100000], Loss: 9.0307\n",
      "Model saved at epoch 44365 with loss: 9.0295\n",
      "Model saved at epoch 44366 with loss: 9.0290\n",
      "Model saved at epoch 44370 with loss: 9.0230\n",
      "Epoch [44370/100000], Loss: 9.0230\n",
      "Epoch [44380/100000], Loss: 9.0331\n",
      "Epoch [44390/100000], Loss: 9.0286\n",
      "Epoch [44400/100000], Loss: 9.0253\n",
      "Model saved at epoch 44403 with loss: 9.0222\n",
      "Model saved at epoch 44404 with loss: 9.0183\n",
      "Epoch [44410/100000], Loss: 9.0301\n",
      "Model saved at epoch 44420 with loss: 9.0172\n",
      "Epoch [44420/100000], Loss: 9.0172\n",
      "Model saved at epoch 44425 with loss: 9.0162\n",
      "Model saved at epoch 44427 with loss: 9.0154\n",
      "Epoch [44430/100000], Loss: 9.0170\n",
      "Model saved at epoch 44436 with loss: 9.0142\n",
      "Model saved at epoch 44437 with loss: 9.0133\n",
      "Model saved at epoch 44438 with loss: 9.0114\n",
      "Epoch [44440/100000], Loss: 9.0169\n",
      "Model saved at epoch 44447 with loss: 9.0110\n",
      "Epoch [44450/100000], Loss: 9.0136\n",
      "Model saved at epoch 44453 with loss: 9.0089\n",
      "Model saved at epoch 44455 with loss: 9.0077\n",
      "Model saved at epoch 44457 with loss: 9.0032\n",
      "Epoch [44460/100000], Loss: 9.0064\n",
      "Model saved at epoch 44461 with loss: 9.0027\n",
      "Model saved at epoch 44462 with loss: 9.0016\n",
      "Epoch [44470/100000], Loss: 9.0054\n",
      "Epoch [44480/100000], Loss: 9.0036\n",
      "Model saved at epoch 44485 with loss: 9.0012\n",
      "Model saved at epoch 44487 with loss: 8.9992\n",
      "Epoch [44490/100000], Loss: 8.9997\n",
      "Epoch [44500/100000], Loss: 9.0028\n",
      "Model saved at epoch 44510 with loss: 8.9989\n",
      "Epoch [44510/100000], Loss: 8.9989\n",
      "Model saved at epoch 44513 with loss: 8.9983\n",
      "Model saved at epoch 44520 with loss: 8.9978\n",
      "Epoch [44520/100000], Loss: 8.9978\n",
      "Model saved at epoch 44521 with loss: 8.9960\n",
      "Model saved at epoch 44523 with loss: 8.9946\n",
      "Model saved at epoch 44524 with loss: 8.9941\n",
      "Epoch [44530/100000], Loss: 8.9966\n",
      "Epoch [44540/100000], Loss: 9.0016\n",
      "Model saved at epoch 44544 with loss: 8.9932\n",
      "Model saved at epoch 44545 with loss: 8.9902\n",
      "Model saved at epoch 44547 with loss: 8.9890\n",
      "Epoch [44550/100000], Loss: 8.9937\n",
      "Model saved at epoch 44558 with loss: 8.9863\n",
      "Epoch [44560/100000], Loss: 8.9886\n",
      "Model saved at epoch 44561 with loss: 8.9844\n",
      "Model saved at epoch 44562 with loss: 8.9814\n",
      "Model saved at epoch 44563 with loss: 8.9808\n",
      "Model saved at epoch 44565 with loss: 8.9770\n",
      "Model saved at epoch 44566 with loss: 8.9769\n",
      "Model saved at epoch 44569 with loss: 8.9762\n",
      "Epoch [44570/100000], Loss: 8.9803\n",
      "Model saved at epoch 44571 with loss: 8.9761\n",
      "Epoch [44580/100000], Loss: 8.9769\n",
      "Model saved at epoch 44584 with loss: 8.9741\n",
      "Model saved at epoch 44590 with loss: 8.9735\n",
      "Epoch [44590/100000], Loss: 8.9735\n",
      "Model saved at epoch 44591 with loss: 8.9727\n",
      "Model saved at epoch 44592 with loss: 8.9727\n",
      "Model saved at epoch 44600 with loss: 8.9717\n",
      "Epoch [44600/100000], Loss: 8.9717\n",
      "Model saved at epoch 44608 with loss: 8.9693\n",
      "Model saved at epoch 44610 with loss: 8.9684\n",
      "Epoch [44610/100000], Loss: 8.9684\n",
      "Model saved at epoch 44613 with loss: 8.9675\n",
      "Model saved at epoch 44616 with loss: 8.9665\n",
      "Model saved at epoch 44617 with loss: 8.9664\n",
      "Model saved at epoch 44618 with loss: 8.9646\n",
      "Epoch [44620/100000], Loss: 8.9701\n",
      "Model saved at epoch 44623 with loss: 8.9619\n",
      "Model saved at epoch 44624 with loss: 8.9612\n",
      "Model saved at epoch 44625 with loss: 8.9590\n",
      "Epoch [44630/100000], Loss: 8.9591\n",
      "Model saved at epoch 44632 with loss: 8.9587\n",
      "Model saved at epoch 44634 with loss: 8.9580\n",
      "Model saved at epoch 44637 with loss: 8.9555\n",
      "Model saved at epoch 44638 with loss: 8.9548\n",
      "Epoch [44640/100000], Loss: 8.9622\n",
      "Model saved at epoch 44648 with loss: 8.9547\n",
      "Epoch [44650/100000], Loss: 8.9555\n",
      "Model saved at epoch 44651 with loss: 8.9546\n",
      "Model saved at epoch 44652 with loss: 8.9492\n",
      "Epoch [44660/100000], Loss: 8.9537\n",
      "Epoch [44670/100000], Loss: 8.9547\n",
      "Epoch [44680/100000], Loss: 8.9511\n",
      "Model saved at epoch 44681 with loss: 8.9478\n",
      "Model saved at epoch 44682 with loss: 8.9468\n",
      "Model saved at epoch 44685 with loss: 8.9465\n",
      "Model saved at epoch 44686 with loss: 8.9462\n",
      "Model saved at epoch 44690 with loss: 8.9454\n",
      "Epoch [44690/100000], Loss: 8.9454\n",
      "Model saved at epoch 44691 with loss: 8.9449\n",
      "Epoch [44700/100000], Loss: 8.9521\n",
      "Model saved at epoch 44708 with loss: 8.9433\n",
      "Epoch [44710/100000], Loss: 8.9483\n",
      "Model saved at epoch 44714 with loss: 8.9424\n",
      "Model saved at epoch 44715 with loss: 8.9387\n",
      "Model saved at epoch 44717 with loss: 8.9364\n",
      "Epoch [44720/100000], Loss: 8.9415\n",
      "Model saved at epoch 44721 with loss: 8.9336\n",
      "Model saved at epoch 44722 with loss: 8.9334\n",
      "Epoch [44730/100000], Loss: 8.9373\n",
      "Epoch [44740/100000], Loss: 8.9402\n",
      "Model saved at epoch 44748 with loss: 8.9321\n",
      "Epoch [44750/100000], Loss: 8.9353\n",
      "Model saved at epoch 44754 with loss: 8.9306\n",
      "Epoch [44760/100000], Loss: 8.9351\n",
      "Model saved at epoch 44768 with loss: 8.9297\n",
      "Epoch [44770/100000], Loss: 8.9313\n",
      "Model saved at epoch 44771 with loss: 8.9283\n",
      "Model saved at epoch 44776 with loss: 8.9268\n",
      "Model saved at epoch 44779 with loss: 8.9265\n",
      "Model saved at epoch 44780 with loss: 8.9257\n",
      "Epoch [44780/100000], Loss: 8.9257\n",
      "Model saved at epoch 44789 with loss: 8.9233\n",
      "Epoch [44790/100000], Loss: 8.9264\n",
      "Model saved at epoch 44792 with loss: 8.9229\n",
      "Model saved at epoch 44793 with loss: 8.9201\n",
      "Model saved at epoch 44796 with loss: 8.9192\n",
      "Epoch [44800/100000], Loss: 8.9241\n",
      "Model saved at epoch 44804 with loss: 8.9178\n",
      "Model saved at epoch 44805 with loss: 8.9163\n",
      "Model saved at epoch 44806 with loss: 8.9139\n",
      "Model saved at epoch 44808 with loss: 8.9124\n",
      "Epoch [44810/100000], Loss: 8.9143\n",
      "Epoch [44820/100000], Loss: 8.9162\n",
      "Model saved at epoch 44825 with loss: 8.9115\n",
      "Epoch [44830/100000], Loss: 8.9172\n",
      "Epoch [44840/100000], Loss: 8.9189\n",
      "Epoch [44850/100000], Loss: 8.9140\n",
      "Model saved at epoch 44852 with loss: 8.9088\n",
      "Model saved at epoch 44853 with loss: 8.9076\n",
      "Model saved at epoch 44855 with loss: 8.9056\n",
      "Epoch [44860/100000], Loss: 8.9128\n",
      "Model saved at epoch 44864 with loss: 8.9051\n",
      "Model saved at epoch 44867 with loss: 8.9018\n",
      "Model saved at epoch 44868 with loss: 8.9008\n",
      "Epoch [44870/100000], Loss: 8.9038\n",
      "Model saved at epoch 44872 with loss: 8.8993\n",
      "Model saved at epoch 44873 with loss: 8.8965\n",
      "Model saved at epoch 44874 with loss: 8.8943\n",
      "Epoch [44880/100000], Loss: 8.9054\n",
      "Epoch [44890/100000], Loss: 8.9001\n",
      "Epoch [44900/100000], Loss: 8.8978\n",
      "Model saved at epoch 44904 with loss: 8.8922\n",
      "Model saved at epoch 44905 with loss: 8.8910\n",
      "Model saved at epoch 44909 with loss: 8.8907\n",
      "Epoch [44910/100000], Loss: 8.8909\n",
      "Model saved at epoch 44912 with loss: 8.8906\n",
      "Model saved at epoch 44913 with loss: 8.8894\n",
      "Model saved at epoch 44918 with loss: 8.8888\n",
      "Model saved at epoch 44919 with loss: 8.8883\n",
      "Epoch [44920/100000], Loss: 8.8884\n",
      "Model saved at epoch 44921 with loss: 8.8862\n",
      "Model saved at epoch 44925 with loss: 8.8859\n",
      "Model saved at epoch 44926 with loss: 8.8854\n",
      "Epoch [44930/100000], Loss: 8.8894\n",
      "Model saved at epoch 44931 with loss: 8.8850\n",
      "Model saved at epoch 44932 with loss: 8.8838\n",
      "Epoch [44940/100000], Loss: 8.8926\n",
      "Model saved at epoch 44945 with loss: 8.8828\n",
      "Model saved at epoch 44946 with loss: 8.8811\n",
      "Epoch [44950/100000], Loss: 8.8830\n",
      "Model saved at epoch 44951 with loss: 8.8807\n",
      "Model saved at epoch 44957 with loss: 8.8763\n",
      "Epoch [44960/100000], Loss: 8.8807\n",
      "Epoch [44970/100000], Loss: 8.8825\n",
      "Model saved at epoch 44976 with loss: 8.8761\n",
      "Model saved at epoch 44977 with loss: 8.8737\n",
      "Model saved at epoch 44978 with loss: 8.8733\n",
      "Model saved at epoch 44979 with loss: 8.8722\n",
      "Epoch [44980/100000], Loss: 8.8748\n",
      "Model saved at epoch 44987 with loss: 8.8714\n",
      "Model saved at epoch 44988 with loss: 8.8685\n",
      "Epoch [44990/100000], Loss: 8.8707\n",
      "Model saved at epoch 44991 with loss: 8.8673\n",
      "Model saved at epoch 44992 with loss: 8.8653\n",
      "Model saved at epoch 44997 with loss: 8.8647\n",
      "Epoch [45000/100000], Loss: 8.8650\n",
      "Model saved at epoch 45003 with loss: 8.8641\n",
      "Model saved at epoch 45004 with loss: 8.8636\n",
      "Epoch [45010/100000], Loss: 8.8647\n",
      "Model saved at epoch 45014 with loss: 8.8627\n",
      "Model saved at epoch 45017 with loss: 8.8592\n",
      "Epoch [45020/100000], Loss: 8.8631\n",
      "Model saved at epoch 45021 with loss: 8.8576\n",
      "Model saved at epoch 45022 with loss: 8.8562\n",
      "Model saved at epoch 45023 with loss: 8.8544\n",
      "Model saved at epoch 45024 with loss: 8.8537\n",
      "Model saved at epoch 45026 with loss: 8.8512\n",
      "Epoch [45030/100000], Loss: 8.8527\n",
      "Epoch [45040/100000], Loss: 8.8529\n",
      "Model saved at epoch 45049 with loss: 8.8507\n",
      "Epoch [45050/100000], Loss: 8.8586\n",
      "Model saved at epoch 45056 with loss: 8.8491\n",
      "Model saved at epoch 45057 with loss: 8.8461\n",
      "Model saved at epoch 45058 with loss: 8.8429\n",
      "Epoch [45060/100000], Loss: 8.8457\n",
      "Model saved at epoch 45063 with loss: 8.8424\n",
      "Epoch [45070/100000], Loss: 8.8452\n",
      "Model saved at epoch 45072 with loss: 8.8416\n",
      "Model saved at epoch 45076 with loss: 8.8413\n",
      "Model saved at epoch 45077 with loss: 8.8389\n",
      "Epoch [45080/100000], Loss: 8.8417\n",
      "Model saved at epoch 45082 with loss: 8.8339\n",
      "Epoch [45090/100000], Loss: 8.8472\n",
      "Epoch [45100/100000], Loss: 8.8406\n",
      "Epoch [45110/100000], Loss: 8.8368\n",
      "Model saved at epoch 45117 with loss: 8.8335\n",
      "Model saved at epoch 45118 with loss: 8.8323\n",
      "Epoch [45120/100000], Loss: 8.8326\n",
      "Model saved at epoch 45124 with loss: 8.8315\n",
      "Model saved at epoch 45127 with loss: 8.8288\n",
      "Epoch [45130/100000], Loss: 8.8307\n",
      "Model saved at epoch 45131 with loss: 8.8263\n",
      "Model saved at epoch 45132 with loss: 8.8245\n",
      "Model saved at epoch 45133 with loss: 8.8225\n",
      "Model saved at epoch 45136 with loss: 8.8218\n",
      "Model saved at epoch 45140 with loss: 8.8204\n",
      "Epoch [45140/100000], Loss: 8.8204\n",
      "Model saved at epoch 45141 with loss: 8.8168\n",
      "Model saved at epoch 45150 with loss: 8.8155\n",
      "Epoch [45150/100000], Loss: 8.8155\n",
      "Model saved at epoch 45151 with loss: 8.8140\n",
      "Epoch [45160/100000], Loss: 9.7368\n",
      "Epoch [45170/100000], Loss: 255333584.0000\n",
      "Epoch [45180/100000], Loss: 2007843072.0000\n",
      "Epoch [45190/100000], Loss: 819167744.0000\n",
      "Epoch [45200/100000], Loss: 281326944.0000\n",
      "Epoch [45210/100000], Loss: 91667216.0000\n",
      "Epoch [45220/100000], Loss: 29381796.0000\n",
      "Epoch [45230/100000], Loss: 9176467.0000\n",
      "Epoch [45240/100000], Loss: 2826604.2500\n",
      "Epoch [45250/100000], Loss: 869274.3125\n",
      "Epoch [45260/100000], Loss: 269044.1875\n",
      "Epoch [45270/100000], Loss: 85537.0625\n",
      "Epoch [45280/100000], Loss: 27324.5195\n",
      "Epoch [45290/100000], Loss: 8769.9434\n",
      "Epoch [45300/100000], Loss: 2739.0759\n",
      "Epoch [45310/100000], Loss: 892.7281\n",
      "Epoch [45320/100000], Loss: 334.9740\n",
      "Epoch [45330/100000], Loss: 150.9548\n",
      "Epoch [45340/100000], Loss: 71.6789\n",
      "Epoch [45350/100000], Loss: 31.3197\n",
      "Epoch [45360/100000], Loss: 18.9712\n",
      "Epoch [45370/100000], Loss: 12.0560\n",
      "Epoch [45380/100000], Loss: 10.2105\n",
      "Epoch [45390/100000], Loss: 9.0392\n",
      "Epoch [45400/100000], Loss: 8.9607\n",
      "Epoch [45410/100000], Loss: 8.8720\n",
      "Epoch [45420/100000], Loss: 8.8640\n",
      "Epoch [45430/100000], Loss: 8.8630\n",
      "Epoch [45440/100000], Loss: 8.8510\n",
      "Epoch [45450/100000], Loss: 8.8543\n",
      "Epoch [45460/100000], Loss: 8.8521\n",
      "Epoch [45470/100000], Loss: 8.8507\n",
      "Epoch [45480/100000], Loss: 8.8488\n",
      "Epoch [45490/100000], Loss: 8.8498\n",
      "Epoch [45500/100000], Loss: 8.8488\n",
      "Epoch [45510/100000], Loss: 8.8454\n",
      "Epoch [45520/100000], Loss: 8.8485\n",
      "Epoch [45530/100000], Loss: 8.8463\n",
      "Epoch [45540/100000], Loss: 8.8473\n",
      "Epoch [45550/100000], Loss: 8.8517\n",
      "Epoch [45560/100000], Loss: 8.8502\n",
      "Epoch [45570/100000], Loss: 8.8461\n",
      "Epoch [45580/100000], Loss: 8.8476\n",
      "Epoch [45590/100000], Loss: 8.8471\n",
      "Epoch [45600/100000], Loss: 8.8516\n",
      "Epoch [45610/100000], Loss: 8.8503\n",
      "Epoch [45620/100000], Loss: 8.8520\n",
      "Epoch [45630/100000], Loss: 8.8500\n",
      "Epoch [45640/100000], Loss: 8.8510\n",
      "Epoch [45650/100000], Loss: 8.8510\n",
      "Epoch [45660/100000], Loss: 8.8516\n",
      "Epoch [45670/100000], Loss: 8.8514\n",
      "Epoch [45680/100000], Loss: 8.8468\n",
      "Epoch [45690/100000], Loss: 8.8459\n",
      "Epoch [45700/100000], Loss: 8.8460\n",
      "Epoch [45710/100000], Loss: 8.8475\n",
      "Epoch [45720/100000], Loss: 8.8497\n",
      "Epoch [45730/100000], Loss: 8.8507\n",
      "Epoch [45740/100000], Loss: 8.8495\n",
      "Epoch [45750/100000], Loss: 8.8493\n",
      "Epoch [45760/100000], Loss: 8.8512\n",
      "Epoch [45770/100000], Loss: 8.8505\n",
      "Epoch [45780/100000], Loss: 8.8502\n",
      "Epoch [45790/100000], Loss: 8.8460\n",
      "Epoch [45800/100000], Loss: 8.8445\n",
      "Epoch [45810/100000], Loss: 8.8462\n",
      "Epoch [45820/100000], Loss: 8.8450\n",
      "Epoch [45830/100000], Loss: 8.8419\n",
      "Epoch [45840/100000], Loss: 8.8441\n",
      "Epoch [45850/100000], Loss: 8.8420\n",
      "Epoch [45860/100000], Loss: 8.8400\n",
      "Epoch [45870/100000], Loss: 8.8404\n",
      "Epoch [45880/100000], Loss: 8.8394\n",
      "Epoch [45890/100000], Loss: 8.8391\n",
      "Epoch [45900/100000], Loss: 8.8379\n",
      "Epoch [45910/100000], Loss: 8.8364\n",
      "Epoch [45920/100000], Loss: 8.8355\n",
      "Epoch [45930/100000], Loss: 8.8361\n",
      "Epoch [45940/100000], Loss: 8.8367\n",
      "Epoch [45950/100000], Loss: 8.8371\n",
      "Epoch [45960/100000], Loss: 8.8365\n",
      "Epoch [45970/100000], Loss: 8.8387\n",
      "Epoch [45980/100000], Loss: 8.8371\n",
      "Epoch [45990/100000], Loss: 8.8364\n",
      "Epoch [46000/100000], Loss: 8.8339\n",
      "Epoch [46010/100000], Loss: 8.8346\n",
      "Epoch [46020/100000], Loss: 8.8368\n",
      "Epoch [46030/100000], Loss: 8.8322\n",
      "Epoch [46040/100000], Loss: 8.8311\n",
      "Epoch [46050/100000], Loss: 8.8344\n",
      "Epoch [46060/100000], Loss: 8.8278\n",
      "Epoch [46070/100000], Loss: 8.8261\n",
      "Epoch [46080/100000], Loss: 8.8299\n",
      "Epoch [46090/100000], Loss: 8.8290\n",
      "Epoch [46100/100000], Loss: 8.8324\n",
      "Epoch [46110/100000], Loss: 8.8319\n",
      "Epoch [46120/100000], Loss: 8.8333\n",
      "Epoch [46130/100000], Loss: 8.8292\n",
      "Epoch [46140/100000], Loss: 8.8313\n",
      "Epoch [46150/100000], Loss: 8.8300\n",
      "Epoch [46160/100000], Loss: 8.8323\n",
      "Epoch [46170/100000], Loss: 8.8286\n",
      "Epoch [46180/100000], Loss: 8.8270\n",
      "Epoch [46190/100000], Loss: 8.8234\n",
      "Epoch [46200/100000], Loss: 8.8207\n",
      "Epoch [46210/100000], Loss: 8.8240\n",
      "Epoch [46220/100000], Loss: 8.8281\n",
      "Epoch [46230/100000], Loss: 8.8246\n",
      "Epoch [46240/100000], Loss: 8.8252\n",
      "Epoch [46250/100000], Loss: 8.8241\n",
      "Epoch [46260/100000], Loss: 8.8242\n",
      "Epoch [46270/100000], Loss: 8.8225\n",
      "Epoch [46280/100000], Loss: 8.8275\n",
      "Epoch [46290/100000], Loss: 8.8318\n",
      "Epoch [46300/100000], Loss: 8.8271\n",
      "Epoch [46310/100000], Loss: 8.8271\n",
      "Epoch [46320/100000], Loss: 8.8245\n",
      "Epoch [46330/100000], Loss: 8.8255\n",
      "Epoch [46340/100000], Loss: 8.8281\n",
      "Epoch [46350/100000], Loss: 8.8294\n",
      "Epoch [46360/100000], Loss: 8.8270\n",
      "Epoch [46370/100000], Loss: 8.8264\n",
      "Epoch [46380/100000], Loss: 8.8298\n",
      "Epoch [46390/100000], Loss: 8.8233\n",
      "Epoch [46400/100000], Loss: 8.8216\n",
      "Epoch [46410/100000], Loss: 8.8185\n",
      "Epoch [46420/100000], Loss: 8.8225\n",
      "Epoch [46430/100000], Loss: 8.8253\n",
      "Epoch [46440/100000], Loss: 8.8226\n",
      "Epoch [46450/100000], Loss: 8.8215\n",
      "Epoch [46460/100000], Loss: 8.8213\n",
      "Epoch [46470/100000], Loss: 8.8199\n",
      "Epoch [46480/100000], Loss: 8.8218\n",
      "Epoch [46490/100000], Loss: 8.8239\n",
      "Epoch [46500/100000], Loss: 8.8237\n",
      "Epoch [46510/100000], Loss: 8.8243\n",
      "Epoch [46520/100000], Loss: 8.8282\n",
      "Epoch [46530/100000], Loss: 8.8281\n",
      "Epoch [46540/100000], Loss: 8.8237\n",
      "Epoch [46550/100000], Loss: 8.8260\n",
      "Epoch [46560/100000], Loss: 8.8230\n",
      "Epoch [46570/100000], Loss: 8.8206\n",
      "Epoch [46580/100000], Loss: 8.8204\n",
      "Epoch [46590/100000], Loss: 8.8216\n",
      "Epoch [46600/100000], Loss: 8.8185\n",
      "Epoch [46610/100000], Loss: 8.8199\n",
      "Epoch [46620/100000], Loss: 8.8221\n",
      "Epoch [46630/100000], Loss: 8.8262\n",
      "Epoch [46640/100000], Loss: 8.8231\n",
      "Epoch [46650/100000], Loss: 8.8248\n",
      "Epoch [46660/100000], Loss: 8.8212\n",
      "Epoch [46670/100000], Loss: 8.8198\n",
      "Epoch [46680/100000], Loss: 8.8199\n",
      "Epoch [46690/100000], Loss: 8.8182\n",
      "Epoch [46700/100000], Loss: 8.8179\n",
      "Epoch [46710/100000], Loss: 8.8211\n",
      "Epoch [46720/100000], Loss: 8.8215\n",
      "Epoch [46730/100000], Loss: 8.8226\n",
      "Epoch [46740/100000], Loss: 8.8219\n",
      "Epoch [46750/100000], Loss: 8.8180\n",
      "Epoch [46760/100000], Loss: 8.8176\n",
      "Epoch [46770/100000], Loss: 8.8146\n",
      "Model saved at epoch 46776 with loss: 8.8137\n",
      "Model saved at epoch 46777 with loss: 8.8136\n",
      "Model saved at epoch 46778 with loss: 8.8132\n",
      "Model saved at epoch 46779 with loss: 8.8124\n",
      "Model saved at epoch 46780 with loss: 8.8118\n",
      "Epoch [46780/100000], Loss: 8.8118\n",
      "Model saved at epoch 46783 with loss: 8.8107\n",
      "Model saved at epoch 46785 with loss: 8.8104\n",
      "Model saved at epoch 46786 with loss: 8.8096\n",
      "Model saved at epoch 46789 with loss: 8.8086\n",
      "Model saved at epoch 46790 with loss: 8.8085\n",
      "Epoch [46790/100000], Loss: 8.8085\n",
      "Model saved at epoch 46796 with loss: 8.8081\n",
      "Epoch [46800/100000], Loss: 8.8086\n",
      "Model saved at epoch 46801 with loss: 8.8075\n",
      "Model saved at epoch 46809 with loss: 8.8072\n",
      "Epoch [46810/100000], Loss: 8.8079\n",
      "Epoch [46820/100000], Loss: 8.8100\n",
      "Epoch [46830/100000], Loss: 8.8123\n",
      "Epoch [46840/100000], Loss: 8.8110\n",
      "Epoch [46850/100000], Loss: 8.8130\n",
      "Epoch [46860/100000], Loss: 8.8131\n",
      "Epoch [46870/100000], Loss: 8.8146\n",
      "Epoch [46880/100000], Loss: 8.8151\n",
      "Epoch [46890/100000], Loss: 8.8125\n",
      "Epoch [46900/100000], Loss: 8.8138\n",
      "Epoch [46910/100000], Loss: 8.8113\n",
      "Epoch [46920/100000], Loss: 8.8119\n",
      "Epoch [46930/100000], Loss: 8.8090\n",
      "Epoch [46940/100000], Loss: 8.8126\n",
      "Epoch [46950/100000], Loss: 8.8138\n",
      "Epoch [46960/100000], Loss: 8.8169\n",
      "Epoch [46970/100000], Loss: 8.8129\n",
      "Epoch [46980/100000], Loss: 8.8111\n",
      "Epoch [46990/100000], Loss: 8.8098\n",
      "Model saved at epoch 46998 with loss: 8.8069\n",
      "Epoch [47000/100000], Loss: 8.8076\n",
      "Epoch [47010/100000], Loss: 8.8083\n",
      "Epoch [47020/100000], Loss: 8.8084\n",
      "Epoch [47030/100000], Loss: 8.8072\n",
      "Model saved at epoch 47031 with loss: 8.8060\n",
      "Model saved at epoch 47038 with loss: 8.8060\n",
      "Model saved at epoch 47039 with loss: 8.8056\n",
      "Model saved at epoch 47040 with loss: 8.8043\n",
      "Epoch [47040/100000], Loss: 8.8043\n",
      "Model saved at epoch 47044 with loss: 8.8036\n",
      "Model saved at epoch 47045 with loss: 8.8027\n",
      "Epoch [47050/100000], Loss: 8.8055\n",
      "Model saved at epoch 47055 with loss: 8.8022\n",
      "Epoch [47060/100000], Loss: 8.8054\n",
      "Epoch [47070/100000], Loss: 8.8065\n",
      "Model saved at epoch 47074 with loss: 8.8020\n",
      "Model saved at epoch 47075 with loss: 8.8015\n",
      "Model saved at epoch 47076 with loss: 8.8013\n",
      "Model saved at epoch 47077 with loss: 8.8011\n",
      "Model saved at epoch 47078 with loss: 8.8008\n",
      "Model saved at epoch 47079 with loss: 8.7998\n",
      "Model saved at epoch 47080 with loss: 8.7995\n",
      "Epoch [47080/100000], Loss: 8.7995\n",
      "Epoch [47090/100000], Loss: 8.8053\n",
      "Epoch [47100/100000], Loss: 8.8032\n",
      "Model saved at epoch 47105 with loss: 8.7991\n",
      "Model saved at epoch 47106 with loss: 8.7982\n",
      "Model saved at epoch 47107 with loss: 8.7982\n",
      "Epoch [47110/100000], Loss: 8.7983\n",
      "Model saved at epoch 47117 with loss: 8.7967\n",
      "Model saved at epoch 47120 with loss: 8.7962\n",
      "Epoch [47120/100000], Loss: 8.7962\n",
      "Model saved at epoch 47121 with loss: 8.7959\n",
      "Model saved at epoch 47122 with loss: 8.7957\n",
      "Epoch [47130/100000], Loss: 8.7988\n",
      "Epoch [47140/100000], Loss: 8.7970\n",
      "Model saved at epoch 47147 with loss: 8.7954\n",
      "Epoch [47150/100000], Loss: 8.7978\n",
      "Epoch [47160/100000], Loss: 8.7960\n",
      "Epoch [47170/100000], Loss: 8.8001\n",
      "Epoch [47180/100000], Loss: 8.8022\n",
      "Epoch [47190/100000], Loss: 8.8058\n",
      "Epoch [47200/100000], Loss: 8.8051\n",
      "Epoch [47210/100000], Loss: 8.8045\n",
      "Epoch [47220/100000], Loss: 8.8024\n",
      "Epoch [47230/100000], Loss: 8.8026\n",
      "Epoch [47240/100000], Loss: 8.8006\n",
      "Epoch [47250/100000], Loss: 8.8005\n",
      "Epoch [47260/100000], Loss: 8.8014\n",
      "Epoch [47270/100000], Loss: 8.8015\n",
      "Epoch [47280/100000], Loss: 8.7985\n",
      "Epoch [47290/100000], Loss: 8.7983\n",
      "Model saved at epoch 47294 with loss: 8.7952\n",
      "Model saved at epoch 47295 with loss: 8.7948\n",
      "Model saved at epoch 47296 with loss: 8.7940\n",
      "Epoch [47300/100000], Loss: 8.7990\n",
      "Epoch [47310/100000], Loss: 8.7983\n",
      "Epoch [47320/100000], Loss: 8.8014\n",
      "Epoch [47330/100000], Loss: 8.7992\n",
      "Epoch [47340/100000], Loss: 8.7968\n",
      "Epoch [47350/100000], Loss: 8.7977\n",
      "Epoch [47360/100000], Loss: 8.7987\n",
      "Model saved at epoch 47366 with loss: 8.7938\n",
      "Model saved at epoch 47367 with loss: 8.7923\n",
      "Model saved at epoch 47369 with loss: 8.7917\n",
      "Model saved at epoch 47370 with loss: 8.7917\n",
      "Epoch [47370/100000], Loss: 8.7917\n",
      "Model saved at epoch 47373 with loss: 8.7908\n",
      "Model saved at epoch 47374 with loss: 8.7905\n",
      "Epoch [47380/100000], Loss: 8.7938\n",
      "Epoch [47390/100000], Loss: 8.7950\n",
      "Epoch [47400/100000], Loss: 8.7934\n",
      "Model saved at epoch 47408 with loss: 8.7905\n",
      "Epoch [47410/100000], Loss: 8.7939\n",
      "Epoch [47420/100000], Loss: 8.7936\n",
      "Epoch [47430/100000], Loss: 8.7926\n",
      "Model saved at epoch 47439 with loss: 8.7903\n",
      "Model saved at epoch 47440 with loss: 8.7892\n",
      "Epoch [47440/100000], Loss: 8.7892\n",
      "Model saved at epoch 47442 with loss: 8.7887\n",
      "Epoch [47450/100000], Loss: 8.7958\n",
      "Epoch [47460/100000], Loss: 8.7977\n",
      "Epoch [47470/100000], Loss: 8.7925\n",
      "Epoch [47480/100000], Loss: 8.7968\n",
      "Epoch [47490/100000], Loss: 8.7938\n",
      "Epoch [47500/100000], Loss: 8.7953\n",
      "Epoch [47510/100000], Loss: 8.7960\n",
      "Epoch [47520/100000], Loss: 8.7943\n",
      "Epoch [47530/100000], Loss: 8.7923\n",
      "Epoch [47540/100000], Loss: 8.7912\n",
      "Model saved at epoch 47542 with loss: 8.7885\n",
      "Model saved at epoch 47543 with loss: 8.7879\n",
      "Epoch [47550/100000], Loss: 8.7928\n",
      "Epoch [47560/100000], Loss: 8.7911\n",
      "Epoch [47570/100000], Loss: 8.7924\n",
      "Epoch [47580/100000], Loss: 8.7922\n",
      "Epoch [47590/100000], Loss: 8.7919\n",
      "Epoch [47600/100000], Loss: 8.7967\n",
      "Epoch [47610/100000], Loss: 8.7887\n",
      "Epoch [47620/100000], Loss: 8.7881\n",
      "Epoch [47630/100000], Loss: 8.7921\n",
      "Epoch [47640/100000], Loss: 8.7889\n",
      "Model saved at epoch 47649 with loss: 8.7870\n",
      "Model saved at epoch 47650 with loss: 8.7870\n",
      "Epoch [47650/100000], Loss: 8.7870\n",
      "Model saved at epoch 47651 with loss: 8.7856\n",
      "Epoch [47660/100000], Loss: 8.7872\n",
      "Epoch [47670/100000], Loss: 8.7887\n",
      "Epoch [47680/100000], Loss: 8.7900\n",
      "Epoch [47690/100000], Loss: 8.7882\n",
      "Epoch [47700/100000], Loss: 8.7914\n",
      "Epoch [47710/100000], Loss: 8.7926\n",
      "Model saved at epoch 47719 with loss: 8.7849\n",
      "Model saved at epoch 47720 with loss: 8.7842\n",
      "Epoch [47720/100000], Loss: 8.7842\n",
      "Model saved at epoch 47721 with loss: 8.7828\n",
      "Epoch [47730/100000], Loss: 8.7892\n",
      "Epoch [47740/100000], Loss: 8.7845\n",
      "Epoch [47750/100000], Loss: 8.7880\n",
      "Epoch [47760/100000], Loss: 8.7889\n",
      "Epoch [47770/100000], Loss: 8.7891\n",
      "Epoch [47780/100000], Loss: 8.7839\n",
      "Model saved at epoch 47785 with loss: 8.7826\n",
      "Model saved at epoch 47790 with loss: 8.7814\n",
      "Epoch [47790/100000], Loss: 8.7814\n",
      "Model saved at epoch 47791 with loss: 8.7788\n",
      "Epoch [47800/100000], Loss: 8.7803\n",
      "Epoch [47810/100000], Loss: 8.7789\n",
      "Epoch [47820/100000], Loss: 8.7832\n",
      "Model saved at epoch 47830 with loss: 8.7785\n",
      "Epoch [47830/100000], Loss: 8.7785\n",
      "Model saved at epoch 47837 with loss: 8.7784\n",
      "Model saved at epoch 47838 with loss: 8.7781\n",
      "Model saved at epoch 47839 with loss: 8.7780\n",
      "Epoch [47840/100000], Loss: 8.7802\n",
      "Model saved at epoch 47842 with loss: 8.7779\n",
      "Epoch [47850/100000], Loss: 8.7786\n",
      "Model saved at epoch 47853 with loss: 8.7774\n",
      "Model saved at epoch 47855 with loss: 8.7761\n",
      "Epoch [47860/100000], Loss: 8.7789\n",
      "Epoch [47870/100000], Loss: 8.7840\n",
      "Epoch [47880/100000], Loss: 8.7862\n",
      "Epoch [47890/100000], Loss: 8.7872\n",
      "Epoch [47900/100000], Loss: 8.7855\n",
      "Epoch [47910/100000], Loss: 8.7869\n",
      "Epoch [47920/100000], Loss: 8.7831\n",
      "Epoch [47930/100000], Loss: 8.7846\n",
      "Epoch [47940/100000], Loss: 8.7793\n",
      "Model saved at epoch 47944 with loss: 8.7758\n",
      "Epoch [47950/100000], Loss: 8.7787\n",
      "Epoch [47960/100000], Loss: 8.7805\n",
      "Epoch [47970/100000], Loss: 8.7824\n",
      "Epoch [47980/100000], Loss: 8.7796\n",
      "Epoch [47990/100000], Loss: 8.7813\n",
      "Epoch [48000/100000], Loss: 8.7818\n",
      "Epoch [48010/100000], Loss: 8.7793\n",
      "Epoch [48020/100000], Loss: 8.7786\n",
      "Model saved at epoch 48026 with loss: 8.7747\n",
      "Model saved at epoch 48028 with loss: 8.7746\n",
      "Epoch [48030/100000], Loss: 8.7756\n",
      "Model saved at epoch 48040 with loss: 8.7743\n",
      "Epoch [48040/100000], Loss: 8.7743\n",
      "Model saved at epoch 48041 with loss: 8.7738\n",
      "Model saved at epoch 48042 with loss: 8.7735\n",
      "Model saved at epoch 48045 with loss: 8.7721\n",
      "Model saved at epoch 48050 with loss: 8.7711\n",
      "Epoch [48050/100000], Loss: 8.7711\n",
      "Model saved at epoch 48052 with loss: 8.7685\n",
      "Model saved at epoch 48053 with loss: 8.7681\n",
      "Epoch [48060/100000], Loss: 8.7697\n",
      "Model saved at epoch 48064 with loss: 8.7668\n",
      "Epoch [48070/100000], Loss: 8.7697\n",
      "Model saved at epoch 48073 with loss: 8.7663\n",
      "Model saved at epoch 48074 with loss: 8.7662\n",
      "Epoch [48080/100000], Loss: 8.7723\n",
      "Epoch [48090/100000], Loss: 8.7708\n",
      "Model saved at epoch 48093 with loss: 8.7660\n",
      "Model saved at epoch 48094 with loss: 8.7657\n",
      "Model saved at epoch 48099 with loss: 8.7655\n",
      "Epoch [48100/100000], Loss: 8.7686\n",
      "Epoch [48110/100000], Loss: 8.7708\n",
      "Epoch [48120/100000], Loss: 8.7716\n",
      "Epoch [48130/100000], Loss: 8.7686\n",
      "Epoch [48140/100000], Loss: 8.7696\n",
      "Epoch [48150/100000], Loss: 8.7686\n",
      "Epoch [48160/100000], Loss: 8.7724\n",
      "Epoch [48170/100000], Loss: 8.7681\n",
      "Model saved at epoch 48173 with loss: 8.7651\n",
      "Model saved at epoch 48179 with loss: 8.7644\n",
      "Epoch [48180/100000], Loss: 8.7658\n",
      "Model saved at epoch 48185 with loss: 8.7642\n",
      "Model saved at epoch 48188 with loss: 8.7639\n",
      "Epoch [48190/100000], Loss: 8.7645\n",
      "Epoch [48200/100000], Loss: 8.7652\n",
      "Model saved at epoch 48201 with loss: 8.7635\n",
      "Model saved at epoch 48202 with loss: 8.7633\n",
      "Model saved at epoch 48203 with loss: 8.7628\n",
      "Model saved at epoch 48204 with loss: 8.7606\n",
      "Model saved at epoch 48207 with loss: 8.7601\n",
      "Epoch [48210/100000], Loss: 8.7638\n",
      "Epoch [48220/100000], Loss: 8.7617\n",
      "Model saved at epoch 48223 with loss: 8.7599\n",
      "Epoch [48230/100000], Loss: 8.7606\n",
      "Model saved at epoch 48231 with loss: 8.7597\n",
      "Model saved at epoch 48233 with loss: 8.7583\n",
      "Model saved at epoch 48234 with loss: 8.7570\n",
      "Epoch [48240/100000], Loss: 8.7600\n",
      "Model saved at epoch 48244 with loss: 8.7554\n",
      "Model saved at epoch 48245 with loss: 8.7549\n",
      "Epoch [48250/100000], Loss: 8.7583\n",
      "Epoch [48260/100000], Loss: 8.7579\n",
      "Epoch [48270/100000], Loss: 8.7582\n",
      "Epoch [48280/100000], Loss: 8.7606\n",
      "Model saved at epoch 48286 with loss: 8.7548\n",
      "Model saved at epoch 48287 with loss: 8.7546\n",
      "Model saved at epoch 48288 with loss: 8.7540\n",
      "Epoch [48290/100000], Loss: 8.7547\n",
      "Epoch [48300/100000], Loss: 8.7591\n",
      "Epoch [48310/100000], Loss: 8.7618\n",
      "Epoch [48320/100000], Loss: 8.7587\n",
      "Model saved at epoch 48330 with loss: 8.7539\n",
      "Epoch [48330/100000], Loss: 8.7539\n",
      "Model saved at epoch 48331 with loss: 8.7523\n",
      "Model saved at epoch 48335 with loss: 8.7520\n",
      "Model saved at epoch 48336 with loss: 8.7519\n",
      "Epoch [48340/100000], Loss: 8.7556\n",
      "Epoch [48350/100000], Loss: 8.7569\n",
      "Epoch [48360/100000], Loss: 8.7562\n",
      "Epoch [48370/100000], Loss: 8.7584\n",
      "Epoch [48380/100000], Loss: 8.7577\n",
      "Epoch [48390/100000], Loss: 8.7554\n",
      "Epoch [48400/100000], Loss: 8.7621\n",
      "Epoch [48410/100000], Loss: 8.7589\n",
      "Epoch [48420/100000], Loss: 8.7579\n",
      "Epoch [48430/100000], Loss: 8.7537\n",
      "Epoch [48440/100000], Loss: 8.7537\n",
      "Model saved at epoch 48449 with loss: 8.7513\n",
      "Epoch [48450/100000], Loss: 8.7533\n",
      "Model saved at epoch 48454 with loss: 8.7509\n",
      "Epoch [48460/100000], Loss: 8.7544\n",
      "Model saved at epoch 48469 with loss: 8.7505\n",
      "Model saved at epoch 48470 with loss: 8.7495\n",
      "Epoch [48470/100000], Loss: 8.7495\n",
      "Model saved at epoch 48471 with loss: 8.7487\n",
      "Model saved at epoch 48480 with loss: 8.7481\n",
      "Epoch [48480/100000], Loss: 8.7481\n",
      "Epoch [48490/100000], Loss: 8.7490\n",
      "Model saved at epoch 48497 with loss: 8.7477\n",
      "Model saved at epoch 48498 with loss: 8.7473\n",
      "Epoch [48500/100000], Loss: 8.7484\n",
      "Model saved at epoch 48504 with loss: 8.7469\n",
      "Model saved at epoch 48509 with loss: 8.7462\n",
      "Model saved at epoch 48510 with loss: 8.7460\n",
      "Epoch [48510/100000], Loss: 8.7460\n",
      "Model saved at epoch 48514 with loss: 8.7455\n",
      "Model saved at epoch 48518 with loss: 8.7448\n",
      "Epoch [48520/100000], Loss: 8.7455\n",
      "Model saved at epoch 48525 with loss: 8.7448\n",
      "Model saved at epoch 48526 with loss: 8.7442\n",
      "Model saved at epoch 48528 with loss: 8.7441\n",
      "Model saved at epoch 48529 with loss: 8.7434\n",
      "Epoch [48530/100000], Loss: 8.7439\n",
      "Model saved at epoch 48531 with loss: 8.7420\n",
      "Epoch [48540/100000], Loss: 8.7436\n",
      "Epoch [48550/100000], Loss: 8.7449\n",
      "Epoch [48560/100000], Loss: 8.7485\n",
      "Epoch [48570/100000], Loss: 8.7514\n",
      "Epoch [48580/100000], Loss: 8.7500\n",
      "Epoch [48590/100000], Loss: 8.7493\n",
      "Epoch [48600/100000], Loss: 8.7454\n",
      "Epoch [48610/100000], Loss: 8.7461\n",
      "Epoch [48620/100000], Loss: 8.7452\n",
      "Model saved at epoch 48629 with loss: 8.7418\n",
      "Model saved at epoch 48630 with loss: 8.7415\n",
      "Epoch [48630/100000], Loss: 8.7415\n",
      "Model saved at epoch 48638 with loss: 8.7406\n",
      "Model saved at epoch 48639 with loss: 8.7403\n",
      "Model saved at epoch 48640 with loss: 8.7400\n",
      "Epoch [48640/100000], Loss: 8.7400\n",
      "Epoch [48650/100000], Loss: 8.7464\n",
      "Epoch [48660/100000], Loss: 8.7463\n",
      "Epoch [48670/100000], Loss: 8.7420\n",
      "Model saved at epoch 48679 with loss: 8.7397\n",
      "Model saved at epoch 48680 with loss: 8.7395\n",
      "Epoch [48680/100000], Loss: 8.7395\n",
      "Model saved at epoch 48681 with loss: 8.7387\n",
      "Model saved at epoch 48683 with loss: 8.7377\n",
      "Model saved at epoch 48684 with loss: 8.7367\n",
      "Model saved at epoch 48685 with loss: 8.7361\n",
      "Epoch [48690/100000], Loss: 8.7362\n",
      "Model saved at epoch 48693 with loss: 8.7350\n",
      "Model saved at epoch 48694 with loss: 8.7340\n",
      "Epoch [48700/100000], Loss: 8.7403\n",
      "Epoch [48710/100000], Loss: 8.7378\n",
      "Model saved at epoch 48712 with loss: 8.7310\n",
      "Epoch [48720/100000], Loss: 8.7362\n",
      "Epoch [48730/100000], Loss: 8.7373\n",
      "Epoch [48740/100000], Loss: 8.7400\n",
      "Epoch [48750/100000], Loss: 8.7409\n",
      "Epoch [48760/100000], Loss: 8.7449\n",
      "Epoch [48770/100000], Loss: 8.7405\n",
      "Epoch [48780/100000], Loss: 8.7376\n",
      "Epoch [48790/100000], Loss: 8.7362\n",
      "Epoch [48800/100000], Loss: 8.7380\n",
      "Epoch [48810/100000], Loss: 8.7320\n",
      "Model saved at epoch 48813 with loss: 8.7305\n",
      "Model saved at epoch 48814 with loss: 8.7297\n",
      "Model saved at epoch 48816 with loss: 8.7285\n",
      "Epoch [48820/100000], Loss: 8.7308\n",
      "Model saved at epoch 48824 with loss: 8.7277\n",
      "Model saved at epoch 48826 with loss: 8.7274\n",
      "Model saved at epoch 48827 with loss: 8.7270\n",
      "Epoch [48830/100000], Loss: 8.7272\n",
      "Model saved at epoch 48833 with loss: 8.7249\n",
      "Model saved at epoch 48834 with loss: 8.7243\n",
      "Epoch [48840/100000], Loss: 8.7266\n",
      "Model saved at epoch 48842 with loss: 8.7224\n",
      "Epoch [48850/100000], Loss: 8.7308\n",
      "Epoch [48860/100000], Loss: 8.7312\n",
      "Epoch [48870/100000], Loss: 8.7288\n",
      "Epoch [48880/100000], Loss: 8.7287\n",
      "Epoch [48890/100000], Loss: 8.7287\n",
      "Epoch [48900/100000], Loss: 8.7251\n",
      "Epoch [48910/100000], Loss: 8.7230\n",
      "Epoch [48920/100000], Loss: 8.7273\n",
      "Epoch [48930/100000], Loss: 8.7258\n",
      "Epoch [48940/100000], Loss: 8.7283\n",
      "Epoch [48950/100000], Loss: 8.7255\n",
      "Model saved at epoch 48954 with loss: 8.7214\n",
      "Model saved at epoch 48955 with loss: 8.7206\n",
      "Model saved at epoch 48956 with loss: 8.7200\n",
      "Model saved at epoch 48957 with loss: 8.7197\n",
      "Model saved at epoch 48958 with loss: 8.7190\n",
      "Model saved at epoch 48959 with loss: 8.7190\n",
      "Model saved at epoch 48960 with loss: 8.7188\n",
      "Epoch [48960/100000], Loss: 8.7188\n",
      "Model saved at epoch 48961 with loss: 8.7163\n",
      "Model saved at epoch 48962 with loss: 8.7156\n",
      "Model saved at epoch 48963 with loss: 8.7144\n",
      "Model saved at epoch 48964 with loss: 8.7119\n",
      "Epoch [48970/100000], Loss: 8.7161\n",
      "Epoch [48980/100000], Loss: 8.7195\n",
      "Epoch [48990/100000], Loss: 8.7190\n",
      "Epoch [49000/100000], Loss: 8.7212\n",
      "Epoch [49010/100000], Loss: 8.7185\n",
      "Epoch [49020/100000], Loss: 8.7167\n",
      "Epoch [49030/100000], Loss: 8.7203\n",
      "Epoch [49040/100000], Loss: 8.7237\n",
      "Epoch [49050/100000], Loss: 8.7202\n",
      "Epoch [49060/100000], Loss: 8.7137\n",
      "Model saved at epoch 49064 with loss: 8.7117\n",
      "Model saved at epoch 49066 with loss: 8.7115\n",
      "Epoch [49070/100000], Loss: 8.7118\n",
      "Model saved at epoch 49072 with loss: 8.7105\n",
      "Model saved at epoch 49074 with loss: 8.7102\n",
      "Model saved at epoch 49077 with loss: 8.7066\n",
      "Model saved at epoch 49078 with loss: 8.7045\n",
      "Model saved at epoch 49079 with loss: 8.7042\n",
      "Model saved at epoch 49080 with loss: 8.7023\n",
      "Epoch [49080/100000], Loss: 8.7023\n",
      "Epoch [49090/100000], Loss: 8.7081\n",
      "Epoch [49100/100000], Loss: 8.7060\n",
      "Epoch [49110/100000], Loss: 8.7034\n",
      "Epoch [49120/100000], Loss: 8.7103\n",
      "Epoch [49130/100000], Loss: 8.7131\n",
      "Epoch [49140/100000], Loss: 8.7145\n",
      "Epoch [49150/100000], Loss: 8.7132\n",
      "Epoch [49160/100000], Loss: 8.7169\n",
      "Epoch [49170/100000], Loss: 8.7084\n",
      "Epoch [49180/100000], Loss: 8.7104\n",
      "Epoch [49190/100000], Loss: 8.7083\n",
      "Epoch [49200/100000], Loss: 8.7140\n",
      "Epoch [49210/100000], Loss: 8.7069\n",
      "Epoch [49220/100000], Loss: 8.7051\n",
      "Model saved at epoch 49227 with loss: 8.7020\n",
      "Model saved at epoch 49229 with loss: 8.7018\n",
      "Model saved at epoch 49230 with loss: 8.7014\n",
      "Epoch [49230/100000], Loss: 8.7014\n",
      "Epoch [49240/100000], Loss: 8.7027\n",
      "Model saved at epoch 49250 with loss: 8.7007\n",
      "Epoch [49250/100000], Loss: 8.7007\n",
      "Model saved at epoch 49251 with loss: 8.6989\n",
      "Model saved at epoch 49254 with loss: 8.6971\n",
      "Model saved at epoch 49255 with loss: 8.6971\n",
      "Model saved at epoch 49257 with loss: 8.6956\n",
      "Epoch [49260/100000], Loss: 8.7018\n",
      "Epoch [49270/100000], Loss: 8.7039\n",
      "Epoch [49280/100000], Loss: 8.7014\n",
      "Epoch [49290/100000], Loss: 8.6960\n",
      "Epoch [49300/100000], Loss: 8.7053\n",
      "Epoch [49310/100000], Loss: 8.7040\n",
      "Epoch [49320/100000], Loss: 8.7010\n",
      "Epoch [49330/100000], Loss: 8.7011\n",
      "Epoch [49340/100000], Loss: 8.7009\n",
      "Model saved at epoch 49346 with loss: 8.6947\n",
      "Epoch [49350/100000], Loss: 8.6973\n",
      "Epoch [49360/100000], Loss: 8.6977\n",
      "Model saved at epoch 49365 with loss: 8.6921\n",
      "Epoch [49370/100000], Loss: 8.6940\n",
      "Epoch [49380/100000], Loss: 8.6950\n",
      "Epoch [49390/100000], Loss: 8.6979\n",
      "Model saved at epoch 49395 with loss: 8.6912\n",
      "Model saved at epoch 49397 with loss: 8.6894\n",
      "Model saved at epoch 49399 with loss: 8.6883\n",
      "Epoch [49400/100000], Loss: 8.6901\n",
      "Epoch [49410/100000], Loss: 8.6935\n",
      "Epoch [49420/100000], Loss: 8.6949\n",
      "Epoch [49430/100000], Loss: 8.6908\n",
      "Model saved at epoch 49440 with loss: 8.6878\n",
      "Epoch [49440/100000], Loss: 8.6878\n",
      "Model saved at epoch 49442 with loss: 8.6874\n",
      "Model saved at epoch 49447 with loss: 8.6861\n",
      "Model saved at epoch 49448 with loss: 8.6860\n",
      "Model saved at epoch 49449 with loss: 8.6858\n",
      "Epoch [49450/100000], Loss: 8.6873\n",
      "Epoch [49460/100000], Loss: 8.6885\n",
      "Epoch [49470/100000], Loss: 8.6883\n",
      "Epoch [49480/100000], Loss: 8.6923\n",
      "Epoch [49490/100000], Loss: 8.6920\n",
      "Epoch [49500/100000], Loss: 8.6885\n",
      "Epoch [49510/100000], Loss: 8.6930\n",
      "Epoch [49520/100000], Loss: 8.6898\n",
      "Epoch [49530/100000], Loss: 8.6944\n",
      "Epoch [49540/100000], Loss: 8.6936\n",
      "Epoch [49550/100000], Loss: 8.6905\n",
      "Epoch [49560/100000], Loss: 8.6876\n",
      "Model saved at epoch 49562 with loss: 8.6849\n",
      "Model saved at epoch 49564 with loss: 8.6828\n",
      "Epoch [49570/100000], Loss: 8.6846\n",
      "Model saved at epoch 49580 with loss: 8.6821\n",
      "Epoch [49580/100000], Loss: 8.6821\n",
      "Model saved at epoch 49582 with loss: 8.6819\n",
      "Model saved at epoch 49583 with loss: 8.6815\n",
      "Model saved at epoch 49585 with loss: 8.6795\n",
      "Epoch [49590/100000], Loss: 8.6814\n",
      "Model saved at epoch 49594 with loss: 8.6791\n",
      "Model saved at epoch 49597 with loss: 8.6779\n",
      "Epoch [49600/100000], Loss: 8.6793\n",
      "Epoch [49610/100000], Loss: 8.6812\n",
      "Model saved at epoch 49614 with loss: 8.6770\n",
      "Model saved at epoch 49615 with loss: 8.6737\n",
      "Epoch [49620/100000], Loss: 8.6778\n",
      "Epoch [49630/100000], Loss: 8.6804\n",
      "Model saved at epoch 49639 with loss: 8.6725\n",
      "Model saved at epoch 49640 with loss: 8.6724\n",
      "Epoch [49640/100000], Loss: 8.6724\n",
      "Epoch [49650/100000], Loss: 8.6771\n",
      "Epoch [49660/100000], Loss: 8.6767\n",
      "Epoch [49670/100000], Loss: 8.6779\n",
      "Epoch [49680/100000], Loss: 8.6778\n",
      "Model saved at epoch 49686 with loss: 8.6722\n",
      "Model saved at epoch 49687 with loss: 8.6705\n",
      "Epoch [49690/100000], Loss: 8.6735\n",
      "Epoch [49700/100000], Loss: 8.6751\n",
      "Model saved at epoch 49709 with loss: 8.6690\n",
      "Epoch [49710/100000], Loss: 8.6733\n",
      "Epoch [49720/100000], Loss: 8.6787\n",
      "Epoch [49730/100000], Loss: 8.6722\n",
      "Model saved at epoch 49734 with loss: 8.6682\n",
      "Model saved at epoch 49735 with loss: 8.6680\n",
      "Model saved at epoch 49736 with loss: 8.6675\n",
      "Epoch [49740/100000], Loss: 8.6748\n",
      "Epoch [49750/100000], Loss: 8.6701\n",
      "Model saved at epoch 49755 with loss: 8.6668\n",
      "Epoch [49760/100000], Loss: 8.6701\n",
      "Epoch [49770/100000], Loss: 8.6701\n",
      "Epoch [49780/100000], Loss: 8.6683\n",
      "Model saved at epoch 49784 with loss: 8.6662\n",
      "Model saved at epoch 49785 with loss: 8.6650\n",
      "Epoch [49790/100000], Loss: 8.6707\n",
      "Epoch [49800/100000], Loss: 8.6685\n",
      "Epoch [49810/100000], Loss: 8.6666\n",
      "Model saved at epoch 49811 with loss: 8.6641\n",
      "Model saved at epoch 49812 with loss: 8.6631\n",
      "Model saved at epoch 49819 with loss: 8.6626\n",
      "Model saved at epoch 49820 with loss: 8.6616\n",
      "Epoch [49820/100000], Loss: 8.6616\n",
      "Model saved at epoch 49826 with loss: 8.6613\n",
      "Model saved at epoch 49828 with loss: 8.6604\n",
      "Model saved at epoch 49829 with loss: 8.6583\n",
      "Epoch [49830/100000], Loss: 8.6583\n",
      "Model saved at epoch 49831 with loss: 8.6576\n",
      "Epoch [49840/100000], Loss: 8.6629\n",
      "Epoch [49850/100000], Loss: 8.6626\n",
      "Model saved at epoch 49857 with loss: 8.6567\n",
      "Model saved at epoch 49858 with loss: 8.6539\n",
      "Epoch [49860/100000], Loss: 8.6555\n",
      "Epoch [49870/100000], Loss: 8.6615\n",
      "Epoch [49880/100000], Loss: 8.6606\n",
      "Epoch [49890/100000], Loss: 8.6574\n",
      "Model saved at epoch 49893 with loss: 8.6524\n",
      "Epoch [49900/100000], Loss: 8.6630\n",
      "Epoch [49910/100000], Loss: 8.6586\n",
      "Epoch [49920/100000], Loss: 8.6588\n",
      "Epoch [49930/100000], Loss: 8.6599\n",
      "Model saved at epoch 49938 with loss: 8.6520\n",
      "Model saved at epoch 49939 with loss: 8.6514\n",
      "Epoch [49940/100000], Loss: 8.6538\n",
      "Model saved at epoch 49943 with loss: 8.6505\n",
      "Epoch [49950/100000], Loss: 8.6566\n",
      "Model saved at epoch 49955 with loss: 8.6497\n",
      "Model saved at epoch 49956 with loss: 8.6480\n",
      "Model saved at epoch 49959 with loss: 8.6479\n",
      "Epoch [49960/100000], Loss: 8.6487\n",
      "Model saved at epoch 49963 with loss: 8.6474\n",
      "Model saved at epoch 49964 with loss: 8.6462\n",
      "Epoch [49970/100000], Loss: 8.6464\n",
      "Epoch [49980/100000], Loss: 8.6518\n",
      "Model saved at epoch 49983 with loss: 8.6454\n",
      "Model saved at epoch 49990 with loss: 8.6446\n",
      "Epoch [49990/100000], Loss: 8.6446\n",
      "Model saved at epoch 49992 with loss: 8.6444\n",
      "Model saved at epoch 49993 with loss: 8.6426\n",
      "Epoch [50000/100000], Loss: 8.6489\n",
      "Epoch [50010/100000], Loss: 8.6524\n",
      "Epoch [50020/100000], Loss: 8.6559\n",
      "Epoch [50030/100000], Loss: 8.6462\n",
      "Epoch [50040/100000], Loss: 8.6474\n",
      "Epoch [50050/100000], Loss: 8.6428\n",
      "Model saved at epoch 50056 with loss: 8.6421\n",
      "Model saved at epoch 50057 with loss: 8.6400\n",
      "Model saved at epoch 50058 with loss: 8.6396\n",
      "Epoch [50060/100000], Loss: 8.6409\n",
      "Model saved at epoch 50061 with loss: 8.6393\n",
      "Model saved at epoch 50062 with loss: 8.6387\n",
      "Model saved at epoch 50064 with loss: 8.6383\n",
      "Model saved at epoch 50065 with loss: 8.6369\n",
      "Model saved at epoch 50066 with loss: 8.6368\n",
      "Model saved at epoch 50068 with loss: 8.6367\n",
      "Epoch [50070/100000], Loss: 8.6387\n",
      "Model saved at epoch 50074 with loss: 8.6327\n",
      "Epoch [50080/100000], Loss: 8.6346\n",
      "Epoch [50090/100000], Loss: 8.6385\n",
      "Epoch [50100/100000], Loss: 8.6414\n",
      "Epoch [50110/100000], Loss: 8.6360\n",
      "Epoch [50120/100000], Loss: 8.6376\n",
      "Model saved at epoch 50124 with loss: 8.6316\n",
      "Epoch [50130/100000], Loss: 8.6325\n",
      "Model saved at epoch 50132 with loss: 8.6309\n",
      "Model saved at epoch 50135 with loss: 8.6302\n",
      "Model saved at epoch 50136 with loss: 8.6293\n",
      "Epoch [50140/100000], Loss: 8.6301\n",
      "Model saved at epoch 50141 with loss: 8.6288\n",
      "Model saved at epoch 50142 with loss: 8.6287\n",
      "Model saved at epoch 50143 with loss: 8.6276\n",
      "Model saved at epoch 50144 with loss: 8.6269\n",
      "Model saved at epoch 50145 with loss: 8.6262\n",
      "Model saved at epoch 50146 with loss: 8.6246\n",
      "Model saved at epoch 50147 with loss: 8.6224\n",
      "Model saved at epoch 50149 with loss: 8.6223\n",
      "Model saved at epoch 50150 with loss: 8.6212\n",
      "Epoch [50150/100000], Loss: 8.6212\n",
      "Epoch [50160/100000], Loss: 8.6247\n",
      "Epoch [50170/100000], Loss: 8.6282\n",
      "Epoch [50180/100000], Loss: 8.6283\n",
      "Epoch [50190/100000], Loss: 8.6249\n",
      "Model saved at epoch 50198 with loss: 8.6191\n",
      "Model saved at epoch 50200 with loss: 8.6187\n",
      "Epoch [50200/100000], Loss: 8.6187\n",
      "Model saved at epoch 50201 with loss: 8.6161\n",
      "Model saved at epoch 50204 with loss: 8.6160\n",
      "Epoch [50210/100000], Loss: 8.6207\n",
      "Epoch [50220/100000], Loss: 8.6265\n",
      "Epoch [50230/100000], Loss: 8.6236\n",
      "Epoch [50240/100000], Loss: 8.6218\n",
      "Epoch [50250/100000], Loss: 8.6173\n",
      "Epoch [50260/100000], Loss: 8.6178\n",
      "Model saved at epoch 50261 with loss: 8.6147\n",
      "Model saved at epoch 50262 with loss: 8.6140\n",
      "Epoch [50270/100000], Loss: 8.6166\n",
      "Epoch [50280/100000], Loss: 8.6155\n",
      "Epoch [50290/100000], Loss: 8.6165\n",
      "Model saved at epoch 50298 with loss: 8.6140\n",
      "Epoch [50300/100000], Loss: 8.6166\n",
      "Model saved at epoch 50304 with loss: 8.6116\n",
      "Model saved at epoch 50309 with loss: 8.6115\n",
      "Model saved at epoch 50310 with loss: 8.6086\n",
      "Epoch [50310/100000], Loss: 8.6086\n",
      "Model saved at epoch 50312 with loss: 8.6077\n",
      "Epoch [50320/100000], Loss: 8.6137\n",
      "Model saved at epoch 50329 with loss: 8.6075\n",
      "Epoch [50330/100000], Loss: 8.6104\n",
      "Model saved at epoch 50332 with loss: 8.6065\n",
      "Model saved at epoch 50336 with loss: 8.6063\n",
      "Model saved at epoch 50337 with loss: 8.6042\n",
      "Model saved at epoch 50338 with loss: 8.6034\n",
      "Model saved at epoch 50339 with loss: 8.6010\n",
      "Model saved at epoch 50340 with loss: 8.6001\n",
      "Epoch [50340/100000], Loss: 8.6001\n",
      "Model saved at epoch 50341 with loss: 8.5969\n",
      "Epoch [50350/100000], Loss: 8.6013\n",
      "Epoch [50360/100000], Loss: 8.5988\n",
      "Epoch [50370/100000], Loss: 8.6008\n",
      "Epoch [50380/100000], Loss: 8.6037\n",
      "Epoch [50390/100000], Loss: 8.6015\n",
      "Epoch [50400/100000], Loss: 8.6068\n",
      "Epoch [50410/100000], Loss: 8.6059\n",
      "Model saved at epoch 50418 with loss: 8.5967\n",
      "Epoch [50420/100000], Loss: 8.5983\n",
      "Epoch [50430/100000], Loss: 8.5999\n",
      "Epoch [50440/100000], Loss: 8.5971\n",
      "Model saved at epoch 50441 with loss: 8.5930\n",
      "Model saved at epoch 50442 with loss: 8.5921\n",
      "Epoch [50450/100000], Loss: 8.5923\n",
      "Model saved at epoch 50454 with loss: 8.5916\n",
      "Model saved at epoch 50455 with loss: 8.5910\n",
      "Model saved at epoch 50458 with loss: 8.5897\n",
      "Epoch [50460/100000], Loss: 8.5930\n",
      "Epoch [50470/100000], Loss: 8.5919\n",
      "Model saved at epoch 50474 with loss: 8.5874\n",
      "Model saved at epoch 50475 with loss: 8.5849\n",
      "Epoch [50480/100000], Loss: 8.5893\n",
      "Model saved at epoch 50489 with loss: 8.5839\n",
      "Epoch [50490/100000], Loss: 8.5852\n",
      "Model saved at epoch 50491 with loss: 8.5826\n",
      "Model saved at epoch 50492 with loss: 8.5823\n",
      "Epoch [50500/100000], Loss: 8.5889\n",
      "Model saved at epoch 50509 with loss: 8.5807\n",
      "Model saved at epoch 50510 with loss: 8.5801\n",
      "Epoch [50510/100000], Loss: 8.5801\n",
      "Model saved at epoch 50519 with loss: 8.5787\n",
      "Epoch [50520/100000], Loss: 8.5833\n",
      "Model saved at epoch 50530 with loss: 8.5784\n",
      "Epoch [50530/100000], Loss: 8.5784\n",
      "Model saved at epoch 50531 with loss: 8.5770\n",
      "Model saved at epoch 50532 with loss: 8.5757\n",
      "Model saved at epoch 50533 with loss: 8.5752\n",
      "Model saved at epoch 50534 with loss: 8.5736\n",
      "Epoch [50540/100000], Loss: 8.5799\n",
      "Epoch [50550/100000], Loss: 8.5773\n",
      "Model saved at epoch 50559 with loss: 8.5685\n",
      "Epoch [50560/100000], Loss: 8.5737\n",
      "Epoch [50570/100000], Loss: 8.5758\n",
      "Epoch [50580/100000], Loss: 8.5695\n",
      "Epoch [50590/100000], Loss: 8.5724\n",
      "Model saved at epoch 50593 with loss: 8.5666\n",
      "Model saved at epoch 50599 with loss: 8.5614\n",
      "Epoch [50600/100000], Loss: 8.5616\n",
      "Epoch [50610/100000], Loss: 8.5672\n",
      "Epoch [50620/100000], Loss: 8.5668\n",
      "Model saved at epoch 50628 with loss: 8.5609\n",
      "Epoch [50630/100000], Loss: 8.5648\n",
      "Epoch [50640/100000], Loss: 8.5674\n",
      "Epoch [50650/100000], Loss: 8.5627\n",
      "Model saved at epoch 50652 with loss: 8.5609\n",
      "Model saved at epoch 50654 with loss: 8.5604\n",
      "Model saved at epoch 50655 with loss: 8.5604\n",
      "Model saved at epoch 50656 with loss: 8.5595\n",
      "Model saved at epoch 50657 with loss: 8.5586\n",
      "Epoch [50660/100000], Loss: 8.5620\n",
      "Epoch [50670/100000], Loss: 8.5690\n",
      "Epoch [50680/100000], Loss: 8.5640\n",
      "Epoch [50690/100000], Loss: 8.5628\n",
      "Model saved at epoch 50693 with loss: 8.5576\n",
      "Model saved at epoch 50697 with loss: 8.5560\n",
      "Model saved at epoch 50698 with loss: 8.5560\n",
      "Epoch [50700/100000], Loss: 8.5618\n",
      "Model saved at epoch 50707 with loss: 8.5542\n",
      "Model saved at epoch 50708 with loss: 8.5533\n",
      "Model saved at epoch 50709 with loss: 8.5511\n",
      "Epoch [50710/100000], Loss: 8.5558\n",
      "Epoch [50720/100000], Loss: 8.5551\n",
      "Model saved at epoch 50724 with loss: 8.5499\n",
      "Epoch [50730/100000], Loss: 8.5595\n",
      "Epoch [50740/100000], Loss: 8.5562\n",
      "Model saved at epoch 50746 with loss: 8.5487\n",
      "Model saved at epoch 50747 with loss: 8.5452\n",
      "Epoch [50750/100000], Loss: 8.5519\n",
      "Epoch [50760/100000], Loss: 8.5558\n",
      "Epoch [50770/100000], Loss: 8.5543\n",
      "Epoch [50780/100000], Loss: 8.5507\n",
      "Epoch [50790/100000], Loss: 8.5564\n",
      "Epoch [50800/100000], Loss: 8.5561\n",
      "Epoch [50810/100000], Loss: 8.5521\n",
      "Model saved at epoch 50820 with loss: 8.5449\n",
      "Epoch [50820/100000], Loss: 8.5449\n",
      "Model saved at epoch 50822 with loss: 8.5441\n",
      "Model saved at epoch 50826 with loss: 8.5435\n",
      "Model saved at epoch 50827 with loss: 8.5415\n",
      "Model saved at epoch 50828 with loss: 8.5367\n",
      "Epoch [50830/100000], Loss: 8.5383\n",
      "Epoch [50840/100000], Loss: 8.5426\n",
      "Epoch [50850/100000], Loss: 8.5401\n",
      "Model saved at epoch 50857 with loss: 8.5355\n",
      "Epoch [50860/100000], Loss: 8.5372\n",
      "Epoch [50870/100000], Loss: 8.5382\n",
      "Model saved at epoch 50875 with loss: 8.5341\n",
      "Epoch [50880/100000], Loss: 8.5359\n",
      "Epoch [50890/100000], Loss: 8.5396\n",
      "Epoch [50900/100000], Loss: 8.5362\n",
      "Model saved at epoch 50906 with loss: 8.5317\n",
      "Model saved at epoch 50907 with loss: 8.5314\n",
      "Model saved at epoch 50908 with loss: 8.5313\n",
      "Epoch [50910/100000], Loss: 8.5330\n",
      "Epoch [50920/100000], Loss: 8.5335\n",
      "Epoch [50930/100000], Loss: 8.5379\n",
      "Epoch [50940/100000], Loss: 8.5358\n",
      "Model saved at epoch 50946 with loss: 8.5302\n",
      "Epoch [50950/100000], Loss: 8.5330\n",
      "Model saved at epoch 50951 with loss: 8.5296\n",
      "Model saved at epoch 50953 with loss: 8.5292\n",
      "Model saved at epoch 50954 with loss: 8.5292\n",
      "Model saved at epoch 50955 with loss: 8.5290\n",
      "Model saved at epoch 50956 with loss: 8.5286\n",
      "Model saved at epoch 50957 with loss: 8.5254\n",
      "Model saved at epoch 50958 with loss: 8.5238\n",
      "Model saved at epoch 50960 with loss: 8.5233\n",
      "Epoch [50960/100000], Loss: 8.5233\n",
      "Epoch [50970/100000], Loss: 8.5282\n",
      "Model saved at epoch 50980 with loss: 8.5211\n",
      "Epoch [50980/100000], Loss: 8.5211\n",
      "Epoch [50990/100000], Loss: 8.5245\n",
      "Epoch [51000/100000], Loss: 8.5262\n",
      "Model saved at epoch 51003 with loss: 8.5203\n",
      "Epoch [51010/100000], Loss: 8.5217\n",
      "Model saved at epoch 51011 with loss: 8.5176\n",
      "Model saved at epoch 51014 with loss: 8.5157\n",
      "Model saved at epoch 51015 with loss: 8.5155\n",
      "Model saved at epoch 51016 with loss: 8.5116\n",
      "Model saved at epoch 51018 with loss: 8.5114\n",
      "Epoch [51020/100000], Loss: 8.5122\n",
      "Model saved at epoch 51022 with loss: 8.5110\n",
      "Epoch [51030/100000], Loss: 8.5145\n",
      "Epoch [51040/100000], Loss: 8.5140\n",
      "Model saved at epoch 51043 with loss: 8.5098\n",
      "Model saved at epoch 51044 with loss: 8.5087\n",
      "Model saved at epoch 51050 with loss: 8.5083\n",
      "Epoch [51050/100000], Loss: 8.5083\n",
      "Epoch [51060/100000], Loss: 8.5151\n",
      "Model saved at epoch 51063 with loss: 8.5078\n",
      "Model saved at epoch 51070 with loss: 8.5076\n",
      "Epoch [51070/100000], Loss: 8.5076\n",
      "Model saved at epoch 51073 with loss: 8.5068\n",
      "Model saved at epoch 51074 with loss: 8.5059\n",
      "Epoch [51080/100000], Loss: 8.5072\n",
      "Model saved at epoch 51085 with loss: 8.5055\n",
      "Model saved at epoch 51089 with loss: 8.5042\n",
      "Model saved at epoch 51090 with loss: 8.5039\n",
      "Epoch [51090/100000], Loss: 8.5039\n",
      "Model saved at epoch 51091 with loss: 8.5033\n",
      "Epoch [51100/100000], Loss: 8.5098\n",
      "Epoch [51110/100000], Loss: 8.5063\n",
      "Model saved at epoch 51115 with loss: 8.5026\n",
      "Model saved at epoch 51116 with loss: 8.5011\n",
      "Epoch [51120/100000], Loss: 8.5059\n",
      "Model saved at epoch 51124 with loss: 8.5008\n",
      "Model saved at epoch 51126 with loss: 8.4979\n",
      "Epoch [51130/100000], Loss: 8.5013\n",
      "Epoch [51140/100000], Loss: 8.5030\n",
      "Epoch [51150/100000], Loss: 8.5001\n",
      "Model saved at epoch 51151 with loss: 8.4975\n",
      "Model saved at epoch 51153 with loss: 8.4957\n",
      "Epoch [51160/100000], Loss: 8.4971\n",
      "Model saved at epoch 51161 with loss: 8.4953\n",
      "Model saved at epoch 51162 with loss: 8.4931\n",
      "Model saved at epoch 51163 with loss: 8.4925\n",
      "Model saved at epoch 51164 with loss: 8.4922\n",
      "Model saved at epoch 51165 with loss: 8.4915\n",
      "Model saved at epoch 51166 with loss: 8.4910\n",
      "Model saved at epoch 51167 with loss: 8.4890\n",
      "Epoch [51170/100000], Loss: 8.4917\n",
      "Model saved at epoch 51177 with loss: 8.4875\n",
      "Epoch [51180/100000], Loss: 8.4904\n",
      "Model saved at epoch 51182 with loss: 8.4872\n",
      "Epoch [51190/100000], Loss: 8.4886\n",
      "Epoch [51200/100000], Loss: 8.4924\n",
      "Model saved at epoch 51210 with loss: 8.4870\n",
      "Epoch [51210/100000], Loss: 8.4870\n",
      "Model saved at epoch 51211 with loss: 8.4860\n",
      "Epoch [51220/100000], Loss: 8.4869\n",
      "Model saved at epoch 51223 with loss: 8.4860\n",
      "Epoch [51230/100000], Loss: 8.4890\n",
      "Model saved at epoch 51231 with loss: 8.4850\n",
      "Epoch [51240/100000], Loss: 8.4904\n",
      "Epoch [51250/100000], Loss: 8.4864\n",
      "Model saved at epoch 51251 with loss: 8.4823\n",
      "Model saved at epoch 51252 with loss: 8.4803\n",
      "Model saved at epoch 51256 with loss: 8.4790\n",
      "Epoch [51260/100000], Loss: 8.4820\n",
      "Model saved at epoch 51262 with loss: 8.4786\n",
      "Model saved at epoch 51265 with loss: 8.4778\n",
      "Epoch [51270/100000], Loss: 8.4833\n",
      "Epoch [51280/100000], Loss: 8.4851\n",
      "Epoch [51290/100000], Loss: 8.4840\n",
      "Model saved at epoch 51295 with loss: 8.4745\n",
      "Model saved at epoch 51296 with loss: 8.4729\n",
      "Model saved at epoch 51298 with loss: 8.4716\n",
      "Model saved at epoch 51299 with loss: 8.4710\n",
      "Epoch [51300/100000], Loss: 8.4744\n",
      "Epoch [51310/100000], Loss: 8.4775\n",
      "Epoch [51320/100000], Loss: 8.4772\n",
      "Epoch [51330/100000], Loss: 8.4769\n",
      "Epoch [51340/100000], Loss: 8.4722\n",
      "Model saved at epoch 51342 with loss: 8.4698\n",
      "Model saved at epoch 51347 with loss: 8.4679\n",
      "Epoch [51350/100000], Loss: 8.4692\n",
      "Model saved at epoch 51356 with loss: 8.4677\n",
      "Model saved at epoch 51357 with loss: 8.4671\n",
      "Epoch [51360/100000], Loss: 8.4688\n",
      "Model saved at epoch 51368 with loss: 8.4664\n",
      "Model saved at epoch 51369 with loss: 8.4653\n",
      "Epoch [51370/100000], Loss: 8.4663\n",
      "Model saved at epoch 51371 with loss: 8.4619\n",
      "Epoch [51380/100000], Loss: 8.4655\n",
      "Model saved at epoch 51382 with loss: 8.4608\n",
      "Epoch [51390/100000], Loss: 8.4681\n",
      "Epoch [51400/100000], Loss: 8.4631\n",
      "Model saved at epoch 51401 with loss: 8.4602\n",
      "Model saved at epoch 51402 with loss: 8.4580\n",
      "Model saved at epoch 51403 with loss: 8.4558\n",
      "Model saved at epoch 51407 with loss: 8.4549\n",
      "Model saved at epoch 51410 with loss: 8.4544\n",
      "Epoch [51410/100000], Loss: 8.4544\n",
      "Model saved at epoch 51413 with loss: 8.4533\n",
      "Epoch [51420/100000], Loss: 8.4606\n",
      "Epoch [51430/100000], Loss: 8.4544\n",
      "Model saved at epoch 51431 with loss: 8.4508\n",
      "Epoch [51440/100000], Loss: 8.4545\n",
      "Epoch [51450/100000], Loss: 8.4595\n",
      "Epoch [51460/100000], Loss: 8.4527\n",
      "Model saved at epoch 51463 with loss: 8.4507\n",
      "Model saved at epoch 51466 with loss: 8.4500\n",
      "Model saved at epoch 51467 with loss: 8.4480\n",
      "Epoch [51470/100000], Loss: 8.4483\n",
      "Model saved at epoch 51471 with loss: 8.4443\n",
      "Epoch [51480/100000], Loss: 8.4514\n",
      "Epoch [51490/100000], Loss: 8.4449\n",
      "Model saved at epoch 51494 with loss: 8.4439\n",
      "Model saved at epoch 51495 with loss: 8.4438\n",
      "Model saved at epoch 51497 with loss: 8.4435\n",
      "Model saved at epoch 51498 with loss: 8.4417\n",
      "Epoch [51500/100000], Loss: 8.4425\n",
      "Model saved at epoch 51501 with loss: 8.4412\n",
      "Model saved at epoch 51503 with loss: 8.4392\n",
      "Model saved at epoch 51509 with loss: 8.4376\n",
      "Epoch [51510/100000], Loss: 8.4393\n",
      "Model saved at epoch 51513 with loss: 8.4314\n",
      "Epoch [51520/100000], Loss: 8.4438\n",
      "Epoch [51530/100000], Loss: 3466647808.0000\n",
      "Epoch [51540/100000], Loss: 2151121152.0000\n",
      "Epoch [51550/100000], Loss: 559733184.0000\n",
      "Epoch [51560/100000], Loss: 93604136.0000\n",
      "Epoch [51570/100000], Loss: 19405434.0000\n",
      "Epoch [51580/100000], Loss: 11212111.0000\n",
      "Epoch [51590/100000], Loss: 7584161.0000\n",
      "Epoch [51600/100000], Loss: 3679101.0000\n",
      "Epoch [51610/100000], Loss: 1267073.8750\n",
      "Epoch [51620/100000], Loss: 262771.5312\n",
      "Epoch [51630/100000], Loss: 29492.2988\n",
      "Epoch [51640/100000], Loss: 15482.0938\n",
      "Epoch [51650/100000], Loss: 15851.8154\n",
      "Epoch [51660/100000], Loss: 7746.0562\n",
      "Epoch [51670/100000], Loss: 1856.0376\n",
      "Epoch [51680/100000], Loss: 237.1911\n",
      "Epoch [51690/100000], Loss: 136.7786\n",
      "Epoch [51700/100000], Loss: 119.8600\n",
      "Epoch [51710/100000], Loss: 37.9276\n",
      "Epoch [51720/100000], Loss: 9.2513\n",
      "Epoch [51730/100000], Loss: 9.5249\n",
      "Model saved at epoch 51736 with loss: 8.3446\n",
      "Epoch [51740/100000], Loss: 8.5374\n",
      "Epoch [51750/100000], Loss: 8.5027\n",
      "Model saved at epoch 51752 with loss: 8.3306\n",
      "Model saved at epoch 51757 with loss: 8.3248\n",
      "Epoch [51760/100000], Loss: 8.3277\n",
      "Model saved at epoch 51761 with loss: 8.2988\n",
      "Model saved at epoch 51762 with loss: 8.2979\n",
      "Model saved at epoch 51766 with loss: 8.2914\n",
      "Model saved at epoch 51767 with loss: 8.2839\n",
      "Epoch [51770/100000], Loss: 8.2930\n",
      "Model saved at epoch 51774 with loss: 8.2810\n",
      "Model saved at epoch 51775 with loss: 8.2747\n",
      "Model saved at epoch 51776 with loss: 8.2737\n",
      "Epoch [51780/100000], Loss: 8.2747\n",
      "Model saved at epoch 51781 with loss: 8.2676\n",
      "Model saved at epoch 51782 with loss: 8.2637\n",
      "Epoch [51790/100000], Loss: 8.2721\n",
      "Model saved at epoch 51798 with loss: 8.2635\n",
      "Epoch [51800/100000], Loss: 8.2653\n",
      "Model saved at epoch 51804 with loss: 8.2632\n",
      "Model saved at epoch 51806 with loss: 8.2617\n",
      "Model saved at epoch 51808 with loss: 8.2616\n",
      "Model saved at epoch 51809 with loss: 8.2610\n",
      "Model saved at epoch 51810 with loss: 8.2605\n",
      "Epoch [51810/100000], Loss: 8.2605\n",
      "Epoch [51820/100000], Loss: 8.2699\n",
      "Epoch [51830/100000], Loss: 8.2719\n",
      "Epoch [51840/100000], Loss: 8.2720\n",
      "Epoch [51850/100000], Loss: 8.2704\n",
      "Epoch [51860/100000], Loss: 8.2696\n",
      "Epoch [51870/100000], Loss: 8.2685\n",
      "Epoch [51880/100000], Loss: 8.2683\n",
      "Epoch [51890/100000], Loss: 8.2668\n",
      "Epoch [51900/100000], Loss: 8.2677\n",
      "Epoch [51910/100000], Loss: 8.2669\n",
      "Epoch [51920/100000], Loss: 8.2673\n",
      "Epoch [51930/100000], Loss: 8.2662\n",
      "Epoch [51940/100000], Loss: 8.2644\n",
      "Epoch [51950/100000], Loss: 8.2632\n",
      "Epoch [51960/100000], Loss: 8.2628\n",
      "Epoch [51970/100000], Loss: 8.2611\n",
      "Epoch [51980/100000], Loss: 8.2641\n",
      "Epoch [51990/100000], Loss: 8.2633\n",
      "Epoch [52000/100000], Loss: 8.2623\n",
      "Epoch [52010/100000], Loss: 8.2649\n",
      "Epoch [52020/100000], Loss: 8.2659\n",
      "Epoch [52030/100000], Loss: 8.2646\n",
      "Epoch [52040/100000], Loss: 8.2649\n",
      "Epoch [52050/100000], Loss: 8.2629\n",
      "Epoch [52060/100000], Loss: 8.2675\n",
      "Epoch [52070/100000], Loss: 8.2671\n",
      "Epoch [52080/100000], Loss: 8.2657\n",
      "Epoch [52090/100000], Loss: 8.2649\n",
      "Epoch [52100/100000], Loss: 8.2658\n",
      "Epoch [52110/100000], Loss: 8.2674\n",
      "Epoch [52120/100000], Loss: 8.2671\n",
      "Epoch [52130/100000], Loss: 8.2649\n",
      "Epoch [52140/100000], Loss: 8.2631\n",
      "Epoch [52150/100000], Loss: 8.2632\n",
      "Epoch [52160/100000], Loss: 8.2623\n",
      "Epoch [52170/100000], Loss: 8.2639\n",
      "Epoch [52180/100000], Loss: 8.2626\n",
      "Epoch [52190/100000], Loss: 8.2623\n",
      "Epoch [52200/100000], Loss: 8.2633\n",
      "Epoch [52210/100000], Loss: 8.2608\n",
      "Epoch [52220/100000], Loss: 8.2633\n",
      "Epoch [52230/100000], Loss: 8.2644\n",
      "Epoch [52240/100000], Loss: 8.2658\n",
      "Epoch [52250/100000], Loss: 8.2665\n",
      "Epoch [52260/100000], Loss: 8.2628\n",
      "Epoch [52270/100000], Loss: 8.2629\n",
      "Model saved at epoch 52280 with loss: 8.2604\n",
      "Epoch [52280/100000], Loss: 8.2604\n",
      "Model saved at epoch 52281 with loss: 8.2595\n",
      "Model saved at epoch 52282 with loss: 8.2590\n",
      "Model saved at epoch 52283 with loss: 8.2585\n",
      "Epoch [52290/100000], Loss: 8.2611\n",
      "Model saved at epoch 52299 with loss: 8.2582\n",
      "Model saved at epoch 52300 with loss: 8.2580\n",
      "Epoch [52300/100000], Loss: 8.2580\n",
      "Model saved at epoch 52301 with loss: 8.2579\n",
      "Model saved at epoch 52303 with loss: 8.2576\n",
      "Epoch [52310/100000], Loss: 8.2593\n",
      "Epoch [52320/100000], Loss: 8.2596\n",
      "Epoch [52330/100000], Loss: 8.2627\n",
      "Epoch [52340/100000], Loss: 8.2646\n",
      "Epoch [52350/100000], Loss: 8.2631\n",
      "Epoch [52360/100000], Loss: 8.2609\n",
      "Epoch [52370/100000], Loss: 8.2600\n",
      "Epoch [52380/100000], Loss: 8.2608\n",
      "Epoch [52390/100000], Loss: 8.2636\n",
      "Epoch [52400/100000], Loss: 8.2645\n",
      "Epoch [52410/100000], Loss: 8.2625\n",
      "Epoch [52420/100000], Loss: 8.2630\n",
      "Epoch [52430/100000], Loss: 8.2639\n",
      "Epoch [52440/100000], Loss: 8.2638\n",
      "Epoch [52450/100000], Loss: 8.2631\n",
      "Epoch [52460/100000], Loss: 8.2636\n",
      "Epoch [52470/100000], Loss: 8.2628\n",
      "Epoch [52480/100000], Loss: 8.2630\n",
      "Epoch [52490/100000], Loss: 8.2614\n",
      "Epoch [52500/100000], Loss: 8.2621\n",
      "Epoch [52510/100000], Loss: 8.2598\n",
      "Epoch [52520/100000], Loss: 8.2621\n",
      "Epoch [52530/100000], Loss: 8.2627\n",
      "Epoch [52540/100000], Loss: 8.2620\n",
      "Epoch [52550/100000], Loss: 8.2610\n",
      "Epoch [52560/100000], Loss: 8.2600\n",
      "Epoch [52570/100000], Loss: 8.2580\n",
      "Epoch [52580/100000], Loss: 8.2588\n",
      "Model saved at epoch 52582 with loss: 8.2571\n",
      "Model saved at epoch 52583 with loss: 8.2566\n",
      "Model saved at epoch 52587 with loss: 8.2565\n",
      "Epoch [52590/100000], Loss: 8.2578\n",
      "Model saved at epoch 52594 with loss: 8.2563\n",
      "Epoch [52600/100000], Loss: 8.2592\n",
      "Epoch [52610/100000], Loss: 8.2580\n",
      "Epoch [52620/100000], Loss: 8.2590\n",
      "Model saved at epoch 52628 with loss: 8.2563\n",
      "Model saved at epoch 52629 with loss: 8.2561\n",
      "Epoch [52630/100000], Loss: 8.2562\n",
      "Model saved at epoch 52632 with loss: 8.2561\n",
      "Model saved at epoch 52633 with loss: 8.2548\n",
      "Epoch [52640/100000], Loss: 8.2555\n",
      "Epoch [52650/100000], Loss: 8.2552\n",
      "Epoch [52660/100000], Loss: 8.2570\n",
      "Model saved at epoch 52663 with loss: 8.2534\n",
      "Model saved at epoch 52664 with loss: 8.2532\n",
      "Epoch [52670/100000], Loss: 8.2541\n",
      "Model saved at epoch 52675 with loss: 8.2520\n",
      "Model saved at epoch 52680 with loss: 8.2509\n",
      "Epoch [52680/100000], Loss: 8.2509\n",
      "Epoch [52690/100000], Loss: 8.2523\n",
      "Epoch [52700/100000], Loss: 8.2519\n",
      "Model saved at epoch 52701 with loss: 8.2509\n",
      "Model saved at epoch 52702 with loss: 8.2508\n",
      "Epoch [52710/100000], Loss: 8.2547\n",
      "Epoch [52720/100000], Loss: 8.2549\n",
      "Epoch [52730/100000], Loss: 8.2575\n",
      "Epoch [52740/100000], Loss: 8.2578\n",
      "Epoch [52750/100000], Loss: 8.2562\n",
      "Epoch [52760/100000], Loss: 8.2574\n",
      "Epoch [52770/100000], Loss: 8.2575\n",
      "Epoch [52780/100000], Loss: 8.2596\n",
      "Epoch [52790/100000], Loss: 8.2589\n",
      "Epoch [52800/100000], Loss: 8.2550\n",
      "Epoch [52810/100000], Loss: 8.2572\n",
      "Epoch [52820/100000], Loss: 8.2578\n",
      "Epoch [52830/100000], Loss: 8.2555\n",
      "Epoch [52840/100000], Loss: 8.2565\n",
      "Epoch [52850/100000], Loss: 8.2569\n",
      "Epoch [52860/100000], Loss: 8.2571\n",
      "Epoch [52870/100000], Loss: 8.2566\n",
      "Epoch [52880/100000], Loss: 8.2587\n",
      "Epoch [52890/100000], Loss: 8.2587\n",
      "Epoch [52900/100000], Loss: 8.2581\n",
      "Epoch [52910/100000], Loss: 8.2583\n",
      "Epoch [52920/100000], Loss: 8.2612\n",
      "Epoch [52930/100000], Loss: 8.2645\n",
      "Epoch [52940/100000], Loss: 8.2629\n",
      "Epoch [52950/100000], Loss: 8.2576\n",
      "Epoch [52960/100000], Loss: 8.2558\n",
      "Epoch [52970/100000], Loss: 8.2555\n",
      "Epoch [52980/100000], Loss: 8.2542\n",
      "Epoch [52990/100000], Loss: 8.2514\n",
      "Model saved at epoch 52994 with loss: 8.2505\n",
      "Model saved at epoch 52995 with loss: 8.2503\n",
      "Epoch [53000/100000], Loss: 8.2513\n",
      "Epoch [53010/100000], Loss: 8.2523\n",
      "Epoch [53020/100000], Loss: 8.2514\n",
      "Epoch [53030/100000], Loss: 8.2510\n",
      "Model saved at epoch 53039 with loss: 8.2502\n",
      "Epoch [53040/100000], Loss: 8.2506\n",
      "Epoch [53050/100000], Loss: 8.2505\n",
      "Model saved at epoch 53052 with loss: 8.2501\n",
      "Model saved at epoch 53053 with loss: 8.2501\n",
      "Epoch [53060/100000], Loss: 8.2513\n",
      "Model saved at epoch 53069 with loss: 8.2500\n",
      "Model saved at epoch 53070 with loss: 8.2492\n",
      "Epoch [53070/100000], Loss: 8.2492\n",
      "Model saved at epoch 53072 with loss: 8.2490\n",
      "Model saved at epoch 53073 with loss: 8.2480\n",
      "Epoch [53080/100000], Loss: 8.2500\n",
      "Model saved at epoch 53087 with loss: 8.2475\n",
      "Epoch [53090/100000], Loss: 8.2497\n",
      "Model saved at epoch 53097 with loss: 8.2462\n",
      "Model saved at epoch 53098 with loss: 8.2455\n",
      "Model saved at epoch 53100 with loss: 8.2455\n",
      "Epoch [53100/100000], Loss: 8.2455\n",
      "Model saved at epoch 53101 with loss: 8.2453\n",
      "Model saved at epoch 53103 with loss: 8.2450\n",
      "Epoch [53110/100000], Loss: 8.2462\n",
      "Model saved at epoch 53111 with loss: 8.2450\n",
      "Model saved at epoch 53112 with loss: 8.2446\n",
      "Model saved at epoch 53113 with loss: 8.2444\n",
      "Model saved at epoch 53114 with loss: 8.2441\n",
      "Epoch [53120/100000], Loss: 8.2456\n",
      "Model saved at epoch 53123 with loss: 8.2433\n",
      "Model saved at epoch 53124 with loss: 8.2433\n",
      "Epoch [53130/100000], Loss: 8.2467\n",
      "Epoch [53140/100000], Loss: 8.2445\n",
      "Model saved at epoch 53147 with loss: 8.2428\n",
      "Model saved at epoch 53148 with loss: 8.2427\n",
      "Epoch [53150/100000], Loss: 8.2427\n",
      "Epoch [53160/100000], Loss: 8.2467\n",
      "Epoch [53170/100000], Loss: 8.2451\n",
      "Epoch [53180/100000], Loss: 8.2455\n",
      "Epoch [53190/100000], Loss: 8.2467\n",
      "Epoch [53200/100000], Loss: 8.2475\n",
      "Epoch [53210/100000], Loss: 8.2498\n",
      "Epoch [53220/100000], Loss: 8.2474\n",
      "Epoch [53230/100000], Loss: 8.2477\n",
      "Epoch [53240/100000], Loss: 8.2473\n",
      "Epoch [53250/100000], Loss: 8.2486\n",
      "Epoch [53260/100000], Loss: 8.2496\n",
      "Epoch [53270/100000], Loss: 8.2505\n",
      "Epoch [53280/100000], Loss: 8.2508\n",
      "Epoch [53290/100000], Loss: 8.2498\n",
      "Epoch [53300/100000], Loss: 8.2478\n",
      "Epoch [53310/100000], Loss: 8.2452\n",
      "Epoch [53320/100000], Loss: 8.2470\n",
      "Epoch [53330/100000], Loss: 8.2478\n",
      "Epoch [53340/100000], Loss: 8.2454\n",
      "Epoch [53350/100000], Loss: 8.2434\n",
      "Epoch [53360/100000], Loss: 8.2440\n",
      "Epoch [53370/100000], Loss: 8.2447\n",
      "Epoch [53380/100000], Loss: 8.2456\n",
      "Epoch [53390/100000], Loss: 8.2458\n",
      "Model saved at epoch 53393 with loss: 8.2426\n",
      "Model saved at epoch 53397 with loss: 8.2425\n",
      "Model saved at epoch 53398 with loss: 8.2412\n",
      "Model saved at epoch 53400 with loss: 8.2408\n",
      "Epoch [53400/100000], Loss: 8.2408\n",
      "Model saved at epoch 53401 with loss: 8.2407\n",
      "Model saved at epoch 53404 with loss: 8.2399\n",
      "Model saved at epoch 53405 with loss: 8.2396\n",
      "Epoch [53410/100000], Loss: 8.2433\n",
      "Model saved at epoch 53420 with loss: 8.2396\n",
      "Epoch [53420/100000], Loss: 8.2396\n",
      "Model saved at epoch 53421 with loss: 8.2390\n",
      "Model saved at epoch 53423 with loss: 8.2382\n",
      "Model saved at epoch 53424 with loss: 8.2382\n",
      "Model saved at epoch 53426 with loss: 8.2378\n",
      "Epoch [53430/100000], Loss: 8.2396\n",
      "Epoch [53440/100000], Loss: 8.2420\n",
      "Epoch [53450/100000], Loss: 8.2415\n",
      "Epoch [53460/100000], Loss: 8.2391\n",
      "Epoch [53470/100000], Loss: 8.2398\n",
      "Epoch [53480/100000], Loss: 8.2407\n",
      "Epoch [53490/100000], Loss: 8.2444\n",
      "Epoch [53500/100000], Loss: 8.2429\n",
      "Epoch [53510/100000], Loss: 8.2442\n",
      "Epoch [53520/100000], Loss: 8.2415\n",
      "Epoch [53530/100000], Loss: 8.2397\n",
      "Epoch [53540/100000], Loss: 8.2390\n",
      "Epoch [53550/100000], Loss: 8.2401\n",
      "Model saved at epoch 53555 with loss: 8.2373\n",
      "Model saved at epoch 53556 with loss: 8.2370\n",
      "Model saved at epoch 53558 with loss: 8.2359\n",
      "Model saved at epoch 53559 with loss: 8.2357\n",
      "Epoch [53560/100000], Loss: 8.2359\n",
      "Model saved at epoch 53561 with loss: 8.2352\n",
      "Model saved at epoch 53562 with loss: 8.2342\n",
      "Model saved at epoch 53563 with loss: 8.2342\n",
      "Epoch [53570/100000], Loss: 8.2352\n",
      "Model saved at epoch 53571 with loss: 8.2335\n",
      "Epoch [53580/100000], Loss: 8.2357\n",
      "Epoch [53590/100000], Loss: 8.2346\n",
      "Epoch [53600/100000], Loss: 8.2372\n",
      "Epoch [53610/100000], Loss: 8.2358\n",
      "Epoch [53620/100000], Loss: 8.2369\n",
      "Epoch [53630/100000], Loss: 8.2384\n",
      "Epoch [53640/100000], Loss: 8.2359\n",
      "Epoch [53650/100000], Loss: 8.2357\n",
      "Epoch [53660/100000], Loss: 8.2366\n",
      "Epoch [53670/100000], Loss: 8.2379\n",
      "Epoch [53680/100000], Loss: 8.2352\n",
      "Epoch [53690/100000], Loss: 8.2378\n",
      "Epoch [53700/100000], Loss: 8.2352\n",
      "Epoch [53710/100000], Loss: 8.2377\n",
      "Epoch [53720/100000], Loss: 8.2373\n",
      "Epoch [53730/100000], Loss: 8.2342\n",
      "Model saved at epoch 53732 with loss: 8.2326\n",
      "Model saved at epoch 53733 with loss: 8.2323\n",
      "Model saved at epoch 53737 with loss: 8.2318\n",
      "Model saved at epoch 53738 with loss: 8.2316\n",
      "Model saved at epoch 53739 with loss: 8.2301\n",
      "Epoch [53740/100000], Loss: 8.2314\n",
      "Model saved at epoch 53744 with loss: 8.2299\n",
      "Epoch [53750/100000], Loss: 8.2301\n",
      "Epoch [53760/100000], Loss: 8.2324\n",
      "Model saved at epoch 53769 with loss: 8.2291\n",
      "Model saved at epoch 53770 with loss: 8.2282\n",
      "Epoch [53770/100000], Loss: 8.2282\n",
      "Model saved at epoch 53771 with loss: 8.2272\n",
      "Model saved at epoch 53772 with loss: 8.2272\n",
      "Model saved at epoch 53773 with loss: 8.2268\n",
      "Model saved at epoch 53775 with loss: 8.2261\n",
      "Model saved at epoch 53776 with loss: 8.2260\n",
      "Epoch [53780/100000], Loss: 8.2269\n",
      "Model saved at epoch 53786 with loss: 8.2258\n",
      "Epoch [53790/100000], Loss: 8.2286\n",
      "Epoch [53800/100000], Loss: 8.2290\n",
      "Epoch [53810/100000], Loss: 8.2286\n",
      "Epoch [53820/100000], Loss: 8.2303\n",
      "Epoch [53830/100000], Loss: 8.2305\n",
      "Epoch [53840/100000], Loss: 8.2319\n",
      "Epoch [53850/100000], Loss: 8.2301\n",
      "Epoch [53860/100000], Loss: 8.2277\n",
      "Epoch [53870/100000], Loss: 8.2268\n",
      "Epoch [53880/100000], Loss: 8.2287\n",
      "Epoch [53890/100000], Loss: 8.2274\n",
      "Epoch [53900/100000], Loss: 8.2284\n",
      "Epoch [53910/100000], Loss: 8.2278\n",
      "Model saved at epoch 53914 with loss: 8.2253\n",
      "Epoch [53920/100000], Loss: 8.2270\n",
      "Epoch [53930/100000], Loss: 8.2274\n",
      "Epoch [53940/100000], Loss: 8.2273\n",
      "Epoch [53950/100000], Loss: 8.2285\n",
      "Model saved at epoch 53959 with loss: 8.2252\n",
      "Epoch [53960/100000], Loss: 8.2257\n",
      "Model saved at epoch 53969 with loss: 8.2249\n",
      "Model saved at epoch 53970 with loss: 8.2239\n",
      "Epoch [53970/100000], Loss: 8.2239\n",
      "Model saved at epoch 53971 with loss: 8.2226\n",
      "Model saved at epoch 53973 with loss: 8.2218\n",
      "Epoch [53980/100000], Loss: 8.2235\n",
      "Epoch [53990/100000], Loss: 8.2261\n",
      "Epoch [54000/100000], Loss: 8.2281\n",
      "Epoch [54010/100000], Loss: 8.2270\n",
      "Epoch [54020/100000], Loss: 8.2263\n",
      "Epoch [54030/100000], Loss: 8.2273\n",
      "Epoch [54040/100000], Loss: 8.2300\n",
      "Epoch [54050/100000], Loss: 8.2273\n",
      "Epoch [54060/100000], Loss: 8.2271\n",
      "Epoch [54070/100000], Loss: 8.2283\n",
      "Epoch [54080/100000], Loss: 8.2282\n",
      "Epoch [54090/100000], Loss: 8.2293\n",
      "Epoch [54100/100000], Loss: 8.2283\n",
      "Epoch [54110/100000], Loss: 8.2264\n",
      "Epoch [54120/100000], Loss: 8.2239\n",
      "Epoch [54130/100000], Loss: 8.2260\n",
      "Epoch [54140/100000], Loss: 8.2252\n",
      "Epoch [54150/100000], Loss: 8.2243\n",
      "Epoch [54160/100000], Loss: 8.2241\n",
      "Epoch [54170/100000], Loss: 8.2237\n",
      "Model saved at epoch 54173 with loss: 8.2207\n",
      "Model saved at epoch 54176 with loss: 8.2205\n",
      "Model saved at epoch 54177 with loss: 8.2198\n",
      "Epoch [54180/100000], Loss: 8.2233\n",
      "Epoch [54190/100000], Loss: 8.2214\n",
      "Model saved at epoch 54198 with loss: 8.2195\n",
      "Model saved at epoch 54199 with loss: 8.2191\n",
      "Epoch [54200/100000], Loss: 8.2192\n",
      "Model saved at epoch 54201 with loss: 8.2189\n",
      "Model saved at epoch 54202 with loss: 8.2187\n",
      "Model saved at epoch 54203 with loss: 8.2183\n",
      "Model saved at epoch 54205 with loss: 8.2180\n",
      "Model saved at epoch 54206 with loss: 8.2177\n",
      "Epoch [54210/100000], Loss: 8.2181\n",
      "Model saved at epoch 54211 with loss: 8.2176\n",
      "Model saved at epoch 54212 with loss: 8.2171\n",
      "Model saved at epoch 54213 with loss: 8.2160\n",
      "Model saved at epoch 54214 with loss: 8.2159\n",
      "Model saved at epoch 54216 with loss: 8.2156\n",
      "Model saved at epoch 54218 with loss: 8.2148\n",
      "Model saved at epoch 54219 with loss: 8.2142\n",
      "Epoch [54220/100000], Loss: 8.2149\n",
      "Epoch [54230/100000], Loss: 8.2199\n",
      "Epoch [54240/100000], Loss: 8.2215\n",
      "Epoch [54250/100000], Loss: 8.2173\n",
      "Epoch [54260/100000], Loss: 8.2160\n",
      "Model saved at epoch 54263 with loss: 8.2142\n",
      "Model saved at epoch 54264 with loss: 8.2141\n",
      "Model saved at epoch 54265 with loss: 8.2133\n",
      "Model saved at epoch 54268 with loss: 8.2129\n",
      "Epoch [54270/100000], Loss: 8.2139\n",
      "Epoch [54280/100000], Loss: 8.2142\n",
      "Epoch [54290/100000], Loss: 8.2152\n",
      "Epoch [54300/100000], Loss: 8.2133\n",
      "Model saved at epoch 54301 with loss: 8.2128\n",
      "Model saved at epoch 54302 with loss: 8.2124\n",
      "Model saved at epoch 54303 with loss: 8.2113\n",
      "Epoch [54310/100000], Loss: 8.2141\n",
      "Epoch [54320/100000], Loss: 8.2160\n",
      "Epoch [54330/100000], Loss: 8.2122\n",
      "Model saved at epoch 54331 with loss: 8.2111\n",
      "Epoch [54340/100000], Loss: 8.2116\n",
      "Model saved at epoch 54341 with loss: 8.2108\n",
      "Epoch [54350/100000], Loss: 8.2136\n",
      "Model saved at epoch 54360 with loss: 8.2104\n",
      "Epoch [54360/100000], Loss: 8.2104\n",
      "Model saved at epoch 54361 with loss: 8.2083\n",
      "Model saved at epoch 54362 with loss: 8.2076\n",
      "Model saved at epoch 54363 with loss: 8.2063\n",
      "Epoch [54370/100000], Loss: 8.2120\n",
      "Epoch [54380/100000], Loss: 8.2116\n",
      "Epoch [54390/100000], Loss: 8.2099\n",
      "Epoch [54400/100000], Loss: 8.2100\n",
      "Epoch [54410/100000], Loss: 8.2111\n",
      "Epoch [54420/100000], Loss: 8.2070\n",
      "Model saved at epoch 54430 with loss: 8.2062\n",
      "Epoch [54430/100000], Loss: 8.2062\n",
      "Model saved at epoch 54431 with loss: 8.2061\n",
      "Model saved at epoch 54433 with loss: 8.2054\n",
      "Model saved at epoch 54436 with loss: 8.2039\n",
      "Epoch [54440/100000], Loss: 8.2085\n",
      "Epoch [54450/100000], Loss: 8.2087\n",
      "Epoch [54460/100000], Loss: 8.2095\n",
      "Epoch [54470/100000], Loss: 8.2075\n",
      "Epoch [54480/100000], Loss: 8.2059\n",
      "Epoch [54490/100000], Loss: 8.2058\n",
      "Model saved at epoch 54496 with loss: 8.2035\n",
      "Model saved at epoch 54497 with loss: 8.2034\n",
      "Model saved at epoch 54498 with loss: 8.2032\n",
      "Epoch [54500/100000], Loss: 8.2048\n",
      "Epoch [54510/100000], Loss: 8.2072\n",
      "Epoch [54520/100000], Loss: 8.2057\n",
      "Model saved at epoch 54522 with loss: 8.2032\n",
      "Model saved at epoch 54523 with loss: 8.2024\n",
      "Epoch [54530/100000], Loss: 8.2063\n",
      "Epoch [54540/100000], Loss: 8.2029\n",
      "Model saved at epoch 54541 with loss: 8.2020\n",
      "Epoch [54550/100000], Loss: 8.2042\n",
      "Epoch [54560/100000], Loss: 8.2050\n",
      "Epoch [54570/100000], Loss: 8.2048\n",
      "Epoch [54580/100000], Loss: 8.2053\n",
      "Model saved at epoch 54583 with loss: 8.2014\n",
      "Epoch [54590/100000], Loss: 8.2021\n",
      "Epoch [54600/100000], Loss: 8.2075\n",
      "Epoch [54610/100000], Loss: 8.2028\n",
      "Epoch [54620/100000], Loss: 8.2041\n",
      "Model saved at epoch 54629 with loss: 8.2010\n",
      "Epoch [54630/100000], Loss: 8.2012\n",
      "Epoch [54640/100000], Loss: 8.2050\n",
      "Epoch [54650/100000], Loss: 8.2018\n",
      "Model saved at epoch 54654 with loss: 8.2009\n",
      "Model saved at epoch 54655 with loss: 8.1999\n",
      "Epoch [54660/100000], Loss: 8.2024\n",
      "Epoch [54670/100000], Loss: 8.2033\n",
      "Epoch [54680/100000], Loss: 8.2028\n",
      "Model saved at epoch 54684 with loss: 8.1997\n",
      "Model saved at epoch 54685 with loss: 8.1986\n",
      "Model saved at epoch 54689 with loss: 8.1985\n",
      "Model saved at epoch 54690 with loss: 8.1975\n",
      "Epoch [54690/100000], Loss: 8.1975\n",
      "Model saved at epoch 54695 with loss: 8.1968\n",
      "Epoch [54700/100000], Loss: 8.2022\n",
      "Epoch [54710/100000], Loss: 8.2002\n",
      "Epoch [54720/100000], Loss: 8.2058\n",
      "Epoch [54730/100000], Loss: 8.2038\n",
      "Epoch [54740/100000], Loss: 8.2031\n",
      "Epoch [54750/100000], Loss: 8.2028\n",
      "Epoch [54760/100000], Loss: 8.2022\n",
      "Epoch [54770/100000], Loss: 8.1980\n",
      "Model saved at epoch 54777 with loss: 8.1950\n",
      "Model saved at epoch 54778 with loss: 8.1942\n",
      "Model saved at epoch 54779 with loss: 8.1937\n",
      "Epoch [54780/100000], Loss: 8.1949\n",
      "Epoch [54790/100000], Loss: 8.1992\n",
      "Epoch [54800/100000], Loss: 8.1954\n",
      "Model saved at epoch 54807 with loss: 8.1924\n",
      "Model saved at epoch 54808 with loss: 8.1907\n",
      "Model saved at epoch 54809 with loss: 8.1906\n",
      "Epoch [54810/100000], Loss: 8.1915\n",
      "Model saved at epoch 54815 with loss: 8.1902\n",
      "Epoch [54820/100000], Loss: 8.1925\n",
      "Epoch [54830/100000], Loss: 8.1926\n",
      "Model saved at epoch 54836 with loss: 8.1897\n",
      "Model saved at epoch 54839 with loss: 8.1893\n",
      "Epoch [54840/100000], Loss: 8.1911\n",
      "Epoch [54850/100000], Loss: 8.1917\n",
      "Epoch [54860/100000], Loss: 8.1899\n",
      "Model saved at epoch 54861 with loss: 8.1889\n",
      "Model saved at epoch 54869 with loss: 8.1883\n",
      "Epoch [54870/100000], Loss: 8.1885\n",
      "Model saved at epoch 54872 with loss: 8.1882\n",
      "Model saved at epoch 54878 with loss: 8.1882\n",
      "Epoch [54880/100000], Loss: 8.1913\n",
      "Epoch [54890/100000], Loss: 8.1890\n",
      "Model saved at epoch 54892 with loss: 8.1881\n",
      "Model saved at epoch 54893 with loss: 8.1868\n",
      "Model saved at epoch 54894 with loss: 8.1853\n",
      "Model saved at epoch 54897 with loss: 8.1849\n",
      "Model saved at epoch 54898 with loss: 8.1837\n",
      "Model saved at epoch 54899 with loss: 8.1836\n",
      "Epoch [54900/100000], Loss: 8.1839\n",
      "Model saved at epoch 54901 with loss: 8.1830\n",
      "Model saved at epoch 54902 with loss: 8.1822\n",
      "Model saved at epoch 54903 with loss: 8.1806\n",
      "Model saved at epoch 54904 with loss: 8.1795\n",
      "Epoch [54910/100000], Loss: 8.1819\n",
      "Epoch [54920/100000], Loss: 8.1812\n",
      "Epoch [54930/100000], Loss: 8.1879\n",
      "Epoch [54940/100000], Loss: 8.1839\n",
      "Epoch [54950/100000], Loss: 8.1851\n",
      "Epoch [54960/100000], Loss: 8.1835\n",
      "Epoch [54970/100000], Loss: 8.1875\n",
      "Epoch [54980/100000], Loss: 8.1879\n",
      "Epoch [54990/100000], Loss: 8.1834\n",
      "Epoch [55000/100000], Loss: 8.1808\n",
      "Epoch [55010/100000], Loss: 8.1816\n",
      "Epoch [55020/100000], Loss: 8.1833\n",
      "Epoch [55030/100000], Loss: 8.1830\n",
      "Epoch [55040/100000], Loss: 8.1823\n",
      "Model saved at epoch 55045 with loss: 8.1794\n",
      "Epoch [55050/100000], Loss: 8.1796\n",
      "Epoch [55060/100000], Loss: 8.1825\n",
      "Epoch [55070/100000], Loss: 8.1865\n",
      "Epoch [55080/100000], Loss: 8.1858\n",
      "Epoch [55090/100000], Loss: 8.1838\n",
      "Epoch [55100/100000], Loss: 8.1853\n",
      "Epoch [55110/100000], Loss: 8.1850\n",
      "Epoch [55120/100000], Loss: 8.1821\n",
      "Epoch [55130/100000], Loss: 8.1849\n",
      "Model saved at epoch 55138 with loss: 8.1783\n",
      "Model saved at epoch 55139 with loss: 8.1764\n",
      "Model saved at epoch 55140 with loss: 8.1750\n",
      "Epoch [55140/100000], Loss: 8.1750\n",
      "Epoch [55150/100000], Loss: 8.1757\n",
      "Epoch [55160/100000], Loss: 8.1784\n",
      "Epoch [55170/100000], Loss: 8.1784\n",
      "Epoch [55180/100000], Loss: 8.1758\n",
      "Model saved at epoch 55187 with loss: 8.1742\n",
      "Epoch [55190/100000], Loss: 8.1778\n",
      "Epoch [55200/100000], Loss: 8.1777\n",
      "Epoch [55210/100000], Loss: 8.1784\n",
      "Epoch [55220/100000], Loss: 8.1766\n",
      "Epoch [55230/100000], Loss: 8.1760\n",
      "Model saved at epoch 55234 with loss: 8.1737\n",
      "Model saved at epoch 55236 with loss: 8.1728\n",
      "Model saved at epoch 55237 with loss: 8.1726\n",
      "Epoch [55240/100000], Loss: 8.1732\n",
      "Model saved at epoch 55245 with loss: 8.1721\n",
      "Model saved at epoch 55248 with loss: 8.1718\n",
      "Model saved at epoch 55249 with loss: 8.1705\n",
      "Epoch [55250/100000], Loss: 8.1719\n",
      "Model saved at epoch 55252 with loss: 8.1704\n",
      "Model saved at epoch 55253 with loss: 8.1693\n",
      "Model saved at epoch 55254 with loss: 8.1687\n",
      "Epoch [55260/100000], Loss: 8.1722\n",
      "Epoch [55270/100000], Loss: 8.1742\n",
      "Epoch [55280/100000], Loss: 8.1771\n",
      "Epoch [55290/100000], Loss: 8.1719\n",
      "Epoch [55300/100000], Loss: 8.1708\n",
      "Model saved at epoch 55305 with loss: 8.1685\n",
      "Model saved at epoch 55306 with loss: 8.1683\n",
      "Model saved at epoch 55307 with loss: 8.1678\n",
      "Model saved at epoch 55309 with loss: 8.1676\n",
      "Epoch [55310/100000], Loss: 8.1678\n",
      "Model saved at epoch 55315 with loss: 8.1670\n",
      "Model saved at epoch 55319 with loss: 8.1667\n",
      "Epoch [55320/100000], Loss: 8.1688\n",
      "Epoch [55330/100000], Loss: 8.1725\n",
      "Model saved at epoch 55339 with loss: 8.1663\n",
      "Model saved at epoch 55340 with loss: 8.1655\n",
      "Epoch [55340/100000], Loss: 8.1655\n",
      "Epoch [55350/100000], Loss: 8.1728\n",
      "Epoch [55360/100000], Loss: 8.1700\n",
      "Epoch [55370/100000], Loss: 8.1745\n",
      "Epoch [55380/100000], Loss: 8.1676\n",
      "Model saved at epoch 55387 with loss: 8.1638\n",
      "Model saved at epoch 55388 with loss: 8.1636\n",
      "Epoch [55390/100000], Loss: 8.1645\n",
      "Model saved at epoch 55391 with loss: 8.1617\n",
      "Epoch [55400/100000], Loss: 8.1648\n",
      "Epoch [55410/100000], Loss: 8.1684\n",
      "Epoch [55420/100000], Loss: 8.1658\n",
      "Model saved at epoch 55430 with loss: 8.1611\n",
      "Epoch [55430/100000], Loss: 8.1611\n",
      "Model saved at epoch 55432 with loss: 8.1600\n",
      "Epoch [55440/100000], Loss: 8.1643\n",
      "Model saved at epoch 55443 with loss: 8.1594\n",
      "Epoch [55450/100000], Loss: 8.1656\n",
      "Epoch [55460/100000], Loss: 8.1625\n",
      "Epoch [55470/100000], Loss: 8.1651\n",
      "Epoch [55480/100000], Loss: 8.1646\n",
      "Model saved at epoch 55490 with loss: 8.1590\n",
      "Epoch [55490/100000], Loss: 8.1590\n",
      "Epoch [55500/100000], Loss: 8.1600\n",
      "Epoch [55510/100000], Loss: 8.1652\n",
      "Epoch [55520/100000], Loss: 8.1681\n",
      "Epoch [55530/100000], Loss: 8.1638\n",
      "Epoch [55540/100000], Loss: 8.1649\n",
      "Epoch [55550/100000], Loss: 8.1628\n",
      "Model saved at epoch 55557 with loss: 8.1590\n",
      "Epoch [55560/100000], Loss: 8.1590\n",
      "Model saved at epoch 55561 with loss: 8.1590\n",
      "Model saved at epoch 55563 with loss: 8.1580\n",
      "Model saved at epoch 55564 with loss: 8.1574\n",
      "Epoch [55570/100000], Loss: 8.1595\n",
      "Model saved at epoch 55578 with loss: 8.1570\n",
      "Model saved at epoch 55579 with loss: 8.1562\n",
      "Epoch [55580/100000], Loss: 8.1565\n",
      "Model saved at epoch 55581 with loss: 8.1560\n",
      "Model saved at epoch 55582 with loss: 8.1552\n",
      "Epoch [55590/100000], Loss: 8.1562\n",
      "Model saved at epoch 55594 with loss: 8.1545\n",
      "Model saved at epoch 55596 with loss: 8.1523\n",
      "Epoch [55600/100000], Loss: 8.1575\n",
      "Epoch [55610/100000], Loss: 8.1553\n",
      "Model saved at epoch 55614 with loss: 8.1518\n",
      "Epoch [55620/100000], Loss: 8.1548\n",
      "Epoch [55630/100000], Loss: 8.1554\n",
      "Epoch [55640/100000], Loss: 8.1545\n",
      "Model saved at epoch 55642 with loss: 8.1513\n",
      "Epoch [55650/100000], Loss: 8.1528\n",
      "Epoch [55660/100000], Loss: 8.1545\n",
      "Epoch [55670/100000], Loss: 8.1560\n",
      "Epoch [55680/100000], Loss: 8.1540\n",
      "Epoch [55690/100000], Loss: 8.1560\n",
      "Epoch [55700/100000], Loss: 8.1534\n",
      "Epoch [55710/100000], Loss: 8.1533\n",
      "Model saved at epoch 55712 with loss: 8.1499\n",
      "Model saved at epoch 55718 with loss: 8.1490\n",
      "Epoch [55720/100000], Loss: 8.1506\n",
      "Model saved at epoch 55724 with loss: 8.1489\n",
      "Model saved at epoch 55725 with loss: 8.1484\n",
      "Model saved at epoch 55727 with loss: 8.1481\n",
      "Epoch [55730/100000], Loss: 8.1495\n",
      "Model saved at epoch 55733 with loss: 8.1473\n",
      "Model saved at epoch 55734 with loss: 8.1463\n",
      "Epoch [55740/100000], Loss: 8.1474\n",
      "Model saved at epoch 55742 with loss: 8.1461\n",
      "Model saved at epoch 55743 with loss: 8.1452\n",
      "Epoch [55750/100000], Loss: 8.1494\n",
      "Epoch [55760/100000], Loss: 8.1500\n",
      "Epoch [55770/100000], Loss: 8.1528\n",
      "Epoch [55780/100000], Loss: 8.1502\n",
      "Epoch [55790/100000], Loss: 8.1488\n",
      "Epoch [55800/100000], Loss: 8.1468\n",
      "Epoch [55810/100000], Loss: 8.1533\n",
      "Epoch [55820/100000], Loss: 8.1488\n",
      "Model saved at epoch 55825 with loss: 8.1450\n",
      "Epoch [55830/100000], Loss: 8.1502\n",
      "Epoch [55840/100000], Loss: 8.1495\n",
      "Epoch [55850/100000], Loss: 8.1477\n",
      "Model saved at epoch 55854 with loss: 8.1440\n",
      "Model saved at epoch 55859 with loss: 8.1429\n",
      "Model saved at epoch 55860 with loss: 8.1420\n",
      "Epoch [55860/100000], Loss: 8.1420\n",
      "Model saved at epoch 55861 with loss: 8.1413\n",
      "Epoch [55870/100000], Loss: 8.1450\n",
      "Model saved at epoch 55878 with loss: 8.1402\n",
      "Epoch [55880/100000], Loss: 8.1422\n",
      "Epoch [55890/100000], Loss: 8.1442\n",
      "Epoch [55900/100000], Loss: 8.1465\n",
      "Epoch [55910/100000], Loss: 8.1433\n",
      "Epoch [55920/100000], Loss: 8.1421\n",
      "Epoch [55930/100000], Loss: 8.1421\n",
      "Epoch [55940/100000], Loss: 8.1416\n",
      "Model saved at epoch 55941 with loss: 8.1383\n",
      "Model saved at epoch 55942 with loss: 8.1378\n",
      "Model saved at epoch 55943 with loss: 8.1353\n",
      "Model saved at epoch 55944 with loss: 8.1341\n",
      "Model saved at epoch 55945 with loss: 8.1341\n",
      "Epoch [55950/100000], Loss: 8.1352\n",
      "Epoch [55960/100000], Loss: 8.1355\n",
      "Model saved at epoch 55967 with loss: 8.1319\n",
      "Model saved at epoch 55968 with loss: 8.1306\n",
      "Model saved at epoch 55969 with loss: 8.1300\n",
      "Model saved at epoch 55970 with loss: 8.1294\n",
      "Epoch [55970/100000], Loss: 8.1294\n",
      "Model saved at epoch 55971 with loss: 8.1282\n",
      "Model saved at epoch 55972 with loss: 8.1273\n",
      "Epoch [55980/100000], Loss: 8.1307\n",
      "Epoch [55990/100000], Loss: 8.1315\n",
      "Epoch [56000/100000], Loss: 8.1317\n",
      "Epoch [56010/100000], Loss: 8.1325\n",
      "Epoch [56020/100000], Loss: 8.1304\n",
      "Epoch [56030/100000], Loss: 8.1332\n",
      "Epoch [56040/100000], Loss: 8.1324\n",
      "Epoch [56050/100000], Loss: 8.1355\n",
      "Epoch [56060/100000], Loss: 8.1309\n",
      "Epoch [56070/100000], Loss: 8.1287\n",
      "Epoch [56080/100000], Loss: 8.1348\n",
      "Epoch [56090/100000], Loss: 8.1339\n",
      "Epoch [56100/100000], Loss: 8.1334\n",
      "Model saved at epoch 56109 with loss: 8.1272\n",
      "Epoch [56110/100000], Loss: 8.1275\n",
      "Epoch [56120/100000], Loss: 8.1296\n",
      "Model saved at epoch 56123 with loss: 8.1244\n",
      "Model saved at epoch 56124 with loss: 8.1221\n",
      "Model saved at epoch 56126 with loss: 8.1210\n",
      "Epoch [56130/100000], Loss: 8.1228\n",
      "Epoch [56140/100000], Loss: 8.1265\n",
      "Epoch [56150/100000], Loss: 8.1253\n",
      "Model saved at epoch 56158 with loss: 8.1207\n",
      "Model saved at epoch 56160 with loss: 8.1184\n",
      "Epoch [56160/100000], Loss: 8.1184\n",
      "Model saved at epoch 56161 with loss: 8.1183\n",
      "Model saved at epoch 56162 with loss: 8.1183\n",
      "Model saved at epoch 56163 with loss: 8.1163\n",
      "Epoch [56170/100000], Loss: 8.1213\n",
      "Epoch [56180/100000], Loss: 8.1231\n",
      "Model saved at epoch 56189 with loss: 8.1154\n",
      "Epoch [56190/100000], Loss: 8.1164\n",
      "Model saved at epoch 56193 with loss: 8.1143\n",
      "Model saved at epoch 56194 with loss: 8.1133\n",
      "Model saved at epoch 56195 with loss: 8.1131\n",
      "Model saved at epoch 56196 with loss: 8.1115\n",
      "Epoch [56200/100000], Loss: 8.1132\n",
      "Epoch [56210/100000], Loss: 8.1188\n",
      "Epoch [56220/100000], Loss: 8.1198\n",
      "Epoch [56230/100000], Loss: 8.1188\n",
      "Epoch [56240/100000], Loss: 8.1223\n",
      "Epoch [56250/100000], Loss: 8.1160\n",
      "Model saved at epoch 56260 with loss: 8.1104\n",
      "Epoch [56260/100000], Loss: 8.1104\n",
      "Epoch [56270/100000], Loss: 8.1148\n",
      "Model saved at epoch 56272 with loss: 8.1103\n",
      "Model saved at epoch 56273 with loss: 8.1101\n",
      "Epoch [56280/100000], Loss: 8.1143\n",
      "Epoch [56290/100000], Loss: 8.1130\n",
      "Epoch [56300/100000], Loss: 8.1193\n",
      "Epoch [56310/100000], Loss: 8.1119\n",
      "Epoch [56320/100000], Loss: 8.1182\n",
      "Epoch [56330/100000], Loss: 8.1144\n",
      "Model saved at epoch 56339 with loss: 8.1098\n",
      "Model saved at epoch 56340 with loss: 8.1094\n",
      "Epoch [56340/100000], Loss: 8.1094\n",
      "Model saved at epoch 56342 with loss: 8.1076\n",
      "Model saved at epoch 56343 with loss: 8.1073\n",
      "Model saved at epoch 56344 with loss: 8.1052\n",
      "Epoch [56350/100000], Loss: 8.1074\n",
      "Epoch [56360/100000], Loss: 8.1112\n",
      "Epoch [56370/100000], Loss: 8.1090\n",
      "Epoch [56380/100000], Loss: 8.1071\n",
      "Model saved at epoch 56382 with loss: 8.1047\n",
      "Model saved at epoch 56383 with loss: 8.1031\n",
      "Epoch [56390/100000], Loss: 8.1110\n",
      "Epoch [56400/100000], Loss: 8.1132\n",
      "Epoch [56410/100000], Loss: 8.1116\n",
      "Model saved at epoch 56420 with loss: 8.1029\n",
      "Epoch [56420/100000], Loss: 8.1029\n",
      "Model saved at epoch 56421 with loss: 8.1013\n",
      "Epoch [56430/100000], Loss: 8.1037\n",
      "Model saved at epoch 56433 with loss: 8.1008\n",
      "Model saved at epoch 56434 with loss: 8.1005\n",
      "Model saved at epoch 56438 with loss: 8.1005\n",
      "Epoch [56440/100000], Loss: 8.1019\n",
      "Epoch [56450/100000], Loss: 8.1034\n",
      "Epoch [56460/100000], Loss: 8.1026\n",
      "Model saved at epoch 56462 with loss: 8.0983\n",
      "Model saved at epoch 56464 with loss: 8.0973\n",
      "Model saved at epoch 56465 with loss: 8.0967\n",
      "Epoch [56470/100000], Loss: 8.0974\n",
      "Model saved at epoch 56472 with loss: 8.0965\n",
      "Model saved at epoch 56479 with loss: 8.0955\n",
      "Model saved at epoch 56480 with loss: 8.0952\n",
      "Epoch [56480/100000], Loss: 8.0952\n",
      "Model saved at epoch 56486 with loss: 8.0951\n",
      "Epoch [56490/100000], Loss: 8.0965\n",
      "Epoch [56500/100000], Loss: 8.0972\n",
      "Epoch [56510/100000], Loss: 8.0986\n",
      "Epoch [56520/100000], Loss: 8.0956\n",
      "Model saved at epoch 56526 with loss: 8.0951\n",
      "Model saved at epoch 56527 with loss: 8.0938\n",
      "Epoch [56530/100000], Loss: 8.0964\n",
      "Model saved at epoch 56531 with loss: 8.0926\n",
      "Model saved at epoch 56534 with loss: 8.0921\n",
      "Model saved at epoch 56535 with loss: 8.0907\n",
      "Model saved at epoch 56536 with loss: 8.0905\n",
      "Epoch [56540/100000], Loss: 8.0910\n",
      "Model saved at epoch 56544 with loss: 8.0903\n",
      "Epoch [56550/100000], Loss: 8.0932\n",
      "Epoch [56560/100000], Loss: 8.0965\n",
      "Epoch [56570/100000], Loss: 8.0981\n",
      "Epoch [56580/100000], Loss: 8.0990\n",
      "Epoch [56590/100000], Loss: 8.1001\n",
      "Epoch [56600/100000], Loss: 8.0971\n",
      "Model saved at epoch 56606 with loss: 8.0902\n",
      "Model saved at epoch 56607 with loss: 8.0894\n",
      "Model saved at epoch 56608 with loss: 8.0889\n",
      "Epoch [56610/100000], Loss: 8.0944\n",
      "Model saved at epoch 56616 with loss: 8.0868\n",
      "Model saved at epoch 56619 with loss: 8.0865\n",
      "Model saved at epoch 56620 with loss: 8.0857\n",
      "Epoch [56620/100000], Loss: 8.0857\n",
      "Model saved at epoch 56621 with loss: 8.0854\n",
      "Model saved at epoch 56622 with loss: 8.0848\n",
      "Model saved at epoch 56623 with loss: 8.0816\n",
      "Epoch [56630/100000], Loss: 8.0845\n",
      "Epoch [56640/100000], Loss: 8.0892\n",
      "Epoch [56650/100000], Loss: 8.0849\n",
      "Epoch [56660/100000], Loss: 8.0891\n",
      "Epoch [56670/100000], Loss: 8.0889\n",
      "Epoch [56680/100000], Loss: 8.0859\n",
      "Model saved at epoch 56685 with loss: 8.0799\n",
      "Model saved at epoch 56687 with loss: 8.0796\n",
      "Epoch [56690/100000], Loss: 8.0819\n",
      "Epoch [56700/100000], Loss: 8.0818\n",
      "Epoch [56710/100000], Loss: 8.0826\n",
      "Model saved at epoch 56714 with loss: 8.0793\n",
      "Epoch [56720/100000], Loss: 8.0818\n",
      "Epoch [56730/100000], Loss: 8.0825\n",
      "Model saved at epoch 56732 with loss: 8.0785\n",
      "Model saved at epoch 56736 with loss: 8.0781\n",
      "Model saved at epoch 56739 with loss: 8.0770\n",
      "Model saved at epoch 56740 with loss: 8.0767\n",
      "Epoch [56740/100000], Loss: 8.0767\n",
      "Epoch [56750/100000], Loss: 8.0786\n",
      "Model saved at epoch 56758 with loss: 8.0757\n",
      "Epoch [56760/100000], Loss: 8.0782\n",
      "Epoch [56770/100000], Loss: 8.0791\n",
      "Model saved at epoch 56778 with loss: 8.0757\n",
      "Epoch [56780/100000], Loss: 8.0760\n",
      "Model saved at epoch 56785 with loss: 8.0744\n",
      "Model saved at epoch 56787 with loss: 8.0739\n",
      "Epoch [56790/100000], Loss: 8.0754\n",
      "Model saved at epoch 56791 with loss: 8.0720\n",
      "Epoch [56800/100000], Loss: 8.0790\n",
      "Epoch [56810/100000], Loss: 8.0757\n",
      "Epoch [56820/100000], Loss: 8.0741\n",
      "Model saved at epoch 56821 with loss: 8.0719\n",
      "Epoch [56830/100000], Loss: 8.0772\n",
      "Epoch [56840/100000], Loss: 8.0719\n",
      "Model saved at epoch 56842 with loss: 8.0711\n",
      "Model saved at epoch 56843 with loss: 8.0705\n",
      "Model saved at epoch 56844 with loss: 8.0703\n",
      "Model saved at epoch 56845 with loss: 8.0700\n",
      "Epoch [56850/100000], Loss: 8.0773\n",
      "Epoch [56860/100000], Loss: 8.0761\n",
      "Epoch [56870/100000], Loss: 8.0751\n",
      "Epoch [56880/100000], Loss: 8.0723\n",
      "Model saved at epoch 56888 with loss: 8.0700\n",
      "Epoch [56890/100000], Loss: 8.0712\n",
      "Epoch [56900/100000], Loss: 8.0729\n",
      "Model saved at epoch 56907 with loss: 8.0699\n",
      "Model saved at epoch 56909 with loss: 8.0693\n",
      "Model saved at epoch 56910 with loss: 8.0671\n",
      "Epoch [56910/100000], Loss: 8.0671\n",
      "Model saved at epoch 56911 with loss: 8.0659\n",
      "Model saved at epoch 56913 with loss: 8.0651\n",
      "Model saved at epoch 56915 with loss: 8.0635\n",
      "Model saved at epoch 56916 with loss: 8.0633\n",
      "Epoch [56920/100000], Loss: 8.0645\n",
      "Model saved at epoch 56929 with loss: 8.0617\n",
      "Model saved at epoch 56930 with loss: 8.0614\n",
      "Epoch [56930/100000], Loss: 8.0614\n",
      "Model saved at epoch 56933 with loss: 8.0596\n",
      "Epoch [56940/100000], Loss: 8.0615\n",
      "Model saved at epoch 56941 with loss: 8.0581\n",
      "Model saved at epoch 56942 with loss: 8.0562\n",
      "Epoch [56950/100000], Loss: 8.0628\n",
      "Epoch [56960/100000], Loss: 8.0573\n",
      "Model saved at epoch 56967 with loss: 8.0551\n",
      "Epoch [56970/100000], Loss: 8.0582\n",
      "Epoch [56980/100000], Loss: 8.0596\n",
      "Epoch [56990/100000], Loss: 8.0572\n",
      "Epoch [57000/100000], Loss: 8.0628\n",
      "Epoch [57010/100000], Loss: 8.0597\n",
      "Epoch [57020/100000], Loss: 8.0561\n",
      "Epoch [57030/100000], Loss: 8.0569\n",
      "Model saved at epoch 57040 with loss: 8.0550\n",
      "Epoch [57040/100000], Loss: 8.0550\n",
      "Model saved at epoch 57041 with loss: 8.0527\n",
      "Epoch [57050/100000], Loss: 8.0561\n",
      "Model saved at epoch 57058 with loss: 8.0521\n",
      "Model saved at epoch 57059 with loss: 8.0515\n",
      "Epoch [57060/100000], Loss: 8.0519\n",
      "Epoch [57070/100000], Loss: 8.0569\n",
      "Epoch [57080/100000], Loss: 8.0535\n",
      "Model saved at epoch 57087 with loss: 8.0509\n",
      "Epoch [57090/100000], Loss: 8.0532\n",
      "Model saved at epoch 57097 with loss: 8.0505\n",
      "Model saved at epoch 57098 with loss: 8.0503\n",
      "Epoch [57100/100000], Loss: 8.0513\n",
      "Model saved at epoch 57102 with loss: 8.0487\n",
      "Model saved at epoch 57103 with loss: 8.0479\n",
      "Model saved at epoch 57106 with loss: 8.0477\n",
      "Epoch [57110/100000], Loss: 8.0510\n",
      "Epoch [57120/100000], Loss: 8.0532\n",
      "Epoch [57130/100000], Loss: 8.0507\n",
      "Epoch [57140/100000], Loss: 8.0517\n",
      "Epoch [57150/100000], Loss: 8.0500\n",
      "Model saved at epoch 57156 with loss: 8.0470\n",
      "Model saved at epoch 57158 with loss: 8.0463\n",
      "Model saved at epoch 57159 with loss: 8.0462\n",
      "Epoch [57160/100000], Loss: 8.0471\n",
      "Model saved at epoch 57166 with loss: 8.0462\n",
      "Model saved at epoch 57167 with loss: 8.0461\n",
      "Model saved at epoch 57168 with loss: 8.0450\n",
      "Epoch [57170/100000], Loss: 8.0490\n",
      "Model saved at epoch 57177 with loss: 8.0448\n",
      "Model saved at epoch 57179 with loss: 8.0416\n",
      "Model saved at epoch 57180 with loss: 8.0408\n",
      "Epoch [57180/100000], Loss: 8.0408\n",
      "Model saved at epoch 57188 with loss: 8.0391\n",
      "Epoch [57190/100000], Loss: 8.0403\n",
      "Model saved at epoch 57198 with loss: 8.0384\n",
      "Model saved at epoch 57199 with loss: 8.0377\n",
      "Model saved at epoch 57200 with loss: 8.0368\n",
      "Epoch [57200/100000], Loss: 8.0368\n",
      "Epoch [57210/100000], Loss: 8.0423\n",
      "Model saved at epoch 57214 with loss: 8.0366\n",
      "Model saved at epoch 57217 with loss: 8.0361\n",
      "Model saved at epoch 57218 with loss: 8.0346\n",
      "Epoch [57220/100000], Loss: 8.0376\n",
      "Model saved at epoch 57224 with loss: 8.0340\n",
      "Model saved at epoch 57226 with loss: 8.0322\n",
      "Epoch [57230/100000], Loss: 8.0383\n",
      "Epoch [57240/100000], Loss: 8.0361\n",
      "Epoch [57250/100000], Loss: 8.0365\n",
      "Epoch [57260/100000], Loss: 8.0378\n",
      "Epoch [57270/100000], Loss: 8.0344\n",
      "Model saved at epoch 57271 with loss: 8.0317\n",
      "Model saved at epoch 57274 with loss: 8.0313\n",
      "Epoch [57280/100000], Loss: 8.0363\n",
      "Epoch [57290/100000], Loss: 8.0350\n",
      "Model saved at epoch 57297 with loss: 8.0309\n",
      "Model saved at epoch 57299 with loss: 8.0300\n",
      "Epoch [57300/100000], Loss: 8.0304\n",
      "Model saved at epoch 57307 with loss: 8.0288\n",
      "Model saved at epoch 57309 with loss: 8.0255\n",
      "Epoch [57310/100000], Loss: 8.0256\n",
      "Model saved at epoch 57316 with loss: 8.0255\n",
      "Epoch [57320/100000], Loss: 8.0273\n",
      "Model saved at epoch 57321 with loss: 8.0248\n",
      "Model saved at epoch 57330 with loss: 8.0247\n",
      "Epoch [57330/100000], Loss: 8.0247\n",
      "Model saved at epoch 57331 with loss: 8.0236\n",
      "Epoch [57340/100000], Loss: 8.0249\n",
      "Model saved at epoch 57345 with loss: 8.0203\n",
      "Epoch [57350/100000], Loss: 8.0216\n",
      "Epoch [57360/100000], Loss: 8.0297\n",
      "Epoch [57370/100000], Loss: 8.0219\n",
      "Model saved at epoch 57373 with loss: 8.0200\n",
      "Model saved at epoch 57374 with loss: 8.0200\n",
      "Epoch [57380/100000], Loss: 8.0255\n",
      "Model saved at epoch 57390 with loss: 8.0193\n",
      "Epoch [57390/100000], Loss: 8.0193\n",
      "Model saved at epoch 57392 with loss: 8.0192\n",
      "Model saved at epoch 57393 with loss: 8.0187\n",
      "Model saved at epoch 57394 with loss: 8.0163\n",
      "Model saved at epoch 57396 with loss: 8.0148\n",
      "Model saved at epoch 57397 with loss: 8.0128\n",
      "Epoch [57400/100000], Loss: 8.0176\n",
      "Epoch [57410/100000], Loss: 8.0203\n",
      "Epoch [57420/100000], Loss: 8.0211\n",
      "Epoch [57430/100000], Loss: 8.0194\n",
      "Epoch [57440/100000], Loss: 8.0152\n",
      "Epoch [57450/100000], Loss: 8.0135\n",
      "Epoch [57460/100000], Loss: 8.0149\n",
      "Model saved at epoch 57461 with loss: 8.0127\n",
      "Model saved at epoch 57467 with loss: 8.0126\n",
      "Model saved at epoch 57468 with loss: 8.0126\n",
      "Model saved at epoch 57470 with loss: 8.0124\n",
      "Epoch [57470/100000], Loss: 8.0124\n",
      "Model saved at epoch 57472 with loss: 8.0116\n",
      "Model saved at epoch 57473 with loss: 8.0106\n",
      "Model saved at epoch 57474 with loss: 8.0099\n",
      "Model saved at epoch 57475 with loss: 8.0087\n",
      "Model saved at epoch 57476 with loss: 8.0076\n",
      "Model saved at epoch 57480 with loss: 8.0070\n",
      "Epoch [57480/100000], Loss: 8.0070\n",
      "Model saved at epoch 57486 with loss: 8.0066\n",
      "Model saved at epoch 57487 with loss: 8.0061\n",
      "Epoch [57490/100000], Loss: 8.0107\n",
      "Model saved at epoch 57498 with loss: 8.0059\n",
      "Model saved at epoch 57499 with loss: 8.0053\n",
      "Epoch [57500/100000], Loss: 8.0094\n",
      "Model saved at epoch 57509 with loss: 8.0048\n",
      "Epoch [57510/100000], Loss: 8.0060\n",
      "Model saved at epoch 57513 with loss: 8.0047\n",
      "Epoch [57520/100000], Loss: 8.0091\n",
      "Epoch [57530/100000], Loss: 8.0089\n",
      "Epoch [57540/100000], Loss: 8.0089\n",
      "Epoch [57550/100000], Loss: 8.0084\n",
      "Epoch [57560/100000], Loss: 8.0087\n",
      "Epoch [57570/100000], Loss: 8.0060\n",
      "Model saved at epoch 57571 with loss: 8.0025\n",
      "Model saved at epoch 57572 with loss: 8.0014\n",
      "Epoch [57580/100000], Loss: 8.0034\n",
      "Model saved at epoch 57583 with loss: 7.9997\n",
      "Model saved at epoch 57584 with loss: 7.9972\n",
      "Epoch [57590/100000], Loss: 8.0044\n",
      "Model saved at epoch 57598 with loss: 7.9961\n",
      "Model saved at epoch 57599 with loss: 7.9959\n",
      "Epoch [57600/100000], Loss: 7.9982\n",
      "Epoch [57610/100000], Loss: 8.0036\n",
      "Epoch [57620/100000], Loss: 7.9977\n",
      "Epoch [57630/100000], Loss: 7.9995\n",
      "Epoch [57640/100000], Loss: 7.9987\n",
      "Model saved at epoch 57641 with loss: 7.9957\n",
      "Model saved at epoch 57647 with loss: 7.9947\n",
      "Model saved at epoch 57648 with loss: 7.9938\n",
      "Model saved at epoch 57649 with loss: 7.9909\n",
      "Epoch [57650/100000], Loss: 7.9936\n",
      "Model saved at epoch 57651 with loss: 7.9908\n",
      "Model saved at epoch 57656 with loss: 7.9905\n",
      "Model saved at epoch 57657 with loss: 7.9896\n",
      "Model saved at epoch 57659 with loss: 7.9883\n",
      "Model saved at epoch 57660 with loss: 7.9876\n",
      "Epoch [57660/100000], Loss: 7.9876\n",
      "Epoch [57670/100000], Loss: 7.9928\n",
      "Epoch [57680/100000], Loss: 7.9922\n",
      "Epoch [57690/100000], Loss: 7.9903\n",
      "Model saved at epoch 57697 with loss: 7.9876\n",
      "Model saved at epoch 57698 with loss: 7.9875\n",
      "Model saved at epoch 57699 with loss: 7.9853\n",
      "Epoch [57700/100000], Loss: 7.9876\n",
      "Model saved at epoch 57702 with loss: 7.9853\n",
      "Model saved at epoch 57703 with loss: 7.9842\n",
      "Model saved at epoch 57710 with loss: 7.9827\n",
      "Epoch [57710/100000], Loss: 7.9827\n",
      "Model saved at epoch 57712 with loss: 7.9824\n",
      "Epoch [57720/100000], Loss: 7.9884\n",
      "Epoch [57730/100000], Loss: 7.9947\n",
      "Epoch [57740/100000], Loss: 7.9880\n",
      "Model saved at epoch 57744 with loss: 7.9806\n",
      "Model saved at epoch 57750 with loss: 7.9787\n",
      "Epoch [57750/100000], Loss: 7.9787\n",
      "Model saved at epoch 57751 with loss: 7.9771\n",
      "Epoch [57760/100000], Loss: 7.9857\n",
      "Epoch [57770/100000], Loss: 7.9827\n",
      "Epoch [57780/100000], Loss: 7.9873\n",
      "Epoch [57790/100000], Loss: 2409.4775\n",
      "Epoch [57800/100000], Loss: 3911349760.0000\n",
      "Epoch [57810/100000], Loss: 632623488.0000\n",
      "Epoch [57820/100000], Loss: 293256512.0000\n",
      "Epoch [57830/100000], Loss: 170140080.0000\n",
      "Epoch [57840/100000], Loss: 63423684.0000\n",
      "Epoch [57850/100000], Loss: 13762433.0000\n",
      "Epoch [57860/100000], Loss: 1114301.8750\n",
      "Epoch [57870/100000], Loss: 569409.9375\n",
      "Epoch [57880/100000], Loss: 700931.2500\n",
      "Epoch [57890/100000], Loss: 318029.3125\n",
      "Epoch [57900/100000], Loss: 71104.1094\n",
      "Epoch [57910/100000], Loss: 13893.4834\n",
      "Epoch [57920/100000], Loss: 9780.0488\n",
      "Epoch [57930/100000], Loss: 3933.5803\n",
      "Epoch [57940/100000], Loss: 383.0071\n",
      "Epoch [57950/100000], Loss: 121.3209\n",
      "Epoch [57960/100000], Loss: 193.4651\n",
      "Epoch [57970/100000], Loss: 73.6773\n",
      "Epoch [57980/100000], Loss: 16.7225\n",
      "Epoch [57990/100000], Loss: 16.4281\n",
      "Epoch [58000/100000], Loss: 10.5262\n",
      "Epoch [58010/100000], Loss: 8.9409\n",
      "Epoch [58020/100000], Loss: 8.2939\n",
      "Epoch [58030/100000], Loss: 8.1666\n",
      "Epoch [58040/100000], Loss: 8.1109\n",
      "Epoch [58050/100000], Loss: 8.1181\n",
      "Epoch [58060/100000], Loss: 8.1107\n",
      "Epoch [58070/100000], Loss: 8.1022\n",
      "Epoch [58080/100000], Loss: 8.1080\n",
      "Epoch [58090/100000], Loss: 8.1063\n",
      "Epoch [58100/100000], Loss: 8.1065\n",
      "Epoch [58110/100000], Loss: 8.1002\n",
      "Epoch [58120/100000], Loss: 8.0994\n",
      "Epoch [58130/100000], Loss: 8.0989\n",
      "Epoch [58140/100000], Loss: 8.0980\n",
      "Epoch [58150/100000], Loss: 8.0984\n",
      "Epoch [58160/100000], Loss: 8.0971\n",
      "Epoch [58170/100000], Loss: 8.0961\n",
      "Epoch [58180/100000], Loss: 8.0928\n",
      "Epoch [58190/100000], Loss: 8.0916\n",
      "Epoch [58200/100000], Loss: 8.0927\n",
      "Epoch [58210/100000], Loss: 8.0903\n",
      "Epoch [58220/100000], Loss: 8.0887\n",
      "Epoch [58230/100000], Loss: 8.0912\n",
      "Epoch [58240/100000], Loss: 8.0847\n",
      "Epoch [58250/100000], Loss: 8.0809\n",
      "Epoch [58260/100000], Loss: 8.0851\n",
      "Epoch [58270/100000], Loss: 8.0793\n",
      "Epoch [58280/100000], Loss: 8.0773\n",
      "Epoch [58290/100000], Loss: 8.0768\n",
      "Epoch [58300/100000], Loss: 8.0758\n",
      "Epoch [58310/100000], Loss: 8.0746\n",
      "Epoch [58320/100000], Loss: 8.0702\n",
      "Epoch [58330/100000], Loss: 8.0686\n",
      "Epoch [58340/100000], Loss: 8.0670\n",
      "Epoch [58350/100000], Loss: 8.0739\n",
      "Epoch [58360/100000], Loss: 8.0701\n",
      "Epoch [58370/100000], Loss: 8.0643\n",
      "Epoch [58380/100000], Loss: 8.0665\n",
      "Epoch [58390/100000], Loss: 8.0623\n",
      "Epoch [58400/100000], Loss: 8.0635\n",
      "Epoch [58410/100000], Loss: 8.0616\n",
      "Epoch [58420/100000], Loss: 8.0636\n",
      "Epoch [58430/100000], Loss: 8.0598\n",
      "Epoch [58440/100000], Loss: 8.0596\n",
      "Epoch [58450/100000], Loss: 8.0594\n",
      "Epoch [58460/100000], Loss: 8.0589\n",
      "Epoch [58470/100000], Loss: 8.0639\n",
      "Epoch [58480/100000], Loss: 8.0608\n",
      "Epoch [58490/100000], Loss: 8.0587\n",
      "Epoch [58500/100000], Loss: 8.0584\n",
      "Epoch [58510/100000], Loss: 8.0566\n",
      "Epoch [58520/100000], Loss: 8.0545\n",
      "Epoch [58530/100000], Loss: 8.0587\n",
      "Epoch [58540/100000], Loss: 8.0556\n",
      "Epoch [58550/100000], Loss: 8.0562\n",
      "Epoch [58560/100000], Loss: 8.0576\n",
      "Epoch [58570/100000], Loss: 8.0568\n",
      "Epoch [58580/100000], Loss: 8.0516\n",
      "Epoch [58590/100000], Loss: 8.0557\n",
      "Epoch [58600/100000], Loss: 8.0562\n",
      "Epoch [58610/100000], Loss: 8.0573\n",
      "Epoch [58620/100000], Loss: 8.0531\n",
      "Epoch [58630/100000], Loss: 8.0512\n",
      "Epoch [58640/100000], Loss: 8.0476\n",
      "Epoch [58650/100000], Loss: 8.0431\n",
      "Epoch [58660/100000], Loss: 8.0386\n",
      "Epoch [58670/100000], Loss: 8.0392\n",
      "Epoch [58680/100000], Loss: 8.0375\n",
      "Epoch [58690/100000], Loss: 8.0348\n",
      "Epoch [58700/100000], Loss: 8.0389\n",
      "Epoch [58710/100000], Loss: 8.0368\n",
      "Epoch [58720/100000], Loss: 8.0365\n",
      "Epoch [58730/100000], Loss: 8.0383\n",
      "Epoch [58740/100000], Loss: 8.0363\n",
      "Epoch [58750/100000], Loss: 8.0347\n",
      "Epoch [58760/100000], Loss: 8.0356\n",
      "Epoch [58770/100000], Loss: 8.0325\n",
      "Epoch [58780/100000], Loss: 8.0347\n",
      "Epoch [58790/100000], Loss: 8.0351\n",
      "Epoch [58800/100000], Loss: 8.0330\n",
      "Epoch [58810/100000], Loss: 8.0320\n",
      "Epoch [58820/100000], Loss: 8.0346\n",
      "Epoch [58830/100000], Loss: 8.0318\n",
      "Epoch [58840/100000], Loss: 8.0298\n",
      "Epoch [58850/100000], Loss: 8.0265\n",
      "Epoch [58860/100000], Loss: 8.0236\n",
      "Epoch [58870/100000], Loss: 8.0224\n",
      "Epoch [58880/100000], Loss: 8.0214\n",
      "Epoch [58890/100000], Loss: 8.0213\n",
      "Epoch [58900/100000], Loss: 8.0213\n",
      "Epoch [58910/100000], Loss: 8.0184\n",
      "Epoch [58920/100000], Loss: 8.0174\n",
      "Epoch [58930/100000], Loss: 8.0143\n",
      "Epoch [58940/100000], Loss: 8.0140\n",
      "Epoch [58950/100000], Loss: 8.0112\n",
      "Epoch [58960/100000], Loss: 8.0115\n",
      "Epoch [58970/100000], Loss: 8.0061\n",
      "Epoch [58980/100000], Loss: 8.0069\n",
      "Epoch [58990/100000], Loss: 8.0076\n",
      "Epoch [59000/100000], Loss: 8.0078\n",
      "Epoch [59010/100000], Loss: 8.0071\n",
      "Epoch [59020/100000], Loss: 8.0077\n",
      "Epoch [59030/100000], Loss: 8.0078\n",
      "Epoch [59040/100000], Loss: 8.0066\n",
      "Epoch [59050/100000], Loss: 8.0097\n",
      "Epoch [59060/100000], Loss: 8.0072\n",
      "Epoch [59070/100000], Loss: 8.0053\n",
      "Epoch [59080/100000], Loss: 8.0032\n",
      "Epoch [59090/100000], Loss: 8.0056\n",
      "Epoch [59100/100000], Loss: 8.0078\n",
      "Epoch [59110/100000], Loss: 8.0043\n",
      "Epoch [59120/100000], Loss: 8.0057\n",
      "Epoch [59130/100000], Loss: 8.0008\n",
      "Epoch [59140/100000], Loss: 8.0019\n",
      "Epoch [59150/100000], Loss: 8.0029\n",
      "Epoch [59160/100000], Loss: 8.0023\n",
      "Epoch [59170/100000], Loss: 8.0039\n",
      "Epoch [59180/100000], Loss: 8.0022\n",
      "Epoch [59190/100000], Loss: 8.0033\n",
      "Epoch [59200/100000], Loss: 8.0007\n",
      "Epoch [59210/100000], Loss: 7.9988\n",
      "Epoch [59220/100000], Loss: 7.9970\n",
      "Epoch [59230/100000], Loss: 7.9994\n",
      "Epoch [59240/100000], Loss: 8.0003\n",
      "Epoch [59250/100000], Loss: 7.9999\n",
      "Epoch [59260/100000], Loss: 7.9943\n",
      "Epoch [59270/100000], Loss: 7.9959\n",
      "Epoch [59280/100000], Loss: 7.9924\n",
      "Epoch [59290/100000], Loss: 7.9937\n",
      "Epoch [59300/100000], Loss: 7.9952\n",
      "Epoch [59310/100000], Loss: 7.9901\n",
      "Epoch [59320/100000], Loss: 7.9897\n",
      "Epoch [59330/100000], Loss: 7.9897\n",
      "Epoch [59340/100000], Loss: 7.9927\n",
      "Epoch [59350/100000], Loss: 7.9932\n",
      "Epoch [59360/100000], Loss: 7.9931\n",
      "Epoch [59370/100000], Loss: 7.9896\n",
      "Epoch [59380/100000], Loss: 7.9932\n",
      "Epoch [59390/100000], Loss: 7.9935\n",
      "Epoch [59400/100000], Loss: 7.9929\n",
      "Epoch [59410/100000], Loss: 7.9928\n",
      "Epoch [59420/100000], Loss: 7.9921\n",
      "Epoch [59430/100000], Loss: 7.9885\n",
      "Epoch [59440/100000], Loss: 7.9898\n",
      "Epoch [59450/100000], Loss: 7.9903\n",
      "Epoch [59460/100000], Loss: 7.9903\n",
      "Epoch [59470/100000], Loss: 7.9904\n",
      "Epoch [59480/100000], Loss: 7.9880\n",
      "Epoch [59490/100000], Loss: 7.9866\n",
      "Epoch [59500/100000], Loss: 7.9833\n",
      "Epoch [59510/100000], Loss: 7.9819\n",
      "Epoch [59520/100000], Loss: 7.9800\n",
      "Epoch [59530/100000], Loss: 7.9813\n",
      "Epoch [59540/100000], Loss: 7.9823\n",
      "Epoch [59550/100000], Loss: 7.9838\n",
      "Epoch [59560/100000], Loss: 7.9809\n",
      "Epoch [59570/100000], Loss: 7.9810\n",
      "Epoch [59580/100000], Loss: 7.9815\n",
      "Epoch [59590/100000], Loss: 7.9818\n",
      "Epoch [59600/100000], Loss: 7.9825\n",
      "Epoch [59610/100000], Loss: 7.9820\n",
      "Epoch [59620/100000], Loss: 7.9835\n",
      "Epoch [59630/100000], Loss: 7.9800\n",
      "Epoch [59640/100000], Loss: 7.9793\n",
      "Epoch [59650/100000], Loss: 7.9785\n",
      "Epoch [59660/100000], Loss: 7.9816\n",
      "Epoch [59670/100000], Loss: 7.9790\n",
      "Model saved at epoch 59678 with loss: 7.9758\n",
      "Model saved at epoch 59679 with loss: 7.9755\n",
      "Epoch [59680/100000], Loss: 7.9758\n",
      "Model saved at epoch 59681 with loss: 7.9745\n",
      "Epoch [59690/100000], Loss: 7.9758\n",
      "Model saved at epoch 59691 with loss: 7.9743\n",
      "Model saved at epoch 59692 with loss: 7.9743\n",
      "Model saved at epoch 59694 with loss: 7.9736\n",
      "Model saved at epoch 59695 with loss: 7.9731\n",
      "Epoch [59700/100000], Loss: 7.9744\n",
      "Model saved at epoch 59703 with loss: 7.9729\n",
      "Epoch [59710/100000], Loss: 7.9753\n",
      "Epoch [59720/100000], Loss: 7.9780\n",
      "Epoch [59730/100000], Loss: 7.9816\n",
      "Epoch [59740/100000], Loss: 7.9799\n",
      "Epoch [59750/100000], Loss: 7.9786\n",
      "Epoch [59760/100000], Loss: 7.9783\n",
      "Epoch [59770/100000], Loss: 7.9733\n",
      "Model saved at epoch 59771 with loss: 7.9721\n",
      "Epoch [59780/100000], Loss: 7.9745\n",
      "Epoch [59790/100000], Loss: 7.9757\n",
      "Epoch [59800/100000], Loss: 7.9737\n",
      "Model saved at epoch 59804 with loss: 7.9715\n",
      "Model saved at epoch 59805 with loss: 7.9710\n",
      "Model saved at epoch 59806 with loss: 7.9706\n",
      "Model saved at epoch 59807 with loss: 7.9696\n",
      "Model saved at epoch 59808 with loss: 7.9694\n",
      "Model saved at epoch 59809 with loss: 7.9690\n",
      "Epoch [59810/100000], Loss: 7.9691\n",
      "Epoch [59820/100000], Loss: 7.9705\n",
      "Epoch [59830/100000], Loss: 7.9743\n",
      "Epoch [59840/100000], Loss: 7.9707\n",
      "Epoch [59850/100000], Loss: 7.9690\n",
      "Epoch [59860/100000], Loss: 7.9716\n",
      "Model saved at epoch 59868 with loss: 7.9684\n",
      "Model saved at epoch 59869 with loss: 7.9675\n",
      "Epoch [59870/100000], Loss: 7.9690\n",
      "Epoch [59880/100000], Loss: 7.9713\n",
      "Epoch [59890/100000], Loss: 7.9683\n",
      "Model saved at epoch 59893 with loss: 7.9674\n",
      "Model saved at epoch 59894 with loss: 7.9667\n",
      "Model saved at epoch 59896 with loss: 7.9663\n",
      "Epoch [59900/100000], Loss: 7.9673\n",
      "Model saved at epoch 59901 with loss: 7.9662\n",
      "Model saved at epoch 59906 with loss: 7.9657\n",
      "Epoch [59910/100000], Loss: 7.9681\n",
      "Epoch [59920/100000], Loss: 7.9659\n",
      "Model saved at epoch 59928 with loss: 7.9655\n",
      "Model saved at epoch 59929 with loss: 7.9647\n",
      "Epoch [59930/100000], Loss: 7.9647\n",
      "Epoch [59940/100000], Loss: 7.9677\n",
      "Model saved at epoch 59945 with loss: 7.9640\n",
      "Model saved at epoch 59946 with loss: 7.9633\n",
      "Model saved at epoch 59947 with loss: 7.9627\n",
      "Epoch [59950/100000], Loss: 7.9653\n",
      "Model saved at epoch 59960 with loss: 7.9614\n",
      "Epoch [59960/100000], Loss: 7.9614\n",
      "Epoch [59970/100000], Loss: 7.9643\n",
      "Epoch [59980/100000], Loss: 7.9638\n",
      "Model saved at epoch 59990 with loss: 7.9609\n",
      "Epoch [59990/100000], Loss: 7.9609\n",
      "Epoch [60000/100000], Loss: 7.9675\n",
      "Epoch [60010/100000], Loss: 7.9679\n",
      "Epoch [60020/100000], Loss: 7.9655\n",
      "Epoch [60030/100000], Loss: 7.9646\n",
      "Epoch [60040/100000], Loss: 7.9612\n",
      "Model saved at epoch 60050 with loss: 7.9602\n",
      "Epoch [60050/100000], Loss: 7.9602\n",
      "Epoch [60060/100000], Loss: 7.9610\n",
      "Model saved at epoch 60070 with loss: 7.9601\n",
      "Epoch [60070/100000], Loss: 7.9601\n",
      "Model saved at epoch 60071 with loss: 7.9598\n",
      "Model saved at epoch 60073 with loss: 7.9597\n",
      "Epoch [60080/100000], Loss: 7.9613\n",
      "Epoch [60090/100000], Loss: 7.9622\n",
      "Epoch [60100/100000], Loss: 7.9603\n",
      "Epoch [60110/100000], Loss: 7.9626\n",
      "Epoch [60120/100000], Loss: 7.9601\n",
      "Epoch [60130/100000], Loss: 7.9643\n",
      "Epoch [60140/100000], Loss: 7.9637\n",
      "Epoch [60150/100000], Loss: 7.9612\n",
      "Model saved at epoch 60157 with loss: 7.9595\n",
      "Model saved at epoch 60158 with loss: 7.9582\n",
      "Model saved at epoch 60159 with loss: 7.9580\n",
      "Epoch [60160/100000], Loss: 7.9588\n",
      "Epoch [60170/100000], Loss: 7.9601\n",
      "Epoch [60180/100000], Loss: 7.9584\n",
      "Model saved at epoch 60186 with loss: 7.9579\n",
      "Epoch [60190/100000], Loss: 7.9592\n",
      "Model saved at epoch 60194 with loss: 7.9576\n",
      "Epoch [60200/100000], Loss: 7.9580\n",
      "Model saved at epoch 60204 with loss: 7.9575\n",
      "Model saved at epoch 60205 with loss: 7.9572\n",
      "Model saved at epoch 60207 with loss: 7.9569\n",
      "Model saved at epoch 60208 with loss: 7.9558\n",
      "Epoch [60210/100000], Loss: 7.9570\n",
      "Epoch [60220/100000], Loss: 7.9584\n",
      "Epoch [60230/100000], Loss: 7.9566\n",
      "Model saved at epoch 60231 with loss: 7.9552\n",
      "Epoch [60240/100000], Loss: 7.9557\n",
      "Model saved at epoch 60247 with loss: 7.9548\n",
      "Model saved at epoch 60248 with loss: 7.9546\n",
      "Model saved at epoch 60249 with loss: 7.9537\n",
      "Model saved at epoch 60250 with loss: 7.9531\n",
      "Epoch [60250/100000], Loss: 7.9531\n",
      "Model saved at epoch 60251 with loss: 7.9528\n",
      "Model saved at epoch 60252 with loss: 7.9525\n",
      "Model saved at epoch 60258 with loss: 7.9522\n",
      "Model saved at epoch 60259 with loss: 7.9515\n",
      "Model saved at epoch 60260 with loss: 7.9509\n",
      "Epoch [60260/100000], Loss: 7.9509\n",
      "Model saved at epoch 60261 with loss: 7.9506\n",
      "Model saved at epoch 60263 with loss: 7.9494\n",
      "Model saved at epoch 60264 with loss: 7.9490\n",
      "Model saved at epoch 60267 with loss: 7.9480\n",
      "Epoch [60270/100000], Loss: 7.9498\n",
      "Epoch [60280/100000], Loss: 7.9523\n",
      "Epoch [60290/100000], Loss: 7.9542\n",
      "Epoch [60300/100000], Loss: 7.9540\n",
      "Epoch [60310/100000], Loss: 7.9519\n",
      "Epoch [60320/100000], Loss: 7.9520\n",
      "Epoch [60330/100000], Loss: 7.9537\n",
      "Epoch [60340/100000], Loss: 7.9568\n",
      "Epoch [60350/100000], Loss: 7.9539\n",
      "Epoch [60360/100000], Loss: 7.9540\n",
      "Epoch [60370/100000], Loss: 7.9523\n",
      "Epoch [60380/100000], Loss: 7.9533\n",
      "Epoch [60390/100000], Loss: 7.9544\n",
      "Epoch [60400/100000], Loss: 7.9535\n",
      "Epoch [60410/100000], Loss: 7.9536\n",
      "Epoch [60420/100000], Loss: 7.9528\n",
      "Epoch [60430/100000], Loss: 7.9540\n",
      "Epoch [60440/100000], Loss: 7.9556\n",
      "Epoch [60450/100000], Loss: 7.9508\n",
      "Epoch [60460/100000], Loss: 7.9540\n",
      "Epoch [60470/100000], Loss: 7.9557\n",
      "Epoch [60480/100000], Loss: 7.9530\n",
      "Epoch [60490/100000], Loss: 7.9508\n",
      "Epoch [60500/100000], Loss: 7.9499\n",
      "Epoch [60510/100000], Loss: 7.9497\n",
      "Model saved at epoch 60517 with loss: 7.9474\n",
      "Model saved at epoch 60518 with loss: 7.9473\n",
      "Epoch [60520/100000], Loss: 7.9492\n",
      "Model saved at epoch 60530 with loss: 7.9473\n",
      "Epoch [60530/100000], Loss: 7.9473\n",
      "Epoch [60540/100000], Loss: 7.9519\n",
      "Epoch [60550/100000], Loss: 7.9539\n",
      "Epoch [60560/100000], Loss: 7.9502\n",
      "Model saved at epoch 60565 with loss: 7.9468\n",
      "Model saved at epoch 60566 with loss: 7.9468\n",
      "Epoch [60570/100000], Loss: 7.9483\n",
      "Epoch [60580/100000], Loss: 7.9482\n",
      "Model saved at epoch 60581 with loss: 7.9467\n",
      "Model saved at epoch 60582 with loss: 7.9462\n",
      "Epoch [60590/100000], Loss: 7.9467\n",
      "Model saved at epoch 60592 with loss: 7.9460\n",
      "Epoch [60600/100000], Loss: 7.9478\n",
      "Model saved at epoch 60604 with loss: 7.9460\n",
      "Model saved at epoch 60607 with loss: 7.9460\n",
      "Model saved at epoch 60608 with loss: 7.9457\n",
      "Epoch [60610/100000], Loss: 7.9467\n",
      "Model saved at epoch 60619 with loss: 7.9453\n",
      "Model saved at epoch 60620 with loss: 7.9451\n",
      "Epoch [60620/100000], Loss: 7.9451\n",
      "Epoch [60630/100000], Loss: 7.9476\n",
      "Epoch [60640/100000], Loss: 7.9492\n",
      "Epoch [60650/100000], Loss: 7.9481\n",
      "Epoch [60660/100000], Loss: 7.9476\n",
      "Model saved at epoch 60668 with loss: 7.9446\n",
      "Epoch [60670/100000], Loss: 7.9474\n",
      "Model saved at epoch 60677 with loss: 7.9443\n",
      "Model saved at epoch 60678 with loss: 7.9442\n",
      "Model saved at epoch 60680 with loss: 7.9438\n",
      "Epoch [60680/100000], Loss: 7.9438\n",
      "Model saved at epoch 60681 with loss: 7.9430\n",
      "Model saved at epoch 60682 with loss: 7.9422\n",
      "Epoch [60690/100000], Loss: 7.9434\n",
      "Model saved at epoch 60693 with loss: 7.9412\n",
      "Model saved at epoch 60694 with loss: 7.9407\n",
      "Model saved at epoch 60695 with loss: 7.9407\n",
      "Epoch [60700/100000], Loss: 7.9419\n",
      "Epoch [60710/100000], Loss: 7.9410\n",
      "Epoch [60720/100000], Loss: 7.9432\n",
      "Model saved at epoch 60729 with loss: 7.9397\n",
      "Epoch [60730/100000], Loss: 7.9406\n",
      "Epoch [60740/100000], Loss: 7.9414\n",
      "Epoch [60750/100000], Loss: 7.9431\n",
      "Epoch [60760/100000], Loss: 7.9420\n",
      "Epoch [60770/100000], Loss: 7.9458\n",
      "Epoch [60780/100000], Loss: 7.9440\n",
      "Epoch [60790/100000], Loss: 7.9448\n",
      "Epoch [60800/100000], Loss: 7.9427\n",
      "Epoch [60810/100000], Loss: 7.9439\n",
      "Epoch [60820/100000], Loss: 7.9449\n",
      "Epoch [60830/100000], Loss: 7.9467\n",
      "Epoch [60840/100000], Loss: 7.9415\n",
      "Model saved at epoch 60844 with loss: 7.9395\n",
      "Model saved at epoch 60850 with loss: 7.9394\n",
      "Epoch [60850/100000], Loss: 7.9394\n",
      "Model saved at epoch 60856 with loss: 7.9386\n",
      "Model saved at epoch 60858 with loss: 7.9377\n",
      "Model saved at epoch 60859 with loss: 7.9376\n",
      "Model saved at epoch 60860 with loss: 7.9374\n",
      "Epoch [60860/100000], Loss: 7.9374\n",
      "Model saved at epoch 60861 with loss: 7.9367\n",
      "Epoch [60870/100000], Loss: 7.9387\n",
      "Epoch [60880/100000], Loss: 7.9411\n",
      "Model saved at epoch 60884 with loss: 7.9361\n",
      "Model saved at epoch 60885 with loss: 7.9351\n",
      "Model saved at epoch 60886 with loss: 7.9349\n",
      "Epoch [60890/100000], Loss: 7.9356\n",
      "Epoch [60900/100000], Loss: 7.9373\n",
      "Epoch [60910/100000], Loss: 7.9390\n",
      "Model saved at epoch 60918 with loss: 7.9342\n",
      "Epoch [60920/100000], Loss: 7.9357\n",
      "Model saved at epoch 60923 with loss: 7.9333\n",
      "Epoch [60930/100000], Loss: 7.9337\n",
      "Epoch [60940/100000], Loss: 7.9367\n",
      "Epoch [60950/100000], Loss: 7.9361\n",
      "Epoch [60960/100000], Loss: 7.9346\n",
      "Epoch [60970/100000], Loss: 7.9356\n",
      "Epoch [60980/100000], Loss: 7.9411\n",
      "Epoch [60990/100000], Loss: 7.9395\n",
      "Epoch [61000/100000], Loss: 7.9409\n",
      "Epoch [61010/100000], Loss: 7.9393\n",
      "Epoch [61020/100000], Loss: 7.9363\n",
      "Epoch [61030/100000], Loss: 7.9349\n",
      "Model saved at epoch 61040 with loss: 7.9331\n",
      "Epoch [61040/100000], Loss: 7.9331\n",
      "Model saved at epoch 61041 with loss: 7.9329\n",
      "Model saved at epoch 61046 with loss: 7.9325\n",
      "Epoch [61050/100000], Loss: 7.9340\n",
      "Model saved at epoch 61053 with loss: 7.9316\n",
      "Model saved at epoch 61054 with loss: 7.9310\n",
      "Epoch [61060/100000], Loss: 7.9317\n",
      "Model saved at epoch 61063 with loss: 7.9300\n",
      "Model saved at epoch 61064 with loss: 7.9298\n",
      "Epoch [61070/100000], Loss: 7.9382\n",
      "Epoch [61080/100000], Loss: 7.9370\n",
      "Epoch [61090/100000], Loss: 7.9335\n",
      "Epoch [61100/100000], Loss: 7.9306\n",
      "Epoch [61110/100000], Loss: 7.9304\n",
      "Model saved at epoch 61116 with loss: 7.9296\n",
      "Model saved at epoch 61117 with loss: 7.9274\n",
      "Epoch [61120/100000], Loss: 7.9282\n",
      "Model saved at epoch 61124 with loss: 7.9273\n",
      "Model saved at epoch 61125 with loss: 7.9272\n",
      "Epoch [61130/100000], Loss: 7.9277\n",
      "Model saved at epoch 61135 with loss: 7.9264\n",
      "Epoch [61140/100000], Loss: 7.9297\n",
      "Epoch [61150/100000], Loss: 7.9283\n",
      "Epoch [61160/100000], Loss: 7.9310\n",
      "Epoch [61170/100000], Loss: 7.9324\n",
      "Epoch [61180/100000], Loss: 7.9289\n",
      "Epoch [61190/100000], Loss: 7.9280\n",
      "Model saved at epoch 61192 with loss: 7.9264\n",
      "Model saved at epoch 61193 with loss: 7.9256\n",
      "Model saved at epoch 61194 with loss: 7.9248\n",
      "Epoch [61200/100000], Loss: 7.9280\n",
      "Epoch [61210/100000], Loss: 7.9252\n",
      "Epoch [61220/100000], Loss: 7.9270\n",
      "Epoch [61230/100000], Loss: 7.9315\n",
      "Epoch [61240/100000], Loss: 7.9295\n",
      "Epoch [61250/100000], Loss: 7.9325\n",
      "Epoch [61260/100000], Loss: 7.9301\n",
      "Epoch [61270/100000], Loss: 7.9272\n",
      "Epoch [61280/100000], Loss: 7.9279\n",
      "Epoch [61290/100000], Loss: 7.9272\n",
      "Model saved at epoch 61292 with loss: 7.9244\n",
      "Model saved at epoch 61295 with loss: 7.9235\n",
      "Epoch [61300/100000], Loss: 7.9265\n",
      "Epoch [61310/100000], Loss: 7.9269\n",
      "Epoch [61320/100000], Loss: 7.9306\n",
      "Epoch [61330/100000], Loss: 7.9295\n",
      "Epoch [61340/100000], Loss: 7.9281\n",
      "Epoch [61350/100000], Loss: 7.9292\n",
      "Epoch [61360/100000], Loss: 7.9285\n",
      "Model saved at epoch 61368 with loss: 7.9227\n",
      "Epoch [61370/100000], Loss: 7.9230\n",
      "Model saved at epoch 61373 with loss: 7.9215\n",
      "Model saved at epoch 61374 with loss: 7.9191\n",
      "Epoch [61380/100000], Loss: 7.9212\n",
      "Epoch [61390/100000], Loss: 7.9215\n",
      "Epoch [61400/100000], Loss: 7.9208\n",
      "Model saved at epoch 61402 with loss: 7.9188\n",
      "Model saved at epoch 61403 with loss: 7.9187\n",
      "Model saved at epoch 61404 with loss: 7.9175\n",
      "Model saved at epoch 61405 with loss: 7.9172\n",
      "Model saved at epoch 61406 with loss: 7.9152\n",
      "Model saved at epoch 61407 with loss: 7.9143\n",
      "Model saved at epoch 61408 with loss: 7.9142\n",
      "Epoch [61410/100000], Loss: 7.9145\n",
      "Model saved at epoch 61417 with loss: 7.9138\n",
      "Epoch [61420/100000], Loss: 7.9140\n",
      "Epoch [61430/100000], Loss: 7.9201\n",
      "Epoch [61440/100000], Loss: 7.9156\n",
      "Epoch [61450/100000], Loss: 7.9188\n",
      "Epoch [61460/100000], Loss: 7.9170\n",
      "Epoch [61470/100000], Loss: 7.9197\n",
      "Epoch [61480/100000], Loss: 7.9208\n",
      "Epoch [61490/100000], Loss: 7.9208\n",
      "Epoch [61500/100000], Loss: 7.9202\n",
      "Epoch [61510/100000], Loss: 7.9233\n",
      "Epoch [61520/100000], Loss: 7.9246\n",
      "Epoch [61530/100000], Loss: 7.9214\n",
      "Epoch [61540/100000], Loss: 7.9200\n",
      "Epoch [61550/100000], Loss: 7.9150\n",
      "Epoch [61560/100000], Loss: 7.9159\n",
      "Model saved at epoch 61565 with loss: 7.9131\n",
      "Model saved at epoch 61566 with loss: 7.9125\n",
      "Model saved at epoch 61567 with loss: 7.9112\n",
      "Model saved at epoch 61568 with loss: 7.9110\n",
      "Epoch [61570/100000], Loss: 7.9123\n",
      "Epoch [61580/100000], Loss: 7.9156\n",
      "Epoch [61590/100000], Loss: 7.9147\n",
      "Epoch [61600/100000], Loss: 7.9145\n",
      "Epoch [61610/100000], Loss: 7.9139\n",
      "Epoch [61620/100000], Loss: 7.9135\n",
      "Epoch [61630/100000], Loss: 7.9171\n",
      "Epoch [61640/100000], Loss: 7.9146\n",
      "Epoch [61650/100000], Loss: 7.9179\n",
      "Epoch [61660/100000], Loss: 7.9172\n",
      "Epoch [61670/100000], Loss: 7.9173\n",
      "Epoch [61680/100000], Loss: 7.9179\n",
      "Epoch [61690/100000], Loss: 7.9129\n",
      "Model saved at epoch 61700 with loss: 7.9103\n",
      "Epoch [61700/100000], Loss: 7.9103\n",
      "Model saved at epoch 61705 with loss: 7.9103\n",
      "Epoch [61710/100000], Loss: 7.9136\n",
      "Epoch [61720/100000], Loss: 7.9145\n",
      "Model saved at epoch 61729 with loss: 7.9099\n",
      "Epoch [61730/100000], Loss: 7.9114\n",
      "Model saved at epoch 61732 with loss: 7.9096\n",
      "Model saved at epoch 61733 with loss: 7.9095\n",
      "Epoch [61740/100000], Loss: 7.9113\n",
      "Model saved at epoch 61742 with loss: 7.9094\n",
      "Model saved at epoch 61744 with loss: 7.9087\n",
      "Model saved at epoch 61746 with loss: 7.9086\n",
      "Model saved at epoch 61747 with loss: 7.9069\n",
      "Epoch [61750/100000], Loss: 7.9089\n",
      "Epoch [61760/100000], Loss: 7.9087\n",
      "Model saved at epoch 61769 with loss: 7.9061\n",
      "Model saved at epoch 61770 with loss: 7.9053\n",
      "Epoch [61770/100000], Loss: 7.9053\n",
      "Model saved at epoch 61771 with loss: 7.9044\n",
      "Epoch [61780/100000], Loss: 7.9093\n",
      "Epoch [61790/100000], Loss: 7.9067\n",
      "Epoch [61800/100000], Loss: 7.9081\n",
      "Epoch [61810/100000], Loss: 7.9117\n",
      "Epoch [61820/100000], Loss: 7.9072\n",
      "Epoch [61830/100000], Loss: 7.9064\n",
      "Model saved at epoch 61836 with loss: 7.9042\n",
      "Epoch [61840/100000], Loss: 7.9064\n",
      "Epoch [61850/100000], Loss: 7.9046\n",
      "Model saved at epoch 61855 with loss: 7.9040\n",
      "Model saved at epoch 61858 with loss: 7.9030\n",
      "Epoch [61860/100000], Loss: 7.9038\n",
      "Model saved at epoch 61862 with loss: 7.9029\n",
      "Model saved at epoch 61867 with loss: 7.9018\n",
      "Epoch [61870/100000], Loss: 7.9025\n",
      "Epoch [61880/100000], Loss: 7.9064\n",
      "Epoch [61890/100000], Loss: 7.9064\n",
      "Epoch [61900/100000], Loss: 7.9057\n",
      "Epoch [61910/100000], Loss: 7.9062\n",
      "Model saved at epoch 61920 with loss: 7.9018\n",
      "Epoch [61920/100000], Loss: 7.9018\n",
      "Model saved at epoch 61921 with loss: 7.9009\n",
      "Model saved at epoch 61922 with loss: 7.9000\n",
      "Epoch [61930/100000], Loss: 7.9036\n",
      "Epoch [61940/100000], Loss: 7.9035\n",
      "Epoch [61950/100000], Loss: 7.9043\n",
      "Epoch [61960/100000], Loss: 7.9056\n",
      "Epoch [61970/100000], Loss: 7.9001\n",
      "Model saved at epoch 61971 with loss: 7.8992\n",
      "Epoch [61980/100000], Loss: 7.9038\n",
      "Epoch [61990/100000], Loss: 7.9044\n",
      "Model saved at epoch 61995 with loss: 7.8992\n",
      "Model saved at epoch 61997 with loss: 7.8992\n",
      "Model saved at epoch 61998 with loss: 7.8988\n",
      "Epoch [62000/100000], Loss: 7.9006\n",
      "Epoch [62010/100000], Loss: 7.9045\n",
      "Model saved at epoch 62017 with loss: 7.8973\n",
      "Model saved at epoch 62019 with loss: 7.8963\n",
      "Epoch [62020/100000], Loss: 7.8975\n",
      "Epoch [62030/100000], Loss: 7.8990\n",
      "Epoch [62040/100000], Loss: 7.8985\n",
      "Epoch [62050/100000], Loss: 7.9007\n",
      "Epoch [62060/100000], Loss: 7.9005\n",
      "Epoch [62070/100000], Loss: 7.8994\n",
      "Epoch [62080/100000], Loss: 7.9031\n",
      "Epoch [62090/100000], Loss: 7.9041\n",
      "Model saved at epoch 62100 with loss: 7.8946\n",
      "Epoch [62100/100000], Loss: 7.8946\n",
      "Model saved at epoch 62101 with loss: 7.8943\n",
      "Epoch [62110/100000], Loss: 7.8974\n",
      "Model saved at epoch 62116 with loss: 7.8942\n",
      "Model saved at epoch 62117 with loss: 7.8920\n",
      "Model saved at epoch 62119 with loss: 7.8909\n",
      "Epoch [62120/100000], Loss: 7.8915\n",
      "Epoch [62130/100000], Loss: 7.8977\n",
      "Epoch [62140/100000], Loss: 7.8997\n",
      "Epoch [62150/100000], Loss: 7.8988\n",
      "Epoch [62160/100000], Loss: 7.8935\n",
      "Epoch [62170/100000], Loss: 7.8961\n",
      "Epoch [62180/100000], Loss: 7.8916\n",
      "Model saved at epoch 62181 with loss: 7.8886\n",
      "Model saved at epoch 62182 with loss: 7.8869\n",
      "Epoch [62190/100000], Loss: 7.8938\n",
      "Epoch [62200/100000], Loss: 7.8939\n",
      "Epoch [62210/100000], Loss: 7.8958\n",
      "Epoch [62220/100000], Loss: 7.8887\n",
      "Epoch [62230/100000], Loss: 7.8905\n",
      "Model saved at epoch 62236 with loss: 7.8856\n",
      "Epoch [62240/100000], Loss: 7.8871\n",
      "Epoch [62250/100000], Loss: 7.8936\n",
      "Epoch [62260/100000], Loss: 7.8872\n",
      "Epoch [62270/100000], Loss: 7.8880\n",
      "Epoch [62280/100000], Loss: 7.8901\n",
      "Epoch [62290/100000], Loss: 7.8861\n",
      "Model saved at epoch 62292 with loss: 7.8856\n",
      "Model saved at epoch 62293 with loss: 7.8848\n",
      "Model saved at epoch 62295 with loss: 7.8848\n",
      "Model saved at epoch 62296 with loss: 7.8842\n",
      "Epoch [62300/100000], Loss: 7.8857\n",
      "Model saved at epoch 62302 with loss: 7.8842\n",
      "Model saved at epoch 62303 with loss: 7.8827\n",
      "Model saved at epoch 62304 with loss: 7.8826\n",
      "Model saved at epoch 62307 with loss: 7.8820\n",
      "Model saved at epoch 62308 with loss: 7.8814\n",
      "Epoch [62310/100000], Loss: 7.8821\n",
      "Epoch [62320/100000], Loss: 7.8843\n",
      "Model saved at epoch 62324 with loss: 7.8811\n",
      "Epoch [62330/100000], Loss: 7.8890\n",
      "Epoch [62340/100000], Loss: 7.8901\n",
      "Epoch [62350/100000], Loss: 7.8868\n",
      "Epoch [62360/100000], Loss: 7.8869\n",
      "Epoch [62370/100000], Loss: 7.8852\n",
      "Model saved at epoch 62373 with loss: 7.8808\n",
      "Model saved at epoch 62374 with loss: 7.8799\n",
      "Model saved at epoch 62380 with loss: 7.8797\n",
      "Epoch [62380/100000], Loss: 7.8797\n",
      "Epoch [62390/100000], Loss: 7.8833\n",
      "Model saved at epoch 62398 with loss: 7.8784\n",
      "Model saved at epoch 62399 with loss: 7.8780\n",
      "Epoch [62400/100000], Loss: 7.8788\n",
      "Model saved at epoch 62403 with loss: 7.8775\n",
      "Model saved at epoch 62404 with loss: 7.8774\n",
      "Model saved at epoch 62406 with loss: 7.8769\n",
      "Model saved at epoch 62407 with loss: 7.8766\n",
      "Epoch [62410/100000], Loss: 7.8794\n",
      "Epoch [62420/100000], Loss: 7.8813\n",
      "Epoch [62430/100000], Loss: 7.8819\n",
      "Epoch [62440/100000], Loss: 7.8790\n",
      "Epoch [62450/100000], Loss: 7.8825\n",
      "Epoch [62460/100000], Loss: 7.8814\n",
      "Model saved at epoch 62468 with loss: 7.8739\n",
      "Epoch [62470/100000], Loss: 7.8755\n",
      "Model saved at epoch 62476 with loss: 7.8739\n",
      "Model saved at epoch 62477 with loss: 7.8729\n",
      "Model saved at epoch 62478 with loss: 7.8710\n",
      "Model saved at epoch 62479 with loss: 7.8694\n",
      "Model saved at epoch 62480 with loss: 7.8690\n",
      "Epoch [62480/100000], Loss: 7.8690\n",
      "Epoch [62490/100000], Loss: 7.8784\n",
      "Epoch [62500/100000], Loss: 7.8755\n",
      "Epoch [62510/100000], Loss: 7.8767\n",
      "Epoch [62520/100000], Loss: 7.8741\n",
      "Epoch [62530/100000], Loss: 7.8705\n",
      "Model saved at epoch 62540 with loss: 7.8689\n",
      "Epoch [62540/100000], Loss: 7.8689\n",
      "Epoch [62550/100000], Loss: 7.8721\n",
      "Model saved at epoch 62557 with loss: 7.8688\n",
      "Model saved at epoch 62560 with loss: 7.8685\n",
      "Epoch [62560/100000], Loss: 7.8685\n",
      "Epoch [62570/100000], Loss: 7.8737\n",
      "Epoch [62580/100000], Loss: 7.8729\n",
      "Epoch [62590/100000], Loss: 7.8754\n",
      "Epoch [62600/100000], Loss: 7.8701\n",
      "Model saved at epoch 62602 with loss: 7.8676\n",
      "Model saved at epoch 62603 with loss: 7.8665\n",
      "Model saved at epoch 62607 with loss: 7.8662\n",
      "Model saved at epoch 62608 with loss: 7.8648\n",
      "Epoch [62610/100000], Loss: 7.8683\n",
      "Epoch [62620/100000], Loss: 7.8685\n",
      "Model saved at epoch 62623 with loss: 7.8648\n",
      "Model saved at epoch 62624 with loss: 7.8642\n",
      "Model saved at epoch 62625 with loss: 7.8636\n",
      "Epoch [62630/100000], Loss: 7.8698\n",
      "Epoch [62640/100000], Loss: 7.8659\n",
      "Epoch [62650/100000], Loss: 7.8656\n",
      "Model saved at epoch 62658 with loss: 7.8628\n",
      "Epoch [62660/100000], Loss: 7.8636\n",
      "Model saved at epoch 62661 with loss: 7.8622\n",
      "Model saved at epoch 62667 with loss: 7.8613\n",
      "Model saved at epoch 62669 with loss: 7.8600\n",
      "Epoch [62670/100000], Loss: 7.8604\n",
      "Model saved at epoch 62675 with loss: 7.8587\n",
      "Model saved at epoch 62676 with loss: 7.8582\n",
      "Epoch [62680/100000], Loss: 7.8589\n",
      "Model saved at epoch 62681 with loss: 7.8573\n",
      "Epoch [62690/100000], Loss: 7.8645\n",
      "Epoch [62700/100000], Loss: 7.8650\n",
      "Epoch [62710/100000], Loss: 7.8620\n",
      "Epoch [62720/100000], Loss: 7.8643\n",
      "Epoch [62730/100000], Loss: 7.8651\n",
      "Epoch [62740/100000], Loss: 7.8626\n",
      "Model saved at epoch 62750 with loss: 7.8556\n",
      "Epoch [62750/100000], Loss: 7.8556\n",
      "Epoch [62760/100000], Loss: 7.8612\n",
      "Epoch [62770/100000], Loss: 7.8635\n",
      "Epoch [62780/100000], Loss: 7.8622\n",
      "Model saved at epoch 62785 with loss: 7.8553\n",
      "Epoch [62790/100000], Loss: 7.8561\n",
      "Model saved at epoch 62792 with loss: 7.8551\n",
      "Model saved at epoch 62793 with loss: 7.8530\n",
      "Epoch [62800/100000], Loss: 7.8572\n",
      "Epoch [62810/100000], Loss: 7.8549\n",
      "Epoch [62820/100000], Loss: 7.8562\n",
      "Epoch [62830/100000], Loss: 7.8565\n",
      "Epoch [62840/100000], Loss: 7.8540\n",
      "Epoch [62850/100000], Loss: 7.8563\n",
      "Epoch [62860/100000], Loss: 7.8537\n",
      "Model saved at epoch 62868 with loss: 7.8524\n",
      "Model saved at epoch 62869 with loss: 7.8512\n",
      "Epoch [62870/100000], Loss: 7.8518\n",
      "Model saved at epoch 62874 with loss: 7.8511\n",
      "Epoch [62880/100000], Loss: 7.8511\n",
      "Model saved at epoch 62881 with loss: 7.8504\n",
      "Epoch [62890/100000], Loss: 7.8538\n",
      "Model saved at epoch 62898 with loss: 7.8500\n",
      "Model saved at epoch 62900 with loss: 7.8479\n",
      "Epoch [62900/100000], Loss: 7.8479\n",
      "Model saved at epoch 62903 with loss: 7.8476\n",
      "Epoch [62910/100000], Loss: 7.8479\n",
      "Epoch [62920/100000], Loss: 7.8484\n",
      "Epoch [62930/100000], Loss: 7.8499\n",
      "Epoch [62940/100000], Loss: 7.8497\n",
      "Epoch [62950/100000], Loss: 7.8477\n",
      "Model saved at epoch 62951 with loss: 7.8465\n",
      "Model saved at epoch 62952 with loss: 7.8452\n",
      "Model saved at epoch 62956 with loss: 7.8449\n",
      "Model saved at epoch 62959 with loss: 7.8428\n",
      "Epoch [62960/100000], Loss: 7.8442\n",
      "Epoch [62970/100000], Loss: 7.8487\n",
      "Epoch [62980/100000], Loss: 7.8457\n",
      "Epoch [62990/100000], Loss: 7.8468\n",
      "Epoch [63000/100000], Loss: 7.8480\n",
      "Model saved at epoch 63006 with loss: 7.8423\n",
      "Epoch [63010/100000], Loss: 7.8423\n",
      "Model saved at epoch 63011 with loss: 7.8407\n",
      "Model saved at epoch 63012 with loss: 7.8399\n",
      "Model saved at epoch 63013 with loss: 7.8389\n",
      "Model saved at epoch 63019 with loss: 7.8382\n",
      "Epoch [63020/100000], Loss: 7.8401\n",
      "Epoch [63030/100000], Loss: 7.8409\n",
      "Epoch [63040/100000], Loss: 7.8485\n",
      "Epoch [63050/100000], Loss: 7.8422\n",
      "Epoch [63060/100000], Loss: 7.8405\n",
      "Epoch [63070/100000], Loss: 7.8462\n",
      "Model saved at epoch 63078 with loss: 7.8378\n",
      "Model saved at epoch 63079 with loss: 7.8370\n",
      "Epoch [63080/100000], Loss: 7.8371\n",
      "Model saved at epoch 63082 with loss: 7.8368\n",
      "Model saved at epoch 63083 with loss: 7.8360\n",
      "Model saved at epoch 63090 with loss: 7.8356\n",
      "Epoch [63090/100000], Loss: 7.8356\n",
      "Epoch [63100/100000], Loss: 7.8382\n",
      "Epoch [63110/100000], Loss: 7.8366\n",
      "Epoch [63120/100000], Loss: 7.8401\n",
      "Epoch [63130/100000], Loss: 7.8441\n",
      "Epoch [63140/100000], Loss: 7.8384\n",
      "Model saved at epoch 63143 with loss: 7.8350\n",
      "Epoch [63150/100000], Loss: 7.8383\n",
      "Model saved at epoch 63157 with loss: 7.8346\n",
      "Model saved at epoch 63158 with loss: 7.8323\n",
      "Epoch [63160/100000], Loss: 7.8371\n",
      "Model saved at epoch 63164 with loss: 7.8311\n",
      "Model saved at epoch 63167 with loss: 7.8307\n",
      "Model saved at epoch 63168 with loss: 7.8306\n",
      "Epoch [63170/100000], Loss: 7.8323\n",
      "Epoch [63180/100000], Loss: 7.8347\n",
      "Model saved at epoch 63187 with loss: 7.8303\n",
      "Model saved at epoch 63188 with loss: 7.8295\n",
      "Epoch [63190/100000], Loss: 7.8332\n",
      "Epoch [63200/100000], Loss: 7.8350\n",
      "Epoch [63210/100000], Loss: 7.8346\n",
      "Epoch [63220/100000], Loss: 7.8340\n",
      "Model saved at epoch 63229 with loss: 7.8287\n",
      "Model saved at epoch 63230 with loss: 7.8284\n",
      "Epoch [63230/100000], Loss: 7.8284\n",
      "Model saved at epoch 63235 with loss: 7.8260\n",
      "Model saved at epoch 63236 with loss: 7.8254\n",
      "Model saved at epoch 63238 with loss: 7.8248\n",
      "Epoch [63240/100000], Loss: 7.8269\n",
      "Epoch [63250/100000], Loss: 7.8302\n",
      "Epoch [63260/100000], Loss: 7.8299\n",
      "Epoch [63270/100000], Loss: 7.8323\n",
      "Epoch [63280/100000], Loss: 7.8276\n",
      "Epoch [63290/100000], Loss: 7.8295\n",
      "Epoch [63300/100000], Loss: 7.8280\n",
      "Model saved at epoch 63303 with loss: 7.8242\n",
      "Epoch [63310/100000], Loss: 7.8246\n",
      "Model saved at epoch 63312 with loss: 7.8238\n",
      "Model saved at epoch 63313 with loss: 7.8237\n",
      "Model saved at epoch 63314 with loss: 7.8220\n",
      "Model saved at epoch 63315 with loss: 7.8209\n",
      "Epoch [63320/100000], Loss: 7.8222\n",
      "Model saved at epoch 63321 with loss: 7.8207\n",
      "Epoch [63330/100000], Loss: 7.8216\n",
      "Model saved at epoch 63335 with loss: 7.8202\n",
      "Model saved at epoch 63336 with loss: 7.8193\n",
      "Model saved at epoch 63337 with loss: 7.8179\n",
      "Epoch [63340/100000], Loss: 7.8196\n",
      "Model saved at epoch 63343 with loss: 7.8175\n",
      "Epoch [63350/100000], Loss: 7.8196\n",
      "Epoch [63360/100000], Loss: 7.8224\n",
      "Epoch [63370/100000], Loss: 7.8226\n",
      "Epoch [63380/100000], Loss: 7.8213\n",
      "Epoch [63390/100000], Loss: 7.8219\n",
      "Model saved at epoch 63397 with loss: 7.8141\n",
      "Model saved at epoch 63398 with loss: 7.8131\n",
      "Model saved at epoch 63399 with loss: 7.8122\n",
      "Epoch [63400/100000], Loss: 7.8153\n",
      "Epoch [63410/100000], Loss: 7.8144\n",
      "Epoch [63420/100000], Loss: 7.8189\n",
      "Epoch [63430/100000], Loss: 7.8211\n",
      "Epoch [63440/100000], Loss: 7.8232\n",
      "Epoch [63450/100000], Loss: 7.8189\n",
      "Model saved at epoch 63458 with loss: 7.8098\n",
      "Epoch [63460/100000], Loss: 7.8138\n",
      "Epoch [63470/100000], Loss: 7.8146\n",
      "Epoch [63480/100000], Loss: 7.8119\n",
      "Model saved at epoch 63486 with loss: 7.8078\n",
      "Model saved at epoch 63488 with loss: 7.8071\n",
      "Epoch [63490/100000], Loss: 7.8103\n",
      "Model saved at epoch 63499 with loss: 7.8071\n",
      "Model saved at epoch 63500 with loss: 7.8053\n",
      "Epoch [63500/100000], Loss: 7.8053\n",
      "Epoch [63510/100000], Loss: 7.8063\n",
      "Model saved at epoch 63519 with loss: 7.8050\n",
      "Epoch [63520/100000], Loss: 7.8052\n",
      "Model saved at epoch 63521 with loss: 7.8042\n",
      "Model saved at epoch 63523 with loss: 7.8042\n",
      "Model saved at epoch 63527 with loss: 7.8030\n",
      "Model saved at epoch 63528 with loss: 7.8022\n",
      "Model saved at epoch 63530 with loss: 7.8019\n",
      "Epoch [63530/100000], Loss: 7.8019\n",
      "Epoch [63540/100000], Loss: 7.8062\n",
      "Model saved at epoch 63546 with loss: 7.8010\n",
      "Model saved at epoch 63547 with loss: 7.8007\n",
      "Epoch [63550/100000], Loss: 7.8043\n",
      "Epoch [63560/100000], Loss: 7.8054\n",
      "Epoch [63570/100000], Loss: 7.8014\n",
      "Model saved at epoch 63572 with loss: 7.8002\n",
      "Model saved at epoch 63575 with loss: 7.8002\n",
      "Model saved at epoch 63576 with loss: 7.7990\n",
      "Model saved at epoch 63577 with loss: 7.7963\n",
      "Epoch [63580/100000], Loss: 7.7980\n",
      "Model saved at epoch 63590 with loss: 7.7960\n",
      "Epoch [63590/100000], Loss: 7.7960\n",
      "Model saved at epoch 63592 with loss: 7.7960\n",
      "Model saved at epoch 63600 with loss: 7.7955\n",
      "Epoch [63600/100000], Loss: 7.7955\n",
      "Epoch [63610/100000], Loss: 7.7976\n",
      "Epoch [63620/100000], Loss: 7.8008\n",
      "Model saved at epoch 63623 with loss: 7.7946\n",
      "Model saved at epoch 63624 with loss: 7.7941\n",
      "Model saved at epoch 63625 with loss: 7.7925\n",
      "Epoch [63630/100000], Loss: 7.7940\n",
      "Model saved at epoch 63631 with loss: 7.7922\n",
      "Model saved at epoch 63632 with loss: 7.7922\n",
      "Epoch [63640/100000], Loss: 7.7922\n",
      "Model saved at epoch 63641 with loss: 7.7909\n",
      "Epoch [63650/100000], Loss: 7.7925\n",
      "Model saved at epoch 63656 with loss: 7.7903\n",
      "Model saved at epoch 63657 with loss: 7.7882\n",
      "Model saved at epoch 63658 with loss: 7.7871\n",
      "Epoch [63660/100000], Loss: 7.7900\n",
      "Model saved at epoch 63663 with loss: 7.7861\n",
      "Model saved at epoch 63667 with loss: 7.7856\n",
      "Epoch [63670/100000], Loss: 7.7877\n",
      "Model saved at epoch 63676 with loss: 7.7845\n",
      "Epoch [63680/100000], Loss: 7.7877\n",
      "Model saved at epoch 63682 with loss: 7.7844\n",
      "Model saved at epoch 63683 with loss: 7.7839\n",
      "Model saved at epoch 63684 with loss: 7.7827\n",
      "Model saved at epoch 63685 with loss: 7.7826\n",
      "Model saved at epoch 63687 with loss: 7.7817\n",
      "Model saved at epoch 63688 with loss: 7.7803\n",
      "Epoch [63690/100000], Loss: 7.7831\n",
      "Model saved at epoch 63694 with loss: 7.7787\n",
      "Epoch [63700/100000], Loss: 7.7866\n",
      "Epoch [63710/100000], Loss: 7.7847\n",
      "Model saved at epoch 63720 with loss: 7.7785\n",
      "Epoch [63720/100000], Loss: 7.7785\n",
      "Epoch [63730/100000], Loss: 7.7807\n",
      "Epoch [63740/100000], Loss: 7.7797\n",
      "Epoch [63750/100000], Loss: 7.7829\n",
      "Epoch [63760/100000], Loss: 7.7854\n",
      "Epoch [63770/100000], Loss: 7.7837\n",
      "Epoch [63780/100000], Loss: 7.7837\n",
      "Model saved at epoch 63783 with loss: 7.7783\n",
      "Model saved at epoch 63790 with loss: 7.7773\n",
      "Epoch [63790/100000], Loss: 7.7773\n",
      "Epoch [63800/100000], Loss: 7.7801\n",
      "Model saved at epoch 63801 with loss: 7.7765\n",
      "Epoch [63810/100000], Loss: 7.7801\n",
      "Epoch [63820/100000], Loss: 7.7836\n",
      "Model saved at epoch 63827 with loss: 7.7765\n",
      "Model saved at epoch 63828 with loss: 7.7761\n",
      "Model saved at epoch 63829 with loss: 7.7743\n",
      "Model saved at epoch 63830 with loss: 7.7741\n",
      "Epoch [63830/100000], Loss: 7.7741\n",
      "Model saved at epoch 63831 with loss: 7.7737\n",
      "Model saved at epoch 63838 with loss: 7.7733\n",
      "Epoch [63840/100000], Loss: 7.7766\n",
      "Epoch [63850/100000], Loss: 7.7830\n",
      "Epoch [63860/100000], Loss: 7.7772\n",
      "Epoch [63870/100000], Loss: 7.7818\n",
      "Model saved at epoch 63876 with loss: 7.7729\n",
      "Model saved at epoch 63877 with loss: 7.7722\n",
      "Model saved at epoch 63878 with loss: 7.7705\n",
      "Epoch [63880/100000], Loss: 7.7744\n",
      "Epoch [63890/100000], Loss: 7.7760\n",
      "Epoch [63900/100000], Loss: 7.7767\n",
      "Model saved at epoch 63910 with loss: 7.7703\n",
      "Epoch [63910/100000], Loss: 7.7703\n",
      "Model saved at epoch 63912 with loss: 7.7699\n",
      "Model saved at epoch 63913 with loss: 7.7681\n",
      "Model saved at epoch 63914 with loss: 7.7665\n",
      "Epoch [63920/100000], Loss: 7.7702\n",
      "Model saved at epoch 63923 with loss: 7.7656\n",
      "Epoch [63930/100000], Loss: 7.7716\n",
      "Epoch [63940/100000], Loss: 7.7707\n",
      "Epoch [63950/100000], Loss: 7.7683\n",
      "Epoch [63960/100000], Loss: 7.7687\n",
      "Epoch [63970/100000], Loss: 7.7671\n",
      "Model saved at epoch 63974 with loss: 7.7646\n",
      "Model saved at epoch 63975 with loss: 7.7638\n",
      "Model saved at epoch 63976 with loss: 7.7617\n",
      "Epoch [63980/100000], Loss: 7.7666\n",
      "Epoch [63990/100000], Loss: 7.7660\n",
      "Model saved at epoch 63993 with loss: 7.7612\n",
      "Model saved at epoch 63994 with loss: 7.7603\n",
      "Model saved at epoch 63995 with loss: 7.7598\n",
      "Epoch [64000/100000], Loss: 7.7631\n",
      "Model saved at epoch 64006 with loss: 7.7598\n",
      "Model saved at epoch 64010 with loss: 7.7593\n",
      "Epoch [64010/100000], Loss: 7.7593\n",
      "Model saved at epoch 64011 with loss: 7.7581\n",
      "Epoch [64020/100000], Loss: 7.7616\n",
      "Model saved at epoch 64028 with loss: 7.7553\n",
      "Model saved at epoch 64029 with loss: 7.7531\n",
      "Epoch [64030/100000], Loss: 7.7552\n",
      "Epoch [64040/100000], Loss: 7.7552\n",
      "Model saved at epoch 64048 with loss: 7.7530\n",
      "Model saved at epoch 64050 with loss: 7.7528\n",
      "Epoch [64050/100000], Loss: 7.7528\n",
      "Epoch [64060/100000], Loss: 7.7583\n",
      "Model saved at epoch 64069 with loss: 7.7527\n",
      "Epoch [64070/100000], Loss: 7.7555\n",
      "Model saved at epoch 64075 with loss: 7.7516\n",
      "Epoch [64080/100000], Loss: 7.7528\n",
      "Model saved at epoch 64082 with loss: 7.7502\n",
      "Model saved at epoch 64083 with loss: 7.7481\n",
      "Model saved at epoch 64084 with loss: 7.7473\n",
      "Epoch [64090/100000], Loss: 7.7494\n",
      "Epoch [64100/100000], Loss: 7.7497\n",
      "Epoch [64110/100000], Loss: 7.7543\n",
      "Epoch [64120/100000], Loss: 7.7536\n",
      "Epoch [64130/100000], Loss: 7.7477\n",
      "Model saved at epoch 64136 with loss: 7.7472\n",
      "Model saved at epoch 64138 with loss: 7.7464\n",
      "Model saved at epoch 64140 with loss: 7.7445\n",
      "Epoch [64140/100000], Loss: 7.7445\n",
      "Model saved at epoch 64144 with loss: 7.7426\n",
      "Model saved at epoch 64145 with loss: 7.7424\n",
      "Epoch [64150/100000], Loss: 7.7458\n",
      "Model saved at epoch 64159 with loss: 7.7422\n",
      "Model saved at epoch 64160 with loss: 7.7405\n",
      "Epoch [64160/100000], Loss: 7.7405\n",
      "Model saved at epoch 64161 with loss: 7.7400\n",
      "Epoch [64170/100000], Loss: 7.7475\n",
      "Epoch [64180/100000], Loss: 7.7463\n",
      "Epoch [64190/100000], Loss: 7.7444\n",
      "Model saved at epoch 64193 with loss: 7.7378\n",
      "Epoch [64200/100000], Loss: 7.7419\n",
      "Epoch [64210/100000], Loss: 7.7443\n",
      "Epoch [64220/100000], Loss: 7.7425\n",
      "Epoch [64230/100000], Loss: 7.7395\n",
      "Epoch [64240/100000], Loss: 7.7389\n",
      "Model saved at epoch 64241 with loss: 7.7373\n",
      "Model saved at epoch 64242 with loss: 7.7364\n",
      "Model saved at epoch 64245 with loss: 7.7353\n",
      "Model saved at epoch 64250 with loss: 7.7329\n",
      "Epoch [64250/100000], Loss: 7.7329\n",
      "Epoch [64260/100000], Loss: 7.7362\n",
      "Model saved at epoch 64266 with loss: 7.7327\n",
      "Epoch [64270/100000], Loss: 7.7365\n",
      "Model saved at epoch 64275 with loss: 7.7325\n",
      "Epoch [64280/100000], Loss: 7.7350\n",
      "Model saved at epoch 64290 with loss: 7.7316\n",
      "Epoch [64290/100000], Loss: 7.7316\n",
      "Epoch [64300/100000], Loss: 7.7348\n",
      "Model saved at epoch 64303 with loss: 7.7311\n",
      "Epoch [64310/100000], Loss: 7.7336\n",
      "Model saved at epoch 64313 with loss: 7.7304\n",
      "Model saved at epoch 64314 with loss: 7.7297\n",
      "Model saved at epoch 64316 with loss: 7.7269\n",
      "Model saved at epoch 64317 with loss: 7.7263\n",
      "Epoch [64320/100000], Loss: 7.7267\n",
      "Model saved at epoch 64321 with loss: 7.7260\n",
      "Epoch [64330/100000], Loss: 7.7319\n",
      "Model saved at epoch 64338 with loss: 7.7248\n",
      "Epoch [64340/100000], Loss: 7.7292\n",
      "Epoch [64350/100000], Loss: 7.7349\n",
      "Epoch [64360/100000], Loss: 7.7319\n",
      "Epoch [64370/100000], Loss: 7.7261\n",
      "Model saved at epoch 64371 with loss: 7.7241\n",
      "Epoch [64380/100000], Loss: 7.7274\n",
      "Model saved at epoch 64390 with loss: 7.7236\n",
      "Epoch [64390/100000], Loss: 7.7236\n",
      "Model saved at epoch 64394 with loss: 7.7227\n",
      "Model saved at epoch 64397 with loss: 7.7195\n",
      "Epoch [64400/100000], Loss: 7.7230\n",
      "Epoch [64410/100000], Loss: 7.7224\n",
      "Model saved at epoch 64419 with loss: 7.7195\n",
      "Epoch [64420/100000], Loss: 7.7212\n",
      "Model saved at epoch 64421 with loss: 7.7185\n",
      "Model saved at epoch 64422 with loss: 7.7175\n",
      "Model saved at epoch 64423 with loss: 7.7159\n",
      "Model saved at epoch 64429 with loss: 7.7159\n",
      "Model saved at epoch 64430 with loss: 7.7134\n",
      "Epoch [64430/100000], Loss: 7.7134\n",
      "Model saved at epoch 64431 with loss: 7.7125\n",
      "Epoch [64440/100000], Loss: 7.7188\n",
      "Epoch [64450/100000], Loss: 7.7215\n",
      "Epoch [64460/100000], Loss: 7.7196\n",
      "Epoch [64470/100000], Loss: 7.7138\n",
      "Model saved at epoch 64474 with loss: 7.7121\n",
      "Model saved at epoch 64476 with loss: 7.7096\n",
      "Epoch [64480/100000], Loss: 7.7135\n",
      "Model saved at epoch 64481 with loss: 7.7055\n",
      "Epoch [64490/100000], Loss: 7.7128\n",
      "Epoch [64500/100000], Loss: 7.7134\n",
      "Epoch [64510/100000], Loss: 1064914176.0000\n",
      "Epoch [64520/100000], Loss: 2101703808.0000\n",
      "Epoch [64530/100000], Loss: 317867456.0000\n",
      "Epoch [64540/100000], Loss: 41464564.0000\n",
      "Epoch [64550/100000], Loss: 7136341.0000\n",
      "Epoch [64560/100000], Loss: 5352534.5000\n",
      "Epoch [64570/100000], Loss: 4616300.0000\n",
      "Epoch [64580/100000], Loss: 2702286.7500\n",
      "Epoch [64590/100000], Loss: 1269052.8750\n",
      "Epoch [64600/100000], Loss: 454618.1250\n",
      "Epoch [64610/100000], Loss: 127462.6016\n",
      "Epoch [64620/100000], Loss: 23821.4336\n",
      "Epoch [64630/100000], Loss: 3464.2756\n",
      "Epoch [64640/100000], Loss: 1694.0930\n",
      "Epoch [64650/100000], Loss: 1586.9486\n",
      "Epoch [64660/100000], Loss: 831.0759\n",
      "Epoch [64670/100000], Loss: 244.1738\n",
      "Epoch [64680/100000], Loss: 37.5288\n",
      "Epoch [64690/100000], Loss: 13.8334\n",
      "Epoch [64700/100000], Loss: 20.6400\n",
      "Epoch [64710/100000], Loss: 12.5923\n",
      "Epoch [64720/100000], Loss: 9.7873\n",
      "Epoch [64730/100000], Loss: 8.2319\n",
      "Epoch [64740/100000], Loss: 7.7410\n",
      "Model saved at epoch 64741 with loss: 7.6793\n",
      "Model saved at epoch 64746 with loss: 7.6769\n",
      "Epoch [64750/100000], Loss: 7.7272\n",
      "Model saved at epoch 64759 with loss: 7.6768\n",
      "Epoch [64760/100000], Loss: 7.6791\n",
      "Epoch [64770/100000], Loss: 7.6821\n",
      "Epoch [64780/100000], Loss: 7.6817\n",
      "Model saved at epoch 64787 with loss: 7.6762\n",
      "Model saved at epoch 64789 with loss: 7.6758\n",
      "Model saved at epoch 64790 with loss: 7.6757\n",
      "Epoch [64790/100000], Loss: 7.6757\n",
      "Epoch [64800/100000], Loss: 7.6818\n",
      "Epoch [64810/100000], Loss: 7.6845\n",
      "Epoch [64820/100000], Loss: 7.6813\n",
      "Epoch [64830/100000], Loss: 7.6814\n",
      "Epoch [64840/100000], Loss: 7.6811\n",
      "Epoch [64850/100000], Loss: 7.6806\n",
      "Epoch [64860/100000], Loss: 7.6807\n",
      "Epoch [64870/100000], Loss: 7.6813\n",
      "Epoch [64880/100000], Loss: 7.6797\n",
      "Epoch [64890/100000], Loss: 7.6772\n",
      "Epoch [64900/100000], Loss: 7.6770\n",
      "Epoch [64910/100000], Loss: 7.6770\n",
      "Epoch [64920/100000], Loss: 7.6794\n",
      "Epoch [64930/100000], Loss: 7.6771\n",
      "Epoch [64940/100000], Loss: 7.6790\n",
      "Epoch [64950/100000], Loss: 7.6783\n",
      "Epoch [64960/100000], Loss: 7.6774\n",
      "Epoch [64970/100000], Loss: 7.6777\n",
      "Epoch [64980/100000], Loss: 7.6791\n",
      "Epoch [64990/100000], Loss: 7.6786\n",
      "Epoch [65000/100000], Loss: 7.6792\n",
      "Epoch [65010/100000], Loss: 7.6774\n",
      "Epoch [65020/100000], Loss: 7.6766\n",
      "Epoch [65030/100000], Loss: 7.6766\n",
      "Model saved at epoch 65035 with loss: 7.6745\n",
      "Epoch [65040/100000], Loss: 7.6762\n",
      "Epoch [65050/100000], Loss: 7.6793\n",
      "Epoch [65060/100000], Loss: 7.6787\n",
      "Epoch [65070/100000], Loss: 7.6796\n",
      "Epoch [65080/100000], Loss: 7.6786\n",
      "Epoch [65090/100000], Loss: 7.6762\n",
      "Epoch [65100/100000], Loss: 7.6767\n",
      "Epoch [65110/100000], Loss: 7.6759\n",
      "Model saved at epoch 65118 with loss: 7.6741\n",
      "Epoch [65120/100000], Loss: 7.6741\n",
      "Epoch [65130/100000], Loss: 7.6745\n",
      "Model saved at epoch 65132 with loss: 7.6736\n",
      "Model saved at epoch 65134 with loss: 7.6725\n",
      "Model saved at epoch 65135 with loss: 7.6725\n",
      "Model saved at epoch 65138 with loss: 7.6720\n",
      "Model saved at epoch 65139 with loss: 7.6717\n",
      "Epoch [65140/100000], Loss: 7.6721\n",
      "Model saved at epoch 65143 with loss: 7.6715\n",
      "Epoch [65150/100000], Loss: 7.6729\n",
      "Epoch [65160/100000], Loss: 7.6739\n",
      "Epoch [65170/100000], Loss: 7.6721\n",
      "Epoch [65180/100000], Loss: 7.6758\n",
      "Epoch [65190/100000], Loss: 7.6753\n",
      "Epoch [65200/100000], Loss: 7.6727\n",
      "Model saved at epoch 65205 with loss: 7.6714\n",
      "Epoch [65210/100000], Loss: 7.6730\n",
      "Epoch [65220/100000], Loss: 7.6740\n",
      "Epoch [65230/100000], Loss: 7.6741\n",
      "Epoch [65240/100000], Loss: 7.6730\n",
      "Epoch [65250/100000], Loss: 7.6729\n",
      "Epoch [65260/100000], Loss: 7.6758\n",
      "Epoch [65270/100000], Loss: 7.6732\n",
      "Epoch [65280/100000], Loss: 7.6736\n",
      "Model saved at epoch 65289 with loss: 7.6707\n",
      "Model saved at epoch 65290 with loss: 7.6704\n",
      "Epoch [65290/100000], Loss: 7.6704\n",
      "Model saved at epoch 65291 with loss: 7.6691\n",
      "Model saved at epoch 65292 with loss: 7.6686\n",
      "Epoch [65300/100000], Loss: 7.6706\n",
      "Epoch [65310/100000], Loss: 7.6713\n",
      "Epoch [65320/100000], Loss: 7.6718\n",
      "Epoch [65330/100000], Loss: 7.6735\n",
      "Epoch [65340/100000], Loss: 7.6737\n",
      "Epoch [65350/100000], Loss: 7.6735\n",
      "Epoch [65360/100000], Loss: 7.6732\n",
      "Epoch [65370/100000], Loss: 7.6728\n",
      "Epoch [65380/100000], Loss: 7.6740\n",
      "Epoch [65390/100000], Loss: 7.6755\n",
      "Epoch [65400/100000], Loss: 7.6703\n",
      "Epoch [65410/100000], Loss: 7.6694\n",
      "Model saved at epoch 65412 with loss: 7.6683\n",
      "Model saved at epoch 65413 with loss: 7.6682\n",
      "Model saved at epoch 65414 with loss: 7.6674\n",
      "Epoch [65420/100000], Loss: 7.6679\n",
      "Model saved at epoch 65425 with loss: 7.6665\n",
      "Model saved at epoch 65427 with loss: 7.6660\n",
      "Epoch [65430/100000], Loss: 7.6661\n",
      "Model saved at epoch 65433 with loss: 7.6659\n",
      "Model saved at epoch 65434 with loss: 7.6650\n",
      "Model saved at epoch 65435 with loss: 7.6647\n",
      "Epoch [65440/100000], Loss: 7.6661\n",
      "Epoch [65450/100000], Loss: 7.6670\n",
      "Epoch [65460/100000], Loss: 7.6674\n",
      "Epoch [65470/100000], Loss: 7.6691\n",
      "Epoch [65480/100000], Loss: 7.6708\n",
      "Epoch [65490/100000], Loss: 7.6695\n",
      "Epoch [65500/100000], Loss: 7.6659\n",
      "Epoch [65510/100000], Loss: 7.6679\n",
      "Model saved at epoch 65514 with loss: 7.6645\n",
      "Model saved at epoch 65515 with loss: 7.6636\n",
      "Model saved at epoch 65517 with loss: 7.6634\n",
      "Model saved at epoch 65518 with loss: 7.6628\n",
      "Epoch [65520/100000], Loss: 7.6630\n",
      "Model saved at epoch 65521 with loss: 7.6628\n",
      "Model saved at epoch 65523 with loss: 7.6627\n",
      "Model saved at epoch 65525 with loss: 7.6626\n",
      "Model saved at epoch 65526 with loss: 7.6621\n",
      "Model saved at epoch 65527 with loss: 7.6615\n",
      "Model saved at epoch 65528 with loss: 7.6610\n",
      "Epoch [65530/100000], Loss: 7.6622\n",
      "Epoch [65540/100000], Loss: 7.6618\n",
      "Epoch [65550/100000], Loss: 7.6616\n",
      "Model saved at epoch 65551 with loss: 7.6608\n",
      "Model saved at epoch 65553 with loss: 7.6601\n",
      "Epoch [65560/100000], Loss: 7.6621\n",
      "Epoch [65570/100000], Loss: 7.6633\n",
      "Epoch [65580/100000], Loss: 7.6664\n",
      "Epoch [65590/100000], Loss: 7.6669\n",
      "Epoch [65600/100000], Loss: 7.6661\n",
      "Epoch [65610/100000], Loss: 7.6668\n",
      "Epoch [65620/100000], Loss: 7.6662\n",
      "Epoch [65630/100000], Loss: 7.6666\n",
      "Epoch [65640/100000], Loss: 7.6664\n",
      "Epoch [65650/100000], Loss: 7.6652\n",
      "Epoch [65660/100000], Loss: 7.6628\n",
      "Epoch [65670/100000], Loss: 7.6625\n",
      "Epoch [65680/100000], Loss: 7.6637\n",
      "Epoch [65690/100000], Loss: 7.6639\n",
      "Epoch [65700/100000], Loss: 7.6660\n",
      "Epoch [65710/100000], Loss: 7.6692\n",
      "Epoch [65720/100000], Loss: 7.6694\n",
      "Epoch [65730/100000], Loss: 7.6684\n",
      "Epoch [65740/100000], Loss: 7.6664\n",
      "Epoch [65750/100000], Loss: 7.6643\n",
      "Epoch [65760/100000], Loss: 7.6675\n",
      "Epoch [65770/100000], Loss: 7.6666\n",
      "Epoch [65780/100000], Loss: 7.6649\n",
      "Epoch [65790/100000], Loss: 7.6650\n",
      "Epoch [65800/100000], Loss: 7.6638\n",
      "Epoch [65810/100000], Loss: 7.6615\n",
      "Model saved at epoch 65813 with loss: 7.6593\n",
      "Epoch [65820/100000], Loss: 7.6628\n",
      "Epoch [65830/100000], Loss: 7.6646\n",
      "Epoch [65840/100000], Loss: 7.6650\n",
      "Epoch [65850/100000], Loss: 7.6641\n",
      "Epoch [65860/100000], Loss: 7.6631\n",
      "Epoch [65870/100000], Loss: 7.6606\n",
      "Epoch [65880/100000], Loss: 7.6619\n",
      "Epoch [65890/100000], Loss: 7.6617\n",
      "Epoch [65900/100000], Loss: 7.6626\n",
      "Epoch [65910/100000], Loss: 7.6646\n",
      "Epoch [65920/100000], Loss: 7.6641\n",
      "Epoch [65930/100000], Loss: 7.6637\n",
      "Epoch [65940/100000], Loss: 7.6675\n",
      "Epoch [65950/100000], Loss: 7.6653\n",
      "Epoch [65960/100000], Loss: 7.6650\n",
      "Epoch [65970/100000], Loss: 7.6644\n",
      "Epoch [65980/100000], Loss: 7.6628\n",
      "Epoch [65990/100000], Loss: 7.6609\n",
      "Epoch [66000/100000], Loss: 7.6599\n",
      "Model saved at epoch 66010 with loss: 7.6593\n",
      "Epoch [66010/100000], Loss: 7.6593\n",
      "Model saved at epoch 66011 with loss: 7.6588\n",
      "Model saved at epoch 66015 with loss: 7.6586\n",
      "Epoch [66020/100000], Loss: 7.6600\n",
      "Model saved at epoch 66027 with loss: 7.6579\n",
      "Model saved at epoch 66029 with loss: 7.6564\n",
      "Model saved at epoch 66030 with loss: 7.6562\n",
      "Epoch [66030/100000], Loss: 7.6562\n",
      "Model saved at epoch 66031 with loss: 7.6561\n",
      "Epoch [66040/100000], Loss: 7.6590\n",
      "Epoch [66050/100000], Loss: 7.6589\n",
      "Epoch [66060/100000], Loss: 7.6617\n",
      "Epoch [66070/100000], Loss: 7.6586\n",
      "Epoch [66080/100000], Loss: 7.6584\n",
      "Epoch [66090/100000], Loss: 7.6581\n",
      "Epoch [66100/100000], Loss: 7.6586\n",
      "Epoch [66110/100000], Loss: 7.6590\n",
      "Epoch [66120/100000], Loss: 7.6590\n",
      "Epoch [66130/100000], Loss: 7.6583\n",
      "Epoch [66140/100000], Loss: 7.6573\n",
      "Model saved at epoch 66145 with loss: 7.6558\n",
      "Model saved at epoch 66146 with loss: 7.6553\n",
      "Model saved at epoch 66148 with loss: 7.6553\n",
      "Model saved at epoch 66149 with loss: 7.6544\n",
      "Model saved at epoch 66150 with loss: 7.6538\n",
      "Epoch [66150/100000], Loss: 7.6538\n",
      "Model saved at epoch 66151 with loss: 7.6534\n",
      "Model saved at epoch 66152 with loss: 7.6526\n",
      "Model saved at epoch 66154 with loss: 7.6524\n",
      "Model saved at epoch 66155 with loss: 7.6522\n",
      "Model saved at epoch 66156 with loss: 7.6519\n",
      "Epoch [66160/100000], Loss: 7.6527\n",
      "Epoch [66170/100000], Loss: 7.6540\n",
      "Epoch [66180/100000], Loss: 7.6545\n",
      "Epoch [66190/100000], Loss: 7.6531\n",
      "Epoch [66200/100000], Loss: 7.6579\n",
      "Epoch [66210/100000], Loss: 7.6567\n",
      "Epoch [66220/100000], Loss: 7.6557\n",
      "Epoch [66230/100000], Loss: 7.6571\n",
      "Epoch [66240/100000], Loss: 7.6539\n",
      "Epoch [66250/100000], Loss: 7.6549\n",
      "Epoch [66260/100000], Loss: 7.6563\n",
      "Model saved at epoch 66268 with loss: 7.6518\n",
      "Model saved at epoch 66269 with loss: 7.6508\n",
      "Model saved at epoch 66270 with loss: 7.6507\n",
      "Epoch [66270/100000], Loss: 7.6507\n",
      "Epoch [66280/100000], Loss: 7.6524\n",
      "Model saved at epoch 66282 with loss: 7.6488\n",
      "Epoch [66290/100000], Loss: 7.6508\n",
      "Epoch [66300/100000], Loss: 7.6525\n",
      "Epoch [66310/100000], Loss: 7.6543\n",
      "Epoch [66320/100000], Loss: 7.6540\n",
      "Epoch [66330/100000], Loss: 7.6517\n",
      "Epoch [66340/100000], Loss: 7.6512\n",
      "Epoch [66350/100000], Loss: 7.6506\n",
      "Epoch [66360/100000], Loss: 7.6501\n",
      "Epoch [66370/100000], Loss: 7.6511\n",
      "Epoch [66380/100000], Loss: 7.6518\n",
      "Epoch [66390/100000], Loss: 7.6518\n",
      "Epoch [66400/100000], Loss: 7.6532\n",
      "Epoch [66410/100000], Loss: 7.6531\n",
      "Epoch [66420/100000], Loss: 7.6532\n",
      "Epoch [66430/100000], Loss: 7.6521\n",
      "Epoch [66440/100000], Loss: 7.6533\n",
      "Epoch [66450/100000], Loss: 7.6561\n",
      "Epoch [66460/100000], Loss: 7.6554\n",
      "Epoch [66470/100000], Loss: 7.6537\n",
      "Epoch [66480/100000], Loss: 7.6530\n",
      "Epoch [66490/100000], Loss: 7.6532\n",
      "Epoch [66500/100000], Loss: 7.6531\n",
      "Epoch [66510/100000], Loss: 7.6533\n",
      "Epoch [66520/100000], Loss: 7.6507\n",
      "Epoch [66530/100000], Loss: 7.6507\n",
      "Epoch [66540/100000], Loss: 7.6522\n",
      "Epoch [66550/100000], Loss: 7.6538\n",
      "Epoch [66560/100000], Loss: 7.6519\n",
      "Epoch [66570/100000], Loss: 7.6524\n",
      "Epoch [66580/100000], Loss: 7.6510\n",
      "Epoch [66590/100000], Loss: 7.6515\n",
      "Epoch [66600/100000], Loss: 7.6511\n",
      "Epoch [66610/100000], Loss: 7.6499\n",
      "Epoch [66620/100000], Loss: 7.6521\n",
      "Epoch [66630/100000], Loss: 7.6490\n",
      "Model saved at epoch 66631 with loss: 7.6476\n",
      "Model saved at epoch 66633 with loss: 7.6466\n",
      "Model saved at epoch 66634 with loss: 7.6460\n",
      "Epoch [66640/100000], Loss: 7.6483\n",
      "Epoch [66650/100000], Loss: 7.6480\n",
      "Epoch [66660/100000], Loss: 7.6475\n",
      "Model saved at epoch 66665 with loss: 7.6458\n",
      "Epoch [66670/100000], Loss: 7.6474\n",
      "Epoch [66680/100000], Loss: 7.6479\n",
      "Epoch [66690/100000], Loss: 7.6476\n",
      "Model saved at epoch 66699 with loss: 7.6453\n",
      "Epoch [66700/100000], Loss: 7.6459\n",
      "Epoch [66710/100000], Loss: 7.6466\n",
      "Model saved at epoch 66715 with loss: 7.6453\n",
      "Model saved at epoch 66716 with loss: 7.6449\n",
      "Model saved at epoch 66718 with loss: 7.6446\n",
      "Epoch [66720/100000], Loss: 7.6461\n",
      "Epoch [66730/100000], Loss: 7.6480\n",
      "Epoch [66740/100000], Loss: 7.6476\n",
      "Model saved at epoch 66742 with loss: 7.6446\n",
      "Model saved at epoch 66745 with loss: 7.6442\n",
      "Model saved at epoch 66746 with loss: 7.6439\n",
      "Model saved at epoch 66748 with loss: 7.6435\n",
      "Model saved at epoch 66749 with loss: 7.6433\n",
      "Epoch [66750/100000], Loss: 7.6464\n",
      "Epoch [66760/100000], Loss: 7.6464\n",
      "Epoch [66770/100000], Loss: 7.6462\n",
      "Epoch [66780/100000], Loss: 7.6450\n",
      "Epoch [66790/100000], Loss: 7.6470\n",
      "Epoch [66800/100000], Loss: 7.6478\n",
      "Epoch [66810/100000], Loss: 7.6486\n",
      "Epoch [66820/100000], Loss: 7.6506\n",
      "Epoch [66830/100000], Loss: 7.6500\n",
      "Epoch [66840/100000], Loss: 7.6495\n",
      "Epoch [66850/100000], Loss: 7.6488\n",
      "Epoch [66860/100000], Loss: 7.6487\n",
      "Epoch [66870/100000], Loss: 7.6459\n",
      "Epoch [66880/100000], Loss: 7.6462\n",
      "Epoch [66890/100000], Loss: 7.6490\n",
      "Epoch [66900/100000], Loss: 7.6500\n",
      "Epoch [66910/100000], Loss: 7.6497\n",
      "Epoch [66920/100000], Loss: 7.6504\n",
      "Epoch [66930/100000], Loss: 7.6517\n",
      "Epoch [66940/100000], Loss: 7.6501\n",
      "Epoch [66950/100000], Loss: 7.6472\n",
      "Epoch [66960/100000], Loss: 7.6468\n",
      "Epoch [66970/100000], Loss: 7.6472\n",
      "Epoch [66980/100000], Loss: 7.6483\n",
      "Epoch [66990/100000], Loss: 7.6508\n",
      "Epoch [67000/100000], Loss: 7.6496\n",
      "Epoch [67010/100000], Loss: 7.6503\n",
      "Epoch [67020/100000], Loss: 7.6482\n",
      "Epoch [67030/100000], Loss: 7.6451\n",
      "Model saved at epoch 67038 with loss: 7.6425\n",
      "Model saved at epoch 67039 with loss: 7.6420\n",
      "Model saved at epoch 67040 with loss: 7.6418\n",
      "Epoch [67040/100000], Loss: 7.6418\n",
      "Model saved at epoch 67043 with loss: 7.6414\n",
      "Model saved at epoch 67044 with loss: 7.6411\n",
      "Epoch [67050/100000], Loss: 7.6438\n",
      "Epoch [67060/100000], Loss: 7.6444\n",
      "Epoch [67070/100000], Loss: 7.6440\n",
      "Epoch [67080/100000], Loss: 7.6490\n",
      "Epoch [67090/100000], Loss: 7.6482\n",
      "Epoch [67100/100000], Loss: 7.6463\n",
      "Epoch [67110/100000], Loss: 7.6475\n",
      "Epoch [67120/100000], Loss: 7.6457\n",
      "Epoch [67130/100000], Loss: 7.6484\n",
      "Epoch [67140/100000], Loss: 7.6462\n",
      "Epoch [67150/100000], Loss: 7.6461\n",
      "Epoch [67160/100000], Loss: 7.6459\n",
      "Epoch [67170/100000], Loss: 7.6456\n",
      "Epoch [67180/100000], Loss: 7.6449\n",
      "Epoch [67190/100000], Loss: 7.6455\n",
      "Epoch [67200/100000], Loss: 7.6446\n",
      "Epoch [67210/100000], Loss: 7.6454\n",
      "Epoch [67220/100000], Loss: 7.6489\n",
      "Epoch [67230/100000], Loss: 7.6487\n",
      "Epoch [67240/100000], Loss: 7.6480\n",
      "Epoch [67250/100000], Loss: 7.6455\n",
      "Epoch [67260/100000], Loss: 7.6446\n",
      "Epoch [67270/100000], Loss: 7.6445\n",
      "Epoch [67280/100000], Loss: 7.6418\n",
      "Epoch [67290/100000], Loss: 7.6457\n",
      "Epoch [67300/100000], Loss: 7.6432\n",
      "Epoch [67310/100000], Loss: 7.6426\n",
      "Epoch [67320/100000], Loss: 7.6443\n",
      "Epoch [67330/100000], Loss: 7.6416\n",
      "Model saved at epoch 67331 with loss: 7.6410\n",
      "Model saved at epoch 67335 with loss: 7.6406\n",
      "Model saved at epoch 67336 with loss: 7.6404\n",
      "Epoch [67340/100000], Loss: 7.6413\n",
      "Model saved at epoch 67345 with loss: 7.6395\n",
      "Epoch [67350/100000], Loss: 7.6410\n",
      "Model saved at epoch 67354 with loss: 7.6391\n",
      "Model saved at epoch 67355 with loss: 7.6391\n",
      "Model saved at epoch 67356 with loss: 7.6389\n",
      "Model saved at epoch 67358 with loss: 7.6382\n",
      "Epoch [67360/100000], Loss: 7.6396\n",
      "Model saved at epoch 67370 with loss: 7.6377\n",
      "Epoch [67370/100000], Loss: 7.6377\n",
      "Model saved at epoch 67371 with loss: 7.6372\n",
      "Model saved at epoch 67376 with loss: 7.6370\n",
      "Epoch [67380/100000], Loss: 7.6389\n",
      "Epoch [67390/100000], Loss: 7.6420\n",
      "Epoch [67400/100000], Loss: 7.6421\n",
      "Epoch [67410/100000], Loss: 7.6404\n",
      "Epoch [67420/100000], Loss: 7.6410\n",
      "Epoch [67430/100000], Loss: 7.6402\n",
      "Epoch [67440/100000], Loss: 7.6422\n",
      "Epoch [67450/100000], Loss: 7.6410\n",
      "Model saved at epoch 67459 with loss: 7.6370\n",
      "Epoch [67460/100000], Loss: 7.6380\n",
      "Model saved at epoch 67469 with loss: 7.6369\n",
      "Epoch [67470/100000], Loss: 7.6372\n",
      "Model saved at epoch 67477 with loss: 7.6357\n",
      "Epoch [67480/100000], Loss: 7.6367\n",
      "Epoch [67490/100000], Loss: 7.6391\n",
      "Epoch [67500/100000], Loss: 7.6413\n",
      "Epoch [67510/100000], Loss: 7.6374\n",
      "Epoch [67520/100000], Loss: 7.6400\n",
      "Epoch [67530/100000], Loss: 7.6402\n",
      "Epoch [67540/100000], Loss: 7.6398\n",
      "Epoch [67550/100000], Loss: 7.6398\n",
      "Epoch [67560/100000], Loss: 7.6400\n",
      "Epoch [67570/100000], Loss: 7.6414\n",
      "Epoch [67580/100000], Loss: 7.6403\n",
      "Epoch [67590/100000], Loss: 7.6383\n",
      "Epoch [67600/100000], Loss: 7.6390\n",
      "Model saved at epoch 67609 with loss: 7.6356\n",
      "Epoch [67610/100000], Loss: 7.6363\n",
      "Model saved at epoch 67613 with loss: 7.6349\n",
      "Model saved at epoch 67615 with loss: 7.6346\n",
      "Model saved at epoch 67618 with loss: 7.6343\n",
      "Model saved at epoch 67619 with loss: 7.6338\n",
      "Epoch [67620/100000], Loss: 7.6348\n",
      "Model saved at epoch 67622 with loss: 7.6337\n",
      "Model saved at epoch 67624 with loss: 7.6323\n",
      "Epoch [67630/100000], Loss: 7.6330\n",
      "Model saved at epoch 67635 with loss: 7.6323\n",
      "Model saved at epoch 67638 with loss: 7.6323\n",
      "Epoch [67640/100000], Loss: 7.6338\n",
      "Model saved at epoch 67647 with loss: 7.6319\n",
      "Epoch [67650/100000], Loss: 7.6340\n",
      "Model saved at epoch 67654 with loss: 7.6316\n",
      "Epoch [67660/100000], Loss: 7.6336\n",
      "Epoch [67670/100000], Loss: 7.6371\n",
      "Epoch [67680/100000], Loss: 7.6354\n",
      "Epoch [67690/100000], Loss: 7.6353\n",
      "Epoch [67700/100000], Loss: 7.6345\n",
      "Epoch [67710/100000], Loss: 7.6346\n",
      "Epoch [67720/100000], Loss: 7.6353\n",
      "Epoch [67730/100000], Loss: 7.6349\n",
      "Epoch [67740/100000], Loss: 7.6344\n",
      "Epoch [67750/100000], Loss: 7.6351\n",
      "Epoch [67760/100000], Loss: 7.6342\n",
      "Epoch [67770/100000], Loss: 7.6331\n",
      "Epoch [67780/100000], Loss: 7.6341\n",
      "Epoch [67790/100000], Loss: 7.6378\n",
      "Epoch [67800/100000], Loss: 7.6405\n",
      "Epoch [67810/100000], Loss: 7.6377\n",
      "Epoch [67820/100000], Loss: 7.6341\n",
      "Model saved at epoch 67828 with loss: 7.6303\n",
      "Model saved at epoch 67829 with loss: 7.6294\n",
      "Model saved at epoch 67830 with loss: 7.6293\n",
      "Epoch [67830/100000], Loss: 7.6293\n",
      "Epoch [67840/100000], Loss: 7.6320\n",
      "Epoch [67850/100000], Loss: 7.6344\n",
      "Epoch [67860/100000], Loss: 7.6357\n",
      "Epoch [67870/100000], Loss: 7.6370\n",
      "Epoch [67880/100000], Loss: 7.6343\n",
      "Epoch [67890/100000], Loss: 7.6335\n",
      "Epoch [67900/100000], Loss: 7.6385\n",
      "Epoch [67910/100000], Loss: 7.6347\n",
      "Epoch [67920/100000], Loss: 7.6382\n",
      "Epoch [67930/100000], Loss: 7.6342\n",
      "Epoch [67940/100000], Loss: 7.6349\n",
      "Epoch [67950/100000], Loss: 7.6329\n",
      "Epoch [67960/100000], Loss: 7.6403\n",
      "Epoch [67970/100000], Loss: 7.6339\n",
      "Epoch [67980/100000], Loss: 7.6344\n",
      "Epoch [67990/100000], Loss: 7.6339\n",
      "Epoch [68000/100000], Loss: 7.6309\n",
      "Model saved at epoch 68005 with loss: 7.6293\n",
      "Model saved at epoch 68006 with loss: 7.6289\n",
      "Epoch [68010/100000], Loss: 7.6320\n",
      "Epoch [68020/100000], Loss: 7.6314\n",
      "Epoch [68030/100000], Loss: 7.6314\n",
      "Epoch [68040/100000], Loss: 7.6327\n",
      "Epoch [68050/100000], Loss: 7.6326\n",
      "Epoch [68060/100000], Loss: 7.6336\n",
      "Epoch [68070/100000], Loss: 7.6325\n",
      "Epoch [68080/100000], Loss: 7.6320\n",
      "Epoch [68090/100000], Loss: 7.6335\n",
      "Epoch [68100/100000], Loss: 7.6300\n",
      "Model saved at epoch 68103 with loss: 7.6287\n",
      "Model saved at epoch 68107 with loss: 7.6285\n",
      "Epoch [68110/100000], Loss: 7.6319\n",
      "Epoch [68120/100000], Loss: 7.6319\n",
      "Epoch [68130/100000], Loss: 7.6308\n",
      "Epoch [68140/100000], Loss: 7.6311\n",
      "Model saved at epoch 68148 with loss: 7.6284\n",
      "Model saved at epoch 68149 with loss: 7.6269\n",
      "Model saved at epoch 68150 with loss: 7.6266\n",
      "Epoch [68150/100000], Loss: 7.6266\n",
      "Model saved at epoch 68151 with loss: 7.6260\n",
      "Model saved at epoch 68152 with loss: 7.6259\n",
      "Model saved at epoch 68153 with loss: 7.6258\n",
      "Epoch [68160/100000], Loss: 7.6292\n",
      "Epoch [68170/100000], Loss: 7.6288\n",
      "Model saved at epoch 68179 with loss: 7.6256\n",
      "Model saved at epoch 68180 with loss: 7.6252\n",
      "Epoch [68180/100000], Loss: 7.6252\n",
      "Epoch [68190/100000], Loss: 7.6309\n",
      "Epoch [68200/100000], Loss: 7.6295\n",
      "Epoch [68210/100000], Loss: 7.6290\n",
      "Epoch [68220/100000], Loss: 7.6322\n",
      "Epoch [68230/100000], Loss: 7.6301\n",
      "Epoch [68240/100000], Loss: 7.6299\n",
      "Epoch [68250/100000], Loss: 7.6293\n",
      "Epoch [68260/100000], Loss: 7.6301\n",
      "Epoch [68270/100000], Loss: 7.6330\n",
      "Epoch [68280/100000], Loss: 7.6327\n",
      "Epoch [68290/100000], Loss: 7.6258\n",
      "Epoch [68300/100000], Loss: 7.6273\n",
      "Epoch [68310/100000], Loss: 7.6272\n",
      "Epoch [68320/100000], Loss: 7.6256\n",
      "Epoch [68330/100000], Loss: 7.6302\n",
      "Epoch [68340/100000], Loss: 7.6340\n",
      "Epoch [68350/100000], Loss: 7.6322\n",
      "Epoch [68360/100000], Loss: 7.6271\n",
      "Epoch [68370/100000], Loss: 7.6269\n",
      "Model saved at epoch 68376 with loss: 7.6245\n",
      "Model saved at epoch 68377 with loss: 7.6236\n",
      "Epoch [68380/100000], Loss: 7.6249\n",
      "Epoch [68390/100000], Loss: 7.6276\n",
      "Model saved at epoch 68394 with loss: 7.6218\n",
      "Model saved at epoch 68395 with loss: 7.6216\n",
      "Model saved at epoch 68396 with loss: 7.6213\n",
      "Model saved at epoch 68397 with loss: 7.6200\n",
      "Epoch [68400/100000], Loss: 7.6235\n",
      "Epoch [68410/100000], Loss: 7.6216\n",
      "Epoch [68420/100000], Loss: 7.6235\n",
      "Epoch [68430/100000], Loss: 7.6236\n",
      "Epoch [68440/100000], Loss: 7.6216\n",
      "Model saved at epoch 68442 with loss: 7.6198\n",
      "Epoch [68450/100000], Loss: 7.6216\n",
      "Epoch [68460/100000], Loss: 7.6208\n",
      "Epoch [68470/100000], Loss: 7.6223\n",
      "Model saved at epoch 68473 with loss: 7.6195\n",
      "Epoch [68480/100000], Loss: 7.6219\n",
      "Epoch [68490/100000], Loss: 7.6221\n",
      "Epoch [68500/100000], Loss: 7.6208\n",
      "Epoch [68510/100000], Loss: 7.6216\n",
      "Epoch [68520/100000], Loss: 7.6238\n",
      "Epoch [68530/100000], Loss: 7.6281\n",
      "Epoch [68540/100000], Loss: 7.6285\n",
      "Epoch [68550/100000], Loss: 7.6279\n",
      "Epoch [68560/100000], Loss: 7.6268\n",
      "Epoch [68570/100000], Loss: 7.6257\n",
      "Epoch [68580/100000], Loss: 7.6199\n",
      "Model saved at epoch 68582 with loss: 7.6191\n",
      "Epoch [68590/100000], Loss: 7.6218\n",
      "Epoch [68600/100000], Loss: 7.6232\n",
      "Epoch [68610/100000], Loss: 7.6203\n",
      "Model saved at epoch 68618 with loss: 7.6188\n",
      "Model saved at epoch 68619 with loss: 7.6178\n",
      "Epoch [68620/100000], Loss: 7.6179\n",
      "Model saved at epoch 68623 with loss: 7.6162\n",
      "Model saved at epoch 68624 with loss: 7.6154\n",
      "Model saved at epoch 68625 with loss: 7.6142\n",
      "Epoch [68630/100000], Loss: 7.6148\n",
      "Epoch [68640/100000], Loss: 7.6170\n",
      "Epoch [68650/100000], Loss: 7.6218\n",
      "Epoch [68660/100000], Loss: 7.6233\n",
      "Epoch [68670/100000], Loss: 7.6171\n",
      "Epoch [68680/100000], Loss: 7.6166\n",
      "Epoch [68690/100000], Loss: 7.6189\n",
      "Epoch [68700/100000], Loss: 7.6208\n",
      "Epoch [68710/100000], Loss: 7.6195\n",
      "Epoch [68720/100000], Loss: 7.6200\n",
      "Epoch [68730/100000], Loss: 7.6214\n",
      "Epoch [68740/100000], Loss: 7.6215\n",
      "Epoch [68750/100000], Loss: 7.6234\n",
      "Epoch [68760/100000], Loss: 7.6187\n",
      "Epoch [68770/100000], Loss: 7.6185\n",
      "Epoch [68780/100000], Loss: 7.6193\n",
      "Epoch [68790/100000], Loss: 7.6208\n",
      "Epoch [68800/100000], Loss: 7.6206\n",
      "Epoch [68810/100000], Loss: 7.6213\n",
      "Epoch [68820/100000], Loss: 7.6168\n",
      "Epoch [68830/100000], Loss: 7.6160\n",
      "Model saved at epoch 68832 with loss: 7.6137\n",
      "Model saved at epoch 68834 with loss: 7.6137\n",
      "Model saved at epoch 68835 with loss: 7.6132\n",
      "Epoch [68840/100000], Loss: 7.6161\n",
      "Epoch [68850/100000], Loss: 7.6151\n",
      "Epoch [68860/100000], Loss: 7.6151\n",
      "Model saved at epoch 68865 with loss: 7.6126\n",
      "Model saved at epoch 68866 with loss: 7.6122\n",
      "Model saved at epoch 68867 with loss: 7.6119\n",
      "Epoch [68870/100000], Loss: 7.6139\n",
      "Epoch [68880/100000], Loss: 7.6163\n",
      "Epoch [68890/100000], Loss: 7.6138\n",
      "Model saved at epoch 68895 with loss: 7.6111\n",
      "Model saved at epoch 68896 with loss: 7.6104\n",
      "Epoch [68900/100000], Loss: 7.6116\n",
      "Model saved at epoch 68904 with loss: 7.6104\n",
      "Model saved at epoch 68905 with loss: 7.6094\n",
      "Epoch [68910/100000], Loss: 7.6110\n",
      "Model saved at epoch 68916 with loss: 7.6093\n",
      "Epoch [68920/100000], Loss: 7.6116\n",
      "Epoch [68930/100000], Loss: 7.6101\n",
      "Model saved at epoch 68931 with loss: 7.6088\n",
      "Epoch [68940/100000], Loss: 7.6104\n",
      "Epoch [68950/100000], Loss: 7.6097\n",
      "Epoch [68960/100000], Loss: 7.6129\n",
      "Epoch [68970/100000], Loss: 7.6090\n",
      "Model saved at epoch 68972 with loss: 7.6087\n",
      "Model saved at epoch 68973 with loss: 7.6085\n",
      "Epoch [68980/100000], Loss: 7.6121\n",
      "Epoch [68990/100000], Loss: 7.6138\n",
      "Epoch [69000/100000], Loss: 7.6149\n",
      "Epoch [69010/100000], Loss: 7.6122\n",
      "Epoch [69020/100000], Loss: 7.6155\n",
      "Epoch [69030/100000], Loss: 7.6114\n",
      "Model saved at epoch 69034 with loss: 7.6081\n",
      "Model saved at epoch 69036 with loss: 7.6066\n",
      "Model saved at epoch 69037 with loss: 7.6059\n",
      "Epoch [69040/100000], Loss: 7.6071\n",
      "Epoch [69050/100000], Loss: 7.6063\n",
      "Model saved at epoch 69051 with loss: 7.6054\n",
      "Model saved at epoch 69052 with loss: 7.6050\n",
      "Model saved at epoch 69054 with loss: 7.6045\n",
      "Model saved at epoch 69058 with loss: 7.6043\n",
      "Epoch [69060/100000], Loss: 7.6075\n",
      "Epoch [69070/100000], Loss: 7.6044\n",
      "Model saved at epoch 69076 with loss: 7.6037\n",
      "Epoch [69080/100000], Loss: 7.6054\n",
      "Epoch [69090/100000], Loss: 7.6073\n",
      "Epoch [69100/100000], Loss: 7.6082\n",
      "Epoch [69110/100000], Loss: 7.6057\n",
      "Epoch [69120/100000], Loss: 7.6056\n",
      "Model saved at epoch 69127 with loss: 7.6028\n",
      "Model saved at epoch 69128 with loss: 7.6023\n",
      "Epoch [69130/100000], Loss: 7.6054\n",
      "Epoch [69140/100000], Loss: 7.6067\n",
      "Epoch [69150/100000], Loss: 7.6063\n",
      "Epoch [69160/100000], Loss: 7.6077\n",
      "Epoch [69170/100000], Loss: 7.6132\n",
      "Epoch [69180/100000], Loss: 7.6073\n",
      "Epoch [69190/100000], Loss: 7.6117\n",
      "Model saved at epoch 69200 with loss: 7.6018\n",
      "Epoch [69200/100000], Loss: 7.6018\n",
      "Model saved at epoch 69206 with loss: 7.6003\n",
      "Epoch [69210/100000], Loss: 7.6022\n",
      "Epoch [69220/100000], Loss: 7.6016\n",
      "Epoch [69230/100000], Loss: 7.6007\n",
      "Model saved at epoch 69232 with loss: 7.6002\n",
      "Model saved at epoch 69236 with loss: 7.5996\n",
      "Model saved at epoch 69239 with loss: 7.5992\n",
      "Epoch [69240/100000], Loss: 7.5993\n",
      "Epoch [69250/100000], Loss: 7.5999\n",
      "Epoch [69260/100000], Loss: 7.6005\n",
      "Epoch [69270/100000], Loss: 7.6046\n",
      "Epoch [69280/100000], Loss: 7.6022\n",
      "Epoch [69290/100000], Loss: 7.6012\n",
      "Model saved at epoch 69300 with loss: 7.5992\n",
      "Epoch [69300/100000], Loss: 7.5992\n",
      "Model saved at epoch 69306 with loss: 7.5989\n",
      "Model saved at epoch 69307 with loss: 7.5983\n",
      "Epoch [69310/100000], Loss: 7.6006\n",
      "Epoch [69320/100000], Loss: 7.6040\n",
      "Epoch [69330/100000], Loss: 7.6040\n",
      "Epoch [69340/100000], Loss: 7.6041\n",
      "Epoch [69350/100000], Loss: 7.6042\n",
      "Epoch [69360/100000], Loss: 7.5988\n",
      "Model saved at epoch 69361 with loss: 7.5978\n",
      "Epoch [69370/100000], Loss: 7.6004\n",
      "Model saved at epoch 69376 with loss: 7.5970\n",
      "Epoch [69380/100000], Loss: 7.5975\n",
      "Epoch [69390/100000], Loss: 7.5995\n",
      "Epoch [69400/100000], Loss: 7.6022\n",
      "Epoch [69410/100000], Loss: 7.6005\n",
      "Epoch [69420/100000], Loss: 7.5988\n",
      "Model saved at epoch 69429 with loss: 7.5964\n",
      "Epoch [69430/100000], Loss: 7.5964\n",
      "Model saved at epoch 69435 with loss: 7.5961\n",
      "Epoch [69440/100000], Loss: 7.5978\n",
      "Model saved at epoch 69443 with loss: 7.5961\n",
      "Model saved at epoch 69444 with loss: 7.5952\n",
      "Model saved at epoch 69445 with loss: 7.5947\n",
      "Epoch [69450/100000], Loss: 7.5977\n",
      "Model saved at epoch 69455 with loss: 7.5934\n",
      "Epoch [69460/100000], Loss: 7.5968\n",
      "Epoch [69470/100000], Loss: 7.5946\n",
      "Epoch [69480/100000], Loss: 7.5954\n",
      "Model saved at epoch 69482 with loss: 7.5930\n",
      "Model saved at epoch 69488 with loss: 7.5928\n",
      "Model saved at epoch 69489 with loss: 7.5923\n",
      "Epoch [69490/100000], Loss: 7.5937\n",
      "Model saved at epoch 69496 with loss: 7.5916\n",
      "Model saved at epoch 69500 with loss: 7.5911\n",
      "Epoch [69500/100000], Loss: 7.5911\n",
      "Epoch [69510/100000], Loss: 7.5940\n",
      "Epoch [69520/100000], Loss: 7.5916\n",
      "Model saved at epoch 69527 with loss: 7.5907\n",
      "Model saved at epoch 69529 with loss: 7.5905\n",
      "Model saved at epoch 69530 with loss: 7.5892\n",
      "Epoch [69530/100000], Loss: 7.5892\n",
      "Model saved at epoch 69532 with loss: 7.5885\n",
      "Epoch [69540/100000], Loss: 7.5907\n",
      "Epoch [69550/100000], Loss: 7.5940\n",
      "Model saved at epoch 69554 with loss: 7.5867\n",
      "Epoch [69560/100000], Loss: 7.5885\n",
      "Epoch [69570/100000], Loss: 7.5872\n",
      "Model saved at epoch 69573 with loss: 7.5866\n",
      "Epoch [69580/100000], Loss: 7.5890\n",
      "Epoch [69590/100000], Loss: 7.5869\n",
      "Model saved at epoch 69593 with loss: 7.5863\n",
      "Epoch [69600/100000], Loss: 7.5915\n",
      "Model saved at epoch 69607 with loss: 7.5858\n",
      "Model saved at epoch 69608 with loss: 7.5855\n",
      "Model saved at epoch 69609 with loss: 7.5844\n",
      "Model saved at epoch 69610 with loss: 7.5833\n",
      "Epoch [69610/100000], Loss: 7.5833\n",
      "Epoch [69620/100000], Loss: 7.5878\n",
      "Epoch [69630/100000], Loss: 7.5882\n",
      "Epoch [69640/100000], Loss: 7.5907\n",
      "Epoch [69650/100000], Loss: 7.5864\n",
      "Epoch [69660/100000], Loss: 7.5842\n",
      "Model saved at epoch 69661 with loss: 7.5830\n",
      "Epoch [69670/100000], Loss: 7.5855\n",
      "Epoch [69680/100000], Loss: 7.5869\n",
      "Model saved at epoch 69684 with loss: 7.5828\n",
      "Model saved at epoch 69685 with loss: 7.5825\n",
      "Model saved at epoch 69686 with loss: 7.5814\n",
      "Model saved at epoch 69687 with loss: 7.5809\n",
      "Model saved at epoch 69690 with loss: 7.5801\n",
      "Epoch [69690/100000], Loss: 7.5801\n",
      "Model saved at epoch 69695 with loss: 7.5792\n",
      "Model saved at epoch 69696 with loss: 7.5786\n",
      "Model saved at epoch 69697 with loss: 7.5783\n",
      "Epoch [69700/100000], Loss: 7.5808\n",
      "Model saved at epoch 69703 with loss: 7.5782\n",
      "Model saved at epoch 69704 with loss: 7.5781\n",
      "Epoch [69710/100000], Loss: 7.5810\n",
      "Epoch [69720/100000], Loss: 7.5807\n",
      "Epoch [69730/100000], Loss: 7.5805\n",
      "Epoch [69740/100000], Loss: 7.5799\n",
      "Epoch [69750/100000], Loss: 7.5811\n",
      "Epoch [69760/100000], Loss: 7.5801\n",
      "Epoch [69770/100000], Loss: 7.5827\n",
      "Epoch [69780/100000], Loss: 7.5827\n",
      "Epoch [69790/100000], Loss: 7.5826\n",
      "Epoch [69800/100000], Loss: 7.5820\n",
      "Epoch [69810/100000], Loss: 7.5813\n",
      "Epoch [69820/100000], Loss: 7.5823\n",
      "Epoch [69830/100000], Loss: 7.5814\n",
      "Epoch [69840/100000], Loss: 7.5807\n",
      "Model saved at epoch 69848 with loss: 7.5778\n",
      "Epoch [69850/100000], Loss: 7.5786\n",
      "Model saved at epoch 69853 with loss: 7.5769\n",
      "Model saved at epoch 69854 with loss: 7.5764\n",
      "Model saved at epoch 69855 with loss: 7.5754\n",
      "Model saved at epoch 69856 with loss: 7.5752\n",
      "Model saved at epoch 69857 with loss: 7.5742\n",
      "Model saved at epoch 69858 with loss: 7.5740\n",
      "Epoch [69860/100000], Loss: 7.5773\n",
      "Epoch [69870/100000], Loss: 7.5784\n",
      "Epoch [69880/100000], Loss: 7.5824\n",
      "Epoch [69890/100000], Loss: 7.5759\n",
      "Epoch [69900/100000], Loss: 7.5770\n",
      "Model saved at epoch 69905 with loss: 7.5731\n",
      "Model saved at epoch 69906 with loss: 7.5718\n",
      "Model saved at epoch 69907 with loss: 7.5714\n",
      "Model saved at epoch 69908 with loss: 7.5710\n",
      "Model saved at epoch 69910 with loss: 7.5705\n",
      "Epoch [69910/100000], Loss: 7.5705\n",
      "Epoch [69920/100000], Loss: 7.5746\n",
      "Epoch [69930/100000], Loss: 7.5771\n",
      "Epoch [69940/100000], Loss: 7.5731\n",
      "Model saved at epoch 69950 with loss: 7.5694\n",
      "Epoch [69950/100000], Loss: 7.5694\n",
      "Model saved at epoch 69951 with loss: 7.5684\n",
      "Model saved at epoch 69952 with loss: 7.5664\n",
      "Epoch [69960/100000], Loss: 7.5713\n",
      "Epoch [69970/100000], Loss: 7.5725\n",
      "Epoch [69980/100000], Loss: 7.5680\n",
      "Epoch [69990/100000], Loss: 7.5688\n",
      "Epoch [70000/100000], Loss: 7.5712\n",
      "Epoch [70010/100000], Loss: 7.5677\n",
      "Model saved at epoch 70013 with loss: 7.5648\n",
      "Model saved at epoch 70015 with loss: 7.5646\n",
      "Epoch [70020/100000], Loss: 7.5665\n",
      "Model saved at epoch 70029 with loss: 7.5643\n",
      "Epoch [70030/100000], Loss: 7.5649\n",
      "Epoch [70040/100000], Loss: 7.5701\n",
      "Epoch [70050/100000], Loss: 7.5706\n",
      "Epoch [70060/100000], Loss: 7.5679\n",
      "Epoch [70070/100000], Loss: 7.5693\n",
      "Epoch [70080/100000], Loss: 7.5660\n",
      "Model saved at epoch 70081 with loss: 7.5639\n",
      "Model saved at epoch 70083 with loss: 7.5638\n",
      "Epoch [70090/100000], Loss: 7.5694\n",
      "Epoch [70100/100000], Loss: 7.5731\n",
      "Epoch [70110/100000], Loss: 7.5696\n",
      "Epoch [70120/100000], Loss: 7.5696\n",
      "Model saved at epoch 70127 with loss: 7.5634\n",
      "Epoch [70130/100000], Loss: 7.5655\n",
      "Epoch [70140/100000], Loss: 7.5718\n",
      "Model saved at epoch 70148 with loss: 7.5628\n",
      "Model saved at epoch 70149 with loss: 7.5626\n",
      "Epoch [70150/100000], Loss: 7.5646\n",
      "Epoch [70160/100000], Loss: 7.5669\n",
      "Epoch [70170/100000], Loss: 7.5662\n",
      "Epoch [70180/100000], Loss: 7.5664\n",
      "Epoch [70190/100000], Loss: 7.5704\n",
      "Epoch [70200/100000], Loss: 7.5662\n",
      "Epoch [70210/100000], Loss: 7.5660\n",
      "Epoch [70220/100000], Loss: 7.5627\n",
      "Model saved at epoch 70221 with loss: 7.5621\n",
      "Model saved at epoch 70222 with loss: 7.5617\n",
      "Model saved at epoch 70230 with loss: 7.5615\n",
      "Epoch [70230/100000], Loss: 7.5615\n",
      "Model saved at epoch 70231 with loss: 7.5613\n",
      "Model saved at epoch 70238 with loss: 7.5602\n",
      "Model saved at epoch 70239 with loss: 7.5599\n",
      "Model saved at epoch 70240 with loss: 7.5585\n",
      "Epoch [70240/100000], Loss: 7.5585\n",
      "Model saved at epoch 70241 with loss: 7.5581\n",
      "Model saved at epoch 70245 with loss: 7.5552\n",
      "Epoch [70250/100000], Loss: 7.5618\n",
      "Epoch [70260/100000], Loss: 7.5593\n",
      "Epoch [70270/100000], Loss: 7.5614\n",
      "Epoch [70280/100000], Loss: 7.5559\n",
      "Model saved at epoch 70287 with loss: 7.5545\n",
      "Epoch [70290/100000], Loss: 7.5558\n",
      "Model saved at epoch 70291 with loss: 7.5543\n",
      "Model saved at epoch 70292 with loss: 7.5537\n",
      "Model saved at epoch 70293 with loss: 7.5529\n",
      "Model saved at epoch 70295 with loss: 7.5516\n",
      "Epoch [70300/100000], Loss: 7.5539\n",
      "Epoch [70310/100000], Loss: 7.5560\n",
      "Epoch [70320/100000], Loss: 7.5526\n",
      "Model saved at epoch 70329 with loss: 7.5513\n",
      "Model saved at epoch 70330 with loss: 7.5499\n",
      "Epoch [70330/100000], Loss: 7.5499\n",
      "Model saved at epoch 70336 with loss: 7.5491\n",
      "Epoch [70340/100000], Loss: 7.5498\n",
      "Model saved at epoch 70341 with loss: 7.5489\n",
      "Model saved at epoch 70342 with loss: 7.5481\n",
      "Model saved at epoch 70346 with loss: 7.5472\n",
      "Model saved at epoch 70349 with loss: 7.5470\n",
      "Epoch [70350/100000], Loss: 7.5484\n",
      "Epoch [70360/100000], Loss: 7.5497\n",
      "Epoch [70370/100000], Loss: 7.5537\n",
      "Epoch [70380/100000], Loss: 7.5483\n",
      "Model saved at epoch 70384 with loss: 7.5469\n",
      "Model saved at epoch 70387 with loss: 7.5463\n",
      "Model saved at epoch 70388 with loss: 7.5457\n",
      "Model saved at epoch 70389 with loss: 7.5432\n",
      "Epoch [70390/100000], Loss: 7.5448\n",
      "Epoch [70400/100000], Loss: 7.5450\n",
      "Epoch [70410/100000], Loss: 7.5490\n",
      "Epoch [70420/100000], Loss: 7.5432\n",
      "Model saved at epoch 70422 with loss: 7.5427\n",
      "Model saved at epoch 70423 with loss: 7.5414\n",
      "Epoch [70430/100000], Loss: 7.5450\n",
      "Model saved at epoch 70439 with loss: 7.5413\n",
      "Epoch [70440/100000], Loss: 7.5426\n",
      "Epoch [70450/100000], Loss: 7.5429\n",
      "Model saved at epoch 70451 with loss: 7.5402\n",
      "Model saved at epoch 70452 with loss: 7.5398\n",
      "Model saved at epoch 70453 with loss: 7.5395\n",
      "Epoch [70460/100000], Loss: 7.5435\n",
      "Epoch [70470/100000], Loss: 7.5432\n",
      "Model saved at epoch 70475 with loss: 7.5393\n",
      "Model saved at epoch 70478 with loss: 7.5379\n",
      "Model saved at epoch 70480 with loss: 7.5375\n",
      "Epoch [70480/100000], Loss: 7.5375\n",
      "Model saved at epoch 70481 with loss: 7.5367\n",
      "Epoch [70490/100000], Loss: 7.5396\n",
      "Model saved at epoch 70496 with loss: 7.5366\n",
      "Model saved at epoch 70498 with loss: 7.5361\n",
      "Epoch [70500/100000], Loss: 7.5383\n",
      "Epoch [70510/100000], Loss: 7.5423\n",
      "Epoch [70520/100000], Loss: 7.5382\n",
      "Epoch [70530/100000], Loss: 7.5421\n",
      "Epoch [70540/100000], Loss: 7.5426\n",
      "Epoch [70550/100000], Loss: 7.5426\n",
      "Epoch [70560/100000], Loss: 7.5392\n",
      "Epoch [70570/100000], Loss: 7.5400\n",
      "Model saved at epoch 70580 with loss: 7.5352\n",
      "Epoch [70580/100000], Loss: 7.5352\n",
      "Model saved at epoch 70584 with loss: 7.5346\n",
      "Epoch [70590/100000], Loss: 7.5367\n",
      "Model saved at epoch 70597 with loss: 7.5342\n",
      "Model saved at epoch 70599 with loss: 7.5342\n",
      "Model saved at epoch 70600 with loss: 7.5328\n",
      "Epoch [70600/100000], Loss: 7.5328\n",
      "Model saved at epoch 70601 with loss: 7.5319\n",
      "Model saved at epoch 70602 with loss: 7.5288\n",
      "Epoch [70610/100000], Loss: 7.5387\n",
      "Epoch [70620/100000], Loss: 7.5349\n",
      "Epoch [70630/100000], Loss: 7.5307\n",
      "Epoch [70640/100000], Loss: 7.5311\n",
      "Model saved at epoch 70644 with loss: 7.5287\n",
      "Model saved at epoch 70645 with loss: 7.5273\n",
      "Epoch [70650/100000], Loss: 7.5346\n",
      "Epoch [70660/100000], Loss: 7.5364\n",
      "Epoch [70670/100000], Loss: 7.5321\n",
      "Epoch [70680/100000], Loss: 7.5334\n",
      "Epoch [70690/100000], Loss: 7.5357\n",
      "Epoch [70700/100000], Loss: 7.5369\n",
      "Epoch [70710/100000], Loss: 7.5299\n",
      "Epoch [70720/100000], Loss: 7.5340\n",
      "Epoch [70730/100000], Loss: 7.5318\n",
      "Epoch [70740/100000], Loss: 7.5303\n",
      "Model saved at epoch 70750 with loss: 7.5264\n",
      "Epoch [70750/100000], Loss: 7.5264\n",
      "Model saved at epoch 70756 with loss: 7.5256\n",
      "Model saved at epoch 70760 with loss: 7.5253\n",
      "Epoch [70760/100000], Loss: 7.5253\n",
      "Model saved at epoch 70762 with loss: 7.5245\n",
      "Model saved at epoch 70763 with loss: 7.5229\n",
      "Epoch [70770/100000], Loss: 7.5280\n",
      "Model saved at epoch 70780 with loss: 7.5223\n",
      "Epoch [70780/100000], Loss: 7.5223\n",
      "Model saved at epoch 70782 with loss: 7.5210\n",
      "Epoch [70790/100000], Loss: 7.5274\n",
      "Epoch [70800/100000], Loss: 7.5216\n",
      "Model saved at epoch 70802 with loss: 7.5193\n",
      "Model saved at epoch 70805 with loss: 7.5193\n",
      "Model saved at epoch 70806 with loss: 7.5192\n",
      "Model saved at epoch 70807 with loss: 7.5190\n",
      "Model saved at epoch 70810 with loss: 7.5179\n",
      "Epoch [70810/100000], Loss: 7.5179\n",
      "Epoch [70820/100000], Loss: 7.5235\n",
      "Epoch [70830/100000], Loss: 7.5249\n",
      "Epoch [70840/100000], Loss: 7.5238\n",
      "Epoch [70850/100000], Loss: 7.5219\n",
      "Epoch [70860/100000], Loss: 7.5200\n",
      "Model saved at epoch 70866 with loss: 7.5174\n",
      "Model saved at epoch 70869 with loss: 7.5172\n",
      "Epoch [70870/100000], Loss: 7.5211\n",
      "Epoch [70880/100000], Loss: 7.5182\n",
      "Model saved at epoch 70884 with loss: 7.5165\n",
      "Model saved at epoch 70885 with loss: 7.5163\n",
      "Model saved at epoch 70886 with loss: 7.5133\n",
      "Epoch [70890/100000], Loss: 7.5171\n",
      "Epoch [70900/100000], Loss: 7.5187\n",
      "Epoch [70910/100000], Loss: 7.5192\n",
      "Epoch [70920/100000], Loss: 7.5169\n",
      "Epoch [70930/100000], Loss: 7.5141\n",
      "Model saved at epoch 70931 with loss: 7.5117\n",
      "Model saved at epoch 70932 with loss: 7.5116\n",
      "Epoch [70940/100000], Loss: 7.5126\n",
      "Model saved at epoch 70947 with loss: 7.5111\n",
      "Model saved at epoch 70948 with loss: 7.5104\n",
      "Model saved at epoch 70949 with loss: 7.5069\n",
      "Epoch [70950/100000], Loss: 7.5108\n",
      "Epoch [70960/100000], Loss: 7.5138\n",
      "Epoch [70970/100000], Loss: 7.5083\n",
      "Model saved at epoch 70971 with loss: 7.5035\n",
      "Model saved at epoch 70978 with loss: 7.5029\n",
      "Epoch [70980/100000], Loss: 7.5078\n",
      "Model saved at epoch 70988 with loss: 7.5020\n",
      "Epoch [70990/100000], Loss: 7.5027\n",
      "Epoch [71000/100000], Loss: 7.5061\n",
      "Epoch [71010/100000], Loss: 7.5080\n",
      "Epoch [71020/100000], Loss: 7.5084\n",
      "Epoch [71030/100000], Loss: 7.5080\n",
      "Epoch [71040/100000], Loss: 7.5093\n",
      "Epoch [71050/100000], Loss: 7.5070\n",
      "Model saved at epoch 71056 with loss: 7.5013\n",
      "Epoch [71060/100000], Loss: 7.5026\n",
      "Epoch [71070/100000], Loss: 79.7140\n",
      "Epoch [71080/100000], Loss: 1564335744.0000\n",
      "Epoch [71090/100000], Loss: 1656044160.0000\n",
      "Epoch [71100/100000], Loss: 370285184.0000\n",
      "Epoch [71110/100000], Loss: 82548208.0000\n",
      "Epoch [71120/100000], Loss: 18528350.0000\n",
      "Epoch [71130/100000], Loss: 5782000.0000\n",
      "Epoch [71140/100000], Loss: 2690524.0000\n",
      "Epoch [71150/100000], Loss: 1235169.5000\n",
      "Epoch [71160/100000], Loss: 526594.3125\n",
      "Epoch [71170/100000], Loss: 239652.5312\n",
      "Epoch [71180/100000], Loss: 103109.0078\n",
      "Epoch [71190/100000], Loss: 36165.3164\n",
      "Epoch [71200/100000], Loss: 9887.6328\n",
      "Epoch [71210/100000], Loss: 1879.0209\n",
      "Epoch [71220/100000], Loss: 406.8278\n",
      "Epoch [71230/100000], Loss: 348.4066\n",
      "Epoch [71240/100000], Loss: 227.5499\n",
      "Epoch [71250/100000], Loss: 87.5123\n",
      "Epoch [71260/100000], Loss: 19.1306\n",
      "Epoch [71270/100000], Loss: 8.9727\n",
      "Epoch [71280/100000], Loss: 8.2330\n",
      "Epoch [71290/100000], Loss: 7.9759\n",
      "Epoch [71300/100000], Loss: 7.5518\n",
      "Model saved at epoch 71310 with loss: 7.4947\n",
      "Epoch [71310/100000], Loss: 7.4947\n",
      "Model saved at epoch 71315 with loss: 7.4885\n",
      "Model saved at epoch 71316 with loss: 7.4825\n",
      "Model saved at epoch 71317 with loss: 7.4786\n",
      "Epoch [71320/100000], Loss: 7.4878\n",
      "Model saved at epoch 71323 with loss: 7.4756\n",
      "Model saved at epoch 71326 with loss: 7.4734\n",
      "Epoch [71330/100000], Loss: 7.4773\n",
      "Model saved at epoch 71334 with loss: 7.4728\n",
      "Model saved at epoch 71335 with loss: 7.4718\n",
      "Model saved at epoch 71337 with loss: 7.4702\n",
      "Model saved at epoch 71338 with loss: 7.4670\n",
      "Model saved at epoch 71339 with loss: 7.4646\n",
      "Epoch [71340/100000], Loss: 7.4658\n",
      "Epoch [71350/100000], Loss: 7.4702\n",
      "Epoch [71360/100000], Loss: 7.4689\n",
      "Epoch [71370/100000], Loss: 7.4676\n",
      "Epoch [71380/100000], Loss: 7.4655\n",
      "Model saved at epoch 71381 with loss: 7.4645\n",
      "Model saved at epoch 71383 with loss: 7.4643\n",
      "Model saved at epoch 71384 with loss: 7.4623\n",
      "Epoch [71390/100000], Loss: 7.4646\n",
      "Epoch [71400/100000], Loss: 7.4678\n",
      "Epoch [71410/100000], Loss: 7.4650\n",
      "Epoch [71420/100000], Loss: 7.4650\n",
      "Epoch [71430/100000], Loss: 7.4644\n",
      "Epoch [71440/100000], Loss: 7.4630\n",
      "Model saved at epoch 71443 with loss: 7.4620\n",
      "Model saved at epoch 71444 with loss: 7.4616\n",
      "Epoch [71450/100000], Loss: 7.4637\n",
      "Epoch [71460/100000], Loss: 7.4640\n",
      "Epoch [71470/100000], Loss: 7.4629\n",
      "Model saved at epoch 71475 with loss: 7.4607\n",
      "Model saved at epoch 71477 with loss: 7.4602\n",
      "Model saved at epoch 71479 with loss: 7.4602\n",
      "Epoch [71480/100000], Loss: 7.4606\n",
      "Model saved at epoch 71482 with loss: 7.4601\n",
      "Model saved at epoch 71488 with loss: 7.4601\n",
      "Epoch [71490/100000], Loss: 7.4605\n",
      "Model saved at epoch 71491 with loss: 7.4590\n",
      "Epoch [71500/100000], Loss: 7.4628\n",
      "Epoch [71510/100000], Loss: 7.4611\n",
      "Epoch [71520/100000], Loss: 7.4595\n",
      "Model saved at epoch 71521 with loss: 7.4586\n",
      "Model saved at epoch 71522 with loss: 7.4584\n",
      "Epoch [71530/100000], Loss: 7.4596\n",
      "Model saved at epoch 71535 with loss: 7.4583\n",
      "Model saved at epoch 71538 with loss: 7.4579\n",
      "Model saved at epoch 71539 with loss: 7.4571\n",
      "Model saved at epoch 71540 with loss: 7.4568\n",
      "Epoch [71540/100000], Loss: 7.4568\n",
      "Model saved at epoch 71542 with loss: 7.4564\n",
      "Model saved at epoch 71544 with loss: 7.4564\n",
      "Model saved at epoch 71550 with loss: 7.4558\n",
      "Epoch [71550/100000], Loss: 7.4558\n",
      "Model saved at epoch 71551 with loss: 7.4547\n",
      "Model saved at epoch 71556 with loss: 7.4535\n",
      "Model saved at epoch 71557 with loss: 7.4531\n",
      "Epoch [71560/100000], Loss: 7.4541\n",
      "Epoch [71570/100000], Loss: 7.4553\n",
      "Epoch [71580/100000], Loss: 7.4561\n",
      "Epoch [71590/100000], Loss: 7.4533\n",
      "Model saved at epoch 71595 with loss: 7.4520\n",
      "Model saved at epoch 71596 with loss: 7.4516\n",
      "Epoch [71600/100000], Loss: 7.4535\n",
      "Epoch [71610/100000], Loss: 7.4528\n",
      "Epoch [71620/100000], Loss: 7.4527\n",
      "Model saved at epoch 71624 with loss: 7.4506\n",
      "Model saved at epoch 71625 with loss: 7.4503\n",
      "Model saved at epoch 71626 with loss: 7.4501\n",
      "Model saved at epoch 71628 with loss: 7.4493\n",
      "Epoch [71630/100000], Loss: 7.4501\n",
      "Model saved at epoch 71631 with loss: 7.4489\n",
      "Model saved at epoch 71632 with loss: 7.4482\n",
      "Epoch [71640/100000], Loss: 7.4509\n",
      "Epoch [71650/100000], Loss: 7.4507\n",
      "Epoch [71660/100000], Loss: 7.4494\n",
      "Epoch [71670/100000], Loss: 7.4501\n",
      "Epoch [71680/100000], Loss: 7.4519\n",
      "Epoch [71690/100000], Loss: 7.4519\n",
      "Epoch [71700/100000], Loss: 7.4498\n",
      "Model saved at epoch 71707 with loss: 7.4479\n",
      "Epoch [71710/100000], Loss: 7.4483\n",
      "Epoch [71720/100000], Loss: 7.4491\n",
      "Model saved at epoch 71725 with loss: 7.4475\n",
      "Model saved at epoch 71726 with loss: 7.4473\n",
      "Model saved at epoch 71727 with loss: 7.4468\n",
      "Epoch [71730/100000], Loss: 7.4473\n",
      "Model saved at epoch 71731 with loss: 7.4467\n",
      "Epoch [71740/100000], Loss: 7.4478\n",
      "Epoch [71750/100000], Loss: 7.4479\n",
      "Model saved at epoch 71756 with loss: 7.4466\n",
      "Epoch [71760/100000], Loss: 7.4470\n",
      "Model saved at epoch 71761 with loss: 7.4464\n",
      "Epoch [71770/100000], Loss: 7.4476\n",
      "Epoch [71780/100000], Loss: 7.4493\n",
      "Epoch [71790/100000], Loss: 7.4498\n",
      "Model saved at epoch 71797 with loss: 7.4453\n",
      "Model saved at epoch 71798 with loss: 7.4438\n",
      "Model saved at epoch 71799 with loss: 7.4435\n",
      "Epoch [71800/100000], Loss: 7.4440\n",
      "Model saved at epoch 71803 with loss: 7.4431\n",
      "Model saved at epoch 71804 with loss: 7.4422\n",
      "Epoch [71810/100000], Loss: 7.4437\n",
      "Epoch [71820/100000], Loss: 7.4446\n",
      "Epoch [71830/100000], Loss: 7.4436\n",
      "Epoch [71840/100000], Loss: 7.4446\n",
      "Epoch [71850/100000], Loss: 7.4456\n",
      "Epoch [71860/100000], Loss: 7.4493\n",
      "Epoch [71870/100000], Loss: 7.4454\n",
      "Model saved at epoch 71878 with loss: 7.4421\n",
      "Model saved at epoch 71879 with loss: 7.4417\n",
      "Epoch [71880/100000], Loss: 7.4425\n",
      "Model saved at epoch 71882 with loss: 7.4414\n",
      "Epoch [71890/100000], Loss: 7.4421\n",
      "Model saved at epoch 71891 with loss: 7.4408\n",
      "Model saved at epoch 71892 with loss: 7.4399\n",
      "Model saved at epoch 71893 with loss: 7.4393\n",
      "Model saved at epoch 71896 with loss: 7.4390\n",
      "Model saved at epoch 71897 with loss: 7.4379\n",
      "Model saved at epoch 71900 with loss: 7.4375\n",
      "Epoch [71900/100000], Loss: 7.4375\n",
      "Model saved at epoch 71905 with loss: 7.4371\n",
      "Model saved at epoch 71907 with loss: 7.4369\n",
      "Model saved at epoch 71908 with loss: 7.4363\n",
      "Epoch [71910/100000], Loss: 7.4388\n",
      "Model saved at epoch 71919 with loss: 7.4358\n",
      "Model saved at epoch 71920 with loss: 7.4357\n",
      "Epoch [71920/100000], Loss: 7.4357\n",
      "Model saved at epoch 71922 with loss: 7.4352\n",
      "Model saved at epoch 71925 with loss: 7.4352\n",
      "Epoch [71930/100000], Loss: 7.4381\n",
      "Epoch [71940/100000], Loss: 7.4396\n",
      "Epoch [71950/100000], Loss: 7.4363\n",
      "Epoch [71960/100000], Loss: 7.4381\n",
      "Model saved at epoch 71969 with loss: 7.4352\n",
      "Epoch [71970/100000], Loss: 7.4352\n",
      "Model saved at epoch 71973 with loss: 7.4344\n",
      "Model saved at epoch 71974 with loss: 7.4344\n",
      "Model saved at epoch 71975 with loss: 7.4344\n",
      "Model saved at epoch 71980 with loss: 7.4341\n",
      "Epoch [71980/100000], Loss: 7.4341\n",
      "Model saved at epoch 71985 with loss: 7.4331\n",
      "Model saved at epoch 71986 with loss: 7.4323\n",
      "Epoch [71990/100000], Loss: 7.4330\n",
      "Epoch [72000/100000], Loss: 7.4343\n",
      "Epoch [72010/100000], Loss: 7.4332\n",
      "Epoch [72020/100000], Loss: 7.4349\n",
      "Epoch [72030/100000], Loss: 7.4341\n",
      "Model saved at epoch 72035 with loss: 7.4322\n",
      "Model saved at epoch 72040 with loss: 7.4315\n",
      "Epoch [72040/100000], Loss: 7.4315\n",
      "Model saved at epoch 72042 with loss: 7.4314\n",
      "Model saved at epoch 72043 with loss: 7.4310\n",
      "Model saved at epoch 72044 with loss: 7.4304\n",
      "Epoch [72050/100000], Loss: 7.4306\n",
      "Epoch [72060/100000], Loss: 7.4330\n",
      "Model saved at epoch 72064 with loss: 7.4290\n",
      "Model saved at epoch 72066 with loss: 7.4286\n",
      "Model saved at epoch 72067 with loss: 7.4273\n",
      "Model saved at epoch 72068 with loss: 7.4269\n",
      "Epoch [72070/100000], Loss: 7.4284\n",
      "Epoch [72080/100000], Loss: 7.4276\n",
      "Model saved at epoch 72088 with loss: 7.4264\n",
      "Model saved at epoch 72089 with loss: 7.4262\n",
      "Epoch [72090/100000], Loss: 7.4269\n",
      "Model saved at epoch 72093 with loss: 7.4258\n",
      "Model saved at epoch 72094 with loss: 7.4258\n",
      "Model saved at epoch 72095 with loss: 7.4254\n",
      "Model saved at epoch 72097 with loss: 7.4250\n",
      "Model saved at epoch 72098 with loss: 7.4249\n",
      "Model saved at epoch 72099 with loss: 7.4242\n",
      "Epoch [72100/100000], Loss: 7.4249\n",
      "Model saved at epoch 72107 with loss: 7.4238\n",
      "Model saved at epoch 72108 with loss: 7.4229\n",
      "Epoch [72110/100000], Loss: 7.4232\n",
      "Model saved at epoch 72112 with loss: 7.4219\n",
      "Model saved at epoch 72113 with loss: 7.4211\n",
      "Epoch [72120/100000], Loss: 7.4228\n",
      "Epoch [72130/100000], Loss: 7.4278\n",
      "Epoch [72140/100000], Loss: 7.4264\n",
      "Epoch [72150/100000], Loss: 7.4269\n",
      "Epoch [72160/100000], Loss: 7.4294\n",
      "Epoch [72170/100000], Loss: 7.4295\n",
      "Epoch [72180/100000], Loss: 7.4294\n",
      "Epoch [72190/100000], Loss: 7.4275\n",
      "Epoch [72200/100000], Loss: 7.4262\n",
      "Epoch [72210/100000], Loss: 7.4276\n",
      "Epoch [72220/100000], Loss: 7.4285\n",
      "Epoch [72230/100000], Loss: 7.4271\n",
      "Epoch [72240/100000], Loss: 7.4284\n",
      "Epoch [72250/100000], Loss: 7.4269\n",
      "Epoch [72260/100000], Loss: 7.4227\n",
      "Epoch [72270/100000], Loss: 7.4245\n",
      "Epoch [72280/100000], Loss: 7.4241\n",
      "Epoch [72290/100000], Loss: 7.4242\n",
      "Epoch [72300/100000], Loss: 7.4233\n",
      "Epoch [72310/100000], Loss: 7.4265\n",
      "Epoch [72320/100000], Loss: 7.4243\n",
      "Epoch [72330/100000], Loss: 7.4222\n",
      "Epoch [72340/100000], Loss: 7.4237\n",
      "Epoch [72350/100000], Loss: 7.4245\n",
      "Epoch [72360/100000], Loss: 7.4239\n",
      "Epoch [72370/100000], Loss: 7.4214\n",
      "Model saved at epoch 72374 with loss: 7.4209\n",
      "Model saved at epoch 72375 with loss: 7.4198\n",
      "Model saved at epoch 72376 with loss: 7.4185\n",
      "Model saved at epoch 72380 with loss: 7.4183\n",
      "Epoch [72380/100000], Loss: 7.4183\n",
      "Model saved at epoch 72382 with loss: 7.4177\n",
      "Model saved at epoch 72384 with loss: 7.4169\n",
      "Model saved at epoch 72386 with loss: 7.4167\n",
      "Model saved at epoch 72388 with loss: 7.4157\n",
      "Model saved at epoch 72389 with loss: 7.4154\n",
      "Model saved at epoch 72390 with loss: 7.4149\n",
      "Epoch [72390/100000], Loss: 7.4149\n",
      "Epoch [72400/100000], Loss: 7.4179\n",
      "Epoch [72410/100000], Loss: 7.4165\n",
      "Epoch [72420/100000], Loss: 7.4156\n",
      "Epoch [72430/100000], Loss: 7.4179\n",
      "Epoch [72440/100000], Loss: 7.4193\n",
      "Epoch [72450/100000], Loss: 7.4193\n",
      "Epoch [72460/100000], Loss: 7.4195\n",
      "Epoch [72470/100000], Loss: 7.4181\n",
      "Epoch [72480/100000], Loss: 7.4170\n",
      "Epoch [72490/100000], Loss: 7.4169\n",
      "Epoch [72500/100000], Loss: 7.4198\n",
      "Epoch [72510/100000], Loss: 7.4195\n",
      "Epoch [72520/100000], Loss: 7.4197\n",
      "Model saved at epoch 72528 with loss: 7.4143\n",
      "Epoch [72530/100000], Loss: 7.4148\n",
      "Model saved at epoch 72532 with loss: 7.4142\n",
      "Model saved at epoch 72540 with loss: 7.4142\n",
      "Epoch [72540/100000], Loss: 7.4142\n",
      "Model saved at epoch 72541 with loss: 7.4140\n",
      "Epoch [72550/100000], Loss: 7.4169\n",
      "Model saved at epoch 72553 with loss: 7.4133\n",
      "Epoch [72560/100000], Loss: 7.4136\n",
      "Model saved at epoch 72561 with loss: 7.4126\n",
      "Model saved at epoch 72562 with loss: 7.4126\n",
      "Epoch [72570/100000], Loss: 7.4135\n",
      "Epoch [72580/100000], Loss: 7.4152\n",
      "Epoch [72590/100000], Loss: 7.4131\n",
      "Model saved at epoch 72597 with loss: 7.4122\n",
      "Model saved at epoch 72599 with loss: 7.4119\n",
      "Model saved at epoch 72600 with loss: 7.4111\n",
      "Epoch [72600/100000], Loss: 7.4111\n",
      "Model saved at epoch 72608 with loss: 7.4110\n",
      "Epoch [72610/100000], Loss: 7.4124\n",
      "Model saved at epoch 72612 with loss: 7.4108\n",
      "Model saved at epoch 72616 with loss: 7.4107\n",
      "Epoch [72620/100000], Loss: 7.4113\n",
      "Epoch [72630/100000], Loss: 7.4122\n",
      "Epoch [72640/100000], Loss: 7.4134\n",
      "Epoch [72650/100000], Loss: 7.4138\n",
      "Epoch [72660/100000], Loss: 7.4140\n",
      "Epoch [72670/100000], Loss: 7.4131\n",
      "Epoch [72680/100000], Loss: 7.4153\n",
      "Epoch [72690/100000], Loss: 7.4152\n",
      "Epoch [72700/100000], Loss: 7.4145\n",
      "Epoch [72710/100000], Loss: 7.4157\n",
      "Epoch [72720/100000], Loss: 7.4174\n",
      "Epoch [72730/100000], Loss: 7.4172\n",
      "Epoch [72740/100000], Loss: 7.4161\n",
      "Epoch [72750/100000], Loss: 7.4151\n",
      "Epoch [72760/100000], Loss: 7.4163\n",
      "Epoch [72770/100000], Loss: 7.4134\n",
      "Epoch [72780/100000], Loss: 7.4126\n",
      "Epoch [72790/100000], Loss: 7.4115\n",
      "Model saved at epoch 72792 with loss: 7.4106\n",
      "Model saved at epoch 72797 with loss: 7.4103\n",
      "Model saved at epoch 72799 with loss: 7.4102\n",
      "Epoch [72800/100000], Loss: 7.4108\n",
      "Model saved at epoch 72803 with loss: 7.4101\n",
      "Model saved at epoch 72804 with loss: 7.4099\n",
      "Model saved at epoch 72806 with loss: 7.4091\n",
      "Model saved at epoch 72807 with loss: 7.4090\n",
      "Model saved at epoch 72808 with loss: 7.4078\n",
      "Model saved at epoch 72809 with loss: 7.4073\n",
      "Epoch [72810/100000], Loss: 7.4075\n",
      "Model saved at epoch 72813 with loss: 7.4070\n",
      "Model saved at epoch 72814 with loss: 7.4066\n",
      "Epoch [72820/100000], Loss: 7.4084\n",
      "Epoch [72830/100000], Loss: 7.4120\n",
      "Epoch [72840/100000], Loss: 7.4088\n",
      "Model saved at epoch 72848 with loss: 7.4060\n",
      "Epoch [72850/100000], Loss: 7.4067\n",
      "Model saved at epoch 72851 with loss: 7.4058\n",
      "Model saved at epoch 72855 with loss: 7.4053\n",
      "Epoch [72860/100000], Loss: 7.4076\n",
      "Epoch [72870/100000], Loss: 7.4105\n",
      "Epoch [72880/100000], Loss: 7.4065\n",
      "Model saved at epoch 72890 with loss: 7.4047\n",
      "Epoch [72890/100000], Loss: 7.4047\n",
      "Model saved at epoch 72895 with loss: 7.4045\n",
      "Model saved at epoch 72897 with loss: 7.4042\n",
      "Model saved at epoch 72898 with loss: 7.4032\n",
      "Epoch [72900/100000], Loss: 7.4050\n",
      "Epoch [72910/100000], Loss: 7.4046\n",
      "Model saved at epoch 72912 with loss: 7.4030\n",
      "Model saved at epoch 72914 with loss: 7.4023\n",
      "Model saved at epoch 72915 with loss: 7.4014\n",
      "Epoch [72920/100000], Loss: 7.4018\n",
      "Model saved at epoch 72921 with loss: 7.4006\n",
      "Epoch [72930/100000], Loss: 7.4028\n",
      "Epoch [72940/100000], Loss: 7.4042\n",
      "Epoch [72950/100000], Loss: 7.4029\n",
      "Epoch [72960/100000], Loss: 7.4035\n",
      "Epoch [72970/100000], Loss: 7.4060\n",
      "Epoch [72980/100000], Loss: 7.4069\n",
      "Epoch [72990/100000], Loss: 7.4067\n",
      "Epoch [73000/100000], Loss: 7.4091\n",
      "Epoch [73010/100000], Loss: 7.4096\n",
      "Epoch [73020/100000], Loss: 7.4131\n",
      "Epoch [73030/100000], Loss: 7.4112\n",
      "Epoch [73040/100000], Loss: 7.4074\n",
      "Epoch [73050/100000], Loss: 7.4088\n",
      "Epoch [73060/100000], Loss: 7.4080\n",
      "Epoch [73070/100000], Loss: 7.4097\n",
      "Epoch [73080/100000], Loss: 7.4091\n",
      "Epoch [73090/100000], Loss: 7.4082\n",
      "Epoch [73100/100000], Loss: 7.4075\n",
      "Epoch [73110/100000], Loss: 7.4040\n",
      "Epoch [73120/100000], Loss: 7.4034\n",
      "Epoch [73130/100000], Loss: 7.4041\n",
      "Epoch [73140/100000], Loss: 7.4034\n",
      "Epoch [73150/100000], Loss: 7.4039\n",
      "Epoch [73160/100000], Loss: 7.4030\n",
      "Epoch [73170/100000], Loss: 7.4051\n",
      "Epoch [73180/100000], Loss: 7.4042\n",
      "Epoch [73190/100000], Loss: 7.4020\n",
      "Epoch [73200/100000], Loss: 7.4023\n",
      "Epoch [73210/100000], Loss: 7.4077\n",
      "Epoch [73220/100000], Loss: 7.4068\n",
      "Epoch [73230/100000], Loss: 7.4084\n",
      "Epoch [73240/100000], Loss: 7.4051\n",
      "Epoch [73250/100000], Loss: 7.4011\n",
      "Epoch [73260/100000], Loss: 7.4010\n",
      "Epoch [73270/100000], Loss: 7.4040\n",
      "Epoch [73280/100000], Loss: 7.4026\n",
      "Epoch [73290/100000], Loss: 7.4044\n",
      "Epoch [73300/100000], Loss: 7.4049\n",
      "Epoch [73310/100000], Loss: 7.4036\n",
      "Epoch [73320/100000], Loss: 7.4041\n",
      "Epoch [73330/100000], Loss: 7.4031\n",
      "Epoch [73340/100000], Loss: 7.4048\n",
      "Epoch [73350/100000], Loss: 7.4053\n",
      "Epoch [73360/100000], Loss: 7.4071\n",
      "Epoch [73370/100000], Loss: 7.4075\n",
      "Epoch [73380/100000], Loss: 7.4059\n",
      "Epoch [73390/100000], Loss: 7.4048\n",
      "Epoch [73400/100000], Loss: 7.4049\n",
      "Epoch [73410/100000], Loss: 7.4040\n",
      "Epoch [73420/100000], Loss: 7.4050\n",
      "Epoch [73430/100000], Loss: 7.4052\n",
      "Epoch [73440/100000], Loss: 7.4067\n",
      "Epoch [73450/100000], Loss: 7.4025\n",
      "Epoch [73460/100000], Loss: 7.4034\n",
      "Epoch [73470/100000], Loss: 7.4016\n",
      "Epoch [73480/100000], Loss: 7.4025\n",
      "Epoch [73490/100000], Loss: 7.4014\n",
      "Model saved at epoch 73491 with loss: 7.4006\n",
      "Model saved at epoch 73492 with loss: 7.4000\n",
      "Model saved at epoch 73499 with loss: 7.3999\n",
      "Model saved at epoch 73500 with loss: 7.3999\n",
      "Epoch [73500/100000], Loss: 7.3999\n",
      "Model saved at epoch 73502 with loss: 7.3994\n",
      "Model saved at epoch 73503 with loss: 7.3994\n",
      "Epoch [73510/100000], Loss: 7.4004\n",
      "Model saved at epoch 73511 with loss: 7.3988\n",
      "Model saved at epoch 73512 with loss: 7.3985\n",
      "Model saved at epoch 73513 with loss: 7.3985\n",
      "Model saved at epoch 73517 with loss: 7.3984\n",
      "Model saved at epoch 73518 with loss: 7.3977\n",
      "Model saved at epoch 73519 with loss: 7.3976\n",
      "Model saved at epoch 73520 with loss: 7.3974\n",
      "Epoch [73520/100000], Loss: 7.3974\n",
      "Model saved at epoch 73521 with loss: 7.3973\n",
      "Model saved at epoch 73522 with loss: 7.3970\n",
      "Model saved at epoch 73523 with loss: 7.3961\n",
      "Epoch [73530/100000], Loss: 7.3997\n",
      "Epoch [73540/100000], Loss: 7.3998\n",
      "Epoch [73550/100000], Loss: 7.4013\n",
      "Epoch [73560/100000], Loss: 7.3988\n",
      "Epoch [73570/100000], Loss: 7.3999\n",
      "Epoch [73580/100000], Loss: 7.3975\n",
      "Model saved at epoch 73583 with loss: 7.3961\n",
      "Epoch [73590/100000], Loss: 7.3963\n",
      "Epoch [73600/100000], Loss: 7.3993\n",
      "Epoch [73610/100000], Loss: 7.3984\n",
      "Epoch [73620/100000], Loss: 7.3983\n",
      "Epoch [73630/100000], Loss: 7.3964\n",
      "Model saved at epoch 73631 with loss: 7.3957\n",
      "Epoch [73640/100000], Loss: 7.3973\n",
      "Epoch [73650/100000], Loss: 7.4012\n",
      "Epoch [73660/100000], Loss: 7.3970\n",
      "Model saved at epoch 73663 with loss: 7.3956\n",
      "Model saved at epoch 73664 with loss: 7.3942\n",
      "Epoch [73670/100000], Loss: 7.3949\n",
      "Model saved at epoch 73671 with loss: 7.3940\n",
      "Epoch [73680/100000], Loss: 7.3956\n",
      "Epoch [73690/100000], Loss: 7.3949\n",
      "Model saved at epoch 73696 with loss: 7.3939\n",
      "Epoch [73700/100000], Loss: 7.3961\n",
      "Epoch [73710/100000], Loss: 7.3963\n",
      "Epoch [73720/100000], Loss: 7.3945\n",
      "Model saved at epoch 73722 with loss: 7.3936\n",
      "Model saved at epoch 73723 with loss: 7.3935\n",
      "Model saved at epoch 73730 with loss: 7.3931\n",
      "Epoch [73730/100000], Loss: 7.3931\n",
      "Model saved at epoch 73731 with loss: 7.3928\n",
      "Model saved at epoch 73733 with loss: 7.3926\n",
      "Epoch [73740/100000], Loss: 7.3927\n",
      "Model saved at epoch 73741 with loss: 7.3918\n",
      "Model saved at epoch 73742 with loss: 7.3917\n",
      "Model saved at epoch 73743 with loss: 7.3912\n",
      "Model saved at epoch 73744 with loss: 7.3905\n",
      "Model saved at epoch 73745 with loss: 7.3900\n",
      "Model saved at epoch 73748 with loss: 7.3894\n",
      "Epoch [73750/100000], Loss: 7.3907\n",
      "Epoch [73760/100000], Loss: 7.3932\n",
      "Epoch [73770/100000], Loss: 7.3912\n",
      "Epoch [73780/100000], Loss: 7.3938\n",
      "Epoch [73790/100000], Loss: 7.3933\n",
      "Epoch [73800/100000], Loss: 7.3955\n",
      "Epoch [73810/100000], Loss: 7.3935\n",
      "Epoch [73820/100000], Loss: 7.3933\n",
      "Epoch [73830/100000], Loss: 7.3947\n",
      "Epoch [73840/100000], Loss: 7.3937\n",
      "Epoch [73850/100000], Loss: 7.3929\n",
      "Epoch [73860/100000], Loss: 7.3933\n",
      "Epoch [73870/100000], Loss: 7.3947\n",
      "Epoch [73880/100000], Loss: 7.3932\n",
      "Epoch [73890/100000], Loss: 7.3962\n",
      "Epoch [73900/100000], Loss: 7.3935\n",
      "Epoch [73910/100000], Loss: 7.3898\n",
      "Epoch [73920/100000], Loss: 7.3904\n",
      "Epoch [73930/100000], Loss: 7.3932\n",
      "Epoch [73940/100000], Loss: 7.3935\n",
      "Epoch [73950/100000], Loss: 7.3913\n",
      "Epoch [73960/100000], Loss: 7.3923\n",
      "Epoch [73970/100000], Loss: 7.3919\n",
      "Epoch [73980/100000], Loss: 7.3911\n",
      "Epoch [73990/100000], Loss: 7.3905\n",
      "Epoch [74000/100000], Loss: 7.3922\n",
      "Epoch [74010/100000], Loss: 7.3921\n",
      "Epoch [74020/100000], Loss: 7.3919\n",
      "Model saved at epoch 74025 with loss: 7.3894\n",
      "Epoch [74030/100000], Loss: 7.3901\n",
      "Model saved at epoch 74038 with loss: 7.3890\n",
      "Epoch [74040/100000], Loss: 7.3892\n",
      "Model saved at epoch 74041 with loss: 7.3889\n",
      "Epoch [74050/100000], Loss: 7.3908\n",
      "Epoch [74060/100000], Loss: 7.3898\n",
      "Model saved at epoch 74062 with loss: 7.3881\n",
      "Model saved at epoch 74065 with loss: 7.3880\n",
      "Epoch [74070/100000], Loss: 7.3887\n",
      "Epoch [74080/100000], Loss: 7.3888\n",
      "Model saved at epoch 74083 with loss: 7.3879\n",
      "Epoch [74090/100000], Loss: 7.3882\n",
      "Model saved at epoch 74091 with loss: 7.3878\n",
      "Model saved at epoch 74092 with loss: 7.3875\n",
      "Epoch [74100/100000], Loss: 7.3888\n",
      "Model saved at epoch 74104 with loss: 7.3873\n",
      "Model saved at epoch 74105 with loss: 7.3870\n",
      "Model saved at epoch 74106 with loss: 7.3867\n",
      "Epoch [74110/100000], Loss: 7.3879\n",
      "Epoch [74120/100000], Loss: 7.3911\n",
      "Epoch [74130/100000], Loss: 7.3908\n",
      "Epoch [74140/100000], Loss: 7.3890\n",
      "Epoch [74150/100000], Loss: 7.3879\n",
      "Epoch [74160/100000], Loss: 7.3893\n",
      "Epoch [74170/100000], Loss: 7.3871\n",
      "Model saved at epoch 74176 with loss: 7.3867\n",
      "Epoch [74180/100000], Loss: 7.3875\n",
      "Epoch [74190/100000], Loss: 7.3890\n",
      "Model saved at epoch 74198 with loss: 7.3865\n",
      "Model saved at epoch 74199 with loss: 7.3854\n",
      "Epoch [74200/100000], Loss: 7.3869\n",
      "Model saved at epoch 74203 with loss: 7.3851\n",
      "Epoch [74210/100000], Loss: 7.3882\n",
      "Epoch [74220/100000], Loss: 7.3888\n",
      "Epoch [74230/100000], Loss: 7.3896\n",
      "Epoch [74240/100000], Loss: 7.3915\n",
      "Epoch [74250/100000], Loss: 7.3903\n",
      "Epoch [74260/100000], Loss: 7.3922\n",
      "Epoch [74270/100000], Loss: 7.3878\n",
      "Epoch [74280/100000], Loss: 7.3882\n",
      "Epoch [74290/100000], Loss: 7.3917\n",
      "Epoch [74300/100000], Loss: 7.3922\n",
      "Epoch [74310/100000], Loss: 7.3940\n",
      "Epoch [74320/100000], Loss: 7.3942\n",
      "Epoch [74330/100000], Loss: 7.3928\n",
      "Epoch [74340/100000], Loss: 7.3896\n",
      "Epoch [74350/100000], Loss: 7.3894\n",
      "Epoch [74360/100000], Loss: 7.3866\n",
      "Epoch [74370/100000], Loss: 7.3886\n",
      "Epoch [74380/100000], Loss: 7.3918\n",
      "Epoch [74390/100000], Loss: 7.3870\n",
      "Epoch [74400/100000], Loss: 7.3903\n",
      "Epoch [74410/100000], Loss: 7.3877\n",
      "Epoch [74420/100000], Loss: 7.3864\n",
      "Model saved at epoch 74425 with loss: 7.3850\n",
      "Model saved at epoch 74426 with loss: 7.3847\n",
      "Model saved at epoch 74427 with loss: 7.3843\n",
      "Model saved at epoch 74428 with loss: 7.3839\n",
      "Model saved at epoch 74429 with loss: 7.3830\n",
      "Model saved at epoch 74430 with loss: 7.3818\n",
      "Epoch [74430/100000], Loss: 7.3818\n",
      "Model saved at epoch 74439 with loss: 7.3814\n",
      "Epoch [74440/100000], Loss: 7.3817\n",
      "Model saved at epoch 74441 with loss: 7.3807\n",
      "Model saved at epoch 74443 with loss: 7.3806\n",
      "Model saved at epoch 74444 with loss: 7.3805\n",
      "Model saved at epoch 74445 with loss: 7.3802\n",
      "Model saved at epoch 74446 with loss: 7.3798\n",
      "Epoch [74450/100000], Loss: 7.3801\n",
      "Epoch [74460/100000], Loss: 7.3835\n",
      "Epoch [74470/100000], Loss: 7.3846\n",
      "Epoch [74480/100000], Loss: 7.3856\n",
      "Epoch [74490/100000], Loss: 7.3835\n",
      "Epoch [74500/100000], Loss: 7.3855\n",
      "Epoch [74510/100000], Loss: 7.3856\n",
      "Epoch [74520/100000], Loss: 7.3843\n",
      "Epoch [74530/100000], Loss: 7.3858\n",
      "Epoch [74540/100000], Loss: 7.3832\n",
      "Epoch [74550/100000], Loss: 7.3831\n",
      "Epoch [74560/100000], Loss: 7.3829\n",
      "Epoch [74570/100000], Loss: 7.3821\n",
      "Epoch [74580/100000], Loss: 7.3823\n",
      "Epoch [74590/100000], Loss: 7.3811\n",
      "Epoch [74600/100000], Loss: 7.3814\n",
      "Epoch [74610/100000], Loss: 7.3826\n",
      "Epoch [74620/100000], Loss: 7.3829\n",
      "Epoch [74630/100000], Loss: 7.3818\n",
      "Epoch [74640/100000], Loss: 7.3816\n",
      "Model saved at epoch 74646 with loss: 7.3795\n",
      "Model saved at epoch 74647 with loss: 7.3787\n",
      "Model saved at epoch 74648 with loss: 7.3784\n",
      "Model saved at epoch 74649 with loss: 7.3778\n",
      "Epoch [74650/100000], Loss: 7.3784\n",
      "Model saved at epoch 74651 with loss: 7.3775\n",
      "Model saved at epoch 74653 with loss: 7.3767\n",
      "Model saved at epoch 74654 with loss: 7.3764\n",
      "Epoch [74660/100000], Loss: 7.3786\n",
      "Epoch [74670/100000], Loss: 7.3786\n",
      "Epoch [74680/100000], Loss: 7.3776\n",
      "Epoch [74690/100000], Loss: 7.3800\n",
      "Epoch [74700/100000], Loss: 7.3799\n",
      "Epoch [74710/100000], Loss: 7.3788\n",
      "Epoch [74720/100000], Loss: 7.3779\n",
      "Epoch [74730/100000], Loss: 7.3784\n",
      "Model saved at epoch 74738 with loss: 7.3764\n",
      "Model saved at epoch 74739 with loss: 7.3761\n",
      "Epoch [74740/100000], Loss: 7.3762\n",
      "Epoch [74750/100000], Loss: 7.3789\n",
      "Epoch [74760/100000], Loss: 7.3781\n",
      "Epoch [74770/100000], Loss: 7.3816\n",
      "Epoch [74780/100000], Loss: 7.3824\n",
      "Epoch [74790/100000], Loss: 7.3828\n",
      "Epoch [74800/100000], Loss: 7.3806\n",
      "Epoch [74810/100000], Loss: 7.3803\n",
      "Epoch [74820/100000], Loss: 7.3806\n",
      "Epoch [74830/100000], Loss: 7.3830\n",
      "Epoch [74840/100000], Loss: 7.3840\n",
      "Epoch [74850/100000], Loss: 7.3820\n",
      "Epoch [74860/100000], Loss: 7.3822\n",
      "Epoch [74870/100000], Loss: 7.3819\n",
      "Epoch [74880/100000], Loss: 7.3852\n",
      "Epoch [74890/100000], Loss: 7.3814\n",
      "Epoch [74900/100000], Loss: 7.3857\n",
      "Epoch [74910/100000], Loss: 7.3874\n",
      "Epoch [74920/100000], Loss: 7.3862\n",
      "Epoch [74930/100000], Loss: 7.3844\n",
      "Epoch [74940/100000], Loss: 7.3837\n",
      "Epoch [74950/100000], Loss: 7.3848\n",
      "Epoch [74960/100000], Loss: 7.3824\n",
      "Epoch [74970/100000], Loss: 7.3829\n",
      "Epoch [74980/100000], Loss: 7.3822\n",
      "Epoch [74990/100000], Loss: 7.3822\n",
      "Epoch [75000/100000], Loss: 7.3825\n",
      "Epoch [75010/100000], Loss: 7.3810\n",
      "Epoch [75020/100000], Loss: 7.3767\n",
      "Model saved at epoch 75023 with loss: 7.3753\n",
      "Model saved at epoch 75024 with loss: 7.3748\n",
      "Epoch [75030/100000], Loss: 7.3751\n",
      "Epoch [75040/100000], Loss: 7.3766\n",
      "Model saved at epoch 75046 with loss: 7.3744\n",
      "Model saved at epoch 75047 with loss: 7.3742\n",
      "Model saved at epoch 75048 with loss: 7.3737\n",
      "Epoch [75050/100000], Loss: 7.3750\n",
      "Epoch [75060/100000], Loss: 7.3768\n",
      "Epoch [75070/100000], Loss: 7.3770\n",
      "Epoch [75080/100000], Loss: 7.3755\n",
      "Epoch [75090/100000], Loss: 7.3765\n",
      "Epoch [75100/100000], Loss: 7.3809\n",
      "Epoch [75110/100000], Loss: 7.3777\n",
      "Epoch [75120/100000], Loss: 7.3780\n",
      "Epoch [75130/100000], Loss: 7.3770\n",
      "Epoch [75140/100000], Loss: 7.3781\n",
      "Epoch [75150/100000], Loss: 7.3779\n",
      "Epoch [75160/100000], Loss: 7.3761\n",
      "Epoch [75170/100000], Loss: 7.3780\n",
      "Epoch [75180/100000], Loss: 7.3802\n",
      "Epoch [75190/100000], Loss: 7.3772\n",
      "Epoch [75200/100000], Loss: 7.3779\n",
      "Model saved at epoch 75208 with loss: 7.3737\n",
      "Epoch [75210/100000], Loss: 7.3740\n",
      "Epoch [75220/100000], Loss: 7.3763\n",
      "Epoch [75230/100000], Loss: 7.3751\n",
      "Model saved at epoch 75234 with loss: 7.3733\n",
      "Model saved at epoch 75235 with loss: 7.3731\n",
      "Model saved at epoch 75236 with loss: 7.3722\n",
      "Epoch [75240/100000], Loss: 7.3731\n",
      "Model saved at epoch 75247 with loss: 7.3716\n",
      "Model saved at epoch 75249 with loss: 7.3707\n",
      "Model saved at epoch 75250 with loss: 7.3703\n",
      "Epoch [75250/100000], Loss: 7.3703\n",
      "Model saved at epoch 75251 with loss: 7.3695\n",
      "Model saved at epoch 75253 with loss: 7.3691\n",
      "Epoch [75260/100000], Loss: 7.3719\n",
      "Epoch [75270/100000], Loss: 7.3721\n",
      "Epoch [75280/100000], Loss: 7.3736\n",
      "Epoch [75290/100000], Loss: 7.3735\n",
      "Epoch [75300/100000], Loss: 7.3720\n",
      "Model saved at epoch 75306 with loss: 7.3686\n",
      "Model saved at epoch 75310 with loss: 7.3686\n",
      "Epoch [75310/100000], Loss: 7.3686\n",
      "Model saved at epoch 75311 with loss: 7.3683\n",
      "Model saved at epoch 75313 with loss: 7.3681\n",
      "Epoch [75320/100000], Loss: 7.3693\n",
      "Model saved at epoch 75324 with loss: 7.3676\n",
      "Model saved at epoch 75327 with loss: 7.3667\n",
      "Epoch [75330/100000], Loss: 7.3702\n",
      "Epoch [75340/100000], Loss: 7.3685\n",
      "Epoch [75350/100000], Loss: 7.3711\n",
      "Epoch [75360/100000], Loss: 7.3682\n",
      "Model saved at epoch 75363 with loss: 7.3659\n",
      "Model saved at epoch 75365 with loss: 7.3652\n",
      "Model saved at epoch 75366 with loss: 7.3642\n",
      "Epoch [75370/100000], Loss: 7.3664\n",
      "Epoch [75380/100000], Loss: 7.3689\n",
      "Epoch [75390/100000], Loss: 7.3707\n",
      "Epoch [75400/100000], Loss: 7.3703\n",
      "Epoch [75410/100000], Loss: 7.3699\n",
      "Epoch [75420/100000], Loss: 7.3691\n",
      "Epoch [75430/100000], Loss: 7.3707\n",
      "Epoch [75440/100000], Loss: 7.3700\n",
      "Epoch [75450/100000], Loss: 7.3697\n",
      "Epoch [75460/100000], Loss: 7.3666\n",
      "Epoch [75470/100000], Loss: 7.3693\n",
      "Epoch [75480/100000], Loss: 7.3657\n",
      "Model saved at epoch 75484 with loss: 7.3638\n",
      "Model saved at epoch 75485 with loss: 7.3631\n",
      "Model saved at epoch 75486 with loss: 7.3627\n",
      "Model saved at epoch 75487 with loss: 7.3625\n",
      "Epoch [75490/100000], Loss: 7.3626\n",
      "Model saved at epoch 75491 with loss: 7.3624\n",
      "Model saved at epoch 75492 with loss: 7.3621\n",
      "Epoch [75500/100000], Loss: 7.3644\n",
      "Epoch [75510/100000], Loss: 7.3622\n",
      "Model saved at epoch 75512 with loss: 7.3617\n",
      "Model saved at epoch 75514 with loss: 7.3606\n",
      "Model saved at epoch 75515 with loss: 7.3601\n",
      "Model saved at epoch 75516 with loss: 7.3601\n",
      "Model saved at epoch 75517 with loss: 7.3593\n",
      "Epoch [75520/100000], Loss: 7.3611\n",
      "Epoch [75530/100000], Loss: 7.3607\n",
      "Epoch [75540/100000], Loss: 7.3642\n",
      "Epoch [75550/100000], Loss: 7.3656\n",
      "Epoch [75560/100000], Loss: 7.3663\n",
      "Epoch [75570/100000], Loss: 7.3633\n",
      "Epoch [75580/100000], Loss: 7.3645\n",
      "Epoch [75590/100000], Loss: 7.3668\n",
      "Epoch [75600/100000], Loss: 7.3652\n",
      "Epoch [75610/100000], Loss: 7.3641\n",
      "Epoch [75620/100000], Loss: 7.3627\n",
      "Epoch [75630/100000], Loss: 7.3625\n",
      "Epoch [75640/100000], Loss: 7.3620\n",
      "Epoch [75650/100000], Loss: 7.3597\n",
      "Model saved at epoch 75655 with loss: 7.3589\n",
      "Model saved at epoch 75656 with loss: 7.3580\n",
      "Model saved at epoch 75657 with loss: 7.3570\n",
      "Epoch [75660/100000], Loss: 7.3585\n",
      "Model saved at epoch 75665 with loss: 7.3566\n",
      "Epoch [75670/100000], Loss: 7.3570\n",
      "Epoch [75680/100000], Loss: 7.3580\n",
      "Epoch [75690/100000], Loss: 7.3574\n",
      "Model saved at epoch 75699 with loss: 7.3559\n",
      "Model saved at epoch 75700 with loss: 7.3559\n",
      "Epoch [75700/100000], Loss: 7.3559\n",
      "Model saved at epoch 75701 with loss: 7.3537\n",
      "Model saved at epoch 75702 with loss: 7.3529\n",
      "Epoch [75710/100000], Loss: 7.3551\n",
      "Epoch [75720/100000], Loss: 7.3562\n",
      "Epoch [75730/100000], Loss: 7.3567\n",
      "Model saved at epoch 75738 with loss: 7.3521\n",
      "Epoch [75740/100000], Loss: 7.3531\n",
      "Model saved at epoch 75741 with loss: 7.3520\n",
      "Model saved at epoch 75745 with loss: 7.3514\n",
      "Epoch [75750/100000], Loss: 7.3536\n",
      "Model saved at epoch 75760 with loss: 7.3510\n",
      "Epoch [75760/100000], Loss: 7.3510\n",
      "Epoch [75770/100000], Loss: 7.3542\n",
      "Epoch [75780/100000], Loss: 7.3560\n",
      "Epoch [75790/100000], Loss: 7.3553\n",
      "Epoch [75800/100000], Loss: 7.3556\n",
      "Epoch [75810/100000], Loss: 7.3538\n",
      "Epoch [75820/100000], Loss: 7.3538\n",
      "Epoch [75830/100000], Loss: 7.3541\n",
      "Epoch [75840/100000], Loss: 7.3530\n",
      "Model saved at epoch 75847 with loss: 7.3502\n",
      "Model saved at epoch 75849 with loss: 7.3497\n",
      "Epoch [75850/100000], Loss: 7.3513\n",
      "Epoch [75860/100000], Loss: 7.3558\n",
      "Epoch [75870/100000], Loss: 7.3542\n",
      "Epoch [75880/100000], Loss: 7.3557\n",
      "Epoch [75890/100000], Loss: 7.3554\n",
      "Epoch [75900/100000], Loss: 7.3545\n",
      "Epoch [75910/100000], Loss: 7.3529\n",
      "Epoch [75920/100000], Loss: 7.3526\n",
      "Epoch [75930/100000], Loss: 7.3529\n",
      "Epoch [75940/100000], Loss: 7.3531\n",
      "Epoch [75950/100000], Loss: 7.3537\n",
      "Model saved at epoch 75957 with loss: 7.3494\n",
      "Model saved at epoch 75958 with loss: 7.3494\n",
      "Model saved at epoch 75959 with loss: 7.3487\n",
      "Model saved at epoch 75960 with loss: 7.3487\n",
      "Epoch [75960/100000], Loss: 7.3487\n",
      "Model saved at epoch 75961 with loss: 7.3480\n",
      "Epoch [75970/100000], Loss: 7.3508\n",
      "Epoch [75980/100000], Loss: 7.3514\n",
      "Epoch [75990/100000], Loss: 7.3486\n",
      "Model saved at epoch 75999 with loss: 7.3479\n",
      "Model saved at epoch 76000 with loss: 7.3476\n",
      "Epoch [76000/100000], Loss: 7.3476\n",
      "Model saved at epoch 76001 with loss: 7.3475\n",
      "Model saved at epoch 76002 with loss: 7.3464\n",
      "Model saved at epoch 76007 with loss: 7.3459\n",
      "Model saved at epoch 76008 with loss: 7.3452\n",
      "Epoch [76010/100000], Loss: 7.3474\n",
      "Model saved at epoch 76018 with loss: 7.3451\n",
      "Epoch [76020/100000], Loss: 7.3470\n",
      "Epoch [76030/100000], Loss: 7.3451\n",
      "Model saved at epoch 76032 with loss: 7.3451\n",
      "Epoch [76040/100000], Loss: 7.3479\n",
      "Epoch [76050/100000], Loss: 7.3510\n",
      "Epoch [76060/100000], Loss: 7.3506\n",
      "Epoch [76070/100000], Loss: 7.3530\n",
      "Epoch [76080/100000], Loss: 7.3509\n",
      "Epoch [76090/100000], Loss: 7.3517\n",
      "Epoch [76100/100000], Loss: 7.3503\n",
      "Epoch [76110/100000], Loss: 7.3500\n",
      "Epoch [76120/100000], Loss: 7.3476\n",
      "Epoch [76130/100000], Loss: 7.3484\n",
      "Epoch [76140/100000], Loss: 7.3454\n",
      "Model saved at epoch 76142 with loss: 7.3449\n",
      "Model saved at epoch 76143 with loss: 7.3444\n",
      "Model saved at epoch 76147 with loss: 7.3441\n",
      "Model saved at epoch 76149 with loss: 7.3439\n",
      "Model saved at epoch 76150 with loss: 7.3438\n",
      "Epoch [76150/100000], Loss: 7.3438\n",
      "Model saved at epoch 76159 with loss: 7.3430\n",
      "Epoch [76160/100000], Loss: 7.3431\n",
      "Model saved at epoch 76161 with loss: 7.3430\n",
      "Epoch [76170/100000], Loss: 7.3445\n",
      "Epoch [76180/100000], Loss: 7.3456\n",
      "Epoch [76190/100000], Loss: 7.3508\n",
      "Epoch [76200/100000], Loss: 7.3453\n",
      "Model saved at epoch 76207 with loss: 7.3427\n",
      "Model saved at epoch 76208 with loss: 7.3419\n",
      "Epoch [76210/100000], Loss: 7.3428\n",
      "Epoch [76220/100000], Loss: 7.3428\n",
      "Epoch [76230/100000], Loss: 7.3436\n",
      "Model saved at epoch 76239 with loss: 7.3415\n",
      "Model saved at epoch 76240 with loss: 7.3413\n",
      "Epoch [76240/100000], Loss: 7.3413\n",
      "Model saved at epoch 76245 with loss: 7.3410\n",
      "Model saved at epoch 76248 with loss: 7.3407\n",
      "Epoch [76250/100000], Loss: 7.3424\n",
      "Model saved at epoch 76251 with loss: 7.3404\n",
      "Model saved at epoch 76252 with loss: 7.3402\n",
      "Model saved at epoch 76254 with loss: 7.3401\n",
      "Model saved at epoch 76256 with loss: 7.3399\n",
      "Model saved at epoch 76257 with loss: 7.3395\n",
      "Epoch [76260/100000], Loss: 7.3406\n",
      "Model saved at epoch 76263 with loss: 7.3384\n",
      "Model saved at epoch 76265 with loss: 7.3383\n",
      "Epoch [76270/100000], Loss: 7.3405\n",
      "Model saved at epoch 76278 with loss: 7.3382\n",
      "Epoch [76280/100000], Loss: 7.3416\n",
      "Epoch [76290/100000], Loss: 7.3450\n",
      "Epoch [76300/100000], Loss: 7.3448\n",
      "Epoch [76310/100000], Loss: 7.3422\n",
      "Epoch [76320/100000], Loss: 7.3406\n",
      "Epoch [76330/100000], Loss: 7.3446\n",
      "Epoch [76340/100000], Loss: 7.3420\n",
      "Epoch [76350/100000], Loss: 7.3413\n",
      "Epoch [76360/100000], Loss: 7.3422\n",
      "Epoch [76370/100000], Loss: 7.3440\n",
      "Epoch [76380/100000], Loss: 7.3400\n",
      "Epoch [76390/100000], Loss: 7.3430\n",
      "Model saved at epoch 76397 with loss: 7.3366\n",
      "Epoch [76400/100000], Loss: 7.3388\n",
      "Model saved at epoch 76404 with loss: 7.3354\n",
      "Model saved at epoch 76408 with loss: 7.3350\n",
      "Model saved at epoch 76410 with loss: 7.3342\n",
      "Epoch [76410/100000], Loss: 7.3342\n",
      "Model saved at epoch 76414 with loss: 7.3341\n",
      "Model saved at epoch 76420 with loss: 7.3339\n",
      "Epoch [76420/100000], Loss: 7.3339\n",
      "Model saved at epoch 76422 with loss: 7.3329\n",
      "Model saved at epoch 76424 with loss: 7.3326\n",
      "Epoch [76430/100000], Loss: 7.3378\n",
      "Epoch [76440/100000], Loss: 7.3363\n",
      "Epoch [76450/100000], Loss: 7.3369\n",
      "Epoch [76460/100000], Loss: 7.3387\n",
      "Epoch [76470/100000], Loss: 7.3361\n",
      "Epoch [76480/100000], Loss: 7.3351\n",
      "Epoch [76490/100000], Loss: 7.3355\n",
      "Epoch [76500/100000], Loss: 7.3358\n",
      "Epoch [76510/100000], Loss: 7.3330\n",
      "Model saved at epoch 76511 with loss: 7.3317\n",
      "Epoch [76520/100000], Loss: 7.3339\n",
      "Epoch [76530/100000], Loss: 7.3352\n",
      "Model saved at epoch 76538 with loss: 7.3316\n",
      "Model saved at epoch 76539 with loss: 7.3313\n",
      "Epoch [76540/100000], Loss: 7.3314\n",
      "Model saved at epoch 76541 with loss: 7.3309\n",
      "Model saved at epoch 76542 with loss: 7.3307\n",
      "Model saved at epoch 76544 with loss: 7.3305\n",
      "Model saved at epoch 76547 with loss: 7.3302\n",
      "Epoch [76550/100000], Loss: 7.3321\n",
      "Epoch [76560/100000], Loss: 7.3344\n",
      "Epoch [76570/100000], Loss: 7.3340\n",
      "Epoch [76580/100000], Loss: 7.3328\n",
      "Model saved at epoch 76589 with loss: 7.3299\n",
      "Epoch [76590/100000], Loss: 7.3299\n",
      "Epoch [76600/100000], Loss: 7.3305\n",
      "Model saved at epoch 76602 with loss: 7.3283\n",
      "Model saved at epoch 76603 with loss: 7.3280\n",
      "Model saved at epoch 76605 with loss: 7.3277\n",
      "Epoch [76610/100000], Loss: 7.3304\n",
      "Epoch [76620/100000], Loss: 7.3280\n",
      "Epoch [76630/100000], Loss: 7.3298\n",
      "Epoch [76640/100000], Loss: 7.3291\n",
      "Model saved at epoch 76649 with loss: 7.3272\n",
      "Epoch [76650/100000], Loss: 7.3285\n",
      "Model saved at epoch 76656 with loss: 7.3263\n",
      "Model saved at epoch 76657 with loss: 7.3256\n",
      "Model saved at epoch 76658 with loss: 7.3252\n",
      "Epoch [76660/100000], Loss: 7.3276\n",
      "Model saved at epoch 76670 with loss: 7.3238\n",
      "Epoch [76670/100000], Loss: 7.3238\n",
      "Epoch [76680/100000], Loss: 7.3270\n",
      "Epoch [76690/100000], Loss: 7.3273\n",
      "Epoch [76700/100000], Loss: 7.3305\n",
      "Epoch [76710/100000], Loss: 7.3277\n",
      "Epoch [76720/100000], Loss: 7.3277\n",
      "Model saved at epoch 76725 with loss: 7.3237\n",
      "Epoch [76730/100000], Loss: 7.3254\n",
      "Model saved at epoch 76733 with loss: 7.3229\n",
      "Model saved at epoch 76734 with loss: 7.3220\n",
      "Epoch [76740/100000], Loss: 7.3233\n",
      "Model saved at epoch 76746 with loss: 7.3209\n",
      "Model saved at epoch 76747 with loss: 7.3199\n",
      "Model saved at epoch 76749 with loss: 7.3179\n",
      "Model saved at epoch 76750 with loss: 7.3174\n",
      "Epoch [76750/100000], Loss: 7.3174\n",
      "Model saved at epoch 76760 with loss: 7.3174\n",
      "Epoch [76760/100000], Loss: 7.3174\n",
      "Model saved at epoch 76761 with loss: 7.3165\n",
      "Epoch [76770/100000], Loss: 7.3225\n",
      "Epoch [76780/100000], Loss: 7.3252\n",
      "Epoch [76790/100000], Loss: 7.3227\n",
      "Epoch [76800/100000], Loss: 7.3219\n",
      "Epoch [76810/100000], Loss: 7.3223\n",
      "Epoch [76820/100000], Loss: 7.3218\n",
      "Epoch [76830/100000], Loss: 7.3221\n",
      "Epoch [76840/100000], Loss: 7.3223\n",
      "Epoch [76850/100000], Loss: 7.3191\n",
      "Epoch [76860/100000], Loss: 7.3213\n",
      "Epoch [76870/100000], Loss: 7.3216\n",
      "Epoch [76880/100000], Loss: 7.3191\n",
      "Epoch [76890/100000], Loss: 7.3166\n",
      "Model saved at epoch 76891 with loss: 7.3162\n",
      "Model saved at epoch 76893 with loss: 7.3161\n",
      "Epoch [76900/100000], Loss: 7.3191\n",
      "Epoch [76910/100000], Loss: 7.3193\n",
      "Epoch [76920/100000], Loss: 7.3209\n",
      "Epoch [76930/100000], Loss: 7.3191\n",
      "Epoch [76940/100000], Loss: 7.3170\n",
      "Model saved at epoch 76942 with loss: 7.3157\n",
      "Model saved at epoch 76943 with loss: 7.3149\n",
      "Model saved at epoch 76947 with loss: 7.3146\n",
      "Epoch [76950/100000], Loss: 7.3163\n",
      "Epoch [76960/100000], Loss: 7.3153\n",
      "Model saved at epoch 76963 with loss: 7.3138\n",
      "Model saved at epoch 76964 with loss: 7.3121\n",
      "Epoch [76970/100000], Loss: 7.3136\n",
      "Epoch [76980/100000], Loss: 7.3142\n",
      "Epoch [76990/100000], Loss: 7.3131\n",
      "Model saved at epoch 76993 with loss: 7.3118\n",
      "Epoch [77000/100000], Loss: 7.3148\n",
      "Epoch [77010/100000], Loss: 7.3172\n",
      "Epoch [77020/100000], Loss: 7.3164\n",
      "Model saved at epoch 77030 with loss: 7.3112\n",
      "Epoch [77030/100000], Loss: 7.3112\n",
      "Model saved at epoch 77031 with loss: 7.3106\n",
      "Model saved at epoch 77032 with loss: 7.3096\n",
      "Epoch [77040/100000], Loss: 7.3133\n",
      "Model saved at epoch 77048 with loss: 7.3096\n",
      "Epoch [77050/100000], Loss: 7.3096\n",
      "Model saved at epoch 77051 with loss: 7.3091\n",
      "Model saved at epoch 77059 with loss: 7.3089\n",
      "Model saved at epoch 77060 with loss: 7.3085\n",
      "Epoch [77060/100000], Loss: 7.3085\n",
      "Model saved at epoch 77069 with loss: 7.3081\n",
      "Epoch [77070/100000], Loss: 7.3087\n",
      "Model saved at epoch 77078 with loss: 7.3064\n",
      "Epoch [77080/100000], Loss: 7.3080\n",
      "Model saved at epoch 77086 with loss: 7.3063\n",
      "Epoch [77090/100000], Loss: 7.3109\n",
      "Model saved at epoch 77093 with loss: 7.3061\n",
      "Model saved at epoch 77100 with loss: 7.3059\n",
      "Epoch [77100/100000], Loss: 7.3059\n",
      "Model saved at epoch 77101 with loss: 7.3054\n",
      "Model saved at epoch 77102 with loss: 7.3048\n",
      "Epoch [77110/100000], Loss: 7.3083\n",
      "Model saved at epoch 77120 with loss: 7.3040\n",
      "Epoch [77120/100000], Loss: 7.3040\n",
      "Model saved at epoch 77123 with loss: 7.3035\n",
      "Epoch [77130/100000], Loss: 7.3090\n",
      "Epoch [77140/100000], Loss: 7.3045\n",
      "Model saved at epoch 77142 with loss: 7.3034\n",
      "Model saved at epoch 77143 with loss: 7.3032\n",
      "Epoch [77150/100000], Loss: 7.3056\n",
      "Epoch [77160/100000], Loss: 7.3047\n",
      "Model saved at epoch 77161 with loss: 7.3017\n",
      "Model saved at epoch 77162 with loss: 7.3006\n",
      "Epoch [77170/100000], Loss: 7.3049\n",
      "Model saved at epoch 77177 with loss: 7.3005\n",
      "Model saved at epoch 77178 with loss: 7.2999\n",
      "Epoch [77180/100000], Loss: 7.3011\n",
      "Epoch [77190/100000], Loss: 7.3014\n",
      "Epoch [77200/100000], Loss: 7.3040\n",
      "Epoch [77210/100000], Loss: 7.3042\n",
      "Epoch [77220/100000], Loss: 7.3015\n",
      "Model saved at epoch 77225 with loss: 7.2984\n",
      "Model saved at epoch 77227 with loss: 7.2976\n",
      "Model saved at epoch 77228 with loss: 7.2973\n",
      "Model saved at epoch 77229 with loss: 7.2957\n",
      "Epoch [77230/100000], Loss: 7.2963\n",
      "Model saved at epoch 77233 with loss: 7.2953\n",
      "Epoch [77240/100000], Loss: 7.3005\n",
      "Epoch [77250/100000], Loss: 7.2988\n",
      "Epoch [77260/100000], Loss: 7.3007\n",
      "Model saved at epoch 77266 with loss: 7.2930\n",
      "Model saved at epoch 77268 with loss: 7.2927\n",
      "Epoch [77270/100000], Loss: 7.2967\n",
      "Epoch [77280/100000], Loss: 7.2947\n",
      "Epoch [77290/100000], Loss: 7.2972\n",
      "Epoch [77300/100000], Loss: 7.2964\n",
      "Model saved at epoch 77302 with loss: 7.2927\n",
      "Epoch [77310/100000], Loss: 7.2971\n",
      "Model saved at epoch 77315 with loss: 7.2926\n",
      "Model saved at epoch 77318 with loss: 7.2921\n",
      "Model saved at epoch 77319 with loss: 7.2899\n",
      "Epoch [77320/100000], Loss: 7.2919\n",
      "Epoch [77330/100000], Loss: 7.2975\n",
      "Epoch [77340/100000], Loss: 7.2972\n",
      "Epoch [77350/100000], Loss: 7.2959\n",
      "Epoch [77360/100000], Loss: 7.2956\n",
      "Epoch [77370/100000], Loss: 7.2952\n",
      "Epoch [77380/100000], Loss: 7.2956\n",
      "Epoch [77390/100000], Loss: 7.2976\n",
      "Epoch [77400/100000], Loss: 7.2944\n",
      "Model saved at epoch 77410 with loss: 7.2892\n",
      "Epoch [77410/100000], Loss: 7.2892\n",
      "Model saved at epoch 77417 with loss: 7.2876\n",
      "Epoch [77420/100000], Loss: 7.2882\n",
      "Model saved at epoch 77421 with loss: 7.2869\n",
      "Epoch [77430/100000], Loss: 7.2889\n",
      "Epoch [77440/100000], Loss: 7.2891\n",
      "Epoch [77450/100000], Loss: 7.2882\n",
      "Epoch [77460/100000], Loss: 7.2883\n",
      "Model saved at epoch 77463 with loss: 7.2864\n",
      "Model saved at epoch 77464 with loss: 7.2848\n",
      "Model saved at epoch 77466 with loss: 7.2839\n",
      "Model saved at epoch 77467 with loss: 7.2818\n",
      "Epoch [77470/100000], Loss: 7.2856\n",
      "Epoch [77480/100000], Loss: 7.2864\n",
      "Epoch [77490/100000], Loss: 7.2846\n",
      "Epoch [77500/100000], Loss: 7.2830\n",
      "Model saved at epoch 77510 with loss: 7.2813\n",
      "Epoch [77510/100000], Loss: 7.2813\n",
      "Model saved at epoch 77513 with loss: 7.2810\n",
      "Model saved at epoch 77514 with loss: 7.2793\n",
      "Epoch [77520/100000], Loss: 7.2832\n",
      "Epoch [77530/100000], Loss: 7.2847\n",
      "Epoch [77540/100000], Loss: 7.2823\n",
      "Model saved at epoch 77547 with loss: 7.2775\n",
      "Model saved at epoch 77548 with loss: 7.2774\n",
      "Epoch [77550/100000], Loss: 7.2793\n",
      "Epoch [77560/100000], Loss: 7.2823\n",
      "Epoch [77570/100000], Loss: 7.2813\n",
      "Model saved at epoch 77573 with loss: 7.2762\n",
      "Model saved at epoch 77574 with loss: 7.2760\n",
      "Model saved at epoch 77579 with loss: 7.2760\n",
      "Model saved at epoch 77580 with loss: 7.2755\n",
      "Epoch [77580/100000], Loss: 7.2755\n",
      "Epoch [77590/100000], Loss: 7.2780\n",
      "Model saved at epoch 77599 with loss: 7.2739\n",
      "Model saved at epoch 77600 with loss: 7.2733\n",
      "Epoch [77600/100000], Loss: 7.2733\n",
      "Model saved at epoch 77608 with loss: 7.2700\n",
      "Epoch [77610/100000], Loss: 7.2731\n",
      "Epoch [77620/100000], Loss: 7.2718\n",
      "Epoch [77630/100000], Loss: 7.2748\n",
      "Epoch [77640/100000], Loss: 7.2737\n",
      "Epoch [77650/100000], Loss: 7.2756\n",
      "Epoch [77660/100000], Loss: 7.2765\n",
      "Epoch [77670/100000], Loss: 7.2713\n",
      "Model saved at epoch 77673 with loss: 7.2697\n",
      "Model saved at epoch 77677 with loss: 7.2685\n",
      "Epoch [77680/100000], Loss: 7.2716\n",
      "Epoch [77690/100000], Loss: 7.2693\n",
      "Epoch [77700/100000], Loss: 7.2756\n",
      "Epoch [77710/100000], Loss: 7.2711\n",
      "Model saved at epoch 77720 with loss: 7.2678\n",
      "Epoch [77720/100000], Loss: 7.2678\n",
      "Epoch [77730/100000], Loss: 7.2737\n",
      "Epoch [77740/100000], Loss: 7.2711\n",
      "Epoch [77750/100000], Loss: 7.2713\n",
      "Epoch [77760/100000], Loss: 7.2728\n",
      "Epoch [77770/100000], Loss: 7.2686\n",
      "Epoch [77780/100000], Loss: 7.2705\n",
      "Epoch [77790/100000], Loss: 7.2714\n",
      "Epoch [77800/100000], Loss: 7.2724\n",
      "Model saved at epoch 77808 with loss: 7.2675\n",
      "Model saved at epoch 77809 with loss: 7.2654\n",
      "Model saved at epoch 77810 with loss: 7.2650\n",
      "Epoch [77810/100000], Loss: 7.2650\n",
      "Model saved at epoch 77816 with loss: 7.2647\n",
      "Epoch [77820/100000], Loss: 7.2649\n",
      "Epoch [77830/100000], Loss: 7.2698\n",
      "Model saved at epoch 77837 with loss: 7.2642\n",
      "Model saved at epoch 77838 with loss: 7.2633\n",
      "Model saved at epoch 77839 with loss: 7.2613\n",
      "Model saved at epoch 77840 with loss: 7.2611\n",
      "Epoch [77840/100000], Loss: 7.2611\n",
      "Model saved at epoch 77841 with loss: 7.2603\n",
      "Model saved at epoch 77842 with loss: 7.2599\n",
      "Model saved at epoch 77843 with loss: 7.2592\n",
      "Epoch [77850/100000], Loss: 7.2669\n",
      "Epoch [77860/100000], Loss: 7.2610\n",
      "Model saved at epoch 77864 with loss: 7.2590\n",
      "Model saved at epoch 77865 with loss: 7.2586\n",
      "Epoch [77870/100000], Loss: 7.2623\n",
      "Epoch [77880/100000], Loss: 7.2677\n",
      "Epoch [77890/100000], Loss: 7.2630\n",
      "Model saved at epoch 77893 with loss: 7.2585\n",
      "Epoch [77900/100000], Loss: 1963.4457\n",
      "Epoch [77910/100000], Loss: 5447378944.0000\n",
      "Epoch [77920/100000], Loss: 2734704128.0000\n",
      "Epoch [77930/100000], Loss: 341558688.0000\n",
      "Epoch [77940/100000], Loss: 72960208.0000\n",
      "Epoch [77950/100000], Loss: 114127720.0000\n",
      "Epoch [77960/100000], Loss: 6220452.5000\n",
      "Epoch [77970/100000], Loss: 8711879.0000\n",
      "Epoch [77980/100000], Loss: 3808025.7500\n",
      "Epoch [77990/100000], Loss: 97651.3828\n",
      "Epoch [78000/100000], Loss: 465778.4375\n",
      "Epoch [78010/100000], Loss: 156184.7656\n",
      "Epoch [78020/100000], Loss: 10106.8711\n",
      "Epoch [78030/100000], Loss: 20119.4961\n",
      "Epoch [78040/100000], Loss: 6894.9336\n",
      "Epoch [78050/100000], Loss: 262.6365\n",
      "Epoch [78060/100000], Loss: 715.2026\n",
      "Epoch [78070/100000], Loss: 375.2823\n",
      "Epoch [78080/100000], Loss: 36.2362\n",
      "Epoch [78090/100000], Loss: 21.6828\n",
      "Epoch [78100/100000], Loss: 20.2055\n",
      "Epoch [78110/100000], Loss: 9.6427\n",
      "Epoch [78120/100000], Loss: 8.1461\n",
      "Epoch [78130/100000], Loss: 7.5177\n",
      "Epoch [78140/100000], Loss: 7.2952\n",
      "Model saved at epoch 78147 with loss: 7.2491\n",
      "Epoch [78150/100000], Loss: 7.2662\n",
      "Model saved at epoch 78151 with loss: 7.2322\n",
      "Model saved at epoch 78152 with loss: 7.2252\n",
      "Epoch [78160/100000], Loss: 7.2283\n",
      "Model saved at epoch 78161 with loss: 7.2224\n",
      "Epoch [78170/100000], Loss: 7.2248\n",
      "Model saved at epoch 78175 with loss: 7.2179\n",
      "Epoch [78180/100000], Loss: 7.2236\n",
      "Epoch [78190/100000], Loss: 7.2240\n",
      "Epoch [78200/100000], Loss: 7.2228\n",
      "Epoch [78210/100000], Loss: 7.2246\n",
      "Epoch [78220/100000], Loss: 7.2211\n",
      "Epoch [78230/100000], Loss: 7.2233\n",
      "Epoch [78240/100000], Loss: 7.2233\n",
      "Epoch [78250/100000], Loss: 7.2222\n",
      "Epoch [78260/100000], Loss: 7.2212\n",
      "Epoch [78270/100000], Loss: 7.2209\n",
      "Epoch [78280/100000], Loss: 7.2216\n",
      "Epoch [78290/100000], Loss: 7.2211\n",
      "Epoch [78300/100000], Loss: 7.2205\n",
      "Epoch [78310/100000], Loss: 7.2196\n",
      "Epoch [78320/100000], Loss: 7.2207\n",
      "Epoch [78330/100000], Loss: 7.2205\n",
      "Epoch [78340/100000], Loss: 7.2205\n",
      "Epoch [78350/100000], Loss: 7.2209\n",
      "Epoch [78360/100000], Loss: 7.2206\n",
      "Epoch [78370/100000], Loss: 7.2216\n",
      "Epoch [78380/100000], Loss: 7.2215\n",
      "Epoch [78390/100000], Loss: 7.2217\n",
      "Epoch [78400/100000], Loss: 7.2218\n",
      "Epoch [78410/100000], Loss: 7.2224\n",
      "Epoch [78420/100000], Loss: 7.2229\n",
      "Epoch [78430/100000], Loss: 7.2230\n",
      "Epoch [78440/100000], Loss: 7.2240\n",
      "Epoch [78450/100000], Loss: 7.2219\n",
      "Epoch [78460/100000], Loss: 7.2216\n",
      "Epoch [78470/100000], Loss: 7.2217\n",
      "Epoch [78480/100000], Loss: 7.2228\n",
      "Epoch [78490/100000], Loss: 7.2229\n",
      "Epoch [78500/100000], Loss: 7.2233\n",
      "Epoch [78510/100000], Loss: 7.2222\n",
      "Epoch [78520/100000], Loss: 7.2236\n",
      "Epoch [78530/100000], Loss: 7.2232\n",
      "Epoch [78540/100000], Loss: 7.2238\n",
      "Epoch [78550/100000], Loss: 7.2236\n",
      "Epoch [78560/100000], Loss: 7.2237\n",
      "Epoch [78570/100000], Loss: 7.2238\n",
      "Epoch [78580/100000], Loss: 7.2234\n",
      "Epoch [78590/100000], Loss: 7.2234\n",
      "Epoch [78600/100000], Loss: 7.2233\n",
      "Epoch [78610/100000], Loss: 7.2239\n",
      "Epoch [78620/100000], Loss: 7.2234\n",
      "Epoch [78630/100000], Loss: 7.2241\n",
      "Epoch [78640/100000], Loss: 7.2247\n",
      "Epoch [78650/100000], Loss: 7.2249\n",
      "Epoch [78660/100000], Loss: 7.2249\n",
      "Epoch [78670/100000], Loss: 7.2248\n",
      "Epoch [78680/100000], Loss: 7.2244\n",
      "Epoch [78690/100000], Loss: 7.2240\n",
      "Epoch [78700/100000], Loss: 7.2240\n",
      "Epoch [78710/100000], Loss: 7.2247\n",
      "Epoch [78720/100000], Loss: 7.2271\n",
      "Epoch [78730/100000], Loss: 7.2276\n",
      "Epoch [78740/100000], Loss: 7.2279\n",
      "Epoch [78750/100000], Loss: 7.2274\n",
      "Epoch [78760/100000], Loss: 7.2277\n",
      "Epoch [78770/100000], Loss: 7.2280\n",
      "Epoch [78780/100000], Loss: 7.2279\n",
      "Epoch [78790/100000], Loss: 7.2284\n",
      "Epoch [78800/100000], Loss: 7.2268\n",
      "Epoch [78810/100000], Loss: 7.2272\n",
      "Epoch [78820/100000], Loss: 7.2275\n",
      "Epoch [78830/100000], Loss: 7.2270\n",
      "Epoch [78840/100000], Loss: 7.2267\n",
      "Epoch [78850/100000], Loss: 7.2255\n",
      "Epoch [78860/100000], Loss: 7.2249\n",
      "Epoch [78870/100000], Loss: 7.2268\n",
      "Epoch [78880/100000], Loss: 7.2270\n",
      "Epoch [78890/100000], Loss: 7.2274\n",
      "Epoch [78900/100000], Loss: 7.2261\n",
      "Epoch [78910/100000], Loss: 7.2272\n",
      "Epoch [78920/100000], Loss: 7.2264\n",
      "Epoch [78930/100000], Loss: 7.2281\n",
      "Epoch [78940/100000], Loss: 7.2280\n",
      "Epoch [78950/100000], Loss: 7.2274\n",
      "Epoch [78960/100000], Loss: 7.2280\n",
      "Epoch [78970/100000], Loss: 7.2279\n",
      "Epoch [78980/100000], Loss: 7.2279\n",
      "Epoch [78990/100000], Loss: 7.2289\n",
      "Epoch [79000/100000], Loss: 7.2300\n",
      "Epoch [79010/100000], Loss: 7.2306\n",
      "Epoch [79020/100000], Loss: 7.2299\n",
      "Epoch [79030/100000], Loss: 7.2273\n",
      "Epoch [79040/100000], Loss: 7.2263\n",
      "Epoch [79050/100000], Loss: 7.2264\n",
      "Epoch [79060/100000], Loss: 7.2257\n",
      "Epoch [79070/100000], Loss: 7.2263\n",
      "Epoch [79080/100000], Loss: 7.2267\n",
      "Epoch [79090/100000], Loss: 7.2279\n",
      "Epoch [79100/100000], Loss: 7.2267\n",
      "Epoch [79110/100000], Loss: 7.2259\n",
      "Epoch [79120/100000], Loss: 7.2254\n",
      "Epoch [79130/100000], Loss: 7.2246\n",
      "Epoch [79140/100000], Loss: 7.2255\n",
      "Epoch [79150/100000], Loss: 7.2256\n",
      "Epoch [79160/100000], Loss: 7.2250\n",
      "Epoch [79170/100000], Loss: 7.2251\n",
      "Epoch [79180/100000], Loss: 7.2241\n",
      "Epoch [79190/100000], Loss: 7.2231\n",
      "Epoch [79200/100000], Loss: 7.2239\n",
      "Epoch [79210/100000], Loss: 7.2232\n",
      "Epoch [79220/100000], Loss: 7.2238\n",
      "Epoch [79230/100000], Loss: 7.2245\n",
      "Epoch [79240/100000], Loss: 7.2237\n",
      "Epoch [79250/100000], Loss: 7.2226\n",
      "Epoch [79260/100000], Loss: 7.2238\n",
      "Epoch [79270/100000], Loss: 7.2242\n",
      "Epoch [79280/100000], Loss: 7.2232\n",
      "Epoch [79290/100000], Loss: 7.2221\n",
      "Epoch [79300/100000], Loss: 7.2229\n",
      "Epoch [79310/100000], Loss: 7.2244\n",
      "Epoch [79320/100000], Loss: 7.2226\n",
      "Epoch [79330/100000], Loss: 7.2217\n",
      "Epoch [79340/100000], Loss: 7.2229\n",
      "Epoch [79350/100000], Loss: 7.2209\n",
      "Epoch [79360/100000], Loss: 7.2200\n",
      "Epoch [79370/100000], Loss: 7.2198\n",
      "Epoch [79380/100000], Loss: 7.2192\n",
      "Epoch [79390/100000], Loss: 7.2201\n",
      "Epoch [79400/100000], Loss: 7.2207\n",
      "Epoch [79410/100000], Loss: 7.2217\n",
      "Epoch [79420/100000], Loss: 7.2228\n",
      "Epoch [79430/100000], Loss: 7.2216\n",
      "Epoch [79440/100000], Loss: 7.2223\n",
      "Epoch [79450/100000], Loss: 7.2216\n",
      "Epoch [79460/100000], Loss: 7.2208\n",
      "Epoch [79470/100000], Loss: 7.2196\n",
      "Epoch [79480/100000], Loss: 7.2194\n",
      "Epoch [79490/100000], Loss: 7.2216\n",
      "Epoch [79500/100000], Loss: 7.2218\n",
      "Epoch [79510/100000], Loss: 7.2209\n",
      "Epoch [79520/100000], Loss: 7.2199\n",
      "Epoch [79530/100000], Loss: 7.2197\n",
      "Epoch [79540/100000], Loss: 7.2182\n",
      "Model saved at epoch 79542 with loss: 7.2175\n",
      "Model saved at epoch 79544 with loss: 7.2172\n",
      "Model saved at epoch 79549 with loss: 7.2171\n",
      "Epoch [79550/100000], Loss: 7.2178\n",
      "Model saved at epoch 79555 with loss: 7.2168\n",
      "Model saved at epoch 79556 with loss: 7.2162\n",
      "Model saved at epoch 79557 with loss: 7.2160\n",
      "Model saved at epoch 79558 with loss: 7.2160\n",
      "Epoch [79560/100000], Loss: 7.2163\n",
      "Epoch [79570/100000], Loss: 7.2198\n",
      "Epoch [79580/100000], Loss: 7.2184\n",
      "Epoch [79590/100000], Loss: 7.2183\n",
      "Epoch [79600/100000], Loss: 7.2190\n",
      "Epoch [79610/100000], Loss: 7.2206\n",
      "Epoch [79620/100000], Loss: 7.2223\n",
      "Epoch [79630/100000], Loss: 7.2225\n",
      "Epoch [79640/100000], Loss: 7.2230\n",
      "Epoch [79650/100000], Loss: 7.2230\n",
      "Epoch [79660/100000], Loss: 7.2241\n",
      "Epoch [79670/100000], Loss: 7.2242\n",
      "Epoch [79680/100000], Loss: 7.2226\n",
      "Epoch [79690/100000], Loss: 7.2222\n",
      "Epoch [79700/100000], Loss: 7.2209\n",
      "Epoch [79710/100000], Loss: 7.2213\n",
      "Epoch [79720/100000], Loss: 7.2225\n",
      "Epoch [79730/100000], Loss: 7.2208\n",
      "Epoch [79740/100000], Loss: 7.2199\n",
      "Epoch [79750/100000], Loss: 7.2207\n",
      "Epoch [79760/100000], Loss: 7.2210\n",
      "Epoch [79770/100000], Loss: 7.2216\n",
      "Epoch [79780/100000], Loss: 7.2203\n",
      "Epoch [79790/100000], Loss: 7.2202\n",
      "Epoch [79800/100000], Loss: 7.2190\n",
      "Epoch [79810/100000], Loss: 7.2202\n",
      "Epoch [79820/100000], Loss: 7.2204\n",
      "Epoch [79830/100000], Loss: 7.2202\n",
      "Epoch [79840/100000], Loss: 7.2208\n",
      "Epoch [79850/100000], Loss: 7.2190\n",
      "Epoch [79860/100000], Loss: 7.2184\n",
      "Epoch [79870/100000], Loss: 7.2183\n",
      "Epoch [79880/100000], Loss: 7.2204\n",
      "Epoch [79890/100000], Loss: 7.2200\n",
      "Epoch [79900/100000], Loss: 7.2211\n",
      "Epoch [79910/100000], Loss: 7.2226\n",
      "Epoch [79920/100000], Loss: 7.2201\n",
      "Epoch [79930/100000], Loss: 7.2207\n",
      "Epoch [79940/100000], Loss: 7.2213\n",
      "Epoch [79950/100000], Loss: 7.2224\n",
      "Epoch [79960/100000], Loss: 7.2225\n",
      "Epoch [79970/100000], Loss: 7.2221\n",
      "Epoch [79980/100000], Loss: 7.2207\n",
      "Epoch [79990/100000], Loss: 7.2223\n",
      "Epoch [80000/100000], Loss: 7.2209\n",
      "Epoch [80010/100000], Loss: 7.2227\n",
      "Epoch [80020/100000], Loss: 7.2219\n",
      "Epoch [80030/100000], Loss: 7.2234\n",
      "Epoch [80040/100000], Loss: 7.2237\n",
      "Epoch [80050/100000], Loss: 7.2231\n",
      "Epoch [80060/100000], Loss: 7.2242\n",
      "Epoch [80070/100000], Loss: 7.2259\n",
      "Epoch [80080/100000], Loss: 7.2250\n",
      "Epoch [80090/100000], Loss: 7.2252\n",
      "Epoch [80100/100000], Loss: 7.2247\n",
      "Epoch [80110/100000], Loss: 7.2232\n",
      "Epoch [80120/100000], Loss: 7.2232\n",
      "Epoch [80130/100000], Loss: 7.2229\n",
      "Epoch [80140/100000], Loss: 7.2219\n",
      "Epoch [80150/100000], Loss: 7.2206\n",
      "Epoch [80160/100000], Loss: 7.2228\n",
      "Epoch [80170/100000], Loss: 7.2212\n",
      "Epoch [80180/100000], Loss: 7.2212\n",
      "Epoch [80190/100000], Loss: 7.2227\n",
      "Epoch [80200/100000], Loss: 7.2216\n",
      "Epoch [80210/100000], Loss: 7.2214\n",
      "Epoch [80220/100000], Loss: 7.2212\n",
      "Epoch [80230/100000], Loss: 7.2203\n",
      "Epoch [80240/100000], Loss: 7.2206\n",
      "Epoch [80250/100000], Loss: 7.2221\n",
      "Epoch [80260/100000], Loss: 7.2238\n",
      "Epoch [80270/100000], Loss: 7.2233\n",
      "Epoch [80280/100000], Loss: 7.2226\n",
      "Epoch [80290/100000], Loss: 7.2229\n",
      "Epoch [80300/100000], Loss: 7.2224\n",
      "Epoch [80310/100000], Loss: 7.2227\n",
      "Epoch [80320/100000], Loss: 7.2236\n",
      "Epoch [80330/100000], Loss: 7.2235\n",
      "Epoch [80340/100000], Loss: 7.2240\n",
      "Epoch [80350/100000], Loss: 7.2237\n",
      "Epoch [80360/100000], Loss: 7.2228\n",
      "Epoch [80370/100000], Loss: 7.2211\n",
      "Epoch [80380/100000], Loss: 7.2235\n",
      "Epoch [80390/100000], Loss: 7.2230\n",
      "Epoch [80400/100000], Loss: 7.2218\n",
      "Epoch [80410/100000], Loss: 7.2240\n",
      "Epoch [80420/100000], Loss: 7.2239\n",
      "Epoch [80430/100000], Loss: 7.2231\n",
      "Epoch [80440/100000], Loss: 7.2231\n",
      "Epoch [80450/100000], Loss: 7.2217\n",
      "Epoch [80460/100000], Loss: 7.2207\n",
      "Epoch [80470/100000], Loss: 7.2215\n",
      "Epoch [80480/100000], Loss: 7.2201\n",
      "Epoch [80490/100000], Loss: 7.2191\n",
      "Epoch [80500/100000], Loss: 7.2208\n",
      "Epoch [80510/100000], Loss: 7.2209\n",
      "Epoch [80520/100000], Loss: 7.2222\n",
      "Epoch [80530/100000], Loss: 7.2218\n",
      "Epoch [80540/100000], Loss: 7.2225\n",
      "Epoch [80550/100000], Loss: 7.2201\n",
      "Epoch [80560/100000], Loss: 7.2205\n",
      "Epoch [80570/100000], Loss: 7.2208\n",
      "Epoch [80580/100000], Loss: 7.2207\n",
      "Epoch [80590/100000], Loss: 7.2220\n",
      "Epoch [80600/100000], Loss: 7.2241\n",
      "Epoch [80610/100000], Loss: 7.2248\n",
      "Epoch [80620/100000], Loss: 7.2254\n",
      "Epoch [80630/100000], Loss: 7.2226\n",
      "Epoch [80640/100000], Loss: 7.2199\n",
      "Epoch [80650/100000], Loss: 7.2192\n",
      "Epoch [80660/100000], Loss: 7.2168\n",
      "Model saved at epoch 80668 with loss: 7.2153\n",
      "Epoch [80670/100000], Loss: 7.2161\n",
      "Model saved at epoch 80677 with loss: 7.2153\n",
      "Epoch [80680/100000], Loss: 7.2167\n",
      "Epoch [80690/100000], Loss: 7.2176\n",
      "Epoch [80700/100000], Loss: 7.2177\n",
      "Epoch [80710/100000], Loss: 7.2178\n",
      "Epoch [80720/100000], Loss: 7.2191\n",
      "Epoch [80730/100000], Loss: 7.2208\n",
      "Epoch [80740/100000], Loss: 7.2196\n",
      "Epoch [80750/100000], Loss: 7.2197\n",
      "Epoch [80760/100000], Loss: 7.2198\n",
      "Epoch [80770/100000], Loss: 7.2187\n",
      "Epoch [80780/100000], Loss: 7.2180\n",
      "Epoch [80790/100000], Loss: 7.2156\n",
      "Model saved at epoch 80800 with loss: 7.2152\n",
      "Epoch [80800/100000], Loss: 7.2152\n",
      "Epoch [80810/100000], Loss: 7.2156\n",
      "Epoch [80820/100000], Loss: 7.2154\n",
      "Model saved at epoch 80821 with loss: 7.2151\n",
      "Model saved at epoch 80822 with loss: 7.2147\n",
      "Model saved at epoch 80823 with loss: 7.2147\n",
      "Model saved at epoch 80824 with loss: 7.2143\n",
      "Epoch [80830/100000], Loss: 7.2157\n",
      "Epoch [80840/100000], Loss: 7.2147\n",
      "Epoch [80850/100000], Loss: 7.2148\n",
      "Epoch [80860/100000], Loss: 7.2168\n",
      "Epoch [80870/100000], Loss: 7.2175\n",
      "Epoch [80880/100000], Loss: 7.2182\n",
      "Epoch [80890/100000], Loss: 7.2185\n",
      "Epoch [80900/100000], Loss: 7.2181\n",
      "Epoch [80910/100000], Loss: 7.2170\n",
      "Epoch [80920/100000], Loss: 7.2187\n",
      "Epoch [80930/100000], Loss: 7.2180\n",
      "Epoch [80940/100000], Loss: 7.2185\n",
      "Epoch [80950/100000], Loss: 7.2190\n",
      "Epoch [80960/100000], Loss: 7.2199\n",
      "Epoch [80970/100000], Loss: 7.2194\n",
      "Epoch [80980/100000], Loss: 7.2186\n",
      "Epoch [80990/100000], Loss: 7.2191\n",
      "Epoch [81000/100000], Loss: 7.2200\n",
      "Epoch [81010/100000], Loss: 7.2194\n",
      "Epoch [81020/100000], Loss: 7.2183\n",
      "Epoch [81030/100000], Loss: 7.2174\n",
      "Epoch [81040/100000], Loss: 7.2169\n",
      "Epoch [81050/100000], Loss: 7.2186\n",
      "Epoch [81060/100000], Loss: 7.2169\n",
      "Model saved at epoch 81068 with loss: 7.2140\n",
      "Model saved at epoch 81069 with loss: 7.2132\n",
      "Epoch [81070/100000], Loss: 7.2133\n",
      "Model saved at epoch 81071 with loss: 7.2128\n",
      "Epoch [81080/100000], Loss: 7.2155\n",
      "Epoch [81090/100000], Loss: 7.2143\n",
      "Model saved at epoch 81100 with loss: 7.2124\n",
      "Epoch [81100/100000], Loss: 7.2124\n",
      "Model saved at epoch 81104 with loss: 7.2120\n",
      "Epoch [81110/100000], Loss: 7.2127\n",
      "Epoch [81120/100000], Loss: 7.2133\n",
      "Epoch [81130/100000], Loss: 7.2134\n",
      "Epoch [81140/100000], Loss: 7.2133\n",
      "Epoch [81150/100000], Loss: 7.2132\n",
      "Epoch [81160/100000], Loss: 7.2123\n",
      "Epoch [81170/100000], Loss: 7.2134\n",
      "Epoch [81180/100000], Loss: 7.2132\n",
      "Model saved at epoch 81186 with loss: 7.2119\n",
      "Epoch [81190/100000], Loss: 7.2130\n",
      "Epoch [81200/100000], Loss: 7.2126\n",
      "Model saved at epoch 81203 with loss: 7.2117\n",
      "Model saved at epoch 81207 with loss: 7.2115\n",
      "Model saved at epoch 81208 with loss: 7.2111\n",
      "Epoch [81210/100000], Loss: 7.2117\n",
      "Model saved at epoch 81218 with loss: 7.2111\n",
      "Model saved at epoch 81219 with loss: 7.2107\n",
      "Model saved at epoch 81220 with loss: 7.2106\n",
      "Epoch [81220/100000], Loss: 7.2106\n",
      "Epoch [81230/100000], Loss: 7.2121\n",
      "Epoch [81240/100000], Loss: 7.2131\n",
      "Epoch [81250/100000], Loss: 7.2134\n",
      "Epoch [81260/100000], Loss: 7.2122\n",
      "Epoch [81270/100000], Loss: 7.2125\n",
      "Epoch [81280/100000], Loss: 7.2138\n",
      "Epoch [81290/100000], Loss: 7.2132\n",
      "Epoch [81300/100000], Loss: 7.2118\n",
      "Epoch [81310/100000], Loss: 7.2138\n",
      "Epoch [81320/100000], Loss: 7.2146\n",
      "Epoch [81330/100000], Loss: 7.2119\n",
      "Epoch [81340/100000], Loss: 7.2124\n",
      "Epoch [81350/100000], Loss: 7.2137\n",
      "Epoch [81360/100000], Loss: 7.2130\n",
      "Epoch [81370/100000], Loss: 7.2128\n",
      "Epoch [81380/100000], Loss: 7.2128\n",
      "Epoch [81390/100000], Loss: 7.2121\n",
      "Epoch [81400/100000], Loss: 7.2111\n",
      "Epoch [81410/100000], Loss: 7.2127\n",
      "Epoch [81420/100000], Loss: 7.2152\n",
      "Epoch [81430/100000], Loss: 7.2121\n",
      "Epoch [81440/100000], Loss: 7.2111\n",
      "Model saved at epoch 81444 with loss: 7.2101\n",
      "Model saved at epoch 81445 with loss: 7.2099\n",
      "Model saved at epoch 81447 with loss: 7.2098\n",
      "Model saved at epoch 81450 with loss: 7.2094\n",
      "Epoch [81450/100000], Loss: 7.2094\n",
      "Model saved at epoch 81451 with loss: 7.2090\n",
      "Model saved at epoch 81452 with loss: 7.2087\n",
      "Model saved at epoch 81454 with loss: 7.2083\n",
      "Model saved at epoch 81456 with loss: 7.2082\n",
      "Model saved at epoch 81457 with loss: 7.2079\n",
      "Model saved at epoch 81458 with loss: 7.2077\n",
      "Epoch [81460/100000], Loss: 7.2090\n",
      "Epoch [81470/100000], Loss: 7.2100\n",
      "Model saved at epoch 81477 with loss: 7.2073\n",
      "Model saved at epoch 81478 with loss: 7.2064\n",
      "Epoch [81480/100000], Loss: 7.2076\n",
      "Epoch [81490/100000], Loss: 7.2122\n",
      "Epoch [81500/100000], Loss: 7.2132\n",
      "Epoch [81510/100000], Loss: 7.2095\n",
      "Epoch [81520/100000], Loss: 7.2087\n",
      "Epoch [81530/100000], Loss: 7.2102\n",
      "Epoch [81540/100000], Loss: 7.2111\n",
      "Epoch [81550/100000], Loss: 7.2090\n",
      "Epoch [81560/100000], Loss: 7.2106\n",
      "Epoch [81570/100000], Loss: 7.2090\n",
      "Epoch [81580/100000], Loss: 7.2098\n",
      "Epoch [81590/100000], Loss: 7.2113\n",
      "Epoch [81600/100000], Loss: 7.2129\n",
      "Epoch [81610/100000], Loss: 7.2098\n",
      "Epoch [81620/100000], Loss: 7.2121\n",
      "Epoch [81630/100000], Loss: 7.2139\n",
      "Epoch [81640/100000], Loss: 7.2121\n",
      "Epoch [81650/100000], Loss: 7.2144\n",
      "Epoch [81660/100000], Loss: 7.2132\n",
      "Epoch [81670/100000], Loss: 7.2107\n",
      "Epoch [81680/100000], Loss: 7.2097\n",
      "Epoch [81690/100000], Loss: 7.2117\n",
      "Epoch [81700/100000], Loss: 7.2107\n",
      "Epoch [81710/100000], Loss: 7.2103\n",
      "Epoch [81720/100000], Loss: 7.2134\n",
      "Epoch [81730/100000], Loss: 7.2118\n",
      "Epoch [81740/100000], Loss: 7.2083\n",
      "Epoch [81750/100000], Loss: 7.2110\n",
      "Epoch [81760/100000], Loss: 7.2122\n",
      "Epoch [81770/100000], Loss: 7.2128\n",
      "Epoch [81780/100000], Loss: 7.2138\n",
      "Epoch [81790/100000], Loss: 7.2134\n",
      "Epoch [81800/100000], Loss: 7.2148\n",
      "Epoch [81810/100000], Loss: 7.2103\n",
      "Epoch [81820/100000], Loss: 7.2106\n",
      "Epoch [81830/100000], Loss: 7.2098\n",
      "Epoch [81840/100000], Loss: 7.2126\n",
      "Epoch [81850/100000], Loss: 7.2121\n",
      "Epoch [81860/100000], Loss: 7.2127\n",
      "Epoch [81870/100000], Loss: 7.2115\n",
      "Epoch [81880/100000], Loss: 7.2120\n",
      "Epoch [81890/100000], Loss: 7.2105\n",
      "Epoch [81900/100000], Loss: 7.2099\n",
      "Epoch [81910/100000], Loss: 7.2096\n",
      "Epoch [81920/100000], Loss: 7.2107\n",
      "Epoch [81930/100000], Loss: 7.2078\n",
      "Epoch [81940/100000], Loss: 7.2113\n",
      "Epoch [81950/100000], Loss: 7.2123\n",
      "Epoch [81960/100000], Loss: 7.2126\n",
      "Epoch [81970/100000], Loss: 7.2103\n",
      "Epoch [81980/100000], Loss: 7.2109\n",
      "Epoch [81990/100000], Loss: 7.2126\n",
      "Epoch [82000/100000], Loss: 7.2114\n",
      "Epoch [82010/100000], Loss: 7.2109\n",
      "Epoch [82020/100000], Loss: 7.2100\n",
      "Epoch [82030/100000], Loss: 7.2071\n",
      "Epoch [82040/100000], Loss: 7.2076\n",
      "Epoch [82050/100000], Loss: 7.2089\n",
      "Epoch [82060/100000], Loss: 7.2080\n",
      "Epoch [82070/100000], Loss: 7.2109\n",
      "Epoch [82080/100000], Loss: 7.2108\n",
      "Epoch [82090/100000], Loss: 7.2102\n",
      "Epoch [82100/100000], Loss: 7.2094\n",
      "Epoch [82110/100000], Loss: 7.2121\n",
      "Epoch [82120/100000], Loss: 7.2117\n",
      "Epoch [82130/100000], Loss: 7.2108\n",
      "Epoch [82140/100000], Loss: 7.2069\n",
      "Model saved at epoch 82142 with loss: 7.2063\n",
      "Model saved at epoch 82149 with loss: 7.2057\n",
      "Epoch [82150/100000], Loss: 7.2073\n",
      "Epoch [82160/100000], Loss: 7.2074\n",
      "Epoch [82170/100000], Loss: 7.2073\n",
      "Epoch [82180/100000], Loss: 7.2065\n",
      "Model saved at epoch 82186 with loss: 7.2055\n",
      "Model saved at epoch 82187 with loss: 7.2046\n",
      "Model saved at epoch 82188 with loss: 7.2040\n",
      "Epoch [82190/100000], Loss: 7.2046\n",
      "Model saved at epoch 82197 with loss: 7.2039\n",
      "Model saved at epoch 82198 with loss: 7.2033\n",
      "Model saved at epoch 82199 with loss: 7.2029\n",
      "Epoch [82200/100000], Loss: 7.2035\n",
      "Model saved at epoch 82202 with loss: 7.2023\n",
      "Model saved at epoch 82204 with loss: 7.2023\n",
      "Epoch [82210/100000], Loss: 7.2026\n",
      "Model saved at epoch 82212 with loss: 7.2006\n",
      "Epoch [82220/100000], Loss: 7.2035\n",
      "Epoch [82230/100000], Loss: 7.2033\n",
      "Epoch [82240/100000], Loss: 7.2031\n",
      "Epoch [82250/100000], Loss: 7.2060\n",
      "Epoch [82260/100000], Loss: 7.2026\n",
      "Epoch [82270/100000], Loss: 7.2033\n",
      "Epoch [82280/100000], Loss: 7.2040\n",
      "Epoch [82290/100000], Loss: 7.2042\n",
      "Epoch [82300/100000], Loss: 7.2034\n",
      "Epoch [82310/100000], Loss: 7.2041\n",
      "Epoch [82320/100000], Loss: 7.2019\n",
      "Model saved at epoch 82324 with loss: 7.2004\n",
      "Model saved at epoch 82325 with loss: 7.1999\n",
      "Model saved at epoch 82326 with loss: 7.1999\n",
      "Model saved at epoch 82327 with loss: 7.1994\n",
      "Model saved at epoch 82328 with loss: 7.1992\n",
      "Model saved at epoch 82329 with loss: 7.1991\n",
      "Epoch [82330/100000], Loss: 7.1996\n",
      "Model saved at epoch 82331 with loss: 7.1986\n",
      "Epoch [82340/100000], Loss: 7.2021\n",
      "Epoch [82350/100000], Loss: 7.2047\n",
      "Epoch [82360/100000], Loss: 7.2049\n",
      "Epoch [82370/100000], Loss: 7.2065\n",
      "Epoch [82380/100000], Loss: 7.2048\n",
      "Epoch [82390/100000], Loss: 7.2028\n",
      "Epoch [82400/100000], Loss: 7.2009\n",
      "Epoch [82410/100000], Loss: 7.2030\n",
      "Epoch [82420/100000], Loss: 7.2016\n",
      "Epoch [82430/100000], Loss: 7.2032\n",
      "Epoch [82440/100000], Loss: 7.2012\n",
      "Epoch [82450/100000], Loss: 7.1997\n",
      "Model saved at epoch 82458 with loss: 7.1986\n",
      "Model saved at epoch 82460 with loss: 7.1979\n",
      "Epoch [82460/100000], Loss: 7.1979\n",
      "Model saved at epoch 82461 with loss: 7.1965\n",
      "Model saved at epoch 82467 with loss: 7.1964\n",
      "Model saved at epoch 82468 with loss: 7.1955\n",
      "Epoch [82470/100000], Loss: 7.1963\n",
      "Epoch [82480/100000], Loss: 7.1976\n",
      "Model saved at epoch 82485 with loss: 7.1949\n",
      "Epoch [82490/100000], Loss: 7.1979\n",
      "Epoch [82500/100000], Loss: 7.1987\n",
      "Epoch [82510/100000], Loss: 7.1990\n",
      "Epoch [82520/100000], Loss: 7.1986\n",
      "Epoch [82530/100000], Loss: 7.1973\n",
      "Epoch [82540/100000], Loss: 7.1976\n",
      "Epoch [82550/100000], Loss: 7.2004\n",
      "Epoch [82560/100000], Loss: 7.1967\n",
      "Epoch [82570/100000], Loss: 7.1970\n",
      "Epoch [82580/100000], Loss: 7.1969\n",
      "Epoch [82590/100000], Loss: 7.2002\n",
      "Epoch [82600/100000], Loss: 7.1965\n",
      "Epoch [82610/100000], Loss: 7.1979\n",
      "Epoch [82620/100000], Loss: 7.1992\n",
      "Epoch [82630/100000], Loss: 7.1982\n",
      "Epoch [82640/100000], Loss: 7.1968\n",
      "Epoch [82650/100000], Loss: 7.1964\n",
      "Model saved at epoch 82652 with loss: 7.1947\n",
      "Model saved at epoch 82656 with loss: 7.1942\n",
      "Model saved at epoch 82657 with loss: 7.1940\n",
      "Epoch [82660/100000], Loss: 7.1942\n",
      "Epoch [82670/100000], Loss: 7.1979\n",
      "Epoch [82680/100000], Loss: 7.1979\n",
      "Epoch [82690/100000], Loss: 7.1988\n",
      "Epoch [82700/100000], Loss: 7.1982\n",
      "Epoch [82710/100000], Loss: 7.1963\n",
      "Model saved at epoch 82718 with loss: 7.1939\n",
      "Model saved at epoch 82719 with loss: 7.1929\n",
      "Model saved at epoch 82720 with loss: 7.1913\n",
      "Epoch [82720/100000], Loss: 7.1913\n",
      "Epoch [82730/100000], Loss: 7.1921\n",
      "Model saved at epoch 82732 with loss: 7.1911\n",
      "Model saved at epoch 82733 with loss: 7.1899\n",
      "Model saved at epoch 82734 with loss: 7.1895\n",
      "Model saved at epoch 82738 with loss: 7.1893\n",
      "Epoch [82740/100000], Loss: 7.1899\n",
      "Epoch [82750/100000], Loss: 7.1918\n",
      "Epoch [82760/100000], Loss: 7.1922\n",
      "Epoch [82770/100000], Loss: 7.1927\n",
      "Epoch [82780/100000], Loss: 7.1942\n",
      "Epoch [82790/100000], Loss: 7.1944\n",
      "Epoch [82800/100000], Loss: 7.1956\n",
      "Epoch [82810/100000], Loss: 7.1929\n",
      "Epoch [82820/100000], Loss: 7.1937\n",
      "Epoch [82830/100000], Loss: 7.1941\n",
      "Epoch [82840/100000], Loss: 7.1927\n",
      "Model saved at epoch 82848 with loss: 7.1887\n",
      "Model saved at epoch 82849 with loss: 7.1886\n",
      "Model saved at epoch 82850 with loss: 7.1871\n",
      "Epoch [82850/100000], Loss: 7.1871\n",
      "Epoch [82860/100000], Loss: 7.1900\n",
      "Epoch [82870/100000], Loss: 7.1903\n",
      "Epoch [82880/100000], Loss: 7.1887\n",
      "Epoch [82890/100000], Loss: 7.1913\n",
      "Epoch [82900/100000], Loss: 7.1904\n",
      "Epoch [82910/100000], Loss: 7.1917\n",
      "Epoch [82920/100000], Loss: 7.1880\n",
      "Model saved at epoch 82921 with loss: 7.1869\n",
      "Model saved at epoch 82922 with loss: 7.1865\n",
      "Epoch [82930/100000], Loss: 7.1891\n",
      "Epoch [82940/100000], Loss: 7.1887\n",
      "Model saved at epoch 82950 with loss: 7.1863\n",
      "Epoch [82950/100000], Loss: 7.1863\n",
      "Model saved at epoch 82951 with loss: 7.1860\n",
      "Model saved at epoch 82953 with loss: 7.1854\n",
      "Model saved at epoch 82954 with loss: 7.1851\n",
      "Model saved at epoch 82955 with loss: 7.1844\n",
      "Epoch [82960/100000], Loss: 7.1852\n",
      "Epoch [82970/100000], Loss: 7.1861\n",
      "Epoch [82980/100000], Loss: 7.1880\n",
      "Epoch [82990/100000], Loss: 7.1859\n",
      "Epoch [83000/100000], Loss: 7.1880\n",
      "Epoch [83010/100000], Loss: 7.1868\n",
      "Epoch [83020/100000], Loss: 7.1863\n",
      "Epoch [83030/100000], Loss: 7.1875\n",
      "Epoch [83040/100000], Loss: 7.1864\n",
      "Model saved at epoch 83044 with loss: 7.1835\n",
      "Model saved at epoch 83045 with loss: 7.1832\n",
      "Model saved at epoch 83049 with loss: 7.1828\n",
      "Model saved at epoch 83050 with loss: 7.1825\n",
      "Epoch [83050/100000], Loss: 7.1825\n",
      "Model saved at epoch 83053 with loss: 7.1819\n",
      "Model saved at epoch 83054 with loss: 7.1789\n",
      "Model saved at epoch 83060 with loss: 7.1788\n",
      "Epoch [83060/100000], Loss: 7.1788\n",
      "Epoch [83070/100000], Loss: 7.1843\n",
      "Epoch [83080/100000], Loss: 7.1844\n",
      "Epoch [83090/100000], Loss: 7.1869\n",
      "Epoch [83100/100000], Loss: 7.1873\n",
      "Epoch [83110/100000], Loss: 7.1866\n",
      "Epoch [83120/100000], Loss: 7.1878\n",
      "Epoch [83130/100000], Loss: 7.1867\n",
      "Epoch [83140/100000], Loss: 7.1877\n",
      "Epoch [83150/100000], Loss: 7.1857\n",
      "Epoch [83160/100000], Loss: 7.1870\n",
      "Epoch [83170/100000], Loss: 7.1863\n",
      "Epoch [83180/100000], Loss: 7.1856\n",
      "Epoch [83190/100000], Loss: 7.1850\n",
      "Epoch [83200/100000], Loss: 7.1865\n",
      "Epoch [83210/100000], Loss: 7.1858\n",
      "Epoch [83220/100000], Loss: 7.1847\n",
      "Epoch [83230/100000], Loss: 7.1820\n",
      "Epoch [83240/100000], Loss: 7.1837\n",
      "Epoch [83250/100000], Loss: 7.1820\n",
      "Epoch [83260/100000], Loss: 7.1796\n",
      "Epoch [83270/100000], Loss: 7.1836\n",
      "Epoch [83280/100000], Loss: 7.1806\n",
      "Epoch [83290/100000], Loss: 7.1831\n",
      "Epoch [83300/100000], Loss: 7.1806\n",
      "Epoch [83310/100000], Loss: 7.1820\n",
      "Epoch [83320/100000], Loss: 7.1825\n",
      "Model saved at epoch 83329 with loss: 7.1787\n",
      "Model saved at epoch 83330 with loss: 7.1784\n",
      "Epoch [83330/100000], Loss: 7.1784\n",
      "Model saved at epoch 83332 with loss: 7.1773\n",
      "Model saved at epoch 83335 with loss: 7.1769\n",
      "Epoch [83340/100000], Loss: 7.1794\n",
      "Model saved at epoch 83345 with loss: 7.1759\n",
      "Model saved at epoch 83346 with loss: 7.1747\n",
      "Model saved at epoch 83347 with loss: 7.1741\n",
      "Model saved at epoch 83349 with loss: 7.1729\n",
      "Model saved at epoch 83350 with loss: 7.1719\n",
      "Epoch [83350/100000], Loss: 7.1719\n",
      "Epoch [83360/100000], Loss: 7.1756\n",
      "Model saved at epoch 83365 with loss: 7.1711\n",
      "Model saved at epoch 83367 with loss: 7.1710\n",
      "Model saved at epoch 83368 with loss: 7.1708\n",
      "Epoch [83370/100000], Loss: 7.1717\n",
      "Model saved at epoch 83374 with loss: 7.1699\n",
      "Epoch [83380/100000], Loss: 7.1724\n",
      "Epoch [83390/100000], Loss: 7.1713\n",
      "Epoch [83400/100000], Loss: 7.1730\n",
      "Epoch [83410/100000], Loss: 7.1737\n",
      "Epoch [83420/100000], Loss: 7.1733\n",
      "Epoch [83430/100000], Loss: 7.1727\n",
      "Model saved at epoch 83438 with loss: 7.1697\n",
      "Epoch [83440/100000], Loss: 7.1701\n",
      "Model saved at epoch 83449 with loss: 7.1697\n",
      "Model saved at epoch 83450 with loss: 7.1685\n",
      "Epoch [83450/100000], Loss: 7.1685\n",
      "Model saved at epoch 83451 with loss: 7.1674\n",
      "Epoch [83460/100000], Loss: 7.1713\n",
      "Epoch [83470/100000], Loss: 7.1721\n",
      "Epoch [83480/100000], Loss: 7.1726\n",
      "Epoch [83490/100000], Loss: 7.1735\n",
      "Epoch [83500/100000], Loss: 7.1692\n",
      "Model saved at epoch 83502 with loss: 7.1669\n",
      "Epoch [83510/100000], Loss: 7.1680\n",
      "Model saved at epoch 83516 with loss: 7.1665\n",
      "Model saved at epoch 83517 with loss: 7.1660\n",
      "Model saved at epoch 83518 with loss: 7.1654\n",
      "Epoch [83520/100000], Loss: 7.1675\n",
      "Epoch [83530/100000], Loss: 7.1694\n",
      "Epoch [83540/100000], Loss: 7.1691\n",
      "Epoch [83550/100000], Loss: 7.1701\n",
      "Epoch [83560/100000], Loss: 7.1724\n",
      "Epoch [83570/100000], Loss: 7.1737\n",
      "Epoch [83580/100000], Loss: 7.1709\n",
      "Model saved at epoch 83589 with loss: 7.1649\n",
      "Model saved at epoch 83590 with loss: 7.1643\n",
      "Epoch [83590/100000], Loss: 7.1643\n",
      "Model saved at epoch 83591 with loss: 7.1639\n",
      "Epoch [83600/100000], Loss: 7.1681\n",
      "Epoch [83610/100000], Loss: 7.1677\n",
      "Epoch [83620/100000], Loss: 7.1707\n",
      "Epoch [83630/100000], Loss: 7.1696\n",
      "Epoch [83640/100000], Loss: 7.1710\n",
      "Epoch [83650/100000], Loss: 7.1727\n",
      "Epoch [83660/100000], Loss: 7.1723\n",
      "Epoch [83670/100000], Loss: 7.1702\n",
      "Epoch [83680/100000], Loss: 1352043776.0000\n",
      "Epoch [83690/100000], Loss: 1236481408.0000\n",
      "Epoch [83700/100000], Loss: 124693416.0000\n",
      "Epoch [83710/100000], Loss: 218919424.0000\n",
      "Epoch [83720/100000], Loss: 59032364.0000\n",
      "Epoch [83730/100000], Loss: 1101680.0000\n",
      "Epoch [83740/100000], Loss: 5857376.0000\n",
      "Epoch [83750/100000], Loss: 3042171.0000\n",
      "Epoch [83760/100000], Loss: 366385.3438\n",
      "Epoch [83770/100000], Loss: 217328.8125\n",
      "Epoch [83780/100000], Loss: 106431.7656\n",
      "Epoch [83790/100000], Loss: 11921.4951\n",
      "Epoch [83800/100000], Loss: 14626.1377\n",
      "Epoch [83810/100000], Loss: 3616.2449\n",
      "Epoch [83820/100000], Loss: 259.1906\n",
      "Epoch [83830/100000], Loss: 778.3091\n",
      "Epoch [83840/100000], Loss: 99.3536\n",
      "Epoch [83850/100000], Loss: 49.8047\n",
      "Epoch [83860/100000], Loss: 33.1166\n",
      "Epoch [83870/100000], Loss: 11.5212\n",
      "Epoch [83880/100000], Loss: 11.8340\n",
      "Epoch [83890/100000], Loss: 7.7845\n",
      "Epoch [83900/100000], Loss: 7.5359\n",
      "Epoch [83910/100000], Loss: 7.1889\n",
      "Epoch [83920/100000], Loss: 7.1819\n",
      "Model saved at epoch 83924 with loss: 7.1633\n",
      "Model saved at epoch 83930 with loss: 7.1619\n",
      "Epoch [83930/100000], Loss: 7.1619\n",
      "Model saved at epoch 83935 with loss: 7.1597\n",
      "Model saved at epoch 83936 with loss: 7.1551\n",
      "Model saved at epoch 83937 with loss: 7.1530\n",
      "Epoch [83940/100000], Loss: 7.1545\n",
      "Model saved at epoch 83941 with loss: 7.1515\n",
      "Epoch [83950/100000], Loss: 7.1551\n",
      "Epoch [83960/100000], Loss: 7.1562\n",
      "Epoch [83970/100000], Loss: 7.1571\n",
      "Epoch [83980/100000], Loss: 7.1549\n",
      "Epoch [83990/100000], Loss: 7.1551\n",
      "Epoch [84000/100000], Loss: 7.1570\n",
      "Epoch [84010/100000], Loss: 7.1549\n",
      "Epoch [84020/100000], Loss: 7.1558\n",
      "Epoch [84030/100000], Loss: 7.1550\n",
      "Epoch [84040/100000], Loss: 7.1542\n",
      "Epoch [84050/100000], Loss: 7.1557\n",
      "Epoch [84060/100000], Loss: 7.1556\n",
      "Epoch [84070/100000], Loss: 7.1558\n",
      "Epoch [84080/100000], Loss: 7.1556\n",
      "Epoch [84090/100000], Loss: 7.1549\n",
      "Epoch [84100/100000], Loss: 7.1552\n",
      "Epoch [84110/100000], Loss: 7.1559\n",
      "Epoch [84120/100000], Loss: 7.1546\n",
      "Epoch [84130/100000], Loss: 7.1555\n",
      "Epoch [84140/100000], Loss: 7.1550\n",
      "Epoch [84150/100000], Loss: 7.1560\n",
      "Epoch [84160/100000], Loss: 7.1541\n",
      "Epoch [84170/100000], Loss: 7.1548\n",
      "Epoch [84180/100000], Loss: 7.1545\n",
      "Epoch [84190/100000], Loss: 7.1547\n",
      "Epoch [84200/100000], Loss: 7.1543\n",
      "Epoch [84210/100000], Loss: 7.1557\n",
      "Epoch [84220/100000], Loss: 7.1548\n",
      "Epoch [84230/100000], Loss: 7.1549\n",
      "Epoch [84240/100000], Loss: 7.1547\n",
      "Epoch [84250/100000], Loss: 7.1534\n",
      "Epoch [84260/100000], Loss: 7.1538\n",
      "Epoch [84270/100000], Loss: 7.1537\n",
      "Model saved at epoch 84280 with loss: 7.1514\n",
      "Epoch [84280/100000], Loss: 7.1514\n",
      "Model saved at epoch 84281 with loss: 7.1507\n",
      "Model saved at epoch 84282 with loss: 7.1506\n",
      "Model saved at epoch 84283 with loss: 7.1499\n",
      "Model saved at epoch 84284 with loss: 7.1499\n",
      "Model saved at epoch 84285 with loss: 7.1498\n",
      "Epoch [84290/100000], Loss: 7.1511\n",
      "Epoch [84300/100000], Loss: 7.1508\n",
      "Epoch [84310/100000], Loss: 7.1526\n",
      "Epoch [84320/100000], Loss: 7.1524\n",
      "Epoch [84330/100000], Loss: 7.1516\n",
      "Epoch [84340/100000], Loss: 7.1517\n",
      "Epoch [84350/100000], Loss: 7.1527\n",
      "Epoch [84360/100000], Loss: 7.1514\n",
      "Model saved at epoch 84366 with loss: 7.1497\n",
      "Model saved at epoch 84367 with loss: 7.1494\n",
      "Epoch [84370/100000], Loss: 7.1499\n",
      "Epoch [84380/100000], Loss: 7.1503\n",
      "Epoch [84390/100000], Loss: 7.1513\n",
      "Epoch [84400/100000], Loss: 7.1510\n",
      "Epoch [84410/100000], Loss: 7.1501\n",
      "Model saved at epoch 84416 with loss: 7.1493\n",
      "Model saved at epoch 84418 with loss: 7.1492\n",
      "Model saved at epoch 84420 with loss: 7.1490\n",
      "Epoch [84420/100000], Loss: 7.1490\n",
      "Epoch [84430/100000], Loss: 7.1504\n",
      "Epoch [84440/100000], Loss: 7.1507\n",
      "Epoch [84450/100000], Loss: 7.1513\n",
      "Epoch [84460/100000], Loss: 7.1527\n",
      "Epoch [84470/100000], Loss: 7.1541\n",
      "Epoch [84480/100000], Loss: 7.1537\n",
      "Epoch [84490/100000], Loss: 7.1529\n",
      "Epoch [84500/100000], Loss: 7.1519\n",
      "Epoch [84510/100000], Loss: 7.1531\n",
      "Epoch [84520/100000], Loss: 7.1533\n",
      "Epoch [84530/100000], Loss: 7.1532\n",
      "Epoch [84540/100000], Loss: 7.1510\n",
      "Epoch [84550/100000], Loss: 7.1508\n",
      "Epoch [84560/100000], Loss: 7.1496\n",
      "Model saved at epoch 84564 with loss: 7.1489\n",
      "Epoch [84570/100000], Loss: 7.1499\n",
      "Epoch [84580/100000], Loss: 7.1512\n",
      "Epoch [84590/100000], Loss: 7.1503\n",
      "Epoch [84600/100000], Loss: 7.1509\n",
      "Epoch [84610/100000], Loss: 7.1502\n",
      "Model saved at epoch 84613 with loss: 7.1488\n",
      "Model saved at epoch 84614 with loss: 7.1481\n",
      "Model saved at epoch 84615 with loss: 7.1480\n",
      "Model saved at epoch 84616 with loss: 7.1478\n",
      "Epoch [84620/100000], Loss: 7.1488\n",
      "Model saved at epoch 84625 with loss: 7.1473\n",
      "Model saved at epoch 84626 with loss: 7.1466\n",
      "Epoch [84630/100000], Loss: 7.1473\n",
      "Model saved at epoch 84632 with loss: 7.1464\n",
      "Epoch [84640/100000], Loss: 7.1476\n",
      "Epoch [84650/100000], Loss: 7.1489\n",
      "Epoch [84660/100000], Loss: 7.1500\n",
      "Epoch [84670/100000], Loss: 7.1486\n",
      "Epoch [84680/100000], Loss: 7.1499\n",
      "Epoch [84690/100000], Loss: 7.1494\n",
      "Epoch [84700/100000], Loss: 7.1492\n",
      "Epoch [84710/100000], Loss: 7.1491\n",
      "Epoch [84720/100000], Loss: 7.1484\n",
      "Epoch [84730/100000], Loss: 7.1481\n",
      "Epoch [84740/100000], Loss: 7.1481\n",
      "Epoch [84750/100000], Loss: 7.1479\n",
      "Epoch [84760/100000], Loss: 7.1483\n",
      "Model saved at epoch 84769 with loss: 7.1464\n",
      "Model saved at epoch 84770 with loss: 7.1461\n",
      "Epoch [84770/100000], Loss: 7.1461\n",
      "Epoch [84780/100000], Loss: 7.1480\n",
      "Epoch [84790/100000], Loss: 7.1489\n",
      "Epoch [84800/100000], Loss: 7.1502\n",
      "Epoch [84810/100000], Loss: 7.1512\n",
      "Epoch [84820/100000], Loss: 7.1521\n",
      "Epoch [84830/100000], Loss: 7.1523\n",
      "Epoch [84840/100000], Loss: 7.1525\n",
      "Epoch [84850/100000], Loss: 7.1523\n",
      "Epoch [84860/100000], Loss: 7.1531\n",
      "Epoch [84870/100000], Loss: 7.1520\n",
      "Epoch [84880/100000], Loss: 7.1502\n",
      "Epoch [84890/100000], Loss: 7.1504\n",
      "Epoch [84900/100000], Loss: 7.1499\n",
      "Epoch [84910/100000], Loss: 7.1498\n",
      "Epoch [84920/100000], Loss: 7.1505\n",
      "Epoch [84930/100000], Loss: 7.1512\n",
      "Epoch [84940/100000], Loss: 7.1534\n",
      "Epoch [84950/100000], Loss: 7.1527\n",
      "Epoch [84960/100000], Loss: 7.1510\n",
      "Epoch [84970/100000], Loss: 7.1506\n",
      "Epoch [84980/100000], Loss: 7.1503\n",
      "Epoch [84990/100000], Loss: 7.1483\n",
      "Epoch [85000/100000], Loss: 7.1484\n",
      "Epoch [85010/100000], Loss: 7.1499\n",
      "Epoch [85020/100000], Loss: 7.1491\n",
      "Epoch [85030/100000], Loss: 7.1517\n",
      "Epoch [85040/100000], Loss: 7.1505\n",
      "Epoch [85050/100000], Loss: 7.1516\n",
      "Epoch [85060/100000], Loss: 7.1495\n",
      "Epoch [85070/100000], Loss: 7.1507\n",
      "Epoch [85080/100000], Loss: 7.1523\n",
      "Epoch [85090/100000], Loss: 7.1522\n",
      "Epoch [85100/100000], Loss: 7.1537\n",
      "Epoch [85110/100000], Loss: 7.1525\n",
      "Epoch [85120/100000], Loss: 7.1529\n",
      "Epoch [85130/100000], Loss: 7.1514\n",
      "Epoch [85140/100000], Loss: 7.1490\n",
      "Epoch [85150/100000], Loss: 7.1488\n",
      "Epoch [85160/100000], Loss: 7.1500\n",
      "Epoch [85170/100000], Loss: 7.1501\n",
      "Epoch [85180/100000], Loss: 7.1506\n",
      "Epoch [85190/100000], Loss: 7.1496\n",
      "Epoch [85200/100000], Loss: 7.1474\n",
      "Epoch [85210/100000], Loss: 7.1486\n",
      "Epoch [85220/100000], Loss: 7.1479\n",
      "Epoch [85230/100000], Loss: 7.1504\n",
      "Epoch [85240/100000], Loss: 7.1503\n",
      "Epoch [85250/100000], Loss: 7.1488\n",
      "Epoch [85260/100000], Loss: 7.1483\n",
      "Epoch [85270/100000], Loss: 7.1483\n",
      "Epoch [85280/100000], Loss: 7.1506\n",
      "Epoch [85290/100000], Loss: 7.1510\n",
      "Epoch [85300/100000], Loss: 7.1521\n",
      "Epoch [85310/100000], Loss: 7.1531\n",
      "Epoch [85320/100000], Loss: 7.1532\n",
      "Epoch [85330/100000], Loss: 7.1513\n",
      "Epoch [85340/100000], Loss: 7.1522\n",
      "Epoch [85350/100000], Loss: 7.1521\n",
      "Epoch [85360/100000], Loss: 7.1525\n",
      "Epoch [85370/100000], Loss: 7.1535\n",
      "Epoch [85380/100000], Loss: 7.1540\n",
      "Epoch [85390/100000], Loss: 7.1522\n",
      "Epoch [85400/100000], Loss: 7.1519\n",
      "Epoch [85410/100000], Loss: 7.1509\n",
      "Epoch [85420/100000], Loss: 7.1511\n",
      "Epoch [85430/100000], Loss: 7.1517\n",
      "Epoch [85440/100000], Loss: 7.1515\n",
      "Epoch [85450/100000], Loss: 7.1510\n",
      "Epoch [85460/100000], Loss: 7.1516\n",
      "Epoch [85470/100000], Loss: 7.1535\n",
      "Epoch [85480/100000], Loss: 7.1521\n",
      "Epoch [85490/100000], Loss: 7.1515\n",
      "Epoch [85500/100000], Loss: 7.1508\n",
      "Epoch [85510/100000], Loss: 7.1487\n",
      "Epoch [85520/100000], Loss: 7.1506\n",
      "Epoch [85530/100000], Loss: 7.1521\n",
      "Epoch [85540/100000], Loss: 7.1513\n",
      "Epoch [85550/100000], Loss: 7.1517\n",
      "Epoch [85560/100000], Loss: 7.1501\n",
      "Epoch [85570/100000], Loss: 7.1497\n",
      "Epoch [85580/100000], Loss: 7.1486\n",
      "Epoch [85590/100000], Loss: 7.1475\n",
      "Epoch [85600/100000], Loss: 7.1488\n",
      "Epoch [85610/100000], Loss: 7.1507\n",
      "Epoch [85620/100000], Loss: 7.1512\n",
      "Epoch [85630/100000], Loss: 7.1508\n",
      "Epoch [85640/100000], Loss: 7.1497\n",
      "Epoch [85650/100000], Loss: 7.1482\n",
      "Epoch [85660/100000], Loss: 7.1475\n",
      "Model saved at epoch 85670 with loss: 7.1458\n",
      "Epoch [85670/100000], Loss: 7.1458\n",
      "Model saved at epoch 85680 with loss: 7.1458\n",
      "Epoch [85680/100000], Loss: 7.1458\n",
      "Model saved at epoch 85681 with loss: 7.1454\n",
      "Model saved at epoch 85685 with loss: 7.1448\n",
      "Model saved at epoch 85686 with loss: 7.1445\n",
      "Model saved at epoch 85688 with loss: 7.1443\n",
      "Model saved at epoch 85689 with loss: 7.1440\n",
      "Model saved at epoch 85690 with loss: 7.1439\n",
      "Epoch [85690/100000], Loss: 7.1439\n",
      "Model saved at epoch 85698 with loss: 7.1436\n",
      "Epoch [85700/100000], Loss: 7.1439\n",
      "Model saved at epoch 85701 with loss: 7.1432\n",
      "Epoch [85710/100000], Loss: 7.1452\n",
      "Epoch [85720/100000], Loss: 7.1475\n",
      "Epoch [85730/100000], Loss: 7.1500\n",
      "Epoch [85740/100000], Loss: 7.1504\n",
      "Epoch [85750/100000], Loss: 7.1516\n",
      "Epoch [85760/100000], Loss: 7.1509\n",
      "Epoch [85770/100000], Loss: 7.1500\n",
      "Epoch [85780/100000], Loss: 7.1504\n",
      "Epoch [85790/100000], Loss: 7.1516\n",
      "Epoch [85800/100000], Loss: 7.1505\n",
      "Epoch [85810/100000], Loss: 7.1496\n",
      "Epoch [85820/100000], Loss: 7.1486\n",
      "Epoch [85830/100000], Loss: 7.1491\n",
      "Epoch [85840/100000], Loss: 7.1482\n",
      "Epoch [85850/100000], Loss: 7.1479\n",
      "Epoch [85860/100000], Loss: 7.1451\n",
      "Epoch [85870/100000], Loss: 7.1442\n",
      "Epoch [85880/100000], Loss: 7.1452\n",
      "Epoch [85890/100000], Loss: 7.1434\n",
      "Model saved at epoch 85891 with loss: 7.1431\n",
      "Model saved at epoch 85892 with loss: 7.1427\n",
      "Model saved at epoch 85895 with loss: 7.1426\n",
      "Epoch [85900/100000], Loss: 7.1435\n",
      "Epoch [85910/100000], Loss: 7.1435\n",
      "Epoch [85920/100000], Loss: 7.1436\n",
      "Model saved at epoch 85927 with loss: 7.1425\n",
      "Model saved at epoch 85928 with loss: 7.1415\n",
      "Model saved at epoch 85929 with loss: 7.1415\n",
      "Model saved at epoch 85930 with loss: 7.1411\n",
      "Epoch [85930/100000], Loss: 7.1411\n",
      "Model saved at epoch 85932 with loss: 7.1411\n",
      "Model saved at epoch 85936 with loss: 7.1410\n",
      "Model saved at epoch 85939 with loss: 7.1407\n",
      "Model saved at epoch 85940 with loss: 7.1403\n",
      "Epoch [85940/100000], Loss: 7.1403\n",
      "Model saved at epoch 85941 with loss: 7.1398\n",
      "Model saved at epoch 85949 with loss: 7.1397\n",
      "Epoch [85950/100000], Loss: 7.1400\n",
      "Epoch [85960/100000], Loss: 7.1417\n",
      "Epoch [85970/100000], Loss: 7.1418\n",
      "Epoch [85980/100000], Loss: 7.1424\n",
      "Epoch [85990/100000], Loss: 7.1439\n",
      "Epoch [86000/100000], Loss: 7.1434\n",
      "Epoch [86010/100000], Loss: 7.1475\n",
      "Epoch [86020/100000], Loss: 7.1468\n",
      "Epoch [86030/100000], Loss: 7.1457\n",
      "Epoch [86040/100000], Loss: 7.1427\n",
      "Epoch [86050/100000], Loss: 7.1458\n",
      "Epoch [86060/100000], Loss: 7.1473\n",
      "Epoch [86070/100000], Loss: 7.1490\n",
      "Epoch [86080/100000], Loss: 7.1498\n",
      "Epoch [86090/100000], Loss: 7.1494\n",
      "Epoch [86100/100000], Loss: 7.1505\n",
      "Epoch [86110/100000], Loss: 7.1497\n",
      "Epoch [86120/100000], Loss: 7.1463\n",
      "Epoch [86130/100000], Loss: 7.1492\n",
      "Epoch [86140/100000], Loss: 7.1489\n",
      "Epoch [86150/100000], Loss: 7.1478\n",
      "Epoch [86160/100000], Loss: 7.1486\n",
      "Epoch [86170/100000], Loss: 7.1468\n",
      "Epoch [86180/100000], Loss: 7.1456\n",
      "Epoch [86190/100000], Loss: 7.1430\n",
      "Epoch [86200/100000], Loss: 7.1428\n",
      "Epoch [86210/100000], Loss: 7.1410\n",
      "Epoch [86220/100000], Loss: 7.1424\n",
      "Epoch [86230/100000], Loss: 7.1422\n",
      "Epoch [86240/100000], Loss: 7.1450\n",
      "Epoch [86250/100000], Loss: 7.1440\n",
      "Epoch [86260/100000], Loss: 7.1405\n",
      "Epoch [86270/100000], Loss: 7.1439\n",
      "Epoch [86280/100000], Loss: 7.1414\n",
      "Epoch [86290/100000], Loss: 7.1401\n",
      "Epoch [86300/100000], Loss: 7.1412\n",
      "Epoch [86310/100000], Loss: 7.1422\n",
      "Epoch [86320/100000], Loss: 7.1418\n",
      "Epoch [86330/100000], Loss: 7.1404\n",
      "Epoch [86340/100000], Loss: 7.1418\n",
      "Epoch [86350/100000], Loss: 7.1414\n",
      "Model saved at epoch 86357 with loss: 7.1395\n",
      "Model saved at epoch 86360 with loss: 7.1395\n",
      "Epoch [86360/100000], Loss: 7.1395\n",
      "Model saved at epoch 86362 with loss: 7.1388\n",
      "Model saved at epoch 86363 with loss: 7.1387\n",
      "Model saved at epoch 86364 with loss: 7.1385\n",
      "Model saved at epoch 86368 with loss: 7.1384\n",
      "Model saved at epoch 86369 with loss: 7.1382\n",
      "Model saved at epoch 86370 with loss: 7.1375\n",
      "Epoch [86370/100000], Loss: 7.1375\n",
      "Epoch [86380/100000], Loss: 7.1391\n",
      "Epoch [86390/100000], Loss: 7.1427\n",
      "Epoch [86400/100000], Loss: 7.1419\n",
      "Epoch [86410/100000], Loss: 7.1399\n",
      "Epoch [86420/100000], Loss: 7.1403\n",
      "Epoch [86430/100000], Loss: 7.1429\n",
      "Epoch [86440/100000], Loss: 7.1426\n",
      "Epoch [86450/100000], Loss: 7.1398\n",
      "Epoch [86460/100000], Loss: 7.1388\n",
      "Epoch [86470/100000], Loss: 7.1408\n",
      "Epoch [86480/100000], Loss: 7.1393\n",
      "Epoch [86490/100000], Loss: 7.1415\n",
      "Epoch [86500/100000], Loss: 7.1421\n",
      "Epoch [86510/100000], Loss: 7.1444\n",
      "Epoch [86520/100000], Loss: 7.1425\n",
      "Epoch [86530/100000], Loss: 7.1401\n",
      "Epoch [86540/100000], Loss: 7.1387\n",
      "Model saved at epoch 86545 with loss: 7.1365\n",
      "Model saved at epoch 86546 with loss: 7.1359\n",
      "Model saved at epoch 86550 with loss: 7.1355\n",
      "Epoch [86550/100000], Loss: 7.1355\n",
      "Model saved at epoch 86551 with loss: 7.1352\n",
      "Epoch [86560/100000], Loss: 7.1373\n",
      "Epoch [86570/100000], Loss: 7.1381\n",
      "Epoch [86580/100000], Loss: 7.1381\n",
      "Epoch [86590/100000], Loss: 7.1372\n",
      "Model saved at epoch 86596 with loss: 7.1351\n",
      "Model saved at epoch 86597 with loss: 7.1350\n",
      "Epoch [86600/100000], Loss: 7.1361\n",
      "Epoch [86610/100000], Loss: 7.1356\n",
      "Model saved at epoch 86611 with loss: 7.1350\n",
      "Model saved at epoch 86612 with loss: 7.1341\n",
      "Model saved at epoch 86615 with loss: 7.1334\n",
      "Model saved at epoch 86616 with loss: 7.1333\n",
      "Model saved at epoch 86617 with loss: 7.1331\n",
      "Model saved at epoch 86618 with loss: 7.1330\n",
      "Epoch [86620/100000], Loss: 7.1335\n",
      "Model saved at epoch 86627 with loss: 7.1328\n",
      "Model saved at epoch 86629 with loss: 7.1321\n",
      "Epoch [86630/100000], Loss: 7.1323\n",
      "Model saved at epoch 86631 with loss: 7.1318\n",
      "Model saved at epoch 86632 with loss: 7.1312\n",
      "Model saved at epoch 86639 with loss: 7.1307\n",
      "Model saved at epoch 86640 with loss: 7.1306\n",
      "Epoch [86640/100000], Loss: 7.1306\n",
      "Epoch [86650/100000], Loss: 7.1332\n",
      "Epoch [86660/100000], Loss: 7.1324\n",
      "Epoch [86670/100000], Loss: 7.1343\n",
      "Epoch [86680/100000], Loss: 7.1347\n",
      "Epoch [86690/100000], Loss: 7.1342\n",
      "Epoch [86700/100000], Loss: 7.1343\n",
      "Epoch [86710/100000], Loss: 7.1336\n",
      "Epoch [86720/100000], Loss: 7.1335\n",
      "Epoch [86730/100000], Loss: 7.1351\n",
      "Epoch [86740/100000], Loss: 7.1347\n",
      "Epoch [86750/100000], Loss: 7.1340\n",
      "Epoch [86760/100000], Loss: 7.1351\n",
      "Epoch [86770/100000], Loss: 7.1344\n",
      "Epoch [86780/100000], Loss: 7.1366\n",
      "Epoch [86790/100000], Loss: 7.1348\n",
      "Epoch [86800/100000], Loss: 7.1385\n",
      "Epoch [86810/100000], Loss: 7.1383\n",
      "Epoch [86820/100000], Loss: 7.1360\n",
      "Epoch [86830/100000], Loss: 7.1379\n",
      "Epoch [86840/100000], Loss: 7.1367\n",
      "Epoch [86850/100000], Loss: 7.1344\n",
      "Epoch [86860/100000], Loss: 7.1314\n",
      "Epoch [86870/100000], Loss: 7.1350\n",
      "Epoch [86880/100000], Loss: 7.1360\n",
      "Epoch [86890/100000], Loss: 7.1346\n",
      "Epoch [86900/100000], Loss: 7.1322\n",
      "Model saved at epoch 86907 with loss: 7.1301\n",
      "Model saved at epoch 86908 with loss: 7.1292\n",
      "Epoch [86910/100000], Loss: 7.1302\n",
      "Epoch [86920/100000], Loss: 7.1316\n",
      "Epoch [86930/100000], Loss: 7.1306\n",
      "Epoch [86940/100000], Loss: 7.1312\n",
      "Epoch [86950/100000], Loss: 7.1300\n",
      "Epoch [86960/100000], Loss: 7.1323\n",
      "Epoch [86970/100000], Loss: 7.1328\n",
      "Epoch [86980/100000], Loss: 7.1337\n",
      "Epoch [86990/100000], Loss: 7.1343\n",
      "Epoch [87000/100000], Loss: 7.1336\n",
      "Epoch [87010/100000], Loss: 7.1364\n",
      "Epoch [87020/100000], Loss: 7.1350\n",
      "Epoch [87030/100000], Loss: 7.1338\n",
      "Epoch [87040/100000], Loss: 7.1345\n",
      "Epoch [87050/100000], Loss: 7.1315\n",
      "Epoch [87060/100000], Loss: 7.1331\n",
      "Model saved at epoch 87066 with loss: 7.1292\n",
      "Epoch [87070/100000], Loss: 7.1326\n",
      "Epoch [87080/100000], Loss: 7.1302\n",
      "Model saved at epoch 87088 with loss: 7.1292\n",
      "Epoch [87090/100000], Loss: 7.1299\n",
      "Epoch [87100/100000], Loss: 7.1327\n",
      "Model saved at epoch 87108 with loss: 7.1290\n",
      "Model saved at epoch 87109 with loss: 7.1287\n",
      "Epoch [87110/100000], Loss: 7.1288\n",
      "Model saved at epoch 87119 with loss: 7.1283\n",
      "Epoch [87120/100000], Loss: 7.1295\n",
      "Model saved at epoch 87127 with loss: 7.1279\n",
      "Model saved at epoch 87129 with loss: 7.1273\n",
      "Epoch [87130/100000], Loss: 7.1277\n",
      "Epoch [87140/100000], Loss: 7.1278\n",
      "Epoch [87150/100000], Loss: 7.1323\n",
      "Epoch [87160/100000], Loss: 7.1331\n",
      "Epoch [87170/100000], Loss: 7.1306\n",
      "Epoch [87180/100000], Loss: 7.1308\n",
      "Epoch [87190/100000], Loss: 7.1313\n",
      "Epoch [87200/100000], Loss: 7.1295\n",
      "Model saved at epoch 87205 with loss: 7.1267\n",
      "Model saved at epoch 87206 with loss: 7.1256\n",
      "Model saved at epoch 87209 with loss: 7.1255\n",
      "Epoch [87210/100000], Loss: 7.1255\n",
      "Model saved at epoch 87217 with loss: 7.1249\n",
      "Epoch [87220/100000], Loss: 7.1249\n",
      "Model saved at epoch 87221 with loss: 7.1240\n",
      "Model saved at epoch 87226 with loss: 7.1226\n",
      "Epoch [87230/100000], Loss: 7.1240\n",
      "Epoch [87240/100000], Loss: 7.1282\n",
      "Epoch [87250/100000], Loss: 7.1295\n",
      "Epoch [87260/100000], Loss: 7.1300\n",
      "Epoch [87270/100000], Loss: 7.1317\n",
      "Epoch [87280/100000], Loss: 7.1346\n",
      "Epoch [87290/100000], Loss: 7.1311\n",
      "Epoch [87300/100000], Loss: 7.1292\n",
      "Epoch [87310/100000], Loss: 7.1302\n",
      "Epoch [87320/100000], Loss: 7.1264\n",
      "Epoch [87330/100000], Loss: 7.1282\n",
      "Epoch [87340/100000], Loss: 7.1283\n",
      "Epoch [87350/100000], Loss: 7.1288\n",
      "Epoch [87360/100000], Loss: 7.1262\n",
      "Model saved at epoch 87370 with loss: 7.1215\n",
      "Epoch [87370/100000], Loss: 7.1215\n",
      "Model saved at epoch 87371 with loss: 7.1188\n",
      "Epoch [87380/100000], Loss: 7.1249\n",
      "Epoch [87390/100000], Loss: 7.1246\n",
      "Epoch [87400/100000], Loss: 7.1261\n",
      "Epoch [87410/100000], Loss: 7.1289\n",
      "Epoch [87420/100000], Loss: 7.1312\n",
      "Epoch [87430/100000], Loss: 7.1287\n",
      "Epoch [87440/100000], Loss: 7.1271\n",
      "Epoch [87450/100000], Loss: 7.1265\n",
      "Epoch [87460/100000], Loss: 7.1282\n",
      "Epoch [87470/100000], Loss: 7.1278\n",
      "Epoch [87480/100000], Loss: 7.1289\n",
      "Epoch [87490/100000], Loss: 7.1318\n",
      "Epoch [87500/100000], Loss: 7.1304\n",
      "Epoch [87510/100000], Loss: 7.1264\n",
      "Epoch [87520/100000], Loss: 7.1291\n",
      "Epoch [87530/100000], Loss: 7.1273\n",
      "Epoch [87540/100000], Loss: 7.1276\n",
      "Epoch [87550/100000], Loss: 7.1265\n",
      "Epoch [87560/100000], Loss: 7.1265\n",
      "Epoch [87570/100000], Loss: 7.1249\n",
      "Epoch [87580/100000], Loss: 7.1230\n",
      "Epoch [87590/100000], Loss: 7.1219\n",
      "Epoch [87600/100000], Loss: 7.1210\n",
      "Epoch [87610/100000], Loss: 7.1224\n",
      "Epoch [87620/100000], Loss: 7.1239\n",
      "Epoch [87630/100000], Loss: 7.1251\n",
      "Epoch [87640/100000], Loss: 7.1228\n",
      "Epoch [87650/100000], Loss: 7.1261\n",
      "Epoch [87660/100000], Loss: 7.1228\n",
      "Epoch [87670/100000], Loss: 7.1209\n",
      "Model saved at epoch 87676 with loss: 7.1183\n",
      "Model saved at epoch 87678 with loss: 7.1183\n",
      "Model saved at epoch 87679 with loss: 7.1182\n",
      "Model saved at epoch 87680 with loss: 7.1181\n",
      "Epoch [87680/100000], Loss: 7.1181\n",
      "Model saved at epoch 87681 with loss: 7.1175\n",
      "Epoch [87690/100000], Loss: 7.1198\n",
      "Epoch [87700/100000], Loss: 7.1211\n",
      "Epoch [87710/100000], Loss: 7.1231\n",
      "Epoch [87720/100000], Loss: 7.1206\n",
      "Epoch [87730/100000], Loss: 7.1192\n",
      "Model saved at epoch 87739 with loss: 7.1165\n",
      "Epoch [87740/100000], Loss: 7.1172\n",
      "Model saved at epoch 87742 with loss: 7.1159\n",
      "Epoch [87750/100000], Loss: 7.1192\n",
      "Epoch [87760/100000], Loss: 7.1196\n",
      "Epoch [87770/100000], Loss: 7.1206\n",
      "Epoch [87780/100000], Loss: 7.1200\n",
      "Epoch [87790/100000], Loss: 7.1227\n",
      "Epoch [87800/100000], Loss: 7.1239\n",
      "Epoch [87810/100000], Loss: 7.1215\n",
      "Epoch [87820/100000], Loss: 7.1163\n",
      "Model saved at epoch 87829 with loss: 7.1156\n",
      "Epoch [87830/100000], Loss: 7.1161\n",
      "Model saved at epoch 87834 with loss: 7.1153\n",
      "Model saved at epoch 87835 with loss: 7.1147\n",
      "Epoch [87840/100000], Loss: 7.1178\n",
      "Epoch [87850/100000], Loss: 7.1186\n",
      "Epoch [87860/100000], Loss: 7.1202\n",
      "Epoch [87870/100000], Loss: 7.1189\n",
      "Epoch [87880/100000], Loss: 7.1216\n",
      "Epoch [87890/100000], Loss: 7.1209\n",
      "Epoch [87900/100000], Loss: 7.1198\n",
      "Epoch [87910/100000], Loss: 7.1172\n",
      "Epoch [87920/100000], Loss: 7.1192\n",
      "Epoch [87930/100000], Loss: 7.1187\n",
      "Epoch [87940/100000], Loss: 7.1225\n",
      "Epoch [87950/100000], Loss: 7.1204\n",
      "Epoch [87960/100000], Loss: 7.1209\n",
      "Epoch [87970/100000], Loss: 7.1188\n",
      "Epoch [87980/100000], Loss: 7.1203\n",
      "Model saved at epoch 87990 with loss: 7.1147\n",
      "Epoch [87990/100000], Loss: 7.1147\n",
      "Model saved at epoch 87991 with loss: 7.1146\n",
      "Model saved at epoch 87992 with loss: 7.1146\n",
      "Model saved at epoch 87993 with loss: 7.1146\n",
      "Model saved at epoch 87998 with loss: 7.1139\n",
      "Model saved at epoch 87999 with loss: 7.1132\n",
      "Epoch [88000/100000], Loss: 7.1144\n",
      "Model saved at epoch 88006 with loss: 7.1132\n",
      "Model saved at epoch 88007 with loss: 7.1125\n",
      "Model saved at epoch 88008 with loss: 7.1122\n",
      "Epoch [88010/100000], Loss: 7.1142\n",
      "Epoch [88020/100000], Loss: 7.1149\n",
      "Epoch [88030/100000], Loss: 7.1138\n",
      "Model saved at epoch 88033 with loss: 7.1118\n",
      "Model saved at epoch 88036 with loss: 7.1104\n",
      "Model saved at epoch 88040 with loss: 7.1101\n",
      "Epoch [88040/100000], Loss: 7.1101\n",
      "Model saved at epoch 88041 with loss: 7.1098\n",
      "Epoch [88050/100000], Loss: 7.1127\n",
      "Epoch [88060/100000], Loss: 7.1102\n",
      "Epoch [88070/100000], Loss: 7.1144\n",
      "Epoch [88080/100000], Loss: 7.1132\n",
      "Epoch [88090/100000], Loss: 7.1128\n",
      "Epoch [88100/100000], Loss: 7.1115\n",
      "Epoch [88110/100000], Loss: 7.1130\n",
      "Epoch [88120/100000], Loss: 7.1121\n",
      "Epoch [88130/100000], Loss: 7.1142\n",
      "Epoch [88140/100000], Loss: 7.1110\n",
      "Epoch [88150/100000], Loss: 7.1122\n",
      "Epoch [88160/100000], Loss: 7.1128\n",
      "Epoch [88170/100000], Loss: 7.1114\n",
      "Model saved at epoch 88177 with loss: 7.1092\n",
      "Model saved at epoch 88178 with loss: 7.1091\n",
      "Model saved at epoch 88179 with loss: 7.1086\n",
      "Model saved at epoch 88180 with loss: 7.1083\n",
      "Epoch [88180/100000], Loss: 7.1083\n",
      "Model saved at epoch 88181 with loss: 7.1061\n",
      "Model saved at epoch 88182 with loss: 7.1057\n",
      "Model saved at epoch 88183 with loss: 7.1052\n",
      "Epoch [88190/100000], Loss: 7.1065\n",
      "Epoch [88200/100000], Loss: 7.1072\n",
      "Model saved at epoch 88201 with loss: 7.1051\n",
      "Model saved at epoch 88202 with loss: 7.1045\n",
      "Model saved at epoch 88203 with loss: 7.1038\n",
      "Model saved at epoch 88207 with loss: 7.1034\n",
      "Epoch [88210/100000], Loss: 7.1047\n",
      "Epoch [88220/100000], Loss: 7.1089\n",
      "Epoch [88230/100000], Loss: 7.1075\n",
      "Epoch [88240/100000], Loss: 7.1075\n",
      "Epoch [88250/100000], Loss: 7.1111\n",
      "Epoch [88260/100000], Loss: 7.1055\n",
      "Epoch [88270/100000], Loss: 7.1051\n",
      "Epoch [88280/100000], Loss: 7.1064\n",
      "Epoch [88290/100000], Loss: 7.1058\n",
      "Model saved at epoch 88300 with loss: 7.1034\n",
      "Epoch [88300/100000], Loss: 7.1034\n",
      "Model saved at epoch 88301 with loss: 7.1017\n",
      "Epoch [88310/100000], Loss: 7.1023\n",
      "Model saved at epoch 88311 with loss: 7.1008\n",
      "Model saved at epoch 88312 with loss: 7.1007\n",
      "Epoch [88320/100000], Loss: 7.1030\n",
      "Epoch [88330/100000], Loss: 7.1045\n",
      "Model saved at epoch 88337 with loss: 7.0997\n",
      "Epoch [88340/100000], Loss: 7.1016\n",
      "Epoch [88350/100000], Loss: 7.1005\n",
      "Model saved at epoch 88353 with loss: 7.0989\n",
      "Epoch [88360/100000], Loss: 7.1005\n",
      "Epoch [88370/100000], Loss: 7.1010\n",
      "Epoch [88380/100000], Loss: 7.1039\n",
      "Epoch [88390/100000], Loss: 7.1015\n",
      "Epoch [88400/100000], Loss: 7.1030\n",
      "Epoch [88410/100000], Loss: 7.1040\n",
      "Epoch [88420/100000], Loss: 7.1048\n",
      "Epoch [88430/100000], Loss: 7.1046\n",
      "Epoch [88440/100000], Loss: 7.1025\n",
      "Epoch [88450/100000], Loss: 7.1052\n",
      "Epoch [88460/100000], Loss: 7.1056\n",
      "Epoch [88470/100000], Loss: 7.1060\n",
      "Epoch [88480/100000], Loss: 7.1042\n",
      "Epoch [88490/100000], Loss: 7.1047\n",
      "Epoch [88500/100000], Loss: 7.1021\n",
      "Epoch [88510/100000], Loss: 7.1027\n",
      "Epoch [88520/100000], Loss: 7.1055\n",
      "Epoch [88530/100000], Loss: 7.1015\n",
      "Epoch [88540/100000], Loss: 7.1024\n",
      "Model saved at epoch 88548 with loss: 7.0979\n",
      "Epoch [88550/100000], Loss: 7.0998\n",
      "Model saved at epoch 88551 with loss: 7.0976\n",
      "Model saved at epoch 88552 with loss: 7.0968\n",
      "Model saved at epoch 88553 with loss: 7.0958\n",
      "Epoch [88560/100000], Loss: 7.0994\n",
      "Epoch [88570/100000], Loss: 7.0995\n",
      "Epoch [88580/100000], Loss: 7.1000\n",
      "Epoch [88590/100000], Loss: 7.1001\n",
      "Epoch [88600/100000], Loss: 7.0989\n",
      "Epoch [88610/100000], Loss: 7.1019\n",
      "Epoch [88620/100000], Loss: 7.1054\n",
      "Epoch [88630/100000], Loss: 7.1021\n",
      "Epoch [88640/100000], Loss: 7.1020\n",
      "Model saved at epoch 88645 with loss: 7.0955\n",
      "Epoch [88650/100000], Loss: 7.0988\n",
      "Epoch [88660/100000], Loss: 7.1004\n",
      "Epoch [88670/100000], Loss: 7.1005\n",
      "Epoch [88680/100000], Loss: 7.0999\n",
      "Epoch [88690/100000], Loss: 7.0982\n",
      "Model saved at epoch 88700 with loss: 7.0950\n",
      "Epoch [88700/100000], Loss: 7.0950\n",
      "Model saved at epoch 88701 with loss: 7.0947\n",
      "Epoch [88710/100000], Loss: 7.0961\n",
      "Epoch [88720/100000], Loss: 7.0993\n",
      "Model saved at epoch 88725 with loss: 7.0941\n",
      "Model saved at epoch 88726 with loss: 7.0932\n",
      "Epoch [88730/100000], Loss: 7.0968\n",
      "Epoch [88740/100000], Loss: 7.0949\n",
      "Epoch [88750/100000], Loss: 7.0965\n",
      "Model saved at epoch 88755 with loss: 7.0931\n",
      "Model saved at epoch 88756 with loss: 7.0923\n",
      "Epoch [88760/100000], Loss: 7.0980\n",
      "Epoch [88770/100000], Loss: 7.1002\n",
      "Epoch [88780/100000], Loss: 7.0995\n",
      "Epoch [88790/100000], Loss: 7.0985\n",
      "Epoch [88800/100000], Loss: 7.0975\n",
      "Epoch [88810/100000], Loss: 7.0993\n",
      "Epoch [88820/100000], Loss: 7.0987\n",
      "Epoch [88830/100000], Loss: 7.0991\n",
      "Epoch [88840/100000], Loss: 7.0955\n",
      "Model saved at epoch 88842 with loss: 7.0909\n",
      "Model saved at epoch 88843 with loss: 7.0902\n",
      "Epoch [88850/100000], Loss: 7.0970\n",
      "Model saved at epoch 88859 with loss: 7.0902\n",
      "Model saved at epoch 88860 with loss: 7.0895\n",
      "Epoch [88860/100000], Loss: 7.0895\n",
      "Model saved at epoch 88861 with loss: 7.0884\n",
      "Epoch [88870/100000], Loss: 7.0891\n",
      "Epoch [88880/100000], Loss: 7.0907\n",
      "Model saved at epoch 88890 with loss: 7.0870\n",
      "Epoch [88890/100000], Loss: 7.0870\n",
      "Model saved at epoch 88893 with loss: 7.0869\n",
      "Model saved at epoch 88894 with loss: 7.0860\n",
      "Model saved at epoch 88895 with loss: 7.0855\n",
      "Epoch [88900/100000], Loss: 7.0886\n",
      "Epoch [88910/100000], Loss: 7.0900\n",
      "Epoch [88920/100000], Loss: 7.0921\n",
      "Epoch [88930/100000], Loss: 7.0887\n",
      "Epoch [88940/100000], Loss: 7.0886\n",
      "Epoch [88950/100000], Loss: 7.0910\n",
      "Epoch [88960/100000], Loss: 7.0895\n",
      "Epoch [88970/100000], Loss: 7.0882\n",
      "Epoch [88980/100000], Loss: 7.0905\n",
      "Epoch [88990/100000], Loss: 7.0884\n",
      "Epoch [89000/100000], Loss: 7.0899\n",
      "Epoch [89010/100000], Loss: 7.0894\n",
      "Epoch [89020/100000], Loss: 7.0867\n",
      "Model saved at epoch 89022 with loss: 7.0835\n",
      "Model saved at epoch 89023 with loss: 7.0832\n",
      "Epoch [89030/100000], Loss: 7.0881\n",
      "Epoch [89040/100000], Loss: 7.0880\n",
      "Epoch [89050/100000], Loss: 7.0870\n",
      "Epoch [89060/100000], Loss: 7.0840\n",
      "Model saved at epoch 89062 with loss: 7.0818\n",
      "Model saved at epoch 89066 with loss: 7.0814\n",
      "Model saved at epoch 89068 with loss: 7.0809\n",
      "Model saved at epoch 89069 with loss: 7.0805\n",
      "Model saved at epoch 89070 with loss: 7.0800\n",
      "Epoch [89070/100000], Loss: 7.0800\n",
      "Model saved at epoch 89077 with loss: 7.0791\n",
      "Epoch [89080/100000], Loss: 7.0829\n",
      "Epoch [89090/100000], Loss: 7.0820\n",
      "Model saved at epoch 89094 with loss: 7.0787\n",
      "Epoch [89100/100000], Loss: 7.0849\n",
      "Epoch [89110/100000], Loss: 7.0814\n",
      "Epoch [89120/100000], Loss: 7.0837\n",
      "Epoch [89130/100000], Loss: 7.0810\n",
      "Epoch [89140/100000], Loss: 7.0807\n",
      "Model saved at epoch 89144 with loss: 7.0783\n",
      "Model saved at epoch 89145 with loss: 7.0777\n",
      "Model saved at epoch 89147 with loss: 7.0772\n",
      "Model saved at epoch 89149 with loss: 7.0761\n",
      "Epoch [89150/100000], Loss: 7.0769\n",
      "Model saved at epoch 89160 with loss: 7.0757\n",
      "Epoch [89160/100000], Loss: 7.0757\n",
      "Model saved at epoch 89161 with loss: 7.0747\n",
      "Epoch [89170/100000], Loss: 7.0803\n",
      "Epoch [89180/100000], Loss: 7.0802\n",
      "Epoch [89190/100000], Loss: 7.0779\n",
      "Epoch [89200/100000], Loss: 7.0830\n",
      "Epoch [89210/100000], Loss: 7.0827\n",
      "Epoch [89220/100000], Loss: 7.0798\n",
      "Epoch [89230/100000], Loss: 7.0779\n",
      "Epoch [89240/100000], Loss: 7.0815\n",
      "Epoch [89250/100000], Loss: 7.0824\n",
      "Epoch [89260/100000], Loss: 7.0755\n",
      "Epoch [89270/100000], Loss: 7.0769\n",
      "Epoch [89280/100000], Loss: 7.0771\n",
      "Epoch [89290/100000], Loss: 7.0817\n",
      "Epoch [89300/100000], Loss: 7.0793\n",
      "Epoch [89310/100000], Loss: 7.0790\n",
      "Epoch [89320/100000], Loss: 7.0789\n",
      "Model saved at epoch 89326 with loss: 7.0747\n",
      "Model saved at epoch 89327 with loss: 7.0741\n",
      "Epoch [89330/100000], Loss: 7.0751\n",
      "Epoch [89340/100000], Loss: 7.0799\n",
      "Model saved at epoch 89347 with loss: 7.0738\n",
      "Epoch [89350/100000], Loss: 7.0765\n",
      "Model saved at epoch 89357 with loss: 7.0734\n",
      "Model saved at epoch 89358 with loss: 7.0730\n",
      "Model saved at epoch 89359 with loss: 7.0724\n",
      "Epoch [89360/100000], Loss: 7.0742\n",
      "Epoch [89370/100000], Loss: 7.0725\n",
      "Epoch [89380/100000], Loss: 7.0758\n",
      "Model saved at epoch 89385 with loss: 7.0703\n",
      "Model saved at epoch 89386 with loss: 7.0690\n",
      "Model saved at epoch 89387 with loss: 7.0682\n",
      "Epoch [89390/100000], Loss: 7.0708\n",
      "Epoch [89400/100000], Loss: 7.0738\n",
      "Epoch [89410/100000], Loss: 7.0762\n",
      "Epoch [89420/100000], Loss: 7.0751\n",
      "Epoch [89430/100000], Loss: 7.0735\n",
      "Epoch [89440/100000], Loss: 7.0685\n",
      "Model saved at epoch 89447 with loss: 7.0681\n",
      "Epoch [89450/100000], Loss: 7.0690\n",
      "Epoch [89460/100000], Loss: 7.0749\n",
      "Epoch [89470/100000], Loss: 7.0708\n",
      "Epoch [89480/100000], Loss: 7.0714\n",
      "Epoch [89490/100000], Loss: 7.0707\n",
      "Model saved at epoch 89495 with loss: 7.0668\n",
      "Model saved at epoch 89497 with loss: 7.0667\n",
      "Epoch [89500/100000], Loss: 7.0691\n",
      "Model saved at epoch 89507 with loss: 7.0658\n",
      "Model saved at epoch 89508 with loss: 7.0648\n",
      "Epoch [89510/100000], Loss: 7.0658\n",
      "Epoch [89520/100000], Loss: 7.0669\n",
      "Epoch [89530/100000], Loss: 7.0699\n",
      "Epoch [89540/100000], Loss: 7.0697\n",
      "Model saved at epoch 89546 with loss: 7.0644\n",
      "Model saved at epoch 89547 with loss: 7.0627\n",
      "Epoch [89550/100000], Loss: 7.0664\n",
      "Epoch [89560/100000], Loss: 7.0700\n",
      "Epoch [89570/100000], Loss: 7.0685\n",
      "Epoch [89580/100000], Loss: 7.0680\n",
      "Epoch [89590/100000], Loss: 7.0681\n",
      "Epoch [89600/100000], Loss: 7.0684\n",
      "Epoch [89610/100000], Loss: 7.0679\n",
      "Epoch [89620/100000], Loss: 7.0692\n",
      "Epoch [89630/100000], Loss: 7.0686\n",
      "Epoch [89640/100000], Loss: 7.0682\n",
      "Epoch [89650/100000], Loss: 7.0654\n",
      "Epoch [89660/100000], Loss: 7.0652\n",
      "Epoch [89670/100000], Loss: 7.0629\n",
      "Epoch [89680/100000], Loss: 7.0641\n",
      "Epoch [89690/100000], Loss: 7.0658\n",
      "Model saved at epoch 89697 with loss: 7.0620\n",
      "Model saved at epoch 89698 with loss: 7.0618\n",
      "Epoch [89700/100000], Loss: 7.0631\n",
      "Model saved at epoch 89703 with loss: 7.0615\n",
      "Epoch [89710/100000], Loss: 7.0640\n",
      "Epoch [89720/100000], Loss: 7.0646\n",
      "Epoch [89730/100000], Loss: 7.0670\n",
      "Model saved at epoch 89733 with loss: 7.0615\n",
      "Epoch [89740/100000], Loss: 7.0636\n",
      "Model saved at epoch 89741 with loss: 7.0614\n",
      "Model saved at epoch 89742 with loss: 7.0600\n",
      "Model saved at epoch 89745 with loss: 7.0595\n",
      "Epoch [89750/100000], Loss: 7.0606\n",
      "Model saved at epoch 89757 with loss: 7.0589\n",
      "Epoch [89760/100000], Loss: 7.0594\n",
      "Epoch [89770/100000], Loss: 7.0607\n",
      "Epoch [89780/100000], Loss: 7.0627\n",
      "Epoch [89790/100000], Loss: 7.0653\n",
      "Epoch [89800/100000], Loss: 7.0617\n",
      "Epoch [89810/100000], Loss: 7.0608\n",
      "Epoch [89820/100000], Loss: 7.0605\n",
      "Epoch [89830/100000], Loss: 7.0615\n",
      "Model saved at epoch 89834 with loss: 7.0577\n",
      "Model saved at epoch 89840 with loss: 7.0576\n",
      "Epoch [89840/100000], Loss: 7.0576\n",
      "Model saved at epoch 89845 with loss: 7.0565\n",
      "Epoch [89850/100000], Loss: 7.0614\n",
      "Epoch [89860/100000], Loss: 7.0599\n",
      "Model saved at epoch 89868 with loss: 7.0558\n",
      "Epoch [89870/100000], Loss: 7.0574\n",
      "Model saved at epoch 89873 with loss: 7.0557\n",
      "Epoch [89880/100000], Loss: 7.0607\n",
      "Epoch [89890/100000], Loss: 7.0559\n",
      "Epoch [89900/100000], Loss: 7.0601\n",
      "Epoch [89910/100000], Loss: 7.0576\n",
      "Model saved at epoch 89912 with loss: 7.0539\n",
      "Epoch [89920/100000], Loss: 7.0562\n",
      "Model saved at epoch 89929 with loss: 7.0536\n",
      "Model saved at epoch 89930 with loss: 7.0530\n",
      "Epoch [89930/100000], Loss: 7.0530\n",
      "Epoch [89940/100000], Loss: 7.0536\n",
      "Model saved at epoch 89944 with loss: 7.0529\n",
      "Epoch [89950/100000], Loss: 7.0554\n",
      "Epoch [89960/100000], Loss: 7.0546\n",
      "Epoch [89970/100000], Loss: 23.4859\n",
      "Epoch [89980/100000], Loss: 8708765696.0000\n",
      "Epoch [89990/100000], Loss: 2576732928.0000\n",
      "Epoch [90000/100000], Loss: 277139104.0000\n",
      "Epoch [90010/100000], Loss: 41031516.0000\n",
      "Epoch [90020/100000], Loss: 97734976.0000\n",
      "Epoch [90030/100000], Loss: 24996756.0000\n",
      "Epoch [90040/100000], Loss: 536599.6250\n",
      "Epoch [90050/100000], Loss: 2840464.2500\n",
      "Epoch [90060/100000], Loss: 1639941.1250\n",
      "Epoch [90070/100000], Loss: 191125.7969\n",
      "Epoch [90080/100000], Loss: 20387.4023\n",
      "Epoch [90090/100000], Loss: 53768.8203\n",
      "Epoch [90100/100000], Loss: 23353.6875\n",
      "Epoch [90110/100000], Loss: 2932.3228\n",
      "Epoch [90120/100000], Loss: 337.6013\n",
      "Epoch [90130/100000], Loss: 704.6895\n",
      "Epoch [90140/100000], Loss: 380.0864\n",
      "Epoch [90150/100000], Loss: 90.8384\n",
      "Epoch [90160/100000], Loss: 13.0210\n",
      "Epoch [90170/100000], Loss: 9.2548\n",
      "Epoch [90180/100000], Loss: 10.9145\n",
      "Epoch [90190/100000], Loss: 8.3279\n",
      "Epoch [90200/100000], Loss: 7.5020\n",
      "Epoch [90210/100000], Loss: 7.2010\n",
      "Epoch [90220/100000], Loss: 7.1380\n",
      "Epoch [90230/100000], Loss: 7.1201\n",
      "Epoch [90240/100000], Loss: 7.1217\n",
      "Epoch [90250/100000], Loss: 7.1136\n",
      "Epoch [90260/100000], Loss: 7.1081\n",
      "Epoch [90270/100000], Loss: 7.1123\n",
      "Epoch [90280/100000], Loss: 7.1127\n",
      "Epoch [90290/100000], Loss: 7.1113\n",
      "Epoch [90300/100000], Loss: 7.1118\n",
      "Epoch [90310/100000], Loss: 7.1133\n",
      "Epoch [90320/100000], Loss: 7.1140\n",
      "Epoch [90330/100000], Loss: 7.1145\n",
      "Epoch [90340/100000], Loss: 7.1132\n",
      "Epoch [90350/100000], Loss: 7.1131\n",
      "Epoch [90360/100000], Loss: 7.1133\n",
      "Epoch [90370/100000], Loss: 7.1137\n",
      "Epoch [90380/100000], Loss: 7.1146\n",
      "Epoch [90390/100000], Loss: 7.1146\n",
      "Epoch [90400/100000], Loss: 7.1148\n",
      "Epoch [90410/100000], Loss: 7.1156\n",
      "Epoch [90420/100000], Loss: 7.1158\n",
      "Epoch [90430/100000], Loss: 7.1156\n",
      "Epoch [90440/100000], Loss: 7.1149\n",
      "Epoch [90450/100000], Loss: 7.1155\n",
      "Epoch [90460/100000], Loss: 7.1148\n",
      "Epoch [90470/100000], Loss: 7.1150\n",
      "Epoch [90480/100000], Loss: 7.1152\n",
      "Epoch [90490/100000], Loss: 7.1147\n",
      "Epoch [90500/100000], Loss: 7.1141\n",
      "Epoch [90510/100000], Loss: 7.1145\n",
      "Epoch [90520/100000], Loss: 7.1142\n",
      "Epoch [90530/100000], Loss: 7.1136\n",
      "Epoch [90540/100000], Loss: 7.1132\n",
      "Epoch [90550/100000], Loss: 7.1134\n",
      "Epoch [90560/100000], Loss: 7.1128\n",
      "Epoch [90570/100000], Loss: 7.1129\n",
      "Epoch [90580/100000], Loss: 7.1118\n",
      "Epoch [90590/100000], Loss: 7.1109\n",
      "Epoch [90600/100000], Loss: 7.1104\n",
      "Epoch [90610/100000], Loss: 7.1116\n",
      "Epoch [90620/100000], Loss: 7.1111\n",
      "Epoch [90630/100000], Loss: 7.1109\n",
      "Epoch [90640/100000], Loss: 7.1109\n",
      "Epoch [90650/100000], Loss: 7.1096\n",
      "Epoch [90660/100000], Loss: 7.1095\n",
      "Epoch [90670/100000], Loss: 7.1099\n",
      "Epoch [90680/100000], Loss: 7.1111\n",
      "Epoch [90690/100000], Loss: 7.1112\n",
      "Epoch [90700/100000], Loss: 7.1113\n",
      "Epoch [90710/100000], Loss: 7.1114\n",
      "Epoch [90720/100000], Loss: 7.1104\n",
      "Epoch [90730/100000], Loss: 7.1099\n",
      "Epoch [90740/100000], Loss: 7.1099\n",
      "Epoch [90750/100000], Loss: 7.1116\n",
      "Epoch [90760/100000], Loss: 7.1112\n",
      "Epoch [90770/100000], Loss: 7.1106\n",
      "Epoch [90780/100000], Loss: 7.1096\n",
      "Epoch [90790/100000], Loss: 7.1089\n",
      "Epoch [90800/100000], Loss: 7.1094\n",
      "Epoch [90810/100000], Loss: 7.1089\n",
      "Epoch [90820/100000], Loss: 7.1100\n",
      "Epoch [90830/100000], Loss: 7.1098\n",
      "Epoch [90840/100000], Loss: 7.1098\n",
      "Epoch [90850/100000], Loss: 7.1106\n",
      "Epoch [90860/100000], Loss: 7.1102\n",
      "Epoch [90870/100000], Loss: 7.1112\n",
      "Epoch [90880/100000], Loss: 7.1100\n",
      "Epoch [90890/100000], Loss: 7.1105\n",
      "Epoch [90900/100000], Loss: 7.1096\n",
      "Epoch [90910/100000], Loss: 7.1096\n",
      "Epoch [90920/100000], Loss: 7.1110\n",
      "Epoch [90930/100000], Loss: 7.1095\n",
      "Epoch [90940/100000], Loss: 7.1089\n",
      "Epoch [90950/100000], Loss: 7.1097\n",
      "Epoch [90960/100000], Loss: 7.1097\n",
      "Epoch [90970/100000], Loss: 7.1106\n",
      "Epoch [90980/100000], Loss: 7.1114\n",
      "Epoch [90990/100000], Loss: 7.1113\n",
      "Epoch [91000/100000], Loss: 7.1120\n",
      "Epoch [91010/100000], Loss: 7.1116\n",
      "Epoch [91020/100000], Loss: 7.1113\n",
      "Epoch [91030/100000], Loss: 7.1126\n",
      "Epoch [91040/100000], Loss: 7.1125\n",
      "Epoch [91050/100000], Loss: 7.1126\n",
      "Epoch [91060/100000], Loss: 7.1128\n",
      "Epoch [91070/100000], Loss: 7.1130\n",
      "Epoch [91080/100000], Loss: 7.1143\n",
      "Epoch [91090/100000], Loss: 7.1144\n",
      "Epoch [91100/100000], Loss: 7.1166\n",
      "Epoch [91110/100000], Loss: 7.1145\n",
      "Epoch [91120/100000], Loss: 7.1140\n",
      "Epoch [91130/100000], Loss: 7.1135\n",
      "Epoch [91140/100000], Loss: 7.1119\n",
      "Epoch [91150/100000], Loss: 7.1118\n",
      "Epoch [91160/100000], Loss: 7.1107\n",
      "Epoch [91170/100000], Loss: 7.1119\n",
      "Epoch [91180/100000], Loss: 7.1126\n",
      "Epoch [91190/100000], Loss: 7.1126\n",
      "Epoch [91200/100000], Loss: 7.1124\n",
      "Epoch [91210/100000], Loss: 7.1114\n",
      "Epoch [91220/100000], Loss: 7.1117\n",
      "Epoch [91230/100000], Loss: 7.1124\n",
      "Epoch [91240/100000], Loss: 7.1124\n",
      "Epoch [91250/100000], Loss: 7.1123\n",
      "Epoch [91260/100000], Loss: 7.1109\n",
      "Epoch [91270/100000], Loss: 7.1110\n",
      "Epoch [91280/100000], Loss: 7.1111\n",
      "Epoch [91290/100000], Loss: 7.1098\n",
      "Epoch [91300/100000], Loss: 7.1095\n",
      "Epoch [91310/100000], Loss: 7.1082\n",
      "Epoch [91320/100000], Loss: 7.1074\n",
      "Epoch [91330/100000], Loss: 7.1082\n",
      "Epoch [91340/100000], Loss: 7.1086\n",
      "Epoch [91350/100000], Loss: 7.1081\n",
      "Epoch [91360/100000], Loss: 7.1093\n",
      "Epoch [91370/100000], Loss: 7.1089\n",
      "Epoch [91380/100000], Loss: 7.1068\n",
      "Epoch [91390/100000], Loss: 7.1062\n",
      "Epoch [91400/100000], Loss: 7.1065\n",
      "Epoch [91410/100000], Loss: 7.1070\n",
      "Epoch [91420/100000], Loss: 7.1078\n",
      "Epoch [91430/100000], Loss: 7.1092\n",
      "Epoch [91440/100000], Loss: 7.1090\n",
      "Epoch [91450/100000], Loss: 7.1083\n",
      "Epoch [91460/100000], Loss: 7.1072\n",
      "Epoch [91470/100000], Loss: 7.1081\n",
      "Epoch [91480/100000], Loss: 7.1073\n",
      "Epoch [91490/100000], Loss: 7.1085\n",
      "Epoch [91500/100000], Loss: 7.1076\n",
      "Epoch [91510/100000], Loss: 7.1081\n",
      "Epoch [91520/100000], Loss: 7.1089\n",
      "Epoch [91530/100000], Loss: 7.1090\n",
      "Epoch [91540/100000], Loss: 7.1087\n",
      "Epoch [91550/100000], Loss: 7.1084\n",
      "Epoch [91560/100000], Loss: 7.1075\n",
      "Epoch [91570/100000], Loss: 7.1075\n",
      "Epoch [91580/100000], Loss: 7.1089\n",
      "Epoch [91590/100000], Loss: 7.1091\n",
      "Epoch [91600/100000], Loss: 7.1077\n",
      "Epoch [91610/100000], Loss: 7.1084\n",
      "Epoch [91620/100000], Loss: 7.1101\n",
      "Epoch [91630/100000], Loss: 7.1081\n",
      "Epoch [91640/100000], Loss: 7.1070\n",
      "Epoch [91650/100000], Loss: 7.1064\n",
      "Epoch [91660/100000], Loss: 7.1069\n",
      "Epoch [91670/100000], Loss: 7.1068\n",
      "Epoch [91680/100000], Loss: 7.1059\n",
      "Epoch [91690/100000], Loss: 7.1063\n",
      "Epoch [91700/100000], Loss: 7.1083\n",
      "Epoch [91710/100000], Loss: 7.1072\n",
      "Epoch [91720/100000], Loss: 7.1073\n",
      "Epoch [91730/100000], Loss: 7.1054\n",
      "Epoch [91740/100000], Loss: 7.1037\n",
      "Epoch [91750/100000], Loss: 7.1023\n",
      "Epoch [91760/100000], Loss: 7.1021\n",
      "Epoch [91770/100000], Loss: 7.1019\n",
      "Epoch [91780/100000], Loss: 7.1022\n",
      "Epoch [91790/100000], Loss: 7.1026\n",
      "Epoch [91800/100000], Loss: 7.1038\n",
      "Epoch [91810/100000], Loss: 7.1033\n",
      "Epoch [91820/100000], Loss: 7.1040\n",
      "Epoch [91830/100000], Loss: 7.1055\n",
      "Epoch [91840/100000], Loss: 7.1074\n",
      "Epoch [91850/100000], Loss: 7.1096\n",
      "Epoch [91860/100000], Loss: 7.1097\n",
      "Epoch [91870/100000], Loss: 7.1097\n",
      "Epoch [91880/100000], Loss: 7.1095\n",
      "Epoch [91890/100000], Loss: 7.1093\n",
      "Epoch [91900/100000], Loss: 7.1107\n",
      "Epoch [91910/100000], Loss: 7.1117\n",
      "Epoch [91920/100000], Loss: 7.1119\n",
      "Epoch [91930/100000], Loss: 7.1109\n",
      "Epoch [91940/100000], Loss: 7.1095\n",
      "Epoch [91950/100000], Loss: 7.1090\n",
      "Epoch [91960/100000], Loss: 7.1087\n",
      "Epoch [91970/100000], Loss: 7.1095\n",
      "Epoch [91980/100000], Loss: 7.1072\n",
      "Epoch [91990/100000], Loss: 7.1085\n",
      "Epoch [92000/100000], Loss: 7.1083\n",
      "Epoch [92010/100000], Loss: 7.1083\n",
      "Epoch [92020/100000], Loss: 7.1089\n",
      "Epoch [92030/100000], Loss: 7.1095\n",
      "Epoch [92040/100000], Loss: 7.1081\n",
      "Epoch [92050/100000], Loss: 7.1089\n",
      "Epoch [92060/100000], Loss: 7.1087\n",
      "Epoch [92070/100000], Loss: 7.1101\n",
      "Epoch [92080/100000], Loss: 7.1090\n",
      "Epoch [92090/100000], Loss: 7.1095\n",
      "Epoch [92100/100000], Loss: 7.1096\n",
      "Epoch [92110/100000], Loss: 7.1092\n",
      "Epoch [92120/100000], Loss: 7.1089\n",
      "Epoch [92130/100000], Loss: 7.1110\n",
      "Epoch [92140/100000], Loss: 7.1121\n",
      "Epoch [92150/100000], Loss: 7.1129\n",
      "Epoch [92160/100000], Loss: 7.1142\n",
      "Epoch [92170/100000], Loss: 7.1129\n",
      "Epoch [92180/100000], Loss: 7.1122\n",
      "Epoch [92190/100000], Loss: 7.1109\n",
      "Epoch [92200/100000], Loss: 7.1104\n",
      "Epoch [92210/100000], Loss: 7.1115\n",
      "Epoch [92220/100000], Loss: 7.1104\n",
      "Epoch [92230/100000], Loss: 7.1081\n",
      "Epoch [92240/100000], Loss: 7.1071\n",
      "Epoch [92250/100000], Loss: 7.1086\n",
      "Epoch [92260/100000], Loss: 7.1076\n",
      "Epoch [92270/100000], Loss: 7.1065\n",
      "Epoch [92280/100000], Loss: 7.1061\n",
      "Epoch [92290/100000], Loss: 7.1050\n",
      "Epoch [92300/100000], Loss: 7.1046\n",
      "Epoch [92310/100000], Loss: 7.1039\n",
      "Epoch [92320/100000], Loss: 7.1041\n",
      "Epoch [92330/100000], Loss: 7.1042\n",
      "Epoch [92340/100000], Loss: 7.1045\n",
      "Epoch [92350/100000], Loss: 7.1050\n",
      "Epoch [92360/100000], Loss: 7.1039\n",
      "Epoch [92370/100000], Loss: 7.1016\n",
      "Epoch [92380/100000], Loss: 7.1033\n",
      "Epoch [92390/100000], Loss: 7.1036\n",
      "Epoch [92400/100000], Loss: 7.1038\n",
      "Epoch [92410/100000], Loss: 7.1035\n",
      "Epoch [92420/100000], Loss: 7.1027\n",
      "Epoch [92430/100000], Loss: 7.1031\n",
      "Epoch [92440/100000], Loss: 7.1016\n",
      "Epoch [92450/100000], Loss: 7.1011\n",
      "Epoch [92460/100000], Loss: 7.1003\n",
      "Epoch [92470/100000], Loss: 7.1005\n",
      "Epoch [92480/100000], Loss: 7.1004\n",
      "Epoch [92490/100000], Loss: 7.1023\n",
      "Epoch [92500/100000], Loss: 7.1030\n",
      "Epoch [92510/100000], Loss: 7.1020\n",
      "Epoch [92520/100000], Loss: 7.1014\n",
      "Epoch [92530/100000], Loss: 7.1006\n",
      "Epoch [92540/100000], Loss: 7.0983\n",
      "Epoch [92550/100000], Loss: 7.0998\n",
      "Epoch [92560/100000], Loss: 7.0990\n",
      "Epoch [92570/100000], Loss: 7.1001\n",
      "Epoch [92580/100000], Loss: 7.1006\n",
      "Epoch [92590/100000], Loss: 7.0985\n",
      "Epoch [92600/100000], Loss: 7.0989\n",
      "Epoch [92610/100000], Loss: 7.1002\n",
      "Epoch [92620/100000], Loss: 7.0994\n",
      "Epoch [92630/100000], Loss: 7.0984\n",
      "Epoch [92640/100000], Loss: 7.0987\n",
      "Epoch [92650/100000], Loss: 7.0948\n",
      "Epoch [92660/100000], Loss: 7.0953\n",
      "Epoch [92670/100000], Loss: 7.0964\n",
      "Epoch [92680/100000], Loss: 7.0962\n",
      "Epoch [92690/100000], Loss: 7.0989\n",
      "Epoch [92700/100000], Loss: 7.1003\n",
      "Epoch [92710/100000], Loss: 7.0984\n",
      "Epoch [92720/100000], Loss: 7.0977\n",
      "Epoch [92730/100000], Loss: 7.0986\n",
      "Epoch [92740/100000], Loss: 7.0987\n",
      "Epoch [92750/100000], Loss: 7.0988\n",
      "Epoch [92760/100000], Loss: 7.0979\n",
      "Epoch [92770/100000], Loss: 7.0972\n",
      "Epoch [92780/100000], Loss: 7.0956\n",
      "Epoch [92790/100000], Loss: 7.0931\n",
      "Epoch [92800/100000], Loss: 7.0932\n",
      "Epoch [92810/100000], Loss: 7.0925\n",
      "Epoch [92820/100000], Loss: 7.0921\n",
      "Epoch [92830/100000], Loss: 7.0929\n",
      "Epoch [92840/100000], Loss: 7.0935\n",
      "Epoch [92850/100000], Loss: 7.0976\n",
      "Epoch [92860/100000], Loss: 7.0967\n",
      "Epoch [92870/100000], Loss: 7.0981\n",
      "Epoch [92880/100000], Loss: 7.0983\n",
      "Epoch [92890/100000], Loss: 7.0975\n",
      "Epoch [92900/100000], Loss: 7.0995\n",
      "Epoch [92910/100000], Loss: 7.1011\n",
      "Epoch [92920/100000], Loss: 7.1037\n",
      "Epoch [92930/100000], Loss: 7.1010\n",
      "Epoch [92940/100000], Loss: 7.1004\n",
      "Epoch [92950/100000], Loss: 7.0979\n",
      "Epoch [92960/100000], Loss: 7.0974\n",
      "Epoch [92970/100000], Loss: 7.0989\n",
      "Epoch [92980/100000], Loss: 7.0989\n",
      "Epoch [92990/100000], Loss: 7.1001\n",
      "Epoch [93000/100000], Loss: 7.0975\n",
      "Epoch [93010/100000], Loss: 7.0974\n",
      "Epoch [93020/100000], Loss: 7.0950\n",
      "Epoch [93030/100000], Loss: 7.0956\n",
      "Epoch [93040/100000], Loss: 7.0945\n",
      "Epoch [93050/100000], Loss: 7.0939\n",
      "Epoch [93060/100000], Loss: 7.0950\n",
      "Epoch [93070/100000], Loss: 7.0947\n",
      "Epoch [93080/100000], Loss: 7.0950\n",
      "Epoch [93090/100000], Loss: 7.0944\n",
      "Epoch [93100/100000], Loss: 7.0939\n",
      "Epoch [93110/100000], Loss: 7.0927\n",
      "Epoch [93120/100000], Loss: 7.0936\n",
      "Epoch [93130/100000], Loss: 7.0937\n",
      "Epoch [93140/100000], Loss: 7.0932\n",
      "Epoch [93150/100000], Loss: 7.0925\n",
      "Epoch [93160/100000], Loss: 7.0913\n",
      "Epoch [93170/100000], Loss: 7.0918\n",
      "Epoch [93180/100000], Loss: 7.0893\n",
      "Epoch [93190/100000], Loss: 7.0877\n",
      "Epoch [93200/100000], Loss: 7.0862\n",
      "Epoch [93210/100000], Loss: 7.0855\n",
      "Epoch [93220/100000], Loss: 7.0866\n",
      "Epoch [93230/100000], Loss: 7.0879\n",
      "Epoch [93240/100000], Loss: 7.0901\n",
      "Epoch [93250/100000], Loss: 7.0913\n",
      "Epoch [93260/100000], Loss: 7.0899\n",
      "Epoch [93270/100000], Loss: 7.0925\n",
      "Epoch [93280/100000], Loss: 7.0934\n",
      "Epoch [93290/100000], Loss: 7.0946\n",
      "Epoch [93300/100000], Loss: 7.0955\n",
      "Epoch [93310/100000], Loss: 7.0966\n",
      "Epoch [93320/100000], Loss: 7.0994\n",
      "Epoch [93330/100000], Loss: 7.0958\n",
      "Epoch [93340/100000], Loss: 7.0952\n",
      "Epoch [93350/100000], Loss: 7.0944\n",
      "Epoch [93360/100000], Loss: 7.0951\n",
      "Epoch [93370/100000], Loss: 7.0927\n",
      "Epoch [93380/100000], Loss: 7.0915\n",
      "Epoch [93390/100000], Loss: 7.0911\n",
      "Epoch [93400/100000], Loss: 7.0913\n",
      "Epoch [93410/100000], Loss: 7.0897\n",
      "Epoch [93420/100000], Loss: 7.0905\n",
      "Epoch [93430/100000], Loss: 7.0896\n",
      "Epoch [93440/100000], Loss: 7.0901\n",
      "Epoch [93450/100000], Loss: 7.0890\n",
      "Epoch [93460/100000], Loss: 7.0914\n",
      "Epoch [93470/100000], Loss: 7.0923\n",
      "Epoch [93480/100000], Loss: 7.0902\n",
      "Epoch [93490/100000], Loss: 7.0908\n",
      "Epoch [93500/100000], Loss: 7.0914\n",
      "Epoch [93510/100000], Loss: 7.0925\n",
      "Epoch [93520/100000], Loss: 7.0914\n",
      "Epoch [93530/100000], Loss: 7.0917\n",
      "Epoch [93540/100000], Loss: 7.0932\n",
      "Epoch [93550/100000], Loss: 7.0924\n",
      "Epoch [93560/100000], Loss: 7.0921\n",
      "Epoch [93570/100000], Loss: 7.0914\n",
      "Epoch [93580/100000], Loss: 7.0939\n",
      "Epoch [93590/100000], Loss: 7.0937\n",
      "Epoch [93600/100000], Loss: 7.0941\n",
      "Epoch [93610/100000], Loss: 7.0936\n",
      "Epoch [93620/100000], Loss: 7.0931\n",
      "Epoch [93630/100000], Loss: 7.0927\n",
      "Epoch [93640/100000], Loss: 7.0912\n",
      "Epoch [93650/100000], Loss: 7.0904\n",
      "Epoch [93660/100000], Loss: 7.0892\n",
      "Epoch [93670/100000], Loss: 7.0923\n",
      "Epoch [93680/100000], Loss: 7.0918\n",
      "Epoch [93690/100000], Loss: 7.0906\n",
      "Epoch [93700/100000], Loss: 7.0912\n",
      "Epoch [93710/100000], Loss: 7.0906\n",
      "Epoch [93720/100000], Loss: 7.0910\n",
      "Epoch [93730/100000], Loss: 7.0905\n",
      "Epoch [93740/100000], Loss: 7.0919\n",
      "Epoch [93750/100000], Loss: 7.0922\n",
      "Epoch [93760/100000], Loss: 7.0914\n",
      "Epoch [93770/100000], Loss: 7.0916\n",
      "Epoch [93780/100000], Loss: 7.0920\n",
      "Epoch [93790/100000], Loss: 7.0916\n",
      "Epoch [93800/100000], Loss: 7.0900\n",
      "Epoch [93810/100000], Loss: 7.0862\n",
      "Epoch [93820/100000], Loss: 7.0861\n",
      "Epoch [93830/100000], Loss: 7.0859\n",
      "Epoch [93840/100000], Loss: 7.0858\n",
      "Epoch [93850/100000], Loss: 7.0845\n",
      "Epoch [93860/100000], Loss: 7.0866\n",
      "Epoch [93870/100000], Loss: 7.0839\n",
      "Epoch [93880/100000], Loss: 7.0853\n",
      "Epoch [93890/100000], Loss: 7.0844\n",
      "Epoch [93900/100000], Loss: 7.0841\n",
      "Epoch [93910/100000], Loss: 7.0823\n",
      "Epoch [93920/100000], Loss: 7.0820\n",
      "Epoch [93930/100000], Loss: 7.0826\n",
      "Epoch [93940/100000], Loss: 7.0822\n",
      "Epoch [93950/100000], Loss: 7.0815\n",
      "Epoch [93960/100000], Loss: 7.0812\n",
      "Epoch [93970/100000], Loss: 7.0825\n",
      "Epoch [93980/100000], Loss: 7.0838\n",
      "Epoch [93990/100000], Loss: 7.0854\n",
      "Epoch [94000/100000], Loss: 7.0854\n",
      "Epoch [94010/100000], Loss: 7.0828\n",
      "Epoch [94020/100000], Loss: 7.0832\n",
      "Epoch [94030/100000], Loss: 7.0861\n",
      "Epoch [94040/100000], Loss: 7.0876\n",
      "Epoch [94050/100000], Loss: 7.0853\n",
      "Epoch [94060/100000], Loss: 7.0874\n",
      "Epoch [94070/100000], Loss: 7.0893\n",
      "Epoch [94080/100000], Loss: 7.0898\n",
      "Epoch [94090/100000], Loss: 7.0899\n",
      "Epoch [94100/100000], Loss: 7.0904\n",
      "Epoch [94110/100000], Loss: 7.0919\n",
      "Epoch [94120/100000], Loss: 7.0881\n",
      "Epoch [94130/100000], Loss: 7.0891\n",
      "Epoch [94140/100000], Loss: 7.0848\n",
      "Epoch [94150/100000], Loss: 7.0854\n",
      "Epoch [94160/100000], Loss: 7.0862\n",
      "Epoch [94170/100000], Loss: 7.0876\n",
      "Epoch [94180/100000], Loss: 7.0851\n",
      "Epoch [94190/100000], Loss: 7.0860\n",
      "Epoch [94200/100000], Loss: 7.0817\n",
      "Epoch [94210/100000], Loss: 7.0819\n",
      "Epoch [94220/100000], Loss: 7.0828\n",
      "Epoch [94230/100000], Loss: 7.0858\n",
      "Epoch [94240/100000], Loss: 7.0874\n",
      "Epoch [94250/100000], Loss: 7.0837\n",
      "Epoch [94260/100000], Loss: 7.0838\n",
      "Epoch [94270/100000], Loss: 7.0866\n",
      "Epoch [94280/100000], Loss: 7.0856\n",
      "Epoch [94290/100000], Loss: 7.0842\n",
      "Epoch [94300/100000], Loss: 7.0859\n",
      "Epoch [94310/100000], Loss: 7.0848\n",
      "Epoch [94320/100000], Loss: 7.0833\n",
      "Epoch [94330/100000], Loss: 7.0848\n",
      "Epoch [94340/100000], Loss: 7.0861\n",
      "Epoch [94350/100000], Loss: 7.0851\n",
      "Epoch [94360/100000], Loss: 7.0855\n",
      "Epoch [94370/100000], Loss: 7.0860\n",
      "Epoch [94380/100000], Loss: 7.0835\n",
      "Epoch [94390/100000], Loss: 7.0840\n",
      "Epoch [94400/100000], Loss: 7.0859\n",
      "Epoch [94410/100000], Loss: 7.0857\n",
      "Epoch [94420/100000], Loss: 7.0843\n",
      "Epoch [94430/100000], Loss: 7.0832\n",
      "Epoch [94440/100000], Loss: 7.0839\n",
      "Epoch [94450/100000], Loss: 7.0817\n",
      "Epoch [94460/100000], Loss: 7.0815\n",
      "Epoch [94470/100000], Loss: 7.0802\n",
      "Epoch [94480/100000], Loss: 7.0817\n",
      "Epoch [94490/100000], Loss: 7.0806\n",
      "Epoch [94500/100000], Loss: 7.0817\n",
      "Epoch [94510/100000], Loss: 7.0846\n",
      "Epoch [94520/100000], Loss: 7.0846\n",
      "Epoch [94530/100000], Loss: 7.0794\n",
      "Epoch [94540/100000], Loss: 7.0807\n",
      "Epoch [94550/100000], Loss: 7.0829\n",
      "Epoch [94560/100000], Loss: 7.0807\n",
      "Epoch [94570/100000], Loss: 7.0815\n",
      "Epoch [94580/100000], Loss: 7.0808\n",
      "Epoch [94590/100000], Loss: 7.0816\n",
      "Epoch [94600/100000], Loss: 7.0840\n",
      "Epoch [94610/100000], Loss: 7.0829\n",
      "Epoch [94620/100000], Loss: 7.0809\n",
      "Epoch [94630/100000], Loss: 7.0803\n",
      "Epoch [94640/100000], Loss: 7.0796\n",
      "Epoch [94650/100000], Loss: 7.0750\n",
      "Epoch [94660/100000], Loss: 7.0777\n",
      "Epoch [94670/100000], Loss: 7.0777\n",
      "Epoch [94680/100000], Loss: 7.0761\n",
      "Epoch [94690/100000], Loss: 7.0756\n",
      "Epoch [94700/100000], Loss: 7.0755\n",
      "Epoch [94710/100000], Loss: 7.0753\n",
      "Epoch [94720/100000], Loss: 7.0755\n",
      "Epoch [94730/100000], Loss: 7.0759\n",
      "Epoch [94740/100000], Loss: 7.0751\n",
      "Epoch [94750/100000], Loss: 7.0773\n",
      "Epoch [94760/100000], Loss: 7.0800\n",
      "Epoch [94770/100000], Loss: 7.0772\n",
      "Epoch [94780/100000], Loss: 7.0745\n",
      "Epoch [94790/100000], Loss: 7.0738\n",
      "Epoch [94800/100000], Loss: 7.0737\n",
      "Epoch [94810/100000], Loss: 7.0778\n",
      "Epoch [94820/100000], Loss: 7.0757\n",
      "Epoch [94830/100000], Loss: 7.0797\n",
      "Epoch [94840/100000], Loss: 7.0819\n",
      "Epoch [94850/100000], Loss: 7.0824\n",
      "Epoch [94860/100000], Loss: 7.0818\n",
      "Epoch [94870/100000], Loss: 7.0828\n",
      "Epoch [94880/100000], Loss: 7.0805\n",
      "Epoch [94890/100000], Loss: 7.0790\n",
      "Epoch [94900/100000], Loss: 7.0773\n",
      "Epoch [94910/100000], Loss: 7.0804\n",
      "Epoch [94920/100000], Loss: 7.0767\n",
      "Epoch [94930/100000], Loss: 7.0757\n",
      "Epoch [94940/100000], Loss: 7.0759\n",
      "Epoch [94950/100000], Loss: 7.0778\n",
      "Epoch [94960/100000], Loss: 7.0773\n",
      "Epoch [94970/100000], Loss: 7.0751\n",
      "Epoch [94980/100000], Loss: 7.0783\n",
      "Epoch [94990/100000], Loss: 7.0780\n",
      "Epoch [95000/100000], Loss: 7.0778\n",
      "Epoch [95010/100000], Loss: 7.0747\n",
      "Epoch [95020/100000], Loss: 7.0753\n",
      "Epoch [95030/100000], Loss: 7.0737\n",
      "Epoch [95040/100000], Loss: 7.0764\n",
      "Epoch [95050/100000], Loss: 7.0768\n",
      "Epoch [95060/100000], Loss: 7.0754\n",
      "Epoch [95070/100000], Loss: 7.0732\n",
      "Epoch [95080/100000], Loss: 7.0732\n",
      "Epoch [95090/100000], Loss: 7.0711\n",
      "Epoch [95100/100000], Loss: 7.0683\n",
      "Epoch [95110/100000], Loss: 7.0688\n",
      "Epoch [95120/100000], Loss: 7.0693\n",
      "Epoch [95130/100000], Loss: 7.0750\n",
      "Epoch [95140/100000], Loss: 7.0724\n",
      "Epoch [95150/100000], Loss: 7.0725\n",
      "Epoch [95160/100000], Loss: 7.0711\n",
      "Epoch [95170/100000], Loss: 7.0695\n",
      "Epoch [95180/100000], Loss: 7.0703\n",
      "Epoch [95190/100000], Loss: 7.0685\n",
      "Epoch [95200/100000], Loss: 7.0725\n",
      "Epoch [95210/100000], Loss: 7.0702\n",
      "Epoch [95220/100000], Loss: 7.0725\n",
      "Epoch [95230/100000], Loss: 7.0678\n",
      "Epoch [95240/100000], Loss: 7.0704\n",
      "Epoch [95250/100000], Loss: 7.0713\n",
      "Epoch [95260/100000], Loss: 7.0712\n",
      "Epoch [95270/100000], Loss: 7.0698\n",
      "Epoch [95280/100000], Loss: 7.0713\n",
      "Epoch [95290/100000], Loss: 7.0714\n",
      "Epoch [95300/100000], Loss: 7.0712\n",
      "Epoch [95310/100000], Loss: 7.0703\n",
      "Epoch [95320/100000], Loss: 7.0725\n",
      "Epoch [95330/100000], Loss: 7.0733\n",
      "Epoch [95340/100000], Loss: 7.0742\n",
      "Epoch [95350/100000], Loss: 7.0738\n",
      "Epoch [95360/100000], Loss: 7.0707\n",
      "Epoch [95370/100000], Loss: 7.0723\n",
      "Epoch [95380/100000], Loss: 7.0711\n",
      "Epoch [95390/100000], Loss: 7.0683\n",
      "Epoch [95400/100000], Loss: 7.0641\n",
      "Epoch [95410/100000], Loss: 7.0664\n",
      "Epoch [95420/100000], Loss: 7.0672\n",
      "Epoch [95430/100000], Loss: 7.0667\n",
      "Epoch [95440/100000], Loss: 7.0675\n",
      "Epoch [95450/100000], Loss: 7.0675\n",
      "Epoch [95460/100000], Loss: 7.0673\n",
      "Epoch [95470/100000], Loss: 7.0650\n",
      "Epoch [95480/100000], Loss: 7.0657\n",
      "Epoch [95490/100000], Loss: 7.0627\n",
      "Epoch [95500/100000], Loss: 7.0662\n",
      "Epoch [95510/100000], Loss: 7.0640\n",
      "Epoch [95520/100000], Loss: 7.0640\n",
      "Epoch [95530/100000], Loss: 7.0634\n",
      "Epoch [95540/100000], Loss: 7.0644\n",
      "Epoch [95550/100000], Loss: 7.0644\n",
      "Epoch [95560/100000], Loss: 7.0624\n",
      "Epoch [95570/100000], Loss: 7.0627\n",
      "Epoch [95580/100000], Loss: 7.0622\n",
      "Epoch [95590/100000], Loss: 7.0637\n",
      "Epoch [95600/100000], Loss: 7.0647\n",
      "Epoch [95610/100000], Loss: 7.0664\n",
      "Epoch [95620/100000], Loss: 7.0645\n",
      "Epoch [95630/100000], Loss: 7.0641\n",
      "Epoch [95640/100000], Loss: 7.0638\n",
      "Epoch [95650/100000], Loss: 7.0635\n",
      "Epoch [95660/100000], Loss: 7.0615\n",
      "Epoch [95670/100000], Loss: 7.0596\n",
      "Epoch [95680/100000], Loss: 7.0625\n",
      "Epoch [95690/100000], Loss: 7.0619\n",
      "Epoch [95700/100000], Loss: 7.0630\n",
      "Epoch [95710/100000], Loss: 7.0627\n",
      "Epoch [95720/100000], Loss: 7.0638\n",
      "Epoch [95730/100000], Loss: 7.0602\n",
      "Epoch [95740/100000], Loss: 7.0618\n",
      "Epoch [95750/100000], Loss: 7.0619\n",
      "Epoch [95760/100000], Loss: 7.0605\n",
      "Epoch [95770/100000], Loss: 7.0592\n",
      "Epoch [95780/100000], Loss: 7.0610\n",
      "Epoch [95790/100000], Loss: 7.0619\n",
      "Epoch [95800/100000], Loss: 7.0626\n",
      "Epoch [95810/100000], Loss: 7.0603\n",
      "Epoch [95820/100000], Loss: 7.0612\n",
      "Epoch [95830/100000], Loss: 7.0607\n",
      "Epoch [95840/100000], Loss: 7.0575\n",
      "Epoch [95850/100000], Loss: 1020017344.0000\n",
      "Epoch [95860/100000], Loss: 177160720.0000\n",
      "Epoch [95870/100000], Loss: 863605760.0000\n",
      "Epoch [95880/100000], Loss: 316647936.0000\n",
      "Epoch [95890/100000], Loss: 50437796.0000\n",
      "Epoch [95900/100000], Loss: 8219081.0000\n",
      "Epoch [95910/100000], Loss: 6387410.5000\n",
      "Epoch [95920/100000], Loss: 5179192.5000\n",
      "Epoch [95930/100000], Loss: 1351988.7500\n",
      "Epoch [95940/100000], Loss: 45310.4180\n",
      "Epoch [95950/100000], Loss: 100940.9219\n",
      "Epoch [95960/100000], Loss: 72596.3047\n",
      "Epoch [95970/100000], Loss: 16846.5039\n",
      "Epoch [95980/100000], Loss: 1699.8551\n",
      "Epoch [95990/100000], Loss: 1811.5668\n",
      "Epoch [96000/100000], Loss: 1200.5747\n",
      "Epoch [96010/100000], Loss: 97.5699\n",
      "Epoch [96020/100000], Loss: 66.2711\n",
      "Epoch [96030/100000], Loss: 62.1430\n",
      "Epoch [96040/100000], Loss: 11.0922\n",
      "Epoch [96050/100000], Loss: 10.3700\n",
      "Epoch [96060/100000], Loss: 7.8265\n",
      "Epoch [96070/100000], Loss: 7.1864\n",
      "Epoch [96080/100000], Loss: 7.1114\n",
      "Model saved at epoch 96090 with loss: 7.0523\n",
      "Epoch [96090/100000], Loss: 7.0523\n",
      "Epoch [96100/100000], Loss: 7.0693\n",
      "Epoch [96110/100000], Loss: 7.0551\n",
      "Model saved at epoch 96120 with loss: 7.0518\n",
      "Epoch [96120/100000], Loss: 7.0518\n",
      "Epoch [96130/100000], Loss: 7.0618\n",
      "Epoch [96140/100000], Loss: 7.0572\n",
      "Epoch [96150/100000], Loss: 7.0537\n",
      "Epoch [96160/100000], Loss: 7.0548\n",
      "Epoch [96170/100000], Loss: 7.0548\n",
      "Epoch [96180/100000], Loss: 7.0530\n",
      "Epoch [96190/100000], Loss: 7.0535\n",
      "Epoch [96200/100000], Loss: 7.0545\n",
      "Epoch [96210/100000], Loss: 7.0521\n",
      "Model saved at epoch 96212 with loss: 7.0514\n",
      "Epoch [96220/100000], Loss: 7.0532\n",
      "Epoch [96230/100000], Loss: 7.0540\n",
      "Epoch [96240/100000], Loss: 7.0524\n",
      "Model saved at epoch 96242 with loss: 7.0511\n",
      "Model saved at epoch 96243 with loss: 7.0504\n",
      "Epoch [96250/100000], Loss: 7.0516\n",
      "Model saved at epoch 96251 with loss: 7.0504\n",
      "Model saved at epoch 96252 with loss: 7.0497\n",
      "Epoch [96260/100000], Loss: 7.0501\n",
      "Epoch [96270/100000], Loss: 7.0510\n",
      "Epoch [96280/100000], Loss: 7.0524\n",
      "Epoch [96290/100000], Loss: 7.0524\n",
      "Epoch [96300/100000], Loss: 7.0547\n",
      "Epoch [96310/100000], Loss: 7.0529\n",
      "Epoch [96320/100000], Loss: 7.0526\n",
      "Epoch [96330/100000], Loss: 7.0513\n",
      "Epoch [96340/100000], Loss: 7.0509\n",
      "Epoch [96350/100000], Loss: 7.0510\n",
      "Epoch [96360/100000], Loss: 7.0515\n",
      "Epoch [96370/100000], Loss: 7.0523\n",
      "Epoch [96380/100000], Loss: 7.0529\n",
      "Epoch [96390/100000], Loss: 7.0523\n",
      "Model saved at epoch 96396 with loss: 7.0489\n",
      "Epoch [96400/100000], Loss: 7.0510\n",
      "Epoch [96410/100000], Loss: 7.0523\n",
      "Epoch [96420/100000], Loss: 7.0546\n",
      "Epoch [96430/100000], Loss: 7.0524\n",
      "Epoch [96440/100000], Loss: 7.0519\n",
      "Epoch [96450/100000], Loss: 7.0512\n",
      "Epoch [96460/100000], Loss: 7.0522\n",
      "Epoch [96470/100000], Loss: 7.0515\n",
      "Epoch [96480/100000], Loss: 7.0509\n",
      "Epoch [96490/100000], Loss: 7.0490\n",
      "Model saved at epoch 96494 with loss: 7.0489\n",
      "Model saved at epoch 96495 with loss: 7.0485\n",
      "Model saved at epoch 96496 with loss: 7.0477\n",
      "Epoch [96500/100000], Loss: 7.0484\n",
      "Epoch [96510/100000], Loss: 7.0488\n",
      "Epoch [96520/100000], Loss: 7.0501\n",
      "Epoch [96530/100000], Loss: 7.0482\n",
      "Model saved at epoch 96536 with loss: 7.0472\n",
      "Epoch [96540/100000], Loss: 7.0486\n",
      "Epoch [96550/100000], Loss: 7.0497\n",
      "Epoch [96560/100000], Loss: 7.0486\n",
      "Model saved at epoch 96568 with loss: 7.0472\n",
      "Epoch [96570/100000], Loss: 7.0480\n",
      "Epoch [96580/100000], Loss: 7.0488\n",
      "Epoch [96590/100000], Loss: 7.0489\n",
      "Model saved at epoch 96594 with loss: 7.0467\n",
      "Model saved at epoch 96595 with loss: 7.0458\n",
      "Epoch [96600/100000], Loss: 7.0477\n",
      "Epoch [96610/100000], Loss: 7.0480\n",
      "Epoch [96620/100000], Loss: 7.0472\n",
      "Epoch [96630/100000], Loss: 7.0479\n",
      "Model saved at epoch 96637 with loss: 7.0454\n",
      "Model saved at epoch 96639 with loss: 7.0453\n",
      "Epoch [96640/100000], Loss: 7.0454\n",
      "Model saved at epoch 96641 with loss: 7.0451\n",
      "Epoch [96650/100000], Loss: 7.0461\n",
      "Model saved at epoch 96656 with loss: 7.0451\n",
      "Epoch [96660/100000], Loss: 7.0459\n",
      "Epoch [96670/100000], Loss: 7.0496\n",
      "Epoch [96680/100000], Loss: 7.0495\n",
      "Epoch [96690/100000], Loss: 7.0485\n",
      "Epoch [96700/100000], Loss: 7.0488\n",
      "Epoch [96710/100000], Loss: 7.0489\n",
      "Epoch [96720/100000], Loss: 7.0480\n",
      "Epoch [96730/100000], Loss: 7.0468\n",
      "Epoch [96740/100000], Loss: 7.0472\n",
      "Epoch [96750/100000], Loss: 7.0468\n",
      "Epoch [96760/100000], Loss: 7.0479\n",
      "Epoch [96770/100000], Loss: 7.0457\n",
      "Model saved at epoch 96771 with loss: 7.0451\n",
      "Model saved at epoch 96772 with loss: 7.0449\n",
      "Model saved at epoch 96773 with loss: 7.0443\n",
      "Epoch [96780/100000], Loss: 7.0461\n",
      "Model saved at epoch 96790 with loss: 7.0433\n",
      "Epoch [96790/100000], Loss: 7.0433\n",
      "Model saved at epoch 96793 with loss: 7.0430\n",
      "Model saved at epoch 96794 with loss: 7.0422\n",
      "Model saved at epoch 96795 with loss: 7.0421\n",
      "Model saved at epoch 96796 with loss: 7.0418\n",
      "Model saved at epoch 96798 with loss: 7.0416\n",
      "Epoch [96800/100000], Loss: 7.0429\n",
      "Epoch [96810/100000], Loss: 7.0446\n",
      "Epoch [96820/100000], Loss: 7.0439\n",
      "Epoch [96830/100000], Loss: 7.0429\n",
      "Model saved at epoch 96839 with loss: 7.0415\n",
      "Model saved at epoch 96840 with loss: 7.0413\n",
      "Epoch [96840/100000], Loss: 7.0413\n",
      "Model saved at epoch 96843 with loss: 7.0411\n",
      "Model saved at epoch 96844 with loss: 7.0401\n",
      "Epoch [96850/100000], Loss: 7.0415\n",
      "Epoch [96860/100000], Loss: 7.0422\n",
      "Epoch [96870/100000], Loss: 7.0423\n",
      "Epoch [96880/100000], Loss: 7.0403\n",
      "Model saved at epoch 96888 with loss: 7.0400\n",
      "Model saved at epoch 96889 with loss: 7.0396\n",
      "Epoch [96890/100000], Loss: 7.0406\n",
      "Epoch [96900/100000], Loss: 7.0409\n",
      "Epoch [96910/100000], Loss: 7.0404\n",
      "Model saved at epoch 96911 with loss: 7.0394\n",
      "Model saved at epoch 96912 with loss: 7.0392\n",
      "Model saved at epoch 96914 with loss: 7.0391\n",
      "Model saved at epoch 96916 with loss: 7.0391\n",
      "Epoch [96920/100000], Loss: 7.0401\n",
      "Model saved at epoch 96930 with loss: 7.0387\n",
      "Epoch [96930/100000], Loss: 7.0387\n",
      "Epoch [96940/100000], Loss: 7.0402\n",
      "Model saved at epoch 96945 with loss: 7.0387\n",
      "Model saved at epoch 96947 with loss: 7.0384\n",
      "Model saved at epoch 96948 with loss: 7.0382\n",
      "Epoch [96950/100000], Loss: 7.0386\n",
      "Epoch [96960/100000], Loss: 7.0395\n",
      "Model saved at epoch 96969 with loss: 7.0380\n",
      "Epoch [96970/100000], Loss: 7.0384\n",
      "Epoch [96980/100000], Loss: 7.0410\n",
      "Epoch [96990/100000], Loss: 7.0421\n",
      "Epoch [97000/100000], Loss: 7.0415\n",
      "Epoch [97010/100000], Loss: 7.0435\n",
      "Epoch [97020/100000], Loss: 7.0418\n",
      "Epoch [97030/100000], Loss: 7.0406\n",
      "Epoch [97040/100000], Loss: 7.0392\n",
      "Epoch [97050/100000], Loss: 7.0394\n",
      "Epoch [97060/100000], Loss: 7.0411\n",
      "Epoch [97070/100000], Loss: 7.0395\n",
      "Epoch [97080/100000], Loss: 7.0385\n",
      "Model saved at epoch 97083 with loss: 7.0372\n",
      "Epoch [97090/100000], Loss: 7.0381\n",
      "Epoch [97100/100000], Loss: 7.0389\n",
      "Epoch [97110/100000], Loss: 7.0388\n",
      "Epoch [97120/100000], Loss: 7.0388\n",
      "Model saved at epoch 97126 with loss: 7.0367\n",
      "Epoch [97130/100000], Loss: 7.0374\n",
      "Epoch [97140/100000], Loss: 7.0373\n",
      "Model saved at epoch 97143 with loss: 7.0361\n",
      "Model saved at epoch 97146 with loss: 7.0357\n",
      "Model saved at epoch 97148 with loss: 7.0351\n",
      "Epoch [97150/100000], Loss: 7.0359\n",
      "Epoch [97160/100000], Loss: 7.0362\n",
      "Epoch [97170/100000], Loss: 7.0389\n",
      "Epoch [97180/100000], Loss: 7.0396\n",
      "Epoch [97190/100000], Loss: 7.0394\n",
      "Epoch [97200/100000], Loss: 7.0393\n",
      "Epoch [97210/100000], Loss: 7.0411\n",
      "Epoch [97220/100000], Loss: 7.0402\n",
      "Epoch [97230/100000], Loss: 7.0404\n",
      "Epoch [97240/100000], Loss: 7.0404\n",
      "Epoch [97250/100000], Loss: 7.0381\n",
      "Epoch [97260/100000], Loss: 7.0378\n",
      "Epoch [97270/100000], Loss: 7.0377\n",
      "Epoch [97280/100000], Loss: 7.0386\n",
      "Epoch [97290/100000], Loss: 7.0389\n",
      "Epoch [97300/100000], Loss: 7.0385\n",
      "Epoch [97310/100000], Loss: 7.0385\n",
      "Epoch [97320/100000], Loss: 7.0375\n",
      "Epoch [97330/100000], Loss: 7.0351\n",
      "Model saved at epoch 97336 with loss: 7.0349\n",
      "Model saved at epoch 97338 with loss: 7.0348\n",
      "Model saved at epoch 97339 with loss: 7.0347\n",
      "Model saved at epoch 97340 with loss: 7.0339\n",
      "Epoch [97340/100000], Loss: 7.0339\n",
      "Model saved at epoch 97343 with loss: 7.0336\n",
      "Model saved at epoch 97344 with loss: 7.0333\n",
      "Model saved at epoch 97345 with loss: 7.0332\n",
      "Model saved at epoch 97348 with loss: 7.0328\n",
      "Model saved at epoch 97349 with loss: 7.0326\n",
      "Model saved at epoch 97350 with loss: 7.0326\n",
      "Epoch [97350/100000], Loss: 7.0326\n",
      "Epoch [97360/100000], Loss: 7.0331\n",
      "Model saved at epoch 97364 with loss: 7.0323\n",
      "Model saved at epoch 97365 with loss: 7.0321\n",
      "Epoch [97370/100000], Loss: 7.0329\n",
      "Model saved at epoch 97372 with loss: 7.0319\n",
      "Model saved at epoch 97373 with loss: 7.0316\n",
      "Model saved at epoch 97375 with loss: 7.0314\n",
      "Epoch [97380/100000], Loss: 7.0325\n",
      "Model saved at epoch 97387 with loss: 7.0311\n",
      "Model saved at epoch 97388 with loss: 7.0311\n",
      "Model saved at epoch 97389 with loss: 7.0310\n",
      "Epoch [97390/100000], Loss: 7.0310\n",
      "Model saved at epoch 97391 with loss: 7.0301\n",
      "Model saved at epoch 97392 with loss: 7.0298\n",
      "Model saved at epoch 97393 with loss: 7.0294\n",
      "Epoch [97400/100000], Loss: 7.0309\n",
      "Epoch [97410/100000], Loss: 7.0330\n",
      "Epoch [97420/100000], Loss: 7.0326\n",
      "Epoch [97430/100000], Loss: 7.0320\n",
      "Epoch [97440/100000], Loss: 7.0314\n",
      "Epoch [97450/100000], Loss: 7.0328\n",
      "Epoch [97460/100000], Loss: 7.0334\n",
      "Epoch [97470/100000], Loss: 7.0316\n",
      "Epoch [97480/100000], Loss: 7.0311\n",
      "Epoch [97490/100000], Loss: 7.0323\n",
      "Epoch [97500/100000], Loss: 7.0315\n",
      "Epoch [97510/100000], Loss: 7.0328\n",
      "Epoch [97520/100000], Loss: 7.0317\n",
      "Epoch [97530/100000], Loss: 7.0310\n",
      "Epoch [97540/100000], Loss: 7.0329\n",
      "Epoch [97550/100000], Loss: 7.0322\n",
      "Epoch [97560/100000], Loss: 7.0334\n",
      "Epoch [97570/100000], Loss: 7.0333\n",
      "Epoch [97580/100000], Loss: 7.0323\n",
      "Epoch [97590/100000], Loss: 7.0315\n",
      "Epoch [97600/100000], Loss: 7.0308\n",
      "Epoch [97610/100000], Loss: 7.0314\n",
      "Epoch [97620/100000], Loss: 7.0305\n",
      "Epoch [97630/100000], Loss: 7.0302\n",
      "Model saved at epoch 97637 with loss: 7.0289\n",
      "Model saved at epoch 97639 with loss: 7.0283\n",
      "Model saved at epoch 97640 with loss: 7.0281\n",
      "Epoch [97640/100000], Loss: 7.0281\n",
      "Model saved at epoch 97644 with loss: 7.0280\n",
      "Model saved at epoch 97645 with loss: 7.0277\n",
      "Model saved at epoch 97647 with loss: 7.0274\n",
      "Epoch [97650/100000], Loss: 7.0285\n",
      "Epoch [97660/100000], Loss: 7.0280\n",
      "Epoch [97670/100000], Loss: 7.0284\n",
      "Epoch [97680/100000], Loss: 7.0289\n",
      "Epoch [97690/100000], Loss: 7.0293\n",
      "Epoch [97700/100000], Loss: 7.0306\n",
      "Epoch [97710/100000], Loss: 7.0311\n",
      "Epoch [97720/100000], Loss: 7.0316\n",
      "Epoch [97730/100000], Loss: 7.0308\n",
      "Epoch [97740/100000], Loss: 7.0306\n",
      "Epoch [97750/100000], Loss: 7.0303\n",
      "Epoch [97760/100000], Loss: 7.0287\n",
      "Epoch [97770/100000], Loss: 7.0279\n",
      "Epoch [97780/100000], Loss: 7.0285\n",
      "Epoch [97790/100000], Loss: 7.0292\n",
      "Epoch [97800/100000], Loss: 7.0284\n",
      "Epoch [97810/100000], Loss: 7.0289\n",
      "Model saved at epoch 97816 with loss: 7.0273\n",
      "Model saved at epoch 97818 with loss: 7.0268\n",
      "Model saved at epoch 97819 with loss: 7.0263\n",
      "Model saved at epoch 97820 with loss: 7.0260\n",
      "Epoch [97820/100000], Loss: 7.0260\n",
      "Epoch [97830/100000], Loss: 7.0277\n",
      "Epoch [97840/100000], Loss: 7.0279\n",
      "Epoch [97850/100000], Loss: 7.0298\n",
      "Epoch [97860/100000], Loss: 7.0288\n",
      "Epoch [97870/100000], Loss: 7.0279\n",
      "Epoch [97880/100000], Loss: 7.0282\n",
      "Epoch [97890/100000], Loss: 7.0295\n",
      "Epoch [97900/100000], Loss: 7.0281\n",
      "Epoch [97910/100000], Loss: 7.0269\n",
      "Model saved at epoch 97912 with loss: 7.0258\n",
      "Model saved at epoch 97913 with loss: 7.0255\n",
      "Epoch [97920/100000], Loss: 7.0269\n",
      "Epoch [97930/100000], Loss: 7.0269\n",
      "Model saved at epoch 97938 with loss: 7.0246\n",
      "Model saved at epoch 97939 with loss: 7.0245\n",
      "Epoch [97940/100000], Loss: 7.0246\n",
      "Model saved at epoch 97945 with loss: 7.0241\n",
      "Model saved at epoch 97947 with loss: 7.0239\n",
      "Model saved at epoch 97948 with loss: 7.0239\n",
      "Epoch [97950/100000], Loss: 7.0241\n",
      "Model saved at epoch 97959 with loss: 7.0237\n",
      "Model saved at epoch 97960 with loss: 7.0236\n",
      "Epoch [97960/100000], Loss: 7.0236\n",
      "Epoch [97970/100000], Loss: 7.0259\n",
      "Epoch [97980/100000], Loss: 7.0248\n",
      "Model saved at epoch 97988 with loss: 7.0236\n",
      "Model saved at epoch 97990 with loss: 7.0236\n",
      "Epoch [97990/100000], Loss: 7.0236\n",
      "Model saved at epoch 97991 with loss: 7.0232\n",
      "Model saved at epoch 97992 with loss: 7.0226\n",
      "Epoch [98000/100000], Loss: 7.0242\n",
      "Epoch [98010/100000], Loss: 7.0238\n",
      "Epoch [98020/100000], Loss: 7.0244\n",
      "Epoch [98030/100000], Loss: 7.0232\n",
      "Epoch [98040/100000], Loss: 7.0241\n",
      "Epoch [98050/100000], Loss: 7.0251\n",
      "Epoch [98060/100000], Loss: 7.0262\n",
      "Epoch [98070/100000], Loss: 7.0276\n",
      "Epoch [98080/100000], Loss: 7.0283\n",
      "Epoch [98090/100000], Loss: 7.0273\n",
      "Epoch [98100/100000], Loss: 7.0266\n",
      "Epoch [98110/100000], Loss: 7.0268\n",
      "Epoch [98120/100000], Loss: 7.0272\n",
      "Epoch [98130/100000], Loss: 7.0257\n",
      "Epoch [98140/100000], Loss: 7.0266\n",
      "Epoch [98150/100000], Loss: 7.0270\n",
      "Epoch [98160/100000], Loss: 7.0256\n",
      "Epoch [98170/100000], Loss: 7.0239\n",
      "Epoch [98180/100000], Loss: 7.0249\n",
      "Epoch [98190/100000], Loss: 7.0250\n",
      "Epoch [98200/100000], Loss: 7.0247\n",
      "Epoch [98210/100000], Loss: 7.0235\n",
      "Epoch [98220/100000], Loss: 7.0240\n",
      "Epoch [98230/100000], Loss: 7.0233\n",
      "Model saved at epoch 98236 with loss: 7.0223\n",
      "Model saved at epoch 98237 with loss: 7.0221\n",
      "Model saved at epoch 98238 with loss: 7.0213\n",
      "Model saved at epoch 98239 with loss: 7.0207\n",
      "Epoch [98240/100000], Loss: 7.0209\n",
      "Model saved at epoch 98241 with loss: 7.0203\n",
      "Model saved at epoch 98242 with loss: 7.0196\n",
      "Epoch [98250/100000], Loss: 7.0200\n",
      "Model saved at epoch 98251 with loss: 7.0195\n",
      "Model saved at epoch 98252 with loss: 7.0186\n",
      "Epoch [98260/100000], Loss: 7.0187\n",
      "Epoch [98270/100000], Loss: 7.0199\n",
      "Epoch [98280/100000], Loss: 7.0208\n",
      "Epoch [98290/100000], Loss: 7.0215\n",
      "Epoch [98300/100000], Loss: 7.0206\n",
      "Epoch [98310/100000], Loss: 7.0208\n",
      "Epoch [98320/100000], Loss: 7.0214\n",
      "Epoch [98330/100000], Loss: 7.0243\n",
      "Epoch [98340/100000], Loss: 7.0250\n",
      "Epoch [98350/100000], Loss: 7.0233\n",
      "Epoch [98360/100000], Loss: 7.0254\n",
      "Epoch [98370/100000], Loss: 7.0256\n",
      "Epoch [98380/100000], Loss: 7.0262\n",
      "Epoch [98390/100000], Loss: 7.0254\n",
      "Epoch [98400/100000], Loss: 7.0251\n",
      "Epoch [98410/100000], Loss: 7.0228\n",
      "Epoch [98420/100000], Loss: 7.0221\n",
      "Epoch [98430/100000], Loss: 7.0203\n",
      "Epoch [98440/100000], Loss: 7.0207\n",
      "Epoch [98450/100000], Loss: 7.0196\n",
      "Model saved at epoch 98454 with loss: 7.0182\n",
      "Epoch [98460/100000], Loss: 7.0198\n",
      "Epoch [98470/100000], Loss: 7.0246\n",
      "Epoch [98480/100000], Loss: 7.0236\n",
      "Epoch [98490/100000], Loss: 7.0225\n",
      "Epoch [98500/100000], Loss: 7.0220\n",
      "Epoch [98510/100000], Loss: 7.0240\n",
      "Epoch [98520/100000], Loss: 7.0220\n",
      "Epoch [98530/100000], Loss: 7.0213\n",
      "Epoch [98540/100000], Loss: 7.0222\n",
      "Epoch [98550/100000], Loss: 7.0215\n",
      "Epoch [98560/100000], Loss: 7.0194\n",
      "Model saved at epoch 98568 with loss: 7.0181\n",
      "Epoch [98570/100000], Loss: 7.0190\n",
      "Epoch [98580/100000], Loss: 7.0204\n",
      "Model saved at epoch 98585 with loss: 7.0176\n",
      "Model saved at epoch 98586 with loss: 7.0175\n",
      "Model saved at epoch 98587 with loss: 7.0171\n",
      "Model saved at epoch 98588 with loss: 7.0170\n",
      "Model saved at epoch 98590 with loss: 7.0165\n",
      "Epoch [98590/100000], Loss: 7.0165\n",
      "Epoch [98600/100000], Loss: 7.0181\n",
      "Epoch [98610/100000], Loss: 7.0177\n",
      "Model saved at epoch 98615 with loss: 7.0162\n",
      "Model saved at epoch 98616 with loss: 7.0156\n",
      "Model saved at epoch 98617 with loss: 7.0152\n",
      "Epoch [98620/100000], Loss: 7.0161\n",
      "Model saved at epoch 98629 with loss: 7.0151\n",
      "Epoch [98630/100000], Loss: 7.0157\n",
      "Epoch [98640/100000], Loss: 7.0169\n",
      "Epoch [98650/100000], Loss: 7.0162\n",
      "Epoch [98660/100000], Loss: 7.0164\n",
      "Epoch [98670/100000], Loss: 7.0159\n",
      "Epoch [98680/100000], Loss: 7.0163\n",
      "Model saved at epoch 98684 with loss: 7.0146\n",
      "Model saved at epoch 98687 with loss: 7.0143\n",
      "Epoch [98690/100000], Loss: 7.0146\n",
      "Model saved at epoch 98693 with loss: 7.0137\n",
      "Model saved at epoch 98694 with loss: 7.0136\n",
      "Epoch [98700/100000], Loss: 7.0152\n",
      "Model saved at epoch 98709 with loss: 7.0133\n",
      "Model saved at epoch 98710 with loss: 7.0132\n",
      "Epoch [98710/100000], Loss: 7.0132\n",
      "Model saved at epoch 98716 with loss: 7.0131\n",
      "Model saved at epoch 98717 with loss: 7.0124\n",
      "Model saved at epoch 98718 with loss: 7.0122\n",
      "Model saved at epoch 98719 with loss: 7.0118\n",
      "Epoch [98720/100000], Loss: 7.0119\n",
      "Epoch [98730/100000], Loss: 7.0131\n",
      "Model saved at epoch 98734 with loss: 7.0110\n",
      "Epoch [98740/100000], Loss: 7.0128\n",
      "Epoch [98750/100000], Loss: 7.0145\n",
      "Epoch [98760/100000], Loss: 7.0153\n",
      "Epoch [98770/100000], Loss: 7.0155\n",
      "Epoch [98780/100000], Loss: 7.0136\n",
      "Epoch [98790/100000], Loss: 7.0151\n",
      "Epoch [98800/100000], Loss: 7.0126\n",
      "Epoch [98810/100000], Loss: 7.0146\n",
      "Epoch [98820/100000], Loss: 7.0144\n",
      "Epoch [98830/100000], Loss: 7.0157\n",
      "Epoch [98840/100000], Loss: 7.0132\n",
      "Epoch [98850/100000], Loss: 7.0129\n",
      "Model saved at epoch 98856 with loss: 7.0105\n",
      "Epoch [98860/100000], Loss: 7.0122\n",
      "Epoch [98870/100000], Loss: 7.0162\n",
      "Epoch [98880/100000], Loss: 7.0140\n",
      "Epoch [98890/100000], Loss: 7.0146\n",
      "Epoch [98900/100000], Loss: 7.0113\n",
      "Model saved at epoch 98901 with loss: 7.0105\n",
      "Model saved at epoch 98902 with loss: 7.0103\n",
      "Model saved at epoch 98903 with loss: 7.0098\n",
      "Model saved at epoch 98904 with loss: 7.0093\n",
      "Model saved at epoch 98905 with loss: 7.0081\n",
      "Epoch [98910/100000], Loss: 7.0118\n",
      "Epoch [98920/100000], Loss: 7.0156\n",
      "Epoch [98930/100000], Loss: 7.0121\n",
      "Epoch [98940/100000], Loss: 7.0109\n",
      "Epoch [98950/100000], Loss: 7.0117\n",
      "Epoch [98960/100000], Loss: 7.0129\n",
      "Epoch [98970/100000], Loss: 7.0176\n",
      "Epoch [98980/100000], Loss: 7.0154\n",
      "Epoch [98990/100000], Loss: 7.0147\n",
      "Epoch [99000/100000], Loss: 7.0126\n",
      "Epoch [99010/100000], Loss: 7.0097\n",
      "Epoch [99020/100000], Loss: 7.0126\n",
      "Epoch [99030/100000], Loss: 7.0132\n",
      "Epoch [99040/100000], Loss: 7.0122\n",
      "Epoch [99050/100000], Loss: 7.0142\n",
      "Epoch [99060/100000], Loss: 7.0127\n",
      "Epoch [99070/100000], Loss: 7.0142\n",
      "Epoch [99080/100000], Loss: 7.0130\n",
      "Epoch [99090/100000], Loss: 7.0121\n",
      "Epoch [99100/100000], Loss: 7.0136\n",
      "Epoch [99110/100000], Loss: 7.0110\n",
      "Epoch [99120/100000], Loss: 7.0122\n",
      "Epoch [99130/100000], Loss: 7.0140\n",
      "Epoch [99140/100000], Loss: 7.0151\n",
      "Epoch [99150/100000], Loss: 7.0124\n",
      "Epoch [99160/100000], Loss: 7.0128\n",
      "Epoch [99170/100000], Loss: 7.0120\n",
      "Epoch [99180/100000], Loss: 7.0137\n",
      "Epoch [99190/100000], Loss: 7.0142\n",
      "Epoch [99200/100000], Loss: 7.0126\n",
      "Epoch [99210/100000], Loss: 7.0117\n",
      "Epoch [99220/100000], Loss: 7.0107\n",
      "Epoch [99230/100000], Loss: 7.0111\n",
      "Epoch [99240/100000], Loss: 7.0108\n",
      "Epoch [99250/100000], Loss: 7.0113\n",
      "Epoch [99260/100000], Loss: 7.0100\n",
      "Epoch [99270/100000], Loss: 7.0107\n",
      "Model saved at epoch 99273 with loss: 7.0080\n",
      "Model saved at epoch 99274 with loss: 7.0078\n",
      "Model saved at epoch 99275 with loss: 7.0073\n",
      "Model saved at epoch 99276 with loss: 7.0066\n",
      "Model saved at epoch 99277 with loss: 7.0065\n",
      "Epoch [99280/100000], Loss: 7.0080\n",
      "Epoch [99290/100000], Loss: 7.0090\n",
      "Epoch [99300/100000], Loss: 7.0099\n",
      "Epoch [99310/100000], Loss: 7.0085\n",
      "Epoch [99320/100000], Loss: 7.0091\n",
      "Epoch [99330/100000], Loss: 7.0090\n",
      "Epoch [99340/100000], Loss: 7.0108\n",
      "Epoch [99350/100000], Loss: 7.0078\n",
      "Model saved at epoch 99359 with loss: 7.0059\n",
      "Model saved at epoch 99360 with loss: 7.0055\n",
      "Epoch [99360/100000], Loss: 7.0055\n",
      "Model saved at epoch 99361 with loss: 7.0055\n",
      "Epoch [99370/100000], Loss: 7.0079\n",
      "Epoch [99380/100000], Loss: 7.0086\n",
      "Epoch [99390/100000], Loss: 7.0101\n",
      "Epoch [99400/100000], Loss: 7.0105\n",
      "Epoch [99410/100000], Loss: 7.0077\n",
      "Epoch [99420/100000], Loss: 7.0072\n",
      "Epoch [99430/100000], Loss: 7.0067\n",
      "Epoch [99440/100000], Loss: 7.0078\n",
      "Model saved at epoch 99444 with loss: 7.0055\n",
      "Model saved at epoch 99445 with loss: 7.0053\n",
      "Epoch [99450/100000], Loss: 7.0070\n",
      "Epoch [99460/100000], Loss: 7.0063\n",
      "Epoch [99470/100000], Loss: 7.0080\n",
      "Model saved at epoch 99475 with loss: 7.0051\n",
      "Epoch [99480/100000], Loss: 7.0054\n",
      "Model saved at epoch 99481 with loss: 7.0041\n",
      "Epoch [99490/100000], Loss: 7.0049\n",
      "Model saved at epoch 99494 with loss: 7.0038\n",
      "Model saved at epoch 99495 with loss: 7.0038\n",
      "Model saved at epoch 99496 with loss: 7.0030\n",
      "Epoch [99500/100000], Loss: 7.0049\n",
      "Epoch [99510/100000], Loss: 7.0057\n",
      "Epoch [99520/100000], Loss: 7.0045\n",
      "Epoch [99530/100000], Loss: 7.0057\n",
      "Model saved at epoch 99533 with loss: 7.0027\n",
      "Model saved at epoch 99536 with loss: 7.0025\n",
      "Model saved at epoch 99537 with loss: 7.0020\n",
      "Model saved at epoch 99539 with loss: 7.0017\n",
      "Epoch [99540/100000], Loss: 7.0028\n",
      "Epoch [99550/100000], Loss: 7.0062\n",
      "Epoch [99560/100000], Loss: 7.0021\n",
      "Model saved at epoch 99564 with loss: 7.0011\n",
      "Epoch [99570/100000], Loss: 7.0032\n",
      "Epoch [99580/100000], Loss: 7.0028\n",
      "Epoch [99590/100000], Loss: 7.0027\n",
      "Model saved at epoch 99594 with loss: 7.0005\n",
      "Model saved at epoch 99600 with loss: 6.9999\n",
      "Epoch [99600/100000], Loss: 6.9999\n",
      "Model saved at epoch 99601 with loss: 6.9996\n",
      "Model saved at epoch 99602 with loss: 6.9990\n",
      "Epoch [99610/100000], Loss: 7.0020\n",
      "Epoch [99620/100000], Loss: 7.0013\n",
      "Epoch [99630/100000], Loss: 7.0036\n",
      "Epoch [99640/100000], Loss: 7.0043\n",
      "Epoch [99650/100000], Loss: 7.0060\n",
      "Epoch [99660/100000], Loss: 7.0006\n",
      "Epoch [99670/100000], Loss: 7.0041\n",
      "Epoch [99680/100000], Loss: 7.0013\n",
      "Epoch [99690/100000], Loss: 7.0008\n",
      "Model saved at epoch 99693 with loss: 6.9985\n",
      "Epoch [99700/100000], Loss: 6.9995\n",
      "Model saved at epoch 99703 with loss: 6.9984\n",
      "Model saved at epoch 99704 with loss: 6.9974\n",
      "Epoch [99710/100000], Loss: 6.9986\n",
      "Epoch [99720/100000], Loss: 6.9997\n",
      "Epoch [99730/100000], Loss: 6.9982\n",
      "Model saved at epoch 99735 with loss: 6.9969\n",
      "Epoch [99740/100000], Loss: 6.9976\n",
      "Model saved at epoch 99742 with loss: 6.9969\n",
      "Epoch [99750/100000], Loss: 6.9980\n",
      "Epoch [99760/100000], Loss: 6.9995\n",
      "Epoch [99770/100000], Loss: 6.9991\n",
      "Epoch [99780/100000], Loss: 7.0010\n",
      "Epoch [99790/100000], Loss: 7.0003\n",
      "Epoch [99800/100000], Loss: 6.9973\n",
      "Epoch [99810/100000], Loss: 6.9987\n",
      "Epoch [99820/100000], Loss: 7.0003\n",
      "Epoch [99830/100000], Loss: 7.0020\n",
      "Epoch [99840/100000], Loss: 7.0024\n",
      "Epoch [99850/100000], Loss: 7.0030\n",
      "Epoch [99860/100000], Loss: 7.0013\n",
      "Epoch [99870/100000], Loss: 6.9998\n",
      "Epoch [99880/100000], Loss: 6.9977\n",
      "Model saved at epoch 99883 with loss: 6.9969\n",
      "Model saved at epoch 99884 with loss: 6.9968\n",
      "Epoch [99890/100000], Loss: 6.9970\n",
      "Epoch [99900/100000], Loss: 6.9990\n",
      "Epoch [99910/100000], Loss: 7.0005\n",
      "Epoch [99920/100000], Loss: 6.9995\n",
      "Model saved at epoch 99926 with loss: 6.9964\n",
      "Model saved at epoch 99927 with loss: 6.9957\n",
      "Model saved at epoch 99930 with loss: 6.9953\n",
      "Epoch [99930/100000], Loss: 6.9953\n",
      "Model saved at epoch 99931 with loss: 6.9943\n",
      "Model saved at epoch 99932 with loss: 6.9938\n",
      "Model saved at epoch 99933 with loss: 6.9936\n",
      "Epoch [99940/100000], Loss: 6.9969\n",
      "Epoch [99950/100000], Loss: 6.9983\n",
      "Epoch [99960/100000], Loss: 6.9974\n",
      "Epoch [99970/100000], Loss: 7.0003\n",
      "Epoch [99980/100000], Loss: 7.0008\n",
      "Epoch [99990/100000], Loss: 6.9991\n",
      "Epoch [100000/100000], Loss: 7.0006\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    predictions = model(inputs)  # Predictions are now on GPU\n",
    "    loss = criterion(predictions, outputs)  # Loss is computed on GPU\n",
    "    loss.backward()  # Backpropagation on GPU\n",
    "    optimizer.step()\n",
    "\n",
    "    current_loss = loss.item()\n",
    "    losses.append(current_loss)\n",
    "    \n",
    "    # Outlier detection: filter out any loss value above a certain threshold\n",
    "    if current_loss <= loss_threshold:\n",
    "        filtered_losses.append(current_loss)\n",
    "\n",
    "    else:\n",
    "        # print(predictions.shape, outputs.shape)\n",
    "        pass\n",
    "\n",
    "    # Save the model if loss is below the threshold and is the minimum observed\n",
    "    if current_loss < loss_threshold and current_loss < min_loss:\n",
    "        min_loss = current_loss\n",
    "        torch.save(model.state_dict(), 'best_model_below_threshold.pth')\n",
    "        print(f'Model saved at epoch {epoch + 1} with loss: {current_loss:.4f}')\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {current_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a97273a-9f96-431b-9b41-71c4c5e24bf4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "282de585-128e-44af-9f81-648f05d7c04f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(filtered_losses, label='Training Loss (filtered)')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Filtered Loss Curve')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6822d0b3-4150-4a10-9302-672ac688a118",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
